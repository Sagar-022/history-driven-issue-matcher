repo_name,contributor_id,issue_id,issue_title,issue_body,issue_comments,issue_state,issue_created_at,issue_closed_at,opened_by,issue_labels,linked_pr_count,modified_source_files,commit_messages
tensorflow/tensorflow,dimvar,24456,Replace deprecated FastGFile with GFile,"
FastGFile has been deprecated and replaced with GFile, though
the example in speech_commands still uses FastGFile. This fix
fix the issue to remove the deprecated warning:
```
WARNING:tensorflow:From <stdin>:1: __init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.gfile.GFile.
```

Signed-off-by: Yong Tang <yong.tang.github@outlook.com>",Nagging Reviewer @yifeif: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.,closed,2018-12-19T23:46:01+00:00,2019-01-08T21:47:40+00:00,yongtang,"cla: yes, ready to pull, size:XS",1,"PR#90394 - third_party/gpus/cuda/hermetic/cuda_redist_versions.bzl: @@ -244,6 +244,7 @@ REDIST_VERSIONS_TO_BUILD_TEMPLATES = {|;|     ""cuda_cudart"": {|;|         ""repo_name"": ""cuda_cudart"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|         },|;|@@ -284,47 +285,54 @@ REDIST_VERSIONS_TO_BUILD_TEMPLATES = {|;|     ""libnvjitlink"": {|;|         ""repo_name"": ""cuda_nvjitlink"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvjitlink.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvjitlink.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvrtc"": {|;|         ""repo_name"": ""cuda_nvrtc"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_cccl"": {|;|         ""repo_name"": ""cuda_cccl"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvcc"": {|;|         ""repo_name"": ""cuda_nvcc"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvml_dev"": {|;|         ""repo_name"": ""cuda_nvml"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvprune"": {|;|         ""repo_name"": ""cuda_nvprune"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvtx"": {|;|         ""repo_name"": ""cuda_nvtx"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|         }, || PR#90394 - third_party/xla/third_party/gpus/cuda/hermetic/cuda_redist_versions.bzl: @@ -244,6 +244,7 @@ REDIST_VERSIONS_TO_BUILD_TEMPLATES = {|;|     ""cuda_cudart"": {|;|         ""repo_name"": ""cuda_cudart"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_cudart.BUILD.tpl"",|;|         },|;|@@ -284,47 +285,54 @@ REDIST_VERSIONS_TO_BUILD_TEMPLATES = {|;|     ""libnvjitlink"": {|;|         ""repo_name"": ""cuda_nvjitlink"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvjitlink.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvjitlink.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvrtc"": {|;|         ""repo_name"": ""cuda_nvrtc"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvrtc.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_cccl"": {|;|         ""repo_name"": ""cuda_cccl"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_cccl.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvcc"": {|;|         ""repo_name"": ""cuda_nvcc"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvcc.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvml_dev"": {|;|         ""repo_name"": ""cuda_nvml"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvml.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvprune"": {|;|         ""repo_name"": ""cuda_nvprune"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvprune.BUILD.tpl"",|;|         },|;|     },|;|     ""cuda_nvtx"": {|;|         ""repo_name"": ""cuda_nvtx"",|;|         ""version_to_template"": {|;|+            ""13"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|             ""12"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|             ""11"": ""//third_party/gpus/cuda/hermetic:cuda_nvtx.BUILD.tpl"",|;|         },","PR #24456: Add support for CUDA 13 (only when available locally)

Imported from GitHub PR https://github.com/openxla/xla/pull/24456

Copybara import of the project:

--
d152d725f2cbbe3bdd1df17a7edcc7da620ad703 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Add support for CUDA 13 (only when available locally)

Merging this change closes #24456

PiperOrigin-RevId: 742806633"
tensorflow/tensorflow,sergachev,24008,Create cloudbuild.yaml,,"
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla -->",closed,2018-11-27T17:45:43+00:00,2018-11-27T17:46:12+00:00,jamiejackherer,cla: no,1,"PR#90303 - third_party/xla/xla/service/gpu/gpu_hlo_schedule.cc: @@ -746,7 +746,7 @@ absl::Status RunAsyncCollectivesConversionPasses(HloModule* module) {|;| absl::StatusOr<ScheduleMetadata> ScheduleGpuModule(|;|     HloModule* module, int64_t pointer_size,|;|     const se::DeviceDescription& gpu_device_info) {|;|-  tsl::profiler::TraceMe traceme(""GpuCompiler::CompileToBackendResult"")|;|;+  tsl::profiler::TraceMe traceme(""ScheduleGpuModule"")|;|; |;|   // Tag the module with its 128 bit fingerprint. The fingerprint should include|;|   // instruction name with ids.","PR #24008: [GPU] Fix TraceMe annotation.

Imported from GitHub PR https://github.com/openxla/xla/pull/24008

Copybara import of the project:

--
829c15522e8ebebb11079913e51fac965f594cb2 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix TraceMe annotation.

Merging this change closes #24008

PiperOrigin-RevId: 742215534"
tensorflow/tensorflow,sergachev,23827,Tensor cpu need cuda?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): W7 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version: 1.12.0
- Python version: 3.6.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: not supported by GPU
- GPU model and memory: Geforce GT 330m



**Describe the problem**
i have cpu tensor,couse my video card don't support cuda acceleration.
I have correctly installed tensorflow by pip command,but i got error when import.
some one told me about cuda driver etc,but why i need it if i want use cpu version?
i tryed to use cuda and cudnn,but error persist
i got this error using keras too

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Xxx\AppData\Local\Programs\Python\Python36\lib\site-packages\
tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\xxx\AppData\Local\Programs\Python\Python36\lib\site-packages\
tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper

    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript
ion)
  File ""C:\Users\xxx\AppData\Local\Programs\Python\Python36\lib\imp.py"", line
243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\xxxx\AppData\Local\Programs\Python\Python36\lib\imp.py"", line
343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed with error code -1073741795
343, in load_dynamic
   

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors
","There's a strong possibility your CPU is refusing to work with the most recent version of TensorFlow. This is a recurring error for newcomers to TensorFlow. Installing any data science library is an art and not a straight-forward task. You'll be lucky if all of your dependencies are in-check and everything works the first time. In short, you will need to downgrade your TensorFlow wheel version.  

Something like this: 
`python -m pip uninstall tensorflow`

Then, proceed to install an earlier version of Tensorflow, like so:
`python -m pip uninstall tensorflow==1.5`

Your computer may require a later(e.g. Tensorflow==1.7) or even an earlier(e.g. Tensorflow==1.4) version. You will need to play and tweak as needed. 

Please be advised that earlier versions of TensorFlow lack performance as well as some features. || i checked and googled all the possibilities,probably is cpu incompatibly with tensors,i downgraded at 1.10.0 and checked the right wheel config.
now seems working but have to test it
my cpu is 720qm (too old) || I see. You will need to invest in a more capable computer in the near future if you want to test newer Tensorflow features.  || i7-720QM does not support AVX. 
Tensorflow==1.5 is the last (official) version that build w/o AVX.
You can use newer tensorflow by installing a custom build w/o AVX, for example: https://github.com/fo40225/tensorflow-windows-wheel

Edit:
fo40225 build tensorflow using VisualStudio 2017. It may not work properly on Windows 7.",closed,2018-11-18T02:49:33+00:00,2019-01-02T22:33:55+00:00,pilo21,comp:runtime,1,"PR#90300 - third_party/xla/docs/tools_multihost_hlo_runner.md: @@ -11,26 +11,23 @@ We can identify these HLOs by seeing `sharding=` annotations. For example|;| `sharding={devices=[1,1,2,1]0,1}` means that the annotated tensor should be|;| sharded to 2 GPUs (GPU0 and GPU1) along the 3rd dimension.|;| |;|-The following instructions assume the working directory is the xla Git|;|+The following instructions assume the working directory is the XLA Git|;| repository and that `./configure.py` has been run.|;| |;| If we have enough GPUs, we can replay these HLOs like this:|;| |;| ```|;|-bazel run -c opt --config=cuda --dynamic_mode=off \|;|-  //xla/tools/multihost_hlo_runner:hlo_runner_main -- my-hlo.txt|;|+bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- my-hlo.txt|;| ```|;| |;| Tip: If the input generation takes too long or uses too much host memory,|;| consider using `--hlo_argument_mode=uninitialized`.|;| |;| It is also possible to compile the same HLO without running it by setting|;|-`--run=false`|;|+`--run=false`:|;| |;| ```|;|-bazel run -c opt --config=cuda --dynamic_mode=off \|;|-  //xla/tools/multihost_hlo_runner:hlo_runner_main \|;|-  -- --run=false my-hlo.txt|;|+bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- --run=false my-hlo.txt|;| ```|;| |;| In that case, a single GPU is necessary, unless the|;|@@ -63,59 +60,57 @@ Note, those instructions can be outdated more quickly. Adjust as needed.|;| ```|;| # The 8 below is the number of GPUs you have.|;| # test-pax.sh --help for more details on the parallelization options|;|-(export XLA_FLAGS=""--xla_dump_to=/tmp/dump --xla_dump_hlo_as_text""; test-pax.sh --fsdp 8 --batch-per-gpu 1)|;|+(export XLA_FLAGS=""--xla_dump_to=/tmp/dump""; test-pax.sh --fsdp 8 --batch-per-gpu 1)|;| |;| ls -lSh /tmp/dump/*before_optimizations.txt|;| # The biggest file one is normally the one you care about.|;| # I picked one, for the rest of the scripts, but the name could change when you change the JAX or XLA version.|;| ```|;| |;|-### Build XLA multinode runner|;|+### Build XLA multihost runner|;| |;| ```|;| cd /opt/xla/|;| ./configure.py --backend CUDA --nccl|;|-bazel build -c opt --config=cuda --dynamic_mode=off //xla/tools/multihost_hlo_runner:hlo_runner_main|;|+bazel build //xla/tools/multihost_hlo_runner:hlo_runner_main|;| ```|;| |;| ### Single process example: Before optimization graph replay|;| |;| ```|;|-bazel run -c opt --config=cuda --dynamic_mode=off //xla/tools/multihost_hlo_runner:hlo_runner_main -- /tmp/dump/module_0023.pjit__wrapped_step_fn.before_optimizations.txt|;|+bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- \|;|+  /tmp/dump/module_0023.pjit__wrapped_step_fn.before_optimizations.txt|;| ```|;| |;| ### Single process example: After optimization graph replay|;| |;|-To replay an optimized HLO, you must use those two parameters|;|-`--run_xla_backend_only=true --xla_disable_all_hlo_passes=true`. Otherwise, it|;|-will try to recompile the HLO and this isn't supported. So it will give you many|;|-strange errors.|;|+To replay an optimized HLO, you must use either `--xla_disable_all_hlo_passes`|;|+or `--run_xla_backend_only`. Otherwise, XLA will try to recompile the HLO and|;|+this isn't supported. So it will give you many strange errors.|;| |;|-Full command: `bazel run -c opt --config=cuda --dynamic_mode=off|;|-//xla/tools/multihost_hlo_runner:hlo_runner_main -- --run_xla_backend_only=true|;|---xla_disable_all_hlo_passes=true|;|+Full command: `bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main --|;|+--run_xla_backend_only|;| /tmp/dump/module_0023.pjit__wrapped_step_fn.sm_8.0_gpu_after_optimizations.txt`|;| |;| ## Multi-processes, single-node|;| |;| ### Launch container|;| |;|-Also install some missing librairies. (Note, that can be outdated more quickly.|;|+Also install some missing libraries. (Note, that can be outdated more quickly.|;| Adjust as needed.)|;| |;| ```|;| docker run -it --shm-size=1g --gpus all ghcr.io/nvidia/jax:pax-2024-06-03|;| apt-get update && apt-get install -y openmpi-bin openmpi-common libopenmpi-dev|;| ```|;| |;|-### Run original model and dump HLO.|;|+### Run original model and dump HLO|;| |;| For this example, we will use an 8-GPU PAXML model from `test-pax.sh`. (Note|;| this will be the same dump as the single process case. So you can do `cp -r|;| /tmp/dump /tmp/dump_multi_process` if you already have it. `export|;|-XLA_FLAGS=""--xla_dump_to=/tmp/dump_multi_process --xla_dump_hlo_as_text"" mpirun|;|---allow-run-as-root -np 8 test-pax.sh --fsdp 8 --batch-per-gpu 1 -o|;|-/tmp/checkpoint --multiprocess`|;|+XLA_FLAGS=""--xla_dump_to=/tmp/dump_multi_process"" mpirun --allow-run-as-root -np|;|+8 test-pax.sh --fsdp 8 --batch-per-gpu 1 -o /tmp/checkpoint --multiprocess`|;| |;| The HLO dump will be saved to `/tmp/dump_multi_process/`. For PAX specifically,|;| the main module will have ""pjit__wrapped_step_fn"" in the name. For this example|;|@@ -129,7 +124,7 @@ Create a bash script called `run.sh`:|;| ```|;| #!/bin/bash|;| export CUDA_VISIBLE_DEVICES=${OMPI_COMM_WORLD_LOCAL_RANK}|;|-bazel run -c opt --config=cuda --dynamic_mode=off //xla/tools/multihost_hlo_runner:hlo_runner_main -- \|;|+bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- \|;|   --task_id=${OMPI_COMM_WORLD_RANK} \|;|   --num_nodes=${OMPI_COMM_WORLD_SIZE} \|;|   --address=127.0.0.1:12345 \|;|@@ -146,10 +141,10 @@ mpirun --allow-run-as-root -np 8 run.sh|;| ### Run on multiple nodes with SLURM|;| |;| When running on multiple nodes using SLURM, you can forward the SLURM env|;|-variables to the hlo runner like so in your slurm job:|;|+variables to the HLO runner like so in your SLURM job:|;| |;| ```|;|-bazel run -c opt --config=cuda --dynamic_mode=off //xla/tools/multihost_hlo_runner:hlo_runner_main -- \|;|+bazel run //xla/tools/multihost_hlo_runner:hlo_runner_main -- \|;|   --task_id=${SLURM_PROCID} \|;|   --num_nodes=${SLURM_NTASKS} \|;|   --address=""${SLURM_LAUNCH_NODE_IPADDR}:12345"" \","PR #23827: [DOC] Fix multihost HLO runner doc.

Imported from GitHub PR https://github.com/openxla/xla/pull/23827

- Omit -c opt which is the default.
 - Omit dump_hlo_as_text which is the default.
 - Omit --config=cuda which is nowadays handled by configure.py.
 - Remove --xla_disable_all_hlo_passes which has no effect in presence of --run_xla_backend_only.
 - Leave single mention of dynamic_mode=off which usually isn't needed.
 - Other minor fixes.
Copybara import of the project:

--
bc64c89d3cb4db37945331d94faf9acc573ed6d9 by Ilia Sergachev <isergachev@nvidia.com>:

[DOC] Fix multihost HLO runner doc.

- Omit -c opt which is the default.
 - Omit dump_hlo_as_text which is the default.
 - Omit --config=cuda which is nowadays handled by configure.py.
 - Remove --xla_disable_all_hlo_passes which has no effect in presence
of --run_xla_backend_only.
 - Leave single mention of dynamic_mode=off which usually isn't needed.
 - Other minor fixes.

Merging this change closes #23827

PiperOrigin-RevId: 742214204"
tensorflow/tensorflow,jaro-sevcik,24248,Support for `skip_mismatch` in `tf.keras.engine.saving.load_weights_from_hdf5_group_by_name`,"**System information**
- TensorFlow version (you are using): 
```
tensorflow                1.12.0          gpu_py36he68c306_0    anaconda
tensorflow-base           1.12.0          gpu_py36h8e0ae2d_0    anaconda
tensorflow-gpu            1.12.0               h0d30ee6_0    anaconda
```

The feature is already supported in `keras-team/keras` and the behaviour and motivation is already explained in: https://github.com/keras-team/keras/pull/8462
","It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.

",closed,2018-12-09T11:27:20+00:00,2018-12-19T23:32:30+00:00,daavoo,,1,"PR#90295 - third_party/xla/xla/service/gpu/transforms/layout_assignment.cc: @@ -340,6 +340,15 @@ bool IsPackedInstruction(const HloInstruction* instruction) {|;|               instruction->operand(0)->shape().element_type()))|;|; }|;| |;|+bool IsCustomCallToMemoryPlacement(const HloInstruction* hlo) {|;|+  if (hlo->opcode() != HloOpcode::kCustomCall) {|;|+    return false|;|;+  }|;|+  const std::string& target = hlo->custom_call_target()|;|;+  return target == memory_annotations::kMoveToDeviceCustomCallTarget |||;|+         target == memory_annotations::kMoveToHostCustomCallTarget|;|;+}|;|+|;| }  // namespace|;| |;| absl::Status GpuLayoutAssignment::AddDotBackendConstraints(|;|@@ -571,6 +580,13 @@ absl::Status GpuLayoutAssignment::AddBackendConstraints(|;|             LayoutUtil::SetToDefaultLayout(subshape)|;|;           })|;|;       TF_RETURN_IF_ERROR(SetInstructionLayout(s, instruction))|;|;+    } else if (IsCustomCallToMemoryPlacement(instruction)) {|;|+      // Make sure that host memory buffers use the default layout so that|;|+      // the compiler does not insert transposes on host memory buffers.|;|+      Shape operand_shape = instruction->operand(0)->shape()|;|;+      LayoutUtil::SetToDefaultLayout(&operand_shape)|;|;+      TF_RETURN_IF_ERROR(SetOperandLayout(operand_shape, instruction, 0))|;|;+      TF_RETURN_IF_ERROR(SetInstructionLayout(operand_shape, instruction))|;|;     }|;|   }|;|   return absl::OkStatus()|;|;@@ -691,19 +707,12 @@ bool GpuLayoutAssignment::PropagateReductionLayoutToOperand(|;| |;| bool GpuLayoutAssignment::InstructionCanChangeLayoutInstance(|;|     const HloInstruction* instruction) {|;|-  // The host offloading custom calls will be eventually removed|;|-  // by the offloader, so we need to make sure that the calls do not change|;|-  // the layout and thus cause layout mismatches after the removal.|;|   // The TopK custom call cannot handle the case if the operand has a different|;|   // layout.|;|   const HloCustomCallInstruction* custom_call =|;|       DynCast<HloCustomCallInstruction>(instruction)|;|;   if (custom_call != nullptr &&|;|-      (custom_call->custom_call_target() ==|;|-           memory_annotations::kMoveToHostCustomCallTarget |||;|-       custom_call->custom_call_target() ==|;|-           memory_annotations::kMoveToDeviceCustomCallTarget |||;|-       custom_call->custom_call_target() == kTopKCustomCallTarget)) {|;|+      custom_call->custom_call_target() == kTopKCustomCallTarget) {|;|     return false|;|;   }|;|  || PR#90295 - third_party/xla/xla/service/gpu/transforms/layout_assignment_test.cc: @@ -517,9 +517,10 @@ TEST_F(LayoutAssignmentTest, MoveToHostCustomCallConstrained) {|;| HloModule TestModule|;| |;| ENTRY entry {|;|-  Arg_0 = f32[2,5,5]{2,1,0} parameter(0)|;|+  Arg_0 = f32[2,5,5]{0,1,2} parameter(0)|;|   custom-call.0 = f32[2,5,5] custom-call(Arg_0), custom_call_target=""MoveToHost""|;|-  ROOT custom-call.1 = f32[2,5,5]{2, 1, 0} custom-call(custom-call.0), custom_call_target=""fixed_call"", operand_layout_constraints={f32[2,5,5]{1,2,0}}|;|+  ROOT custom-call.1 = f32[2,5,5]{2, 1, 0} custom-call(custom-call.0),|;|+      custom_call_target=""fixed_call"", operand_layout_constraints={f32[2,5,5]{1,2,0}}|;| }|;| )""|;|;   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m,|;|@@ -536,19 +537,19 @@ ENTRY entry {|;|   const HloInstruction* call_0 = FindInstruction(m.get(), ""custom-call.0"")|;|;   const Layout input_layout = call_0->operand(0)->shape().layout()|;|;   const Layout output_layout = call_0->shape().layout()|;|;-  EXPECT_TRUE(LayoutUtil::Equal(input_layout, output_layout))|;|-      << ""Expected the same input/output layouts.  Input: "" << input_layout|;|-      << "". Output: "" << output_layout|;|;+  EXPECT_EQ(input_layout, LayoutUtil::GetDefaultLayoutForR3())|;|;+  EXPECT_EQ(output_layout, LayoutUtil::GetDefaultLayoutForR3())|;|; }|;| |;| TEST_F(LayoutAssignmentTest, MoveToDeviceCustomCallConstrained) {|;|   const char* module_str = R""(|;| HloModule TestModule|;| |;| ENTRY entry {|;|-  Arg_0 = f32[2,5,5]{2,1,0} parameter(0)|;|+  Arg_0 = f32[2,5,5]{1,2,0} parameter(0)|;|   custom-call.0 = f32[2,5,5] custom-call(Arg_0), custom_call_target=""MoveToDevice""|;|-  ROOT custom-call.1 = f32[2,5,5]{2, 1, 0} custom-call(custom-call.0), custom_call_target=""fixed_call"", operand_layout_constraints={f32[2,5,5]{1,2,0}}|;|+  ROOT custom-call.1 = f32[2,5,5]{2, 1, 0} custom-call(custom-call.0),|;|+      custom_call_target=""fixed_call"", operand_layout_constraints={f32[2,5,5]{0,1,2}}|;| }|;| )""|;|;   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m,|;|@@ -565,9 +566,8 @@ ENTRY entry {|;|   const HloInstruction* call_0 = FindInstruction(m.get(), ""custom-call.0"")|;|;   const Layout input_layout = call_0->operand(0)->shape().layout()|;|;   const Layout output_layout = call_0->shape().layout()|;|;-  EXPECT_TRUE(LayoutUtil::Equal(input_layout, output_layout))|;|-      << ""Expected the same input/output layouts.  Input: "" << input_layout|;|-      << "". Output: "" << output_layout|;|;+  EXPECT_EQ(input_layout, LayoutUtil::GetDefaultLayoutForR3())|;|;+  EXPECT_EQ(output_layout, LayoutUtil::GetDefaultLayoutForR3())|;|; }|;| |;| TEST_F(LayoutAssignmentTest, CuDNNConvolutionHasNHWCLayoutPostHopper) {","PR #24248: Move-to-memory-space custom calls use default layout

Imported from GitHub PR https://github.com/openxla/xla/pull/24248

Using non-default layout for MoveToHost makes the compiler
insert a transpose operation on the host value if that value
flows into the root of the entry computation. Such transposes
cause the host offloader to emit a slow on-host transpose
(and a warning on the console). We see those warnings on
maxtext llama2-7b with optimizer state offloading with fsdp=2.

This patch enforces default layout for on-host values so that
no transpose is necessary (as long as there is no override
of layout for host values in entry computation).

Note that such transposes cannot be sunk into the uses
by the offloading lagalizer because there is nowhere
to sink to - the value is returned from the computation.
Copybara import of the project:

--
ad192bbba93040a88bda9e4e1074dd1de7153b32 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Use default layout for offloading ops

--
f8f0ddcf73c9a4792cbbfd99c2d465f4de80c418 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Address reviewer comments

Merging this change closes #24248

PiperOrigin-RevId: 742185098"
tensorflow/tensorflow,acxz,61823,[rocm] [build] sh: line 1: /opt/rocm/hip/bin/hipcc: No such file or directory,"### Issue type

Build/Install

### Have you reproduced the bug with TensorFlow Nightly?

Yes

### Source

source

### TensorFlow version

2.13.0

### Custom code

No

### OS platform and distribution

Arch Linux

### Mobile device

_No response_

### Python version

3.11

### Bazel version

5.4.0

### GCC/compiler version

12.3.0

### CUDA/cuDNN version

ROCm 5.6.0

### GPU model and memory

_No response_

### Current behavior?

Build fails with the following error:
```
sh: line 1: /opt/rocm/hip/bin/hipcc: No such file or directory
```

### Standalone code to reproduce the issue

```shell
Build the code from source with ROCM 5.6.0
```


### Relevant log output

_No response_","Are you satisfied with the resolution of your issue?
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/61823"">Yes</a>
<a href=""https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/61823"">No</a>
",closed,2023-09-09T18:40:05+00:00,2023-09-21T06:56:18+00:00,acxz,"stat:awaiting tensorflower, type:build/install, subtype: ubuntu/linux, TF 2.13",1,"PR#61824 - third_party/gpus/rocm_configure.bzl: @@ -751,7 +751,7 @@ def _create_local_rocm_repository(repository_ctx):|;|         tpl_paths[""crosstool:clang/bin/crosstool_wrapper_driver_rocm""],|;|         {|;|             ""%{cpu_compiler}"": str(cc),|;|-            ""%{hipcc_path}"": rocm_config.rocm_toolkit_path + ""/hip/bin/hipcc"",|;|+            ""%{hipcc_path}"": rocm_config.rocm_toolkit_path + ""/bin/hipcc"",|;|             ""%{hipcc_env}"": _hipcc_env(repository_ctx),|;|             ""%{rocr_runtime_path}"": rocm_config.rocm_toolkit_path + ""/lib"",|;|             ""%{rocr_runtime_library}"": ""hsa-runtime64"",",fix hipcc path
tensorflow/tensorflow,chaserileyroberts,23790,"fix tf.Saver save and restore bug under distributed setting(with ps, master and worker)","This pull request allow using more than one PS in distributed training, saving and restore models without using any shared file stream. The following issues will be fixed, although it is closed:
   https://github.com/tensorflow/tensor2tensor/issues/394
   https://github.com/tensorflow/tensorflow/issues/6374

@tobyyouup @mrry  @ericyue ","
Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

:memo: **Please visit <https://cla.developers.google.com/> to sign.**

Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.

----

#### What to do if you already signed the CLA

##### Individual signers

*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).

##### Corporate signers

*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).
*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).
*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).
		

<!-- need_sender_cla --> || I signed it. || I signed it. || CLAs look good, thanks!

<!-- ok --> || Transferring my review request to @allenlavoie, since this is related to saving checkpoints. || One high-level question is how this relates to `Saver(sharded=False)`.

Another question is what this does to users of shared filesystems who are using the current sharded behavior. Doesn't this create a bunch of extra communication and a bottleneck? || @allenlavoie
    This modification does not affect tf.Saver(sharded=False), the sharded controls whether the model are saved in one file or multiple files. I test with both sharded = True and sharded = False, both settings work with the current modification. 
    As for extra communication, shared file system also involves lots of communication. Moreover, pull parameters from sever is necessary for every iteration. 
    I experiment with two PS, the saving time does not increase significantly(13s vs 12s). Experiment with nvidia GPU M40, RFCN model, Resnet-50 backbone, pascal voc datasets, batch_size = 1.
** Two PS after modification: 
[INFO] 2018-11-18 16:32:52,305 tf_logging.py:115 : Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.
[INFO] 2018-11-18 16:33:05,211 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis_more/model.ckpt.
** One PS before modification:
[INFO] 2018-10-23 11:57:29,569 tf_logging.py:115 : Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt.
[INFO] 2018-10-23 11:57:41,622 tf_logging.py:115 : Saving checkpoints for 0 into pascal_resnet50_rfcn_model_dis/model.ckpt. || @allenlavoie I look into the details of tf.train.Saver, the non sharded case are not affected, because no tf.device is set on the call path, so it is default to job:master. I log out the device placement, and it shows that both restore and save operation are placed on job:master. 

tensorflow/core/common_runtime/placer.cc:935] save/SaveV2: (SaveV2)/job:master/replica:0/task:0/device:CPU:0
tensorflow/core/common_runtime/placer.cc:935] save/RestoreV2: (RestoreV2)/job:master/replica:0/task:0/device:CPU:0 || I meant more that this seems like it's re-implementing non-sharded save in the `sharded=True` path. Why doesn't `sharded=False` fix issues caused by not having a shared filesystem? || @allenlavoie What is the purpose to use the sharded parameter? 
In my understanding, it just split the checkpoint data into multiple file parts.
I do not think a shared file system could avoid network communication overhead. 
Besides, many code using tf.Saver default to set sharded = True, such as tf.estimator.
If sharded is not necessary, should this parameter be dropped? || My impression is that `sharded=True` is mainly useful if you can't fit all of your variables in memory on a single machine.

So you shard the variables among a bunch of parameter servers. But now if you go to save without sharding, you copy all of the variables to a single machine and run out of memory. Theoretically this could be serialized so each shard gets saved before the next gets copied to the machine doing the saving, but that seems very complicated and pretty slow.

So instead the assumption is that a distributed filesystem handles the shards, and each parameter server can just dump whatever they have to it. This assumption is annoying if there is no distributed filesystem, but I don't think copying all the shards to a single machine helps. Maybe the discussion should be around whether `sharded=True` is a good default, or whether it needs to be clearer in the documentation that a shared filesystem is an assumption for distributed `Estimator`?

FWIW `tf.train.Saver` will probably not be in TensorFlow 2.x. We haven't yet settled on an API to expose this kind of sharding behavior. || I close the pull request. If anyone need my fix, can pull from my forked respository.",closed,2018-11-16T07:05:06+00:00,2018-11-23T01:23:17+00:00,chengmengli06,cla: yes,1,"PR#90194 - third_party/xla/xla/service/BUILD: @@ -4081,6 +4081,7 @@ cc_library(|;|         ""//xla:permutation_util"",|;|         ""//xla:shape_layout"",|;|         ""//xla:shape_util"",|;|+        ""//xla:side_effect_util"",|;|         ""//xla:status_macros"",|;|         ""//xla:util"",|;|         ""//xla:xla_data_proto_cc"", || PR#90194 - third_party/xla/xla/service/gpu/BUILD: @@ -1528,6 +1528,7 @@ cc_library(|;|         ""//xla/service/gpu/transforms:dot_operand_converter"",|;|         ""//xla/service/gpu/transforms:double_buffer_loop_unrolling"",|;|         ""//xla/service/gpu/transforms:dynamic_slice_fusion_rewriter"",|;|+        ""//xla/service/gpu/transforms:explicit_collectives_group_async_wrapper"",|;|         ""//xla/service/gpu/transforms:explicit_stream_annotation_async_wrapper"",|;|         ""//xla/service/gpu/transforms:fusion_block_level_rewriter"",|;|         ""//xla/service/gpu/transforms:fusion_wrapper"", || PR#90194 - third_party/xla/xla/service/gpu/gpu_compiler.cc: @@ -205,6 +205,7 @@ limitations under the License.|;| #include ""xla/service/gpu/transforms/dot_operand_converter.h""|;| #include ""xla/service/gpu/transforms/double_buffer_loop_unrolling.h""|;| #include ""xla/service/gpu/transforms/dynamic_slice_fusion_rewriter.h""|;|+#include ""xla/service/gpu/transforms/explicit_collectives_group_async_wrapper.h""|;| #include ""xla/service/gpu/transforms/explicit_stream_annotation_async_wrapper.h""|;| #include ""xla/service/gpu/transforms/fusion_wrapper.h""|;| #include ""xla/service/gpu/transforms/gemm_broadcast_folding_rewriter.h""|;|@@ -1211,6 +1212,7 @@ absl::Status RunPostFusionSimplificationPasses(|;|           .xla_gpu_experimental_stream_annotation()) {|;|     pipeline.AddPass<ExplicitStreamAnnotationAsyncWrapper>()|;|;   }|;|+  pipeline.AddPass<ExplicitCollectivesGroupAsyncWrapper>()|;|;   return pipeline.Run(hlo_module).status()|;|; }|;|  || PR#90194 - third_party/xla/xla/service/gpu/transforms/BUILD: @@ -1624,6 +1624,44 @@ xla_cc_test(|;|     ],|;| )|;| |;|+cc_library(|;|+    name = ""explicit_collectives_group_async_wrapper"",|;|+    srcs = [""explicit_collectives_group_async_wrapper.cc""],|;|+    hdrs = [""explicit_collectives_group_async_wrapper.h""],|;|+    deps = [|;|+        ""//xla:side_effect_util"",|;|+        ""//xla:util"",|;|+        ""//xla:xla_data_proto_cc"",|;|+        ""//xla/hlo/ir:hlo"",|;|+        ""//xla/hlo/pass:hlo_pass"",|;|+        ""//xla/service/gpu:backend_configs_cc"",|;|+        ""//xla/tsl/platform:errors"",|;|+        ""//xla/tsl/platform:statusor"",|;|+        ""@com_google_absl//absl/container:flat_hash_set"",|;|+        ""@com_google_absl//absl/log"",|;|+        ""@com_google_absl//absl/status:statusor"",|;|+        ""@com_google_absl//absl/strings:string_view"",|;|+    ],|;|+)|;|+|;|+xla_cc_test(|;|+    name = ""explicit_collectives_group_async_wrapper_test"",|;|+    srcs = [""explicit_collectives_group_async_wrapper_test.cc""],|;|+    deps = [|;|+        "":explicit_collectives_group_async_wrapper"",|;|+        ""//xla:side_effect_util"",|;|+        ""//xla/hlo/ir:hlo"",|;|+        ""//xla/hlo/testlib:filecheck"",|;|+        ""//xla/service/gpu:backend_configs_cc"",|;|+        ""//xla/tests:hlo_test_base"",|;|+        ""//xla/tsl/lib/core:status_test_util"",|;|+        ""//xla/tsl/platform:statusor"",|;|+        ""@com_google_absl//absl/status:statusor"",|;|+        ""@com_google_absl//absl/strings:string_view"",|;|+        ""@com_google_googletest//:gtest_main"",|;|+    ],|;|+)|;|+|;| cc_library(|;|     name = ""explicit_stream_annotation_async_wrapper"",|;|     srcs = [""explicit_stream_annotation_async_wrapper.cc""], || PR#90194 - third_party/xla/xla/service/gpu/transforms/explicit_collectives_group_async_wrapper.cc: @@ -0,0 +1,81 @@|;|+/* Copyright 2024 The OpenXLA Authors. All Rights Reserved.|;|+|;|+Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+you may not use this file except in compliance with the License.|;|+You may obtain a copy of the License at|;|+|;|+    http://www.apache.org/licenses/LICENSE-2.0|;|+|;|+Unless required by applicable law or agreed to in writing, software|;|+distributed under the License is distributed on an ""AS IS"" BASIS,|;|+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+See the License for the specific language governing permissions and|;|+limitations under the License.|;|+==============================================================================*/|;|+|;|+#include ""xla/service/gpu/transforms/explicit_collectives_group_async_wrapper.h""|;|+|;|+#include ""absl/container/flat_hash_set.h""|;|+#include ""absl/log/log.h""|;|+#include ""absl/status/statusor.h""|;|+#include ""absl/strings/string_view.h""|;|+#include ""xla/hlo/ir/hlo_clone_context.h""|;|+#include ""xla/hlo/ir/hlo_computation.h""|;|+#include ""xla/hlo/ir/hlo_instruction.h""|;|+#include ""xla/hlo/ir/hlo_opcode.h""|;|+#include ""xla/service/gpu/backend_configs.pb.h""|;|+#include ""xla/side_effect_util.h""|;|+#include ""xla/tsl/platform/errors.h""|;|+#include ""xla/tsl/platform/statusor.h""|;|+#include ""xla/util.h""|;|+#include ""xla/xla_data.pb.h""|;|+|;|+namespace xla {|;|+namespace gpu {|;|+|;|+namespace {|;|+|;|+absl::StatusOr<bool> CreateCollectivesGroupAsyncPair(HloInstruction* instr) {|;|+  if (instr->opcode() != HloOpcode::kCall |||;|+      !instr->frontend_attributes().map().contains(kCollectivesGroupAttr)) {|;|+    return false|;|;+  }|;|+  HloComputation* computation = instr->parent()|;|;+  auto new_computation = instr->GetModule()->AddEmbeddedComputation(|;|+      instr->to_apply()->Clone(""collectives_group""))|;|;+  // Get the shapes for the original instruction.|;|+  std::vector<const Shape*> parameter_shapes(instr->operand_count())|;|;+  for (int i = 0; i < instr->operand_count(); ++i) {|;|+    parameter_shapes[i] = &instr->operand(i)->shape()|;|;+  }|;|+  std::vector<Shape> start_shapes = {|;|+      ShapeUtil::MakeTupleShapeWithPtrs(parameter_shapes), instr->shape()}|;|;+  HloInstruction* async_start =|;|+      computation->AddInstruction(HloInstruction::CreateAsyncStart(|;|+          ShapeUtil::MakeTupleShape(start_shapes), instr->operands(),|;|+          new_computation, ""explicit""))|;|;+  HloInstruction* async_done = computation->AddInstruction(|;|+      HloInstruction::CreateAsyncDone(instr->shape(), async_start))|;|;+  // Forward frontend attributes to both async instructions.|;|+  async_start->set_frontend_attributes(instr->frontend_attributes())|;|;+  async_done->set_frontend_attributes(instr->frontend_attributes())|;|;+  TF_RETURN_IF_ERROR(computation->ReplaceInstruction(instr, async_done))|;|;+  return true|;|;+}|;|+}  // namespace|;|+|;|+absl::StatusOr<bool> ExplicitCollectivesGroupAsyncWrapper::Run(|;|+    HloModule* module,|;|+    const absl::flat_hash_set<absl::string_view>& execution_threads) {|;|+  bool changed = false|;|;+  for (const HloComputation* comp : module->computations()) {|;|+    for (HloInstruction* instr : comp->instructions()) {|;|+      TF_ASSIGN_OR_RETURN(bool result, CreateCollectivesGroupAsyncPair(instr))|;|;+      changed |= result|;|;+    }|;|+  }|;|+  return changed|;|;+}|;|+|;|+}  // namespace gpu|;|+}  // namespace xla || PR#90194 - third_party/xla/xla/service/gpu/transforms/explicit_collectives_group_async_wrapper.h: @@ -0,0 +1,50 @@|;|+/* Copyright 2025 The OpenXLA Authors. All Rights Reserved.|;|+|;|+Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+you may not use this file except in compliance with the License.|;|+You may obtain a copy of the License at|;|+|;|+    http://www.apache.org/licenses/LICENSE-2.0|;|+|;|+Unless required by applicable law or agreed to in writing, software|;|+distributed under the License is distributed on an ""AS IS"" BASIS,|;|+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+See the License for the specific language governing permissions and|;|+limitations under the License.|;|+==============================================================================*/|;|+|;|+#ifndef XLA_SERVICE_GPU_TRANSFORMS_EXPLICIT_COLLECTIVES_GROUP_ASYNC_WRAPPER_H_|;|+#define XLA_SERVICE_GPU_TRANSFORMS_EXPLICIT_COLLECTIVES_GROUP_ASYNC_WRAPPER_H_|;|+|;|+#include ""absl/container/flat_hash_set.h""|;|+#include ""absl/status/statusor.h""|;|+#include ""absl/strings/string_view.h""|;|+#include ""xla/hlo/ir/hlo_computation.h""|;|+#include ""xla/hlo/ir/hlo_module.h""|;|+#include ""xla/hlo/pass/hlo_pass_interface.h""|;|+|;|+namespace xla {|;|+namespace gpu {|;|+|;|+// This pass will find the kCall instructions that|;|+// are annotated with explicit collectives groups in their frontend|;|+// attributes. It then will convert the kCall into an async|;|+// start-done pair with the same computation. This is then|;|+// picked up by the IR emitter stage, and the entire computation|;|+// will be launched in a single Collective Group.|;|+class ExplicitCollectivesGroupAsyncWrapper : public HloModulePass {|;|+ public:|;|+  absl::string_view name() const override {|;|+    return ""explicit-collectives-group-async-wrapper""|;|;+  }|;|+|;|+  using HloPassInterface::Run|;|;+  absl::StatusOr<bool> Run(|;|+      HloModule* module,|;|+      const absl::flat_hash_set<absl::string_view>& execution_threads) override|;|;+}|;|;+|;|+}  // namespace gpu|;|+}  // namespace xla|;|+|;|+#endif  // XLA_SERVICE_GPU_TRANSFORMS_EXPLICIT_COLLECTIVES_GROUP_ASYNC_WRAPPER_H_ || PR#90194 - third_party/xla/xla/service/gpu/transforms/explicit_collectives_group_async_wrapper_test.cc: @@ -0,0 +1,106 @@|;|+/* Copyright 2024 The OpenXLA Authors. All Rights Reserved.|;|+|;|+Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+you may not use this file except in compliance with the License.|;|+You may obtain a copy of the License at|;|+|;|+    http://www.apache.org/licenses/LICENSE-2.0|;|+|;|+Unless required by applicable law or agreed to in writing, software|;|+distributed under the License is distributed on an ""AS IS"" BASIS,|;|+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+See the License for the specific language governing permissions and|;|+limitations under the License.|;|+==============================================================================*/|;|+|;|+#include ""xla/service/gpu/transforms/explicit_collectives_group_async_wrapper.h""|;|+|;|+#include <memory>|;|+|;|+#include <gtest/gtest.h>|;|+#include ""absl/status/statusor.h""|;|+#include ""absl/strings/string_view.h""|;|+#include ""xla/hlo/ir/hlo_instruction.h""|;|+#include ""xla/hlo/testlib/filecheck.h""|;|+#include ""xla/service/gpu/backend_configs.pb.h""|;|+#include ""xla/side_effect_util.h""|;|+#include ""xla/tests/hlo_test_base.h""|;|+#include ""xla/tsl/lib/core/status_test_util.h""|;|+#include ""xla/tsl/platform/statusor.h""|;|+|;|+namespace xla::gpu {|;|+namespace {|;|+|;|+using ExplicitCollectivesGroupAsyncWrapperTest = HloTestBase|;|;+|;|+TEST_F(ExplicitCollectivesGroupAsyncWrapperTest, AnnotatedOpIsWrapped) {|;|+  const absl::string_view hlo_string = R""(|;|+  HloModule composite|;|+  comms {|;|+    a = f32[1] parameter(0)|;|+    x = f32[1] all-gather(a), dimensions={0}|;|+    y = f32[1] collective-permute(a), source_target_pairs={{0,1}}|;|+    ROOT result = (f32[1], f32[1]) tuple(x, y)|;|+  }|;|+|;|+  ENTRY main {|;|+    b = f32[1] parameter(0)|;|+    ROOT c = (f32[1], f32[1]) call(b), to_apply=comms, frontend_attributes={_collectives_group=""""}|;|+  }|;|+  )""|;|;+|;|+  auto debug_options = HloTestBase::GetDebugOptionsForTest()|;|;+  auto module = ParseAndReturnVerifiedModule(hlo_string).value()|;|;+  ExplicitCollectivesGroupAsyncWrapper wrapper_pass|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(bool mutated, wrapper_pass.Run(module.get()))|;|;+  absl::StatusOr<bool> filecheck_result = RunFileCheck(module->ToString({}), R""(|;|+  // CHECK: %b = f32[1]{0} parameter(0)|;|+  // CHECK: %tuple-start = ((f32[1]{0}), (f32[1]{0}, f32[1]{0})) async-start(%b), async_execution_thread=""explicit"", calls=%comms.collectives_group, frontend_attributes={_collectives_group=""""}|;|+  // CHECK: ROOT %tuple-done = (f32[1]{0}, f32[1]{0}) async-done(%tuple-start), frontend_attributes={_collectives_group=""""}|;|+  )"")|;|;+  TF_ASSERT_OK(filecheck_result.status())|;|;+  EXPECT_TRUE(*filecheck_result)|;|;+  ASSERT_TRUE(mutated)|;|;+}|;|+|;|+TEST_F(ExplicitCollectivesGroupAsyncWrapperTest, ManyCollectivesGroups) {|;|+  // This test calls the same collectives group computation twice, so the|;|+  // computation is cloned so it can be used with many async instructions.|;|+  const absl::string_view hlo_string = R""(|;|+  HloModule composite|;|+  comms {|;|+    a = f32[1] parameter(0)|;|+    x = f32[1] all-gather(a), dimensions={0}|;|+    y = f32[1] collective-permute(a), source_target_pairs={{0,1}}|;|+    ROOT result = (f32[1], f32[1]) tuple(x, y)|;|+  }|;|+|;|+  ENTRY main {|;|+    b = f32[1] parameter(0)|;|+    group1 = (f32[1], f32[1]) call(b), to_apply=comms, frontend_attributes={_collectives_group=""""}|;|+    c = get-tuple-element(group1), index=0|;|+    ROOT d = (f32[1], f32[1]) call(c), to_apply=comms, frontend_attributes={_collectives_group=""""}|;|+  }|;|+  )""|;|;+|;|+  auto debug_options = HloTestBase::GetDebugOptionsForTest()|;|;+  auto module = ParseAndReturnVerifiedModule(hlo_string).value()|;|;+  ExplicitCollectivesGroupAsyncWrapper wrapper_pass|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(bool mutated, wrapper_pass.Run(module.get()))|;|;+  absl::StatusOr<bool> filecheck_result = RunFileCheck(module->ToString({}), R""(|;|+  // CHECK: %b = f32[1]{0} parameter(0)|;|+  // CHECK: %tuple-start = ((f32[1]{0}), (f32[1]{0}, f32[1]{0})) async-start(%b), async_execution_thread=""explicit"", calls=%comms.collectives_group, frontend_attributes={_collectives_group=""""} |;|+  // CHECK: %tuple-done = (f32[1]{0}, f32[1]{0}) async-done(%tuple-start), frontend_attributes={_collectives_group=""""}|;|+  // CHECK: %c = f32[1]{0} get-tuple-element(%tuple-done), index=0|;|+  // CHECK: %tuple-start.1 = ((f32[1]{0}), (f32[1]{0}, f32[1]{0})) async-start(%c), async_execution_thread=""explicit"", calls=%comms.collectives_group.1, frontend_attributes={_collectives_group=""""}|;|+  // CHECK: ROOT %tuple-done.1 = (f32[1]{0}, f32[1]{0}) async-done(%tuple-start.1), frontend_attributes={_collectives_group=""""}|;|+  )"")|;|;+  TF_ASSERT_OK(filecheck_result.status())|;|;+  EXPECT_TRUE(*filecheck_result)|;|;+  ASSERT_TRUE(mutated)|;|;+}|;|+|;|+}  // namespace|;|+}  // namespace xla::gpu || PR#90194 - third_party/xla/xla/service/hlo_verifier.cc: @@ -59,6 +59,7 @@ limitations under the License.|;| #include ""xla/shape.h""|;| #include ""xla/shape_layout.h""|;| #include ""xla/shape_util.h""|;|+#include ""xla/side_effect_util.h""|;| #include ""xla/status_macros.h""|;| #include ""xla/util.h""|;| #include ""xla/xla_data.pb.h""|;|@@ -3084,6 +3085,16 @@ class InstructionVerifier : public DfsHloVisitorWithDefault {|;|   std::optional<int64_t> num_devices_|;|; }|;|; |;|+bool IsCollectivesGroupComputation(HloComputation* computation) {|;|+  auto maybe_caller = computation->GetUniqueCaller(HloOpcode::kAsyncStart)|;|;+  if (!maybe_caller.has_value()) {|;|+    return false|;|;+  }|;|+  return (*maybe_caller)|;|+      ->get_frontend_attribute(kCollectivesGroupAttr)|;|+      .has_value()|;|;+}|;|+|;| }  // namespace|;| |;| absl::StatusOr<bool> HloVerifier::Run(|;|@@ -3119,7 +3130,8 @@ absl::StatusOr<bool> HloVerifier::Run(|;|       // collection of send/recv instructions. This is needed to represent NCCL|;|       // groups on GPU.|;|       if (computation->IsAsyncComputation() &&|;|-          !computation->OnlyContainsSendRecv()) {|;|+          !computation->OnlyContainsSendRecv() &&|;|+          !IsCollectivesGroupComputation(computation)) {|;|         TF_RETURN_IF_ERROR(VerifyAsyncComputation(computation))|;|;       }|;|     } || PR#90194 - third_party/xla/xla/side_effect_util.cc: @@ -79,4 +79,5 @@ const char kMustFuseAttr[] = ""MUST_FUSE""|;|; |;| const char kMaximalFuseAttr[] = ""MAXIMAL_FUSE""|;|; |;|+const char kCollectivesGroupAttr[] = ""_collectives_group""|;|; }  // namespace xla || PR#90194 - third_party/xla/xla/side_effect_util.h: @@ -96,6 +96,10 @@ extern const char kXlaSchedulingGroupIdAttr[]|;|; // are added.|;| extern const char kMustFuseAttr[]|;|; extern const char kMaximalFuseAttr[]|;|;+|;|+// XLA frontend attribute for specifying groups of collectives that should be|;|+// launched together.|;|+extern const char kCollectivesGroupAttr[]|;|; }  // namespace xla|;| |;| #endif  // XLA_SIDE_EFFECT_UTIL_H_ || PR#90194 - third_party/xla/xla/tests/nccl_group_execution_test.cc: @@ -125,6 +125,50 @@ XLA_TEST_F(NcclGroupExecutionTest, NcclGroupSendRecvNoWhileLoop) {|;|   EXPECT_EQ(results[3].ToStringWithoutShapeOneline(), ""( 0, 2000 )"")|;|; }|;| |;|+XLA_TEST_F(NcclGroupExecutionTest, BidirectionalCommunication) {|;|+  const absl::string_view kModuleStr = R""(|;|+  HloModule module_main, entry_computation_layout={()->(u32[], u32[])}|;|+|;|+  bidirectional_ring {|;|+    a = u32[] parameter(0)|;|+    start = (u32[], u32[]) collective-permute-start(a), channel_id=2, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+    done = u32[] collective-permute-done(start)|;|+    start.1 = (u32[], u32[]) collective-permute-start(a), channel_id=1, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+    done.1 = u32[] collective-permute-done(start.1)|;|+    ROOT tuple = (u32[], u32[]) tuple(done, done.1)|;|+  }|;|+|;|+  ENTRY main {|;|+    id = u32[] replica-id()|;|+    async-comm-start = ((u32[]), (u32[], u32[])) async-start(id), calls=bidirectional_ring,|;|+      frontend_attributes={_collectives_group=""""}|;|+   ROOT async-comm-done = (u32[], u32[]) async-done(async-comm-start)|;|+  }|;|+|;|+  )""|;|;+  const int64_t kNumReplicas = 4|;|;+  if (test_runner().device_count() < kNumReplicas) {|;|+    GTEST_SKIP() << ""Test requires at least "" << kNumReplicas << "" devices (""|;|+                 << test_runner().device_count() << "" available)""|;|;+  }|;|+|;|+  HloModuleConfig config =|;|+      GetModuleConfigForTest(/*replica_count=*/kNumReplicas)|;|;+  std::unique_ptr<VerifiedHloModule> module|;|;+  TF_ASSERT_OK_AND_ASSIGN(module,|;|+                          ParseAndReturnVerifiedModule(kModuleStr, config))|;|;+  TF_ASSERT_OK_AND_ASSIGN(|;|+      std::vector<Literal> results,|;|+      ExecuteReplicated(std::move(module), absl::Span<Literal* const>{},|;|+                        kNumReplicas,|;|+                        /*run_hlo_passes=*/true))|;|;+  ASSERT_EQ(results.size(), kNumReplicas)|;|;+  EXPECT_EQ(results[0].ToStringWithoutShapeOneline(), ""( 3, 1 )"")|;|;+  EXPECT_EQ(results[1].ToStringWithoutShapeOneline(), ""( 0, 2 )"")|;|;+  EXPECT_EQ(results[2].ToStringWithoutShapeOneline(), ""( 1, 3 )"")|;|;+  EXPECT_EQ(results[3].ToStringWithoutShapeOneline(), ""( 2, 0 )"")|;|;+}|;|+|;| }  // namespace|;| |;| }  // namespace xla","PR #23790: Add explicit collectives grouping pass.

Imported from GitHub PR https://github.com/openxla/xla/pull/23790

This PR adds an explicit frontend attribute to jitted JAX methods that will force the computation to be run in a single NCCL Group.

The intention of this change is to enable ""multi-directional communications"" that better saturate NVLink systems. We reuse the existing NCCLGroupThunk logic during the IR emitter stage, so we only need to introduce the async wrapper and call inliner.

Here is an example of using this feature from JAX.

```python
import jax
from jax._src.xla_metadata import set_xla_metadata
from jax.experimental.shard_map import shard_map
from jax.sharding import Mesh, PartitionSpec as P
from functools import partial

num_devices = 4
mesh = Mesh(np.array(jax.devices()), ('i',))

# Unique source target pairs for our two ppermutes later.
perm_up = [(i, (i+1) % num_devices) for i in range(num_devices)]
perm_down = [(i, (i-1) % num_devices) for i in range(num_devices)]

# NCCL Group computations _must_ be jitted.
@jax.jit
def bidir_comms(a):
    b = jax.lax.ppermute(a, ""i"", perm_up)
    c = jax.lax.ppermute(a, ""i"", perm_down)
    return b, c

@jax.jit
@partial(shard_map, mesh=mesh, in_specs=P(None, 'i'), out_specs=P(None, 'i'))
def groups(a):
   # Running our jitted function in this context will force the use of a NCCL Group.
    with set_xla_metadata(_collectives_group="""", inlineable=""false""):
        b, c = bidir_comms(a)
    return b + c
```

This is nsys trace with the annotation.
![Screenshot 2025-03-16 at 8 32 44 PM](https://github.com/user-attachments/assets/4f9ea41b-5b78-40ab-a1f1-c58815c963de)

Vs without the additional annotation
![Screenshot 2025-03-16 at 8 31 56 PM](https://github.com/user-attachments/assets/4937107e-f457-424e-8e36-73512b13dc5c)

As you can see, there is only a single NCCL kernel in the annotated example.
Copybara import of the project:

--
d5fa129a55c089ee8374df4982be748517775bbe by chaserileyroberts <chaser@nvidia.com>:

Add explicit nccl grouping pass

--
36ad18d8c604a6cb2559dcca8c29530beb5da888 by chaserileyroberts <chaser@nvidia.com>:

Nccl->Collectives

Merging this change closes #23790

PiperOrigin-RevId: 741580937"
tensorflow/tensorflow,kasper0406,24114,Fix version number in Bazel downgrade warning,"I have upgraded to Bazel 0.20:

```bash
$ bazel version
INFO: Invocation ID: 00114105-2567-451d-b22d-bb21e2d14b11
Build label: 0.20.0
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Nov 30 14:39:01 2018 (1543588741)
Build timestamp: 1543588741
Build timestamp as int: 1543588741
```

Bazel version check is introduced in e7a123f4b361b8104b783d8b1407b45dc087491c. 
Before this patch:

```bash
$ ./configure
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
INFO: Invocation ID: b6a7b9a2-db26-4777-a4bb-f5a668e52e82
You have bazel 0.20.0 installed.
Please downgrade your bazel installation to version 0.15.0 or lower to build TensorFlow!
Configuration finished
```

After this patch:

```bash
$ ./configure
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
INFO: Invocation ID: 34b75ed8-1359-4fa7-ba71-b67fd887ee3a
You have bazel 0.20.0 installed.
Please downgrade your bazel installation to version 0.19.2 or lower to build TensorFlow!
Configuration finished
```","@harshini-gadige Mind to pull? || > @harshini-gadige Mind to pull?

Sure. Will keep you posted. || Seems fixed by 3360c72f32894bc12f5592398d8becbc726ab2d1. Closing for now.",closed,2018-12-03T05:19:11+00:00,2018-12-10T06:35:45+00:00,byronyi,"cla: yes, ready to pull",1,"PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc: @@ -126,11 +126,13 @@ bool IsFp8Type(Type t) {|;| Value Cast(EmitterLocOpBuilder& b, Value value, Type dst_element_ty) {|;|   Type src_ty = value.getType()|;|;   Type src_element_ty = src_ty|;|;+  Type fp16_ty = b.getF16Type()|;|;   Type fp32_ty = b.getF32Type()|;|;   Type dst_ty = dst_element_ty|;|;   if (auto src_shaped_ty = mlir::dyn_cast<ShapedType>(src_ty)) {|;|     src_element_ty = src_shaped_ty.getElementType()|;|;     dst_ty = src_shaped_ty.clone(src_shaped_ty.getShape(), dst_element_ty)|;|;+    fp16_ty = src_shaped_ty.clone(src_shaped_ty.getShape(), b.getF16Type())|;|;     fp32_ty = src_shaped_ty.clone(src_shaped_ty.getShape(), b.getF32Type())|;|;   }|;|   if (src_ty == dst_ty) {|;|@@ -156,14 +158,21 @@ Value Cast(EmitterLocOpBuilder& b, Value value, Type dst_element_ty) {|;|     // because LLVM doesn't support casts from/to FP8.|;|     // TODO(b/266862493): Add end-to-end test once FP8 support lands in XLA as|;|     // we can't test the code below without patching the feature.|;|-    if (IsFp8Type(src_element_ty)) {|;|+    if (IsFp8Type(src_element_ty) && !IsFp8Type(dst_element_ty)) {|;|       return b.create<mt::FpToFpOp>(dst_ty, value)|;|;     }|;|-    if (IsFp8Type(dst_element_ty)) {|;|+    if (IsFp8Type(dst_element_ty) && !IsFp8Type(src_element_ty)) {|;|       return b.create<mt::FpToFpOp>(|;|           dst_ty, value,|;|           mt::RoundingModeAttr::get(b.getContext(), mt::RoundingMode::RTNE))|;|;     }|;|+    if (IsFp8Type(src_element_ty) && IsFp8Type(dst_element_ty)) {|;|+      // FP8 <-> FP8 conversion needs to go through FP16|;|+      auto fp16_value = b.create<mt::FpToFpOp>(fp16_ty, value)|;|;+      return b.create<mt::FpToFpOp>(|;|+          dst_ty, fp16_value,|;|+          mt::RoundingModeAttr::get(b.getContext(), mt::RoundingMode::RTNE))|;|;+    }|;| |;|     if (src_fp_element_ty.getFPMantissaWidth() >|;|         dst_fp_element_ty.getFPMantissaWidth()) { || PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc: @@ -4202,6 +4202,36 @@ ENTRY main {|;|   EXPECT_TRUE(RunAndCompare(hlo_text, ErrorSpec{/*aabs=*/1.0, /*arel=*/1e-3}))|;|; }|;| |;|+TEST_F(TritonTest, FP8ToFP8EndToEnd) {|;|+  if (!GetCudaComputeCapability().IsAtLeastHopper()) {|;|+    GTEST_SKIP() << ""Doesn't pass on pre-Hopper GPUs.""|;|;+  }|;|+|;|+  const std::string hlo_text = R""(|;|+HloModule t|;|+|;|+triton_dot {|;|+  parameter_0 = f8e5m2[32,32]{1,0} parameter(0)|;|+  parameter_1 = f8e4m3fn[32,32]{1,0} parameter(1)|;|+  convert = f8e4m3fn[32,32]{1,0} convert(parameter_0)|;|+  ROOT dot = f32[32,32]{1,0} dot(convert, parameter_1),|;|+                lhs_contracting_dims={1}, rhs_contracting_dims={1}|;|+}|;|+|;|+ENTRY main {|;|+  parameter_0 = f8e5m2[32,32]{1,0} parameter(0)|;|+  parameter_1 = f8e4m3fn[32,32]{1,0} parameter(1)|;|+  ROOT gemm_fusion_dot = f32[32,32]{1,0} fusion(parameter_0, parameter_1),|;|+       kind=kCustom, calls=triton_dot,|;|+       backend_config={|;|+       ""fusion_backend_config"":{""kind"":""__triton_gemm"",""triton_gemm_config"":|;|+         {""block_m"":""32"",""block_n"":""32"",""block_k"":""32"",""split_k"":""1"",|;|+          ""num_stages"":""1"",""num_warps"":""4"",""num_ctas"":""1""}}}|;|+})""|;|;+|;|+  EXPECT_TRUE(RunAndCompare(hlo_text, ErrorSpec{/*aabs=*/1.0, /*arel=*/1e-3}))|;|;+}|;|+|;| // Test PreventMmaV3LoopUnrolling pass in order to keep compile time low.|;| // See b/344841434.|;| TEST_F(TritonGemmTest, TestPreventMMAV3LoopUnrolling) { || PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc: @@ -2021,6 +2021,40 @@ ENTRY entry_computation {|;|   EXPECT_TRUE(RunAndCompareNoHloPasses(std::move(module), kExactMatch))|;|; }|;| |;|+TEST_F(TritonEmitterTest, FP8ToFP8EndToEnd) {|;|+  if (auto cc =|;|+          std::get_if<se::CudaComputeCapability>(&GpuComputeCapability())) {|;|+    if (!cc->IsAtLeastHopper()) {|;|+      GTEST_SKIP() << ""Doesn't pass on pre-Hopper GPUs.""|;|;+    }|;|+  }|;|+|;|+  const std::string hlo_text = R""(|;|+HloModule t|;|+|;|+triton_dot {|;|+  parameter_0 = f8e5m2[32,32]{1,0} parameter(0)|;|+  parameter_1 = f8e4m3fn[32,32]{1,0} parameter(1)|;|+  convert = f8e4m3fn[32,32]{1,0} convert(parameter_0)|;|+  ROOT dot = f32[32,32]{1,0} dot(convert, parameter_1),|;|+                lhs_contracting_dims={1}, rhs_contracting_dims={1}|;|+}|;|+|;|+ENTRY main {|;|+  parameter_0 = f8e5m2[32,32]{1,0} parameter(0)|;|+  parameter_1 = f8e4m3fn[32,32]{1,0} parameter(1)|;|+  ROOT gemm_fusion_dot = f32[32,32]{1,0} fusion(parameter_0, parameter_1),|;|+       kind=kCustom, calls=triton_dot,|;|+       backend_config={|;|+       ""fusion_backend_config"":{""kind"":""__triton_gemm"",""triton_gemm_config"":|;|+         {""block_m"":""32"",""block_n"":""32"",""block_k"":""32"",""split_k"":""1"",|;|+          ""num_stages"":""1"",""num_warps"":""4"",""num_ctas"":""1""}}}|;|+})""|;|;+|;|+  EXPECT_TRUE(RunAndCompareNoHloPasses(hlo_text,|;|+                                       ErrorSpec{/*aabs=*/1.0, /*arel=*/1e-3}))|;|;+}|;|+|;| TEST_F(TritonEmitterTest, SingleTileDotWithNestedFusionsIsEmittedCorrectly) {|;|   // Simplest case when everything fits into one tile that is useful for|;|   // debugging. This also tests support for empty nested fusions. || PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_legacy_matmul.cc: @@ -227,121 +227,6 @@ bool IsFp8Type(Type t) {|;|                    mlir::Float8E4M3B11FNUZType>(t)|;|; }|;| |;|-Value Cast(EmitterLocOpBuilder b, Value value, Type dst_element_ty) {|;|-  Type src_ty = value.getType()|;|;-  Type src_element_ty = src_ty|;|;-  Type fp32_ty = b.getF32Type()|;|;-  Type dst_ty = dst_element_ty|;|;-  if (auto src_shaped_ty = mlir::dyn_cast<ShapedType>(src_ty)) {|;|-    src_element_ty = src_shaped_ty.getElementType()|;|;-    dst_ty = src_shaped_ty.clone(src_shaped_ty.getShape(), dst_element_ty)|;|;-    fp32_ty = src_shaped_ty.clone(src_shaped_ty.getShape(), b.getF32Type())|;|;-  }|;|-  if (src_ty == dst_ty) {|;|-    return value|;|;-  }|;|-|;|-  // All operations on bf16 are done through f32.|;|-  if (src_element_ty.isBF16()) {|;|-    return Cast(b, b.create<ma::ExtFOp>(fp32_ty, value), dst_element_ty)|;|;-  }|;|-  if (dst_element_ty.isBF16()) {|;|-    // S8 -> BF16 is directly supported and doesn't need to go through f32.|;|-    if (!src_element_ty.isInteger(8)) {|;|-      return b.create<ma::TruncFOp>(dst_ty, Cast(b, value, b.getF32Type()))|;|;-    }|;|-  }|;|-|;|-  // float => float|;|-  auto src_fp_element_ty = mlir::dyn_cast<mlir::FloatType>(src_element_ty)|;|;-  auto dst_fp_element_ty = mlir::dyn_cast<mlir::FloatType>(dst_element_ty)|;|;-  if (src_fp_element_ty && dst_fp_element_ty) {|;|-    // F8 <-> FP16, BF16, FP32, FP64 need to be handled via Triton's tt.fp_to_fp|;|-    // because LLVM doesn't support casts from/to FP8.|;|-    // TODO(b/266862493): Add end-to-end test once FP8 support lands in XLA as|;|-    // we can't test the code below without patching the feature.|;|-    if (IsFp8Type(src_element_ty)) {|;|-      return b.create<mt::FpToFpOp>(dst_ty, value)|;|;-    }|;|-    if (IsFp8Type(dst_element_ty)) {|;|-      return b.create<mt::FpToFpOp>(|;|-          dst_ty, value,|;|-          mt::RoundingModeAttr::get(b.getContext(), mt::RoundingMode::RTNE))|;|;-    }|;|-|;|-    if (src_fp_element_ty.getFPMantissaWidth() >|;|-        dst_fp_element_ty.getFPMantissaWidth()) {|;|-      return b.create<ma::TruncFOp>(dst_ty, value)|;|;-    } else {|;|-      return b.create<ma::ExtFOp>(dst_ty, value)|;|;-    }|;|-  }|;|-  // int => int|;|-  if (mlir::isa<mlir::IntegerType>(src_element_ty) &&|;|-      mlir::isa<mlir::IntegerType>(dst_element_ty)) {|;|-    if (src_element_ty.getIntOrFloatBitWidth() <|;|-        dst_element_ty.getIntOrFloatBitWidth()) {|;|-      if (src_element_ty.isInteger(1)) {|;|-        return b.create<ma::ExtUIOp>(dst_ty, value)|;|;-      }|;|-      return b.create<ma::ExtSIOp>(dst_ty, value)|;|;-    }|;|-    return b.create<ma::TruncIOp>(dst_ty, value)|;|;-  }|;|-  // int => float|;|-  if (mlir::isa<mlir::IntegerType>(src_element_ty) && dst_fp_element_ty) {|;|-    // TODO(b/266862493): Support unsigned integer types.|;|-    if (src_element_ty.isInteger(1)) {|;|-      return b.create<ma::UIToFPOp>(dst_ty, value)|;|;-    }|;|-    return b.create<ma::SIToFPOp>(dst_ty, value)|;|;-  }|;|-  // float => int|;|-  if (src_fp_element_ty && mlir::isa<mlir::IntegerType>(dst_element_ty)) {|;|-    if (dst_element_ty.isInteger(1)) {|;|-      return b.create<ma::CmpFOp>(ma::CmpFPredicate::UNE, value,|;|-                                  ZerosLike(b, value))|;|;-    }|;|-    // TODO(b/266862493): Support unsigned integer types.|;|-    // The current logic handles signed integer types only. Additional handling|;|-    // is needed for unsigned integer types.|;|-    auto cst_int = [&](EmitterLocOpBuilder b, int64_t x) {|;|-      if (auto src_shaped_ty = mlir::dyn_cast<ShapedType>(src_ty)) {|;|-        return CreateConst(b, dst_element_ty, x, src_shaped_ty.getShape())|;|;-      } else {|;|-        return CreateConst(b, dst_element_ty, x)|;|;-      }|;|-    }|;|;-    auto cst_float = [&](EmitterLocOpBuilder b, int64_t x) {|;|-      if (auto src_shaped_ty = mlir::dyn_cast<ShapedType>(src_ty)) {|;|-        return CreateConst(b, src_fp_element_ty, x, src_shaped_ty.getShape())|;|;-      } else {|;|-        return CreateConst(b, src_fp_element_ty, x)|;|;-      }|;|-    }|;|;-    auto fptosi = b.create<ma::FPToSIOp>(dst_ty, value)|;|;-    int64_t min = llvm::minIntN(dst_element_ty.getIntOrFloatBitWidth())|;|;-    int64_t max = llvm::maxIntN(dst_element_ty.getIntOrFloatBitWidth())|;|;-|;|-    // value <= static_cast<float>(INT_MIN) ? INT_MIN : ...|;|-    auto clamped = b.create<ma::SelectOp>(|;|-        b.create<ma::CmpFOp>(ma::CmpFPredicate::OLE, value, cst_float(b, min)),|;|-        cst_int(b, min), fptosi)|;|;-    // value >= static_cast<float>(INT_MAX) ? INT_MAX : ...|;|-    clamped = b.create<ma::SelectOp>(|;|-        b.create<ma::CmpFOp>(ma::CmpFPredicate::OGE, value, cst_float(b, max)),|;|-        cst_int(b, max), clamped)|;|;-    // isnan(value) ? 0 : ...|;|-    return b.create<ma::SelectOp>(|;|-        b.create<ma::CmpFOp>(ma::CmpFPredicate::UNO, value, value),|;|-        cst_int(b, 0), clamped)|;|;-  }|;|-|;|-  LOG(FATAL) << ""Type conversion not supported: ""|;|-             << llvm_ir::DumpToString(src_element_ty) << "" -> ""|;|-             << llvm_ir::DumpToString(dst_element_ty)|;|;-}|;|-|;| Value Subtract(EmitterLocOpBuilder b, ValueRange values) {|;|   if (mlir::isa<mlir::IntegerType>(mlir::getElementTypeOrSelf(values[0]))) {|;|     return b.create<ma::SubIOp>(values[0], values[1])|;|;@@ -448,7 +333,7 @@ absl::StatusOr<Value> EmitElementwise(EmitterLocOpBuilder b,|;|     case HloOpcode::kConvert: {|;|       TF_ASSIGN_OR_RETURN(Type dst_ty,|;|                           TritonType(b, hlo.shape().element_type()))|;|;-      return Cast(b, inputs[0], dst_ty)|;|;+      return triton::Cast(b, inputs[0], dst_ty)|;|;     }|;|     case HloOpcode::kAdd:|;|       if (is_integer) {|;|@@ -661,7 +546,7 @@ absl::StatusOr<Value> EmitScope(|;|     if (hlo->opcode() == HloOpcode::kConvert &&|;|         hlo->operand(0)->shape().element_type() == S4) {|;|       Value unpacked|;|;-      unpacked = Cast(b, values[hlo->operand(0)], b.getI8Type())|;|;+      unpacked = triton::Cast(b, values[hlo->operand(0)], b.getI8Type())|;|;       std::vector<Value> operands({unpacked})|;|;       TF_ASSIGN_OR_RETURN(result, EmitElementwise(b, libdevice_path,|;|                                                   device_info, *hlo, operands))|;|;@@ -817,7 +702,7 @@ ma::ConstantOp Cst64(EmitterLocOpBuilder b, int64_t v) {|;| }|;| |;| Value RoundToBF16(EmitterLocOpBuilder b, Value input) {|;|-  return Cast(b, input, b.getBF16Type())|;|;+  return triton::Cast(b, input, b.getBF16Type())|;|; }|;|; |;| /*static*/ absl::StatusOr<MatMulDims> MatMulDims::Create(|;|@@ -1480,7 +1365,7 @@ class MatMulEmitterHelper {|;|           ""64 bit dynamic-slice indices are not supported yet."")|;|;     }|;|     majormost_dim_start_index_val =|;|-        Cast(b, majormost_dim_start_index_val, b.getI32Type())|;|;+        triton::Cast(b, majormost_dim_start_index_val, b.getI32Type())|;|;     majormost_dim_start_index_val =|;|         b.create<ma::MaxSIOp>(majormost_dim_start_index_val, Cst32(b, 0))|;|;     majormost_dim_start_index_val =|;|@@ -2041,7 +1926,7 @@ class IterableInput {|;|     Value param_value = EmitParameterLoad(b, args.front(), boundary_checks_)|;|;     if (type_ != storage_type_) {|;|       // For example cast i8 to i1.|;|-      param_value = Cast(b, param_value, type_)|;|;+      param_value = triton::Cast(b, param_value, type_)|;|;     }|;|     return param_value|;|;   }|;|@@ -2167,10 +2052,10 @@ Value EmitRegularMatmul(EmitterLocOpBuilder& b, Value lhs, Value rhs, Value acc,|;|   if (dot_instr->precision_config().algorithm() ==|;|       PrecisionConfig::ALG_DOT_BF16_BF16_F32) {|;|     if (dot_instr->operand(0)->shape().element_type() == F32) {|;|-      lhs = Cast(b, lhs, b.getBF16Type())|;|;+      lhs = triton::Cast(b, lhs, b.getBF16Type())|;|;     }|;|     if (dot_instr->operand(1)->shape().element_type() == F32) {|;|-      rhs = Cast(b, rhs, b.getBF16Type())|;|;+      rhs = triton::Cast(b, rhs, b.getBF16Type())|;|;     }|;|   }|;| |;|@@ -2364,7 +2249,7 @@ absl::StatusOr<std::optional<stream_executor::gpu::TmaMetadata>> EmitMatMul(|;|   absl::flat_hash_map<const HloInstruction*, Value> values_out|;|;   TF_ASSIGN_OR_RETURN(Type acc_final_ty,|;|                       TritonType(b, dot_instr->shape().element_type()))|;|;-  values_out[dot_instr] = Cast(b, acc_final, acc_final_ty)|;|;+  values_out[dot_instr] = triton::Cast(b, acc_final, acc_final_ty)|;|; |;|   // Emit the output scope.|;|   if (std::vector<const HloInstruction*> to_emit = || PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/support.cc: @@ -130,10 +130,13 @@ CodegenDecision IsTritonSupportedConversion(|;|     return error_message()|;|;   }|;| |;|-  if (input != output &&|;|-      (any_is(PrimitiveType::F8E4M3FN) || any_is(PrimitiveType::F8E5M2)) &&|;|-      !(any_is(PrimitiveType::F16) || any_is(PrimitiveType::BF16) |||;|-        any_is(PrimitiveType::F32))) {|;|+  bool is_f8_conversion =|;|+      any_is(PrimitiveType::F8E4M3FN) && any_is(PrimitiveType::F8E5M2)|;|;+  bool is_f8 = any_is(PrimitiveType::F8E4M3FN) || any_is(PrimitiveType::F8E5M2)|;|;+  bool is_f16_or_f32 = any_is(PrimitiveType::F16) |||;|+                       any_is(PrimitiveType::BF16) |||;|+                       any_is(PrimitiveType::F32)|;|;+  if (input != output && is_f8 && !is_f8_conversion && !is_f16_or_f32) {|;|     return error_message()|;|;   }|;|  || PR#90124 - third_party/xla/xla/backends/gpu/codegen/triton/support_test.cc: @@ -410,11 +410,13 @@ ENTRY triton_computation {|;|     skip_failure_branch_to_avoid_crash |=|;|         (data_type_in == PrimitiveType::F8E4M3FN &&|;|          data_type_out == PrimitiveType::F64)|;|;+|;|+    skip_failure_branch_to_avoid_crash |=|;|+        any_is(PrimitiveType::F8E4M3FN) && any_is(PrimitiveType::F8E5M2)|;|;   }|;| |;|   // Crashes due to unsupported/unspecified rounding mode.|;|   skip_failure_branch_to_avoid_crash |=|;|-      (any_is(PrimitiveType::F8E4M3FN) && any_is(PrimitiveType::F8E5M2)) |||;|       (data_type_in == PrimitiveType::F64 &&|;|        (data_type_out == PrimitiveType::F8E4M3FN |||;|         data_type_out == PrimitiveType::F8E5M2));","PR #24114: Triton/Nvidia: Fix fused fp8 <-> fp8 conversions

Imported from GitHub PR https://github.com/openxla/xla/pull/24114

Converting FP8 <-> FP8 fails because the Triton compiler does not support it.
The proposed fix will make the conversion go through FP16.

Two questions:
1) Are there any better approaches of solving this?
2) I could not find a place to put unit tests for this, and in the code there is a comment saying:
    ```
        // TODO(b/266862493): Add end-to-end test once FP8 support lands in XLA as
        // we can't test the code below without patching the feature.
    ```
    Wondering if there is a place where I can add a test?

### Details
When converting FP8 types, the XLA compiler emits a `fp_to_fp` Triton instruction. If the source type is FP8, no rounding strategy is specified.

Concretely, this causes the following Triton to be emitted:
<details>
<summary>
<code>%24 = tt.fp_to_fp %20 : tensor<32x64xf8E5M2> -> tensor<32x64xf8E4M3FN></code>
</summary>

```
module {
  tt.func @gemm_fusion_dot_320_impl(%arg0: !tt.ptr<f8E4M3FN> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f8E5M2> {tt.divisibility = 16 : i32}, %arg2: !tt.ptr<f8E4M3FN> {tt.divisibility = 16 : i32}) {
    %cst = arith.constant dense<0.000000e+00> : tensor<64x64xf8E4M3FN>
    %cst_0 = arith.constant dense<0.000000e+00> : tensor<32x64xf8E4M3FN>
    %c90_i32 = arith.constant 90 : i32
    %c32000_i64 = arith.constant 32000 : i64
    %c64_i32 = arith.constant 64 : i32
    %c90_i64 = arith.constant 90 : i64
    %c768_i64 = arith.constant 768 : i64
    %c0_i32 = arith.constant 0 : i32
    %c1_i64 = arith.constant 1 : i64
    %c32_i32 = arith.constant 32 : i32
    %c24_i32 = arith.constant 24 : i32
    %c8_i32 = arith.constant 8 : i32
    %c4000_i32 = arith.constant 4000 : i32
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<32x64xf32>
    %0 = tt.get_program_id x : i32
    %1 = arith.divsi %0, %c4000_i32 : i32
    %2 = arith.muli %1, %c8_i32 : i32
    %3 = arith.subi %c24_i32, %2 : i32
    %4 = arith.cmpi slt, %3, %c8_i32 : i32
    %5 = arith.select %4, %3, %c8_i32 : i32
    %6 = arith.remsi %0, %5 : i32
    %7 = arith.addi %2, %6 : i32
    %8 = arith.remsi %0, %c4000_i32 : i32
    %9 = arith.divsi %8, %5 : i32
    %10 = arith.muli %7, %c32_i32 : i32
    %11 = tt.make_tensor_ptr %arg1, [%c768_i64, %c90_i64], [%c1_i64, %c768_i64], [%c0_i32, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x64xf8E5M2>>
    %12 = tt.advance %11, [%10, %c0_i32] : <tensor<32x64xf8E5M2>>
    %13 = arith.muli %9, %c64_i32 : i32
    %14 = tt.make_tensor_ptr %arg0, [%c90_i64, %c32000_i64], [%c1_i64, %c90_i64], [%c0_i32, %c0_i32] {order = array<i32: 1, 0>} : <tensor<64x64xf8E4M3FN>>
    %15 = tt.advance %14, [%c0_i32, %13] : <tensor<64x64xf8E4M3FN>>
    %16:3 = scf.for %arg3 = %c0_i32 to %c90_i32 step %c64_i32 iter_args(%arg4 = %12, %arg5 = %15, %arg6 = %cst_1) -> (!tt.ptr<tensor<32x64xf8E5M2>>, !tt.ptr<tensor<64x64xf8E4M3FN>>, tensor<32x64xf32>)  : i32 {
      %20 = tt.load %arg4 {boundaryCheck = array<i32: 1>, padding = 1 : i32} : !tt.ptr<tensor<32x64xf8E5M2>>
      %21 = tt.advance %arg4, [%c0_i32, %c64_i32] : <tensor<32x64xf8E5M2>>
      %22 = tt.load %arg5 {boundaryCheck = array<i32: 0>, padding = 1 : i32} : !tt.ptr<tensor<64x64xf8E4M3FN>>
      %23 = tt.advance %arg5, [%c64_i32, %c0_i32] : <tensor<64x64xf8E4M3FN>>
      %24 = tt.fp_to_fp %20 : tensor<32x64xf8E5M2> -> tensor<32x64xf8E4M3FN>
      %25 = arith.subi %c90_i32, %arg3 : i32
      %26 = arith.cmpi slt, %25, %c64_i32 : i32
      %27 = scf.if %26 -> (tensor<32x64xf8E4M3FN>) {
        %30 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32>
        %31 = tt.expand_dims %30 {axis = 0 : i32} : tensor<64xi32> -> tensor<1x64xi32>
        %32 = tt.splat %25 : i32 -> tensor<1x64xi32>
        %33 = arith.cmpi slt, %31, %32 : tensor<1x64xi32>
        %34 = tt.broadcast %33 : tensor<1x64xi1> -> tensor<32x64xi1>
        %35 = arith.select %34, %24, %cst_0 : tensor<32x64xi1>, tensor<32x64xf8E4M3FN>
        scf.yield %35 : tensor<32x64xf8E4M3FN>
      } else {
        scf.yield %24 : tensor<32x64xf8E4M3FN>
      }
      %28 = scf.if %26 -> (tensor<64x64xf8E4M3FN>) {
        %30 = tt.make_range {end = 64 : i32, start = 0 : i32} : tensor<64xi32>
        %31 = tt.expand_dims %30 {axis = 1 : i32} : tensor<64xi32> -> tensor<64x1xi32>
        %32 = tt.splat %25 : i32 -> tensor<64x1xi32>
        %33 = arith.cmpi slt, %31, %32 : tensor<64x1xi32>
        %34 = tt.broadcast %33 : tensor<64x1xi1> -> tensor<64x64xi1>
        %35 = arith.select %34, %22, %cst : tensor<64x64xi1>, tensor<64x64xf8E4M3FN>
        scf.yield %35 : tensor<64x64xf8E4M3FN>
      } else {
        scf.yield %22 : tensor<64x64xf8E4M3FN>
      }
      %29 = tt.dot %27, %28, %arg6, inputPrecision = tf32 {maxNumImpreciseAcc = 2147483647 : i32} : tensor<32x64xf8E4M3FN> * tensor<64x64xf8E4M3FN> -> tensor<32x64xf32>
      scf.yield %21, %23, %29 : !tt.ptr<tensor<32x64xf8E5M2>>, !tt.ptr<tensor<64x64xf8E4M3FN>>, tensor<32x64xf32>
    }
    %17 = tt.fp_to_fp %16#2, rounding = rtne : tensor<32x64xf32> -> tensor<32x64xf8E4M3FN>
    %18 = tt.make_tensor_ptr %arg2, [%c768_i64, %c32000_i64], [%c1_i64, %c768_i64], [%c0_i32, %c0_i32] {order = array<i32: 1, 0>} : <tensor<32x64xf8E4M3FN>>
    %19 = tt.advance %18, [%10, %13] : <tensor<32x64xf8E4M3FN>>
    tt.store %19, %17 : !tt.ptr<tensor<32x64xf8E4M3FN>>
    tt.return
  }
}
```
</details>

Which leads to a failing assertion:
```
#0  0x000073413786d9fc in pthread_kill () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x0000734137819476 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x00007341377ff7f3 in abort () from /lib/x86_64-linux-gnu/libc.so.6
#3  0x00007341377ff71b in ?? () from /lib/x86_64-linux-gnu/libc.so.6
#4  0x0000734137810e96 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6
#5  0x000057d936b1777b in mlir::triton::gpu::(anonymous namespace)::FpToFpOpConversion::createDestOps (this=0x733d08425cc0, op=..., adaptor=..., rewriter=..., elemTy=..., operands=..., loc=...)
    at external/triton/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/ElementwiseOpToLLVM.cpp:500
#6  0x000057d936b17195 in mlir::triton::gpu::ElementwiseOpConversionBase<mlir::triton::FpToFpOp, mlir::triton::gpu::(anonymous namespace)::FpToFpOpConversion>::matchAndRewrite (this=0x733d08425cc0, op=..., adaptor=..., rewriter=...)
    at external/triton/include/triton/Conversion/TritonGPUToLLVM/ElementwiseOpToLLVMBase.h:188
[...]
#29 0x000057d93fa6cade in mlir::PassManager::run (this=0x733e80fba158, op=0x733d080bbc20) at external/llvm-project/mlir/lib/Pass/Pass.cpp:885
#30 0x000057d9363f6b1b in xla::gpu::CompileTritonToLLVM (hlo_config=..., hlo_module_name=""gemm_fusion_dot.320"", device_info=..., block_level_parameters=..., triton_module=..., llvm_module=0x733d0816d6a0, mlir_context=..., is_xla_fusion=true, emit_kernel=true)
    at xla/backends/gpu/codegen/triton/fusion_emitter.cc:1627
#31 0x000057d9363f5a5d in xla::gpu::TritonWrapper (fn_name=""gemm_fusion_dot_320_impl"", fusion=0x733d080a31c0, cc=std::variant<stream_executor::CudaComputeCapability, stream_executor::RocmComputeCapability> [index 0] = {...}, device_info=..., block_level_parameters=...,
    llvm_module=0x733d0816d6a0, mlir_context=...) at xla/backends/gpu/codegen/triton/fusion_emitter.cc:1531
```

However, this fails Triton compilation:
* First it hits an assertion that the rounding strategy when the destination type is FP8 must be specified
* Adding the rounding strategy, then goes on to another issue, that no methods for converting FP8 <-> FP8 are specified

To work around the above two issues, I propose going through FP16 when both the source and destination types are FP8's.
Copybara import of the project:

--
afd3929099fc4d1045275ca3210e0bc727a2b906 by Kasper Nielsen <kasper0406@gmail.com>:

Fix fused fp8 <-> fp8 conversions

--
66340aa808f58e5dc6ab1c2e06790ceccde95540 by Kasper Nielsen <kasper0406@gmail.com>:

Add unit tests and refactor duplicated code

--
07ae307879eff24ad2f85607e94503deda1074e4 by Kasper Nielsen <kasper0406@gmail.com>:

Run clang-format

--
fe967ff94ffc5f34f07bff142b5d10d81d5e4dce by Kasper Nielsen <kasper0406@gmail.com>:

Fix support conversion tests

Merging this change closes #24114

PiperOrigin-RevId: 741473648"
tensorflow/tensorflow,tyb0807,24086,[Intel MKL] Adding support to handle FusedConv2D,"This commit adds support to handle Grappler-fused Conv2D operators
in MKL layout pass.

Some changes are from clang format check, and not related to handling
of fusion.","I am closing this PR temporarily until we figure out internal logistics. Sorry for trouble. || Opening up again.. || @penpornk Thanks for comments. I have addressed all of them. Pls take a look. || @penpornk Thanks. Pls take a look. || @penpornk Thanks for feedback. Pls take a look.
 || Hi @penpornk thanks for approving. I am not able to access the log for Windows bagel build failure - not sure if it is related to my PR also. || @nhasabni No worries! Those are existing failures. This PR has already been pulled in and is getting merged.",closed,2018-12-01T00:14:56+00:00,2018-12-12T01:24:07+00:00,nhasabni,"cla: yes, ready to pull",1,"PR#90156 - third_party/xla/xla/service/spmd/gather_scatter_handler.cc: @@ -193,6 +193,20 @@ std::vector<int64_t> GatherOutputDimsByPriority(|;|   return priority_dims_for_output|;|; }|;| |;|+template <typename T>|;|+HloInstruction* CreateMaxIndicesConstant(|;|+    const Shape& operand_base_shape, absl::Span<const int64_t> start_index_map,|;|+    SpmdBuilder* b) {|;|+  std::vector<T> max_indices_values|;|;+  max_indices_values.reserve(start_index_map.size())|;|;+  for (int64_t operand_dim : start_index_map) {|;|+    max_indices_values.push_back(|;|+        static_cast<T>(operand_base_shape.dimensions(operand_dim) - 1))|;|;+  }|;|+  return b->AddInstruction(HloInstruction::CreateConstant(|;|+      LiteralUtil::CreateR1<T>(max_indices_values)))|;|;+}|;|+|;| PartitionedHlo ClampGatherIndices(const PartitionedHlo& indices,|;|                                   const Shape& operand_base_shape,|;|                                   absl::Span<const int64_t> start_index_map,|;|@@ -201,14 +215,19 @@ PartitionedHlo ClampGatherIndices(const PartitionedHlo& indices,|;| |;|   HloInstruction* max_indices|;|;   if (index_vector_dim < indices.num_dimensions()) {|;|-    std::vector<int32_t> max_indices_values|;|;-    max_indices_values.reserve(start_index_map.size())|;|;-    for (int64_t operand_dim : start_index_map) {|;|-      max_indices_values.push_back(operand_base_shape.dimensions(operand_dim) -|;|-                                   1)|;|;+    switch (indices_type) {|;|+      case S32:|;|+        max_indices = CreateMaxIndicesConstant<int32_t>(operand_base_shape,|;|+                                                        start_index_map, b)|;|;+        break|;|;+      case S64:|;|+        max_indices = CreateMaxIndicesConstant<int64_t>(operand_base_shape,|;|+                                                        start_index_map, b)|;|;+        break|;|;+      default:|;|+        LOG(FATAL) << ""Unsupported indices type: ""|;|+                   << PrimitiveType_Name(indices_type)|;|;     }|;|-    max_indices = b->AddInstruction(HloInstruction::CreateConstant(|;|-        LiteralUtil::CreateR1<int32_t>(max_indices_values)))|;|;     max_indices = b->AddInstruction(HloInstruction::CreateBroadcast(|;|         indices.hlo()->shape(), max_indices, {index_vector_dim}))|;|;   } else { || PR#90156 - third_party/xla/xla/service/spmd/spmd_partitioner.cc: @@ -3860,6 +3860,12 @@ absl::Status SpmdPartitioningVisitor::HandleDynamicUpdateSlice(|;|       auto per_partition_size_hlo = add_hlo(HloInstruction::CreateConstant(|;|           LiteralUtil::CreateR0<int>(per_partition_size)))|;|;       const Shape& offset_shape = per_partition_size_hlo->shape()|;|;+      const Shape& index_shape = new_indices[dim]->shape()|;|;+      if (offset_shape.element_type() != index_shape.element_type())|;|+        new_indices[dim] = add_hlo(HloInstruction::CreateConvert(|;|+            ShapeUtil::ChangeElementType(index_shape,|;|+                                         offset_shape.element_type()),|;|+            new_indices[dim]))|;|;       auto partition_offset = add_hlo(HloInstruction::CreateBinary(|;|           offset_shape, HloOpcode::kMultiply, partition_ordinals[dim],|;|           per_partition_size_hlo))|;|;@@ -3897,6 +3903,12 @@ absl::Status SpmdPartitioningVisitor::HandleDynamicUpdateSlice(|;|               partition_offset)),|;|           add_hlo(|;|               HloInstruction::CreateConstant(LiteralUtil::CreateR0<int>(0)))))|;|;+      if (new_indices[dim]->shape().element_type() !=|;|+          index_shape.element_type())|;|+        new_indices[dim] = add_hlo(HloInstruction::CreateConvert(|;|+            ShapeUtil::ChangeElementType(new_indices[dim]->shape(),|;|+                                         index_shape.element_type()),|;|+            new_indices[dim]))|;|;     }|;| |;|     // Create dynamic update slice.","PR #24086: Fix element type mismatch from ClampGatherIndices

Imported from GitHub PR https://github.com/openxla/xla/pull/24086

Copybara import of the project:

--
53f1acd286f095058022bb74d8ae58e14205ebda by tyb0807 <sontuan.vu119@gmail.com>:

Fix element type mismatch from ClampGatherIndices

--
385f23d2fabfde468433182e79ac15fc411fde82 by tyb0807 <sontuan.vu119@gmail.com>:

Fix element type mismatch for DUS indices in SPMD

Merging this change closes #24086

PiperOrigin-RevId: 741410709"
tensorflow/tensorflow,terryysun,23522,Conversion from pb to tflite fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.11.0-0-gc19e29306c
- Python version: python 3.5
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: only CPU
- GPU model and memory: - 

**Describe the current behavior**
I built a Neural network with the following code:

```
import tensorflow as tf
import numpy as np


class AlexNet(object):
    """"""Implementation of the AlexNet.""""""

    def __init__(self, x, keep_prob, num_classes, skip_layer,
                 weights_path='DEFAULT'):
        """"""Create the graph of the AlexNet model.
        Args:
            x: Placeholder for the input tensor.
            keep_prob: Dropout probability.
            num_classes: Number of classes in the dataset.
            skip_layer: List of names of the layer, that get trained from
                scratch
            weights_path: Complete path to the pretrained weight file, if it
                isn't in the same folder as this code
        """"""
        # Parse input arguments into class variables
        self.X = x
        self.NUM_CLASSES = num_classes
        self.KEEP_PROB = keep_prob
        self.SKIP_LAYER = skip_layer

        if weights_path == 'DEFAULT':
            self.WEIGHTS_PATH = 'bvlc_alexnet.npy'
        else:
            self.WEIGHTS_PATH = weights_path

        # Call the create function to build the computational graph of AlexNet
        self.create()

    def create(self):
        """"""Create the network graph.""""""
        # 1st Layer: Conv (w ReLu) -> Lrn -> Pool
        conv1 = conv(self.X, 11, 11, 96, 4, 4, padding='VALID', name='conv1')
        norm1 = lrn(conv1, 2, 2e-05, 0.75, name='norm1')
        pool1 = max_pool(norm1, 3, 3, 2, 2, padding='VALID', name='pool1')

        # 2nd Layer: Conv (w ReLu)  -> Lrn -> Pool with 2 groups
        conv2 = conv(pool1, 5, 5, 256, 1, 1, groups=2, name='conv2')
        norm2 = lrn(conv2, 2, 2e-05, 0.75, name='norm2')
        pool2 = max_pool(norm2, 3, 3, 2, 2, padding='VALID', name='pool2')

        # 3rd Layer: Conv (w ReLu)
        self.conv3 = conv(pool2, 3, 3, 384, 1, 1, name='conv3')

        # 4th Layer: Conv (w ReLu) splitted into two groups
        conv4 = conv(self.conv3, 3, 3, 384, 1, 1, groups=2, name='conv4')

        # 5th Layer: Conv (w ReLu) -> Pool splitted into two groups
        conv5 = conv(conv4, 3, 3, 256, 1, 1, groups=2, name='conv5')
        self.pool5 = max_pool(conv5, 3, 3, 2, 2, padding='VALID', name='pool5')

        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout
        flattened = tf.reshape(self.pool5, [-1, 6*6*256])
        fc6 = fc(flattened, 6*6*256, 4096, name='fc6')
        dropout6 = dropout(fc6, self.KEEP_PROB)

        # 7th Layer: FC (w ReLu) -> Dropout
        fc7 = fc(dropout6, 4096, 4096, name='fc7')
        dropout7 = dropout(fc7, self.KEEP_PROB)

        # 8th Layer: FC and return unscaled activations
        self.fc8 = fc(dropout7, 4096, self.NUM_CLASSES, relu=False, name='fc8')

    def load_initial_weights(self, session):
        """"""Load weights from file into network.
        As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/
        come as a dict of lists (e.g. weights['conv1'] is a list) and not as
        dict of dicts (e.g. weights['conv1'] is a dict with keys 'weights' &
        'biases') we need a special load function
        """"""
        # Load the weights into memory
        weights_dict = np.load(self.WEIGHTS_PATH, encoding='bytes').item()

        # Loop over all layer names stored in the weights dict
        for op_name in weights_dict:

            # Check if layer should be trained from scratch
            if op_name not in self.SKIP_LAYER:

                with tf.variable_scope(op_name, reuse=True):

                    # Assign weights/biases to their corresponding tf variable
                    for data in weights_dict[op_name]:

                        # Biases
                        if len(data.shape) == 1:
                            var = tf.get_variable('biases', trainable=False)
                            session.run(var.assign(data))

                        # Weights
                        else:
                            var = tf.get_variable('weights', trainable=False)
                            session.run(var.assign(data))


def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,
         padding='SAME', groups=1):
    """"""Create a convolution layer.
    Adapted from: https://github.com/ethereon/caffe-tensorflow
    """"""
    # Get number of input channels
    input_channels = int(x.get_shape()[-1])

    # Create lambda function for the convolution
    convolve = lambda i, k: tf.nn.conv2d(i, k,
                                         strides=[1, stride_y, stride_x, 1],
                                         padding=padding)

    with tf.variable_scope(name) as scope:
        # Create tf variables for the weights and biases of the conv layer
        weights = tf.get_variable('weights', shape=[filter_height,
                                                    filter_width,
                                                    input_channels/groups,
                                                    num_filters])
        biases = tf.get_variable('biases', shape=[num_filters])

    if groups == 1:
        conv = convolve(x, weights)

    # In the cases of multiple groups, split inputs & weights and
    else:
        # Split input and weights and convolve them separately
        input_groups = tf.split(axis=3, num_or_size_splits=groups, value=x)
        weight_groups = tf.split(axis=3, num_or_size_splits=groups,
                                 value=weights)
        output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]

        # Concat the convolved output together again
        conv = tf.concat(axis=3, values=output_groups)

    # Add biases
    bias = tf.reshape(tf.nn.bias_add(conv, biases), tf.shape(conv))

    # Apply relu function
    relu = tf.nn.relu(bias, name=scope.name)

    return relu


def fc(x, num_in, num_out, name, relu=True):
    """"""Create a fully connected layer.""""""
    with tf.variable_scope(name) as scope:

        # Create tf variables for the weights and biases
        weights = tf.get_variable('weights', shape=[num_in, num_out],
                                  trainable=True)
        biases = tf.get_variable('biases', [num_out], trainable=True)

        # Matrix multiply weights and inputs and add bias
        act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)

    if relu:
        # Apply ReLu non linearity
        relu = tf.nn.relu(act)
        return relu
    else:
        return act


def max_pool(x, filter_height, filter_width, stride_y, stride_x, name,
             padding='SAME'):
    """"""Create a max pooling layer.""""""
    return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],
                          strides=[1, stride_y, stride_x, 1],
                          padding=padding, name=name)


def lrn(x, radius, alpha, beta, name, bias=1.0):
    """"""Create a local response normalization layer.""""""
    return tf.nn.local_response_normalization(x, depth_radius=radius,
                                              alpha=alpha, beta=beta,
                                              bias=bias, name=name)


def dropout(x, keep_prob):
    """"""Create a dropout layer.""""""
    return tf.nn.dropout(x, keep_prob)
```
I loaded the weights from a .npy file and saved the resulting pb file. I saved the resulting pb file with this code:
from tensorflow.python.tools import freeze_graph

```
SAVED_MODEL_PATH = ""save_path/""
MODEL_NAME = ""cut_net_pool5""

input_graph = SAVED_MODEL_PATH + MODEL_NAME + '.pb'
# any other saver to use other than default
input_saver = """"
# earlier definition file format text or binary
input_binary = True
# checkpoint file to merge with graph definition
input_checkpoint = SAVED_MODEL_PATH + MODEL_NAME + '.ckpt'
# output nodes inn our model
output_node_names = 'output'
restore_op_name = 'save/restore_all'
filename_tensor_name = 'save/Const:0'
# output path
output_graph = SAVED_MODEL_PATH + '2frozen_' + MODEL_NAME + '.pb'
# default True
clear_devices = True
initializer_nodes = """"
variable_names_blacklist = """"

freeze_graph.freeze_graph(
    input_graph,
    input_saver,
    input_binary,
    input_checkpoint,
    output_node_names,
    restore_op_name,
    filename_tensor_name,
    output_graph,
    clear_devices,
    initializer_nodes,
    variable_names_blacklist
)
```


**Describe the expected behavior**
I tried to export the resulting .pb file to tflite via this command in the terminal:

`tflite_convert --output_file=test.tflite --graph_def_file=frozen.pb --input_arrays=Placeholder --output_arrays=output `

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
The command fails with the following message:

`tensorflow/contrib/lite/toco/tooling_util.cc:981] Check failed: name.substr(colon_pos +1).find_first_not_of(""0123456789"") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon\nAborted (core dumped)\n`
",This works now with regard to issue #22897 ,closed,2018-11-05T11:40:21+00:00,2018-11-15T10:17:17+00:00,Noltibus,comp:lite,1,"PR#90155 - third_party/xla/xla/service/collective_ops_utils.cc: @@ -158,6 +158,36 @@ absl::StatusOr<std::vector<int>> GetParticipatingIDs(|;|                           group->replica_ids().end())|;|; }|;| |;|+absl::StatusOr<std::vector<std::vector<int64_t>>> GetAsyncReplicaGroups(|;|+    const HloInstruction* instruction) {|;|+  std::vector<std::vector<int64_t>> replica_groups|;|;+  if (instruction->opcode() == HloOpcode::kCollectivePermuteStart) {|;|+    absl::c_transform(instruction->source_target_pairs(),|;|+                      std::back_inserter(replica_groups),|;|+                      [](const std::pair<int64_t, int64_t>& pair) {|;|+                        std::vector<int64_t> ids({pair.first, pair.second})|;|;+                        return ids|;|;+                      })|;|;+  } else if (instruction->IsAsynchronous() |||;|+             instruction->opcode() == HloOpcode::kAllGatherStart |||;|+             instruction->opcode() == HloOpcode::kAllReduceStart) {|;|+    absl::c_transform(|;|+        instruction->replica_groups(), std::back_inserter(replica_groups),|;|+        [](const ReplicaGroup& group) {|;|+          std::vector<int64_t> ids|;|;+          absl::c_transform(group.replica_ids(), std::back_inserter(ids),|;|+                            [](auto id) { return id; })|;|;+          return ids|;|;+        })|;|;+  } else {|;|+    return InvalidArgument(|;|+        ""Unexpected instruction type: %s is not an async collective ""|;|+        ""instruction"",|;|+        instruction->ToString())|;|;+  }|;|+  return replica_groups|;|;+}|;|+|;| absl::StatusOr<CollectiveOpGroupMode> GetCollectiveOpGroupMode(|;|     const HloInstruction* instr) {|;|   if (auto collective = DynCast<HloAllGatherInstruction>(instr)) {|;|@@ -742,6 +772,52 @@ bool IsCollective(const HloInstruction* instruction) {|;|   return false|;|; }|;| |;|+absl::StatusOr<bool> IsAsyncCollective(const HloInstruction* instruction) {|;|+  if (!IsNonFusionCollective(instruction)) {|;|+    return false|;|;+  }|;|+  if (instruction->IsAsynchronous()) {|;|+    switch (instruction->async_wrapped_opcode()) {|;|+      case HloOpcode::kAllGather:|;|+      case HloOpcode::kAllReduce:|;|+      case HloOpcode::kAllToAll:|;|+      case HloOpcode::kCollectiveBroadcast:|;|+      case HloOpcode::kCollectivePermute:|;|+      case HloOpcode::kRaggedAllToAll:|;|+      case HloOpcode::kReduceScatter:|;|+        return true|;|;+      default:|;|+        return absl::InvalidArgumentError(""Async instruction "" +|;|+                                          instruction->ToString() +|;|+                                          "" is not a collective."")|;|;+    }|;|+  }|;|+  switch (instruction->opcode()) {|;|+    case HloOpcode::kAllGatherStart:|;|+    case HloOpcode::kAllGatherDone:|;|+    case HloOpcode::kAllReduceStart:|;|+    case HloOpcode::kAllReduceDone:|;|+    case HloOpcode::kCollectivePermuteStart:|;|+    case HloOpcode::kCollectivePermuteDone:|;|+      return true|;|;+    case HloOpcode::kSend:|;|+    case HloOpcode::kRecv:|;|+      return !Cast<HloSendRecvInstruction>(instruction)->is_host_transfer()|;|;+    case HloOpcode::kAllGather:|;|+    case HloOpcode::kAllReduce:|;|+    case HloOpcode::kAllToAll:|;|+    case HloOpcode::kCollectiveBroadcast:|;|+    case HloOpcode::kCollectivePermute:|;|+    case HloOpcode::kRaggedAllToAll:|;|+    case HloOpcode::kReduceScatter:|;|+      return false|;|;+    default:|;|+      return absl::InvalidArgumentError(""Instruction "" +|;|+                                        instruction->ToString() +|;|+                                        "" is not an async collective."")|;|;+  }|;|+}|;|+|;| HloInstruction* IsOrHasCollectiveWithChannelId(HloInstruction* instruction) {|;|   if (instruction->opcode() == HloOpcode::kFusion) {|;|     for (auto* inner_inst : instruction->fused_instructions()) { || PR#90155 - third_party/xla/xla/service/collective_ops_utils.h: @@ -126,6 +126,10 @@ absl::StatusOr<std::vector<int>> GetParticipatingIDs(|;|     std::optional<int> total_participant_count,|;|     absl::Span<const ReplicaGroup> groups)|;|; |;|+// Returns the replica groups for the given async collective instruction.|;|+absl::StatusOr<std::vector<std::vector<int64_t>>> GetAsyncReplicaGroups(|;|+    const HloInstruction* instruction)|;|;+|;| absl::string_view CollectiveOpGroupModeToString(|;|     CollectiveOpGroupMode group_mode)|;|; |;|@@ -251,6 +255,9 @@ bool IsNonFusionCollective(const HloInstruction* instruction)|;|; // Returns true if instruction is a collective op or a collective fusion.|;| bool IsCollective(const HloInstruction* instruction)|;|; |;|+// Returns true if instruction is an async collective op.|;|+absl::StatusOr<bool> IsAsyncCollective(const HloInstruction* instruction)|;|;+|;| // Returns the collective instruction if argument is a collective op (or a|;| // collective fusion) with channel_id.|;| HloInstruction* IsOrHasCollectiveWithChannelId(HloInstruction* instruction); || PR#90155 - third_party/xla/xla/service/collective_ops_utils_test.cc: @@ -290,6 +290,168 @@ TEST(IsExclusivelyCrossModuleTest, CrossModuleWithGlobalIds) {|;|   EXPECT_TRUE(is_exclusively_cross_module)|;|; }|;| |;|+TEST(CollectiveOpsUtilsTest, GetReplicaGroups) {|;|+  // Create a module for the test|;|+  HloModule module(""GetReplicaGroupsTest"", HloModuleConfig())|;|;+|;|+  // Set up a collective permute start instruction|;|+  auto builder = HloComputation::Builder(""GetReplicaGroupsTest"")|;|;+  auto param_shape = ShapeUtil::MakeShape(F32, {4, 4})|;|;+  HloInstruction *param_0 = builder.AddInstruction(|;|+      HloInstruction::CreateParameter(0, param_shape, ""p0""))|;|;+|;|+  // Test for CollectivePermuteStart|;|+  std::vector<std::pair<int64_t, int64_t>> source_target_pairs = {|;|+      {0, 1}, {1, 2}, {2, 3}, {3, 0}}|;|;+|;|+  HloInstruction *permute_start =|;|+      builder.AddInstruction(HloInstruction::CreateCollectivePermuteStart(|;|+          param_shape, param_0, source_target_pairs, /*channel_id=*/1))|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(std::vector<std::vector<int64_t>> permute_groups,|;|+                          GetAsyncReplicaGroups(permute_start))|;|;+  EXPECT_EQ(permute_groups.size(), 4)|;|;+  for (int i = 0; i < 4; ++i) {|;|+    EXPECT_EQ(permute_groups[i].size(), 2)|;|;+    EXPECT_EQ(permute_groups[i][0], source_target_pairs[i].first)|;|;+    EXPECT_EQ(permute_groups[i][1], source_target_pairs[i].second)|;|;+  }|;|+|;|+  // Test for AllGatherStart|;|+  std::vector<ReplicaGroup> replica_groups =|;|+      CreateReplicaGroups({{0, 1}, {2, 3}})|;|;+  HloInstruction *all_gather_start =|;|+      builder.AddInstruction(HloInstruction::CreateAllGatherStart(|;|+          ShapeUtil::MakeTupleShape({param_shape, param_shape}), {param_0},|;|+          /*all_gather_dimension=*/0, replica_groups,|;|+          /*constrain_layout=*/false,|;|+          /*channel_id=*/1, /*use_global_device_ids=*/false))|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(std::vector<std::vector<int64_t>> all_gather_groups,|;|+                          GetAsyncReplicaGroups(all_gather_start))|;|;+  EXPECT_EQ(all_gather_groups.size(), 2)|;|;+  EXPECT_THAT(all_gather_groups[0], testing::ElementsAre(0, 1))|;|;+  EXPECT_THAT(all_gather_groups[1], testing::ElementsAre(2, 3))|;|;+|;|+  // Test for AllReduceStart|;|+  // Create a reduction computation|;|+  HloComputation::Builder reducer_builder(""add"")|;|;+  auto reducer_x = reducer_builder.AddInstruction(|;|+      HloInstruction::CreateParameter(0, ShapeUtil::MakeScalarShape(F32), ""x""))|;|;+  auto reducer_y = reducer_builder.AddInstruction(|;|+      HloInstruction::CreateParameter(1, ShapeUtil::MakeScalarShape(F32), ""y""))|;|;+  reducer_builder.AddInstruction(HloInstruction::CreateBinary(|;|+      ShapeUtil::MakeScalarShape(F32), HloOpcode::kAdd, reducer_x, reducer_y))|;|;+|;|+  HloComputation *add_computation =|;|+      module.AddEmbeddedComputation(reducer_builder.Build())|;|;+|;|+  HloInstruction *all_reduce_start =|;|+      builder.AddInstruction(HloInstruction::CreateAllReduceStart(|;|+          ShapeUtil::MakeTupleShape({param_shape, param_shape}), {param_0},|;|+          add_computation, replica_groups, /*constrain_layout=*/false,|;|+          /*channel_id=*/2, /*use_global_device_ids=*/false))|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(std::vector<std::vector<int64_t>> all_reduce_groups,|;|+                          GetAsyncReplicaGroups(all_reduce_start))|;|;+  EXPECT_EQ(all_reduce_groups.size(), 2)|;|;+  EXPECT_THAT(all_reduce_groups[0], testing::ElementsAre(0, 1))|;|;+  EXPECT_THAT(all_reduce_groups[1], testing::ElementsAre(2, 3))|;|;+}|;|+|;|+TEST(CollectiveOpsUtilsTest, IsAsyncCollective) {|;|+  // Create module and computation|;|+  HloModule module(""test_module"", HloModuleConfig())|;|;+  auto builder = HloComputation::Builder(""IsAsyncCollectiveTest"")|;|;+  auto param_shape = ShapeUtil::MakeShape(F32, {4, 4})|;|;+  HloInstruction *param_0 = builder.AddInstruction(|;|+      HloInstruction::CreateParameter(0, param_shape, ""p0""))|;|;+|;|+  // Test for CollectivePermuteStart and CollectivePermuteDone|;|+  std::vector<std::pair<int64_t, int64_t>> source_target_pairs = {|;|+      {0, 1}, {1, 2}, {2, 3}, {3, 0}}|;|;+|;|+  HloInstruction *permute_start =|;|+      builder.AddInstruction(HloInstruction::CreateCollectivePermuteStart(|;|+          param_shape, param_0, source_target_pairs, /*channel_id=*/1))|;|;+|;|+  auto is_async_status = IsAsyncCollective(permute_start)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  HloInstruction *permute_done =|;|+      builder.AddInstruction(HloInstruction::CreateUnary(|;|+          param_shape, HloOpcode::kCollectivePermuteDone, permute_start))|;|;+|;|+  is_async_status = IsAsyncCollective(permute_done)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  // Test for AllGatherStart and AllGatherDone|;|+  std::vector<ReplicaGroup> replica_groups =|;|+      CreateReplicaGroups({{0, 1}, {2, 3}})|;|;+|;|+  HloInstruction *all_gather_start =|;|+      builder.AddInstruction(HloInstruction::CreateAllGatherStart(|;|+          ShapeUtil::MakeTupleShape(|;|+              {ShapeUtil::MakeShape(F32, {8, 4}), param_shape}),|;|+          {param_0}, /*all_gather_dimension=*/0, replica_groups,|;|+          /*constrain_layout=*/false,|;|+          /*channel_id=*/2, /*use_global_device_ids=*/false))|;|;+|;|+  is_async_status = IsAsyncCollective(all_gather_start)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  HloInstruction *all_gather_done = builder.AddInstruction(|;|+      HloInstruction::CreateUnary(ShapeUtil::MakeShape(F32, {8, 4}),|;|+                                  HloOpcode::kAllGatherDone, all_gather_start))|;|;+|;|+  is_async_status = IsAsyncCollective(all_gather_done)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  // Test for AllReduceStart and AllReduceDone|;|+  // First create a reduction computation|;|+  HloComputation::Builder reducer_builder(""add"")|;|;+  HloInstruction *reducer_x = reducer_builder.AddInstruction(|;|+      HloInstruction::CreateParameter(0, ShapeUtil::MakeScalarShape(F32), ""x""))|;|;+  HloInstruction *reducer_y = reducer_builder.AddInstruction(|;|+      HloInstruction::CreateParameter(1, ShapeUtil::MakeScalarShape(F32), ""y""))|;|;+  reducer_builder.AddInstruction(HloInstruction::CreateBinary(|;|+      ShapeUtil::MakeScalarShape(F32), HloOpcode::kAdd, reducer_x, reducer_y))|;|;+|;|+  HloComputation *add_computation =|;|+      module.AddEmbeddedComputation(reducer_builder.Build())|;|;+|;|+  HloInstruction *all_reduce_start =|;|+      builder.AddInstruction(HloInstruction::CreateAllReduceStart(|;|+          ShapeUtil::MakeTupleShape({param_shape, param_shape}), {param_0},|;|+          add_computation, replica_groups, /*constrain_layout=*/false,|;|+          /*channel_id=*/3, /*use_global_device_ids=*/false))|;|;+|;|+  is_async_status = IsAsyncCollective(all_reduce_start)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  HloInstruction *all_reduce_done =|;|+      builder.AddInstruction(HloInstruction::CreateUnary(|;|+          param_shape, HloOpcode::kAllReduceDone, all_reduce_start))|;|;+|;|+  is_async_status = IsAsyncCollective(all_reduce_done)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_TRUE(is_async_status.value())|;|;+|;|+  // Test for regular CollectivePermute (non-async)|;|+  HloInstruction *permute =|;|+      builder.AddInstruction(HloInstruction::CreateCollectivePermute(|;|+          param_shape, param_0, source_target_pairs, /*channel_id=*/1))|;|;+|;|+  is_async_status = IsAsyncCollective(permute)|;|;+  EXPECT_TRUE(is_async_status.ok())|;|;+  EXPECT_FALSE(is_async_status.value())|;|;+}|;|+|;| TEST(IsExclusivelyCrossReplicaTest, CrossReplicaNoChannelSet) {|;|   int64_t num_replicas = 4|;|;   int64_t num_partitions = 2;","PR #23522: [NVIDIA GPU] [XLA_GPU_MS_COLLECTIVE] Add utility functions for async collective stream assignment

Imported from GitHub PR https://github.com/openxla/xla/pull/23522

Breaking https://github.com/openxla/xla/pull/22450 into 3 steps:
1. Utility functions with unit tests.
2. Update to execution stream assignment.
3. Runtime integration.

This is the first step where we introduce the util functions needed and test them throughly.
Copybara import of the project:

--
2f88001a9fff5752912d4bdff8b464437a9e259c by Terry Sun <tesun@nvidia.com>:

util for async comm stream assignment

--
395fbb11d5f77fe94610987067062911f8aaca6c by Terry Sun <tesun@nvidia.com>:

naming and exception handling

--
590c460706ea35a51ad7697394f969a9f08bd0d2 by Terry Sun <tesun@nvidia.com>:

list false cases and throw error for unexpected

Merging this change closes #23522

PiperOrigin-RevId: 741356306"
tensorflow/tensorflow,vfdev-5,24255,Fix TF Lite Android Demo app build to work in Android Studio,"**TESTING**

- Before the fix I was unable to build in either Android Studio 3.1, or Android Studio 3.2.  
- After the fix I could build and launch the app using Android Studio 3.2.1 and emulator Pixel XL API 24.

**DETAIL**

Here is a list of seven of the errors resolved by these updates:

1) Disable Jack to fix compile errors.

Error was:
```
org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':app:transformJackWithJackForDebug'.
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:84)
	at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:55)
	... (truncated)
```

Source: https://developer.android.com/studio/write/java8-support#disable_jack

2) Update the plugin to support Java 8 features.

Error was:
```
Jack is required to support java 8 language features. Either enable Jack or remove sourceCompatibility JavaVersion.VERSION_1_8.
```

Source: https://developer.android.com/studio/releases/gradle-plugin#updating-plugin

3) Update repositories to include google()

Error was:
```
Could not find com.android.tools.build:aapt2:3.2.1-4818971.
```

4) Change 'compile' to 'implementation' in build.gradle

Error was:
```
Configuration 'compile' is obsolete and has been replaced with 'implementation' and 'api'.
It will be removed at the end of 2018. For more information see: http://d.android.com/r/tools/update-dependency-configurations.html
```

5) Update build tools

Error was:
```
The specified Android SDK Build Tools version (26.0.3) is ignored, as it is below the minimum supported version (28.0.3) for Android Gradle Plugin 3.2.1.
Android SDK Build Tools 28.0.3 will be used.
To suppress this warning, remove ""buildToolsVersion '26.0.3'"" from your build.gradle file, as each version of the Android Gradle Plugin now has a default version of the build tools.
Update Build Tools version and sync project
Open File
```

6) Update library dependencies

![screen shot 2018-12-09 at 11 51 26 am](https://user-images.githubusercontent.com/739125/49700514-97d47f80-fbad-11e8-8222-74469ddb705d.png)

![screen shot 2018-12-09 at 12 16 09 pm](https://user-images.githubusercontent.com/739125/49700518-a6229b80-fbad-11e8-9cf1-50637de78ed1.png)

**MISC NOTES**

AndroidManifest.xml shows this warning in Android Studio:
```
The minSdk version should not be declared in the android manifest file. You can move the version from the manifest to the defaultConfig in the build.gradle file.
Open Manifest File
Remove minSdkVersion and sync project
```
@jdduke requested we leave the minSdkVersion in AndroidManifest.xml so it can still be built with Bazel.  I added a [comment to the XML](https://github.com/tensorflow/tensorflow/pull/24255/files#diff-b2a1cafabbd44e7687f1ac02600d8da4R26
) to warn other people not to try and fix that warning.","Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied. || Can you check the latest version of the demo? It should have most of the changes you're trying to land. Give that a try and let us know, thanks. || I confirm that the latest version of the demo app on master now builds and runs fine in Android Studio 3.2.1 on macOS 10.13.6.  Closing this PR. 👍 ",closed,2018-12-09T17:27:22+00:00,2019-02-19T02:24:43+00:00,daj,"cla: yes, awaiting review, comp:lite, size:S",1,"PR#90121 - third_party/py/rules_python.patch: @@ -72,25 +72,22 @@ index 774c24d1..91e59f9b 100644|;|  }|;| |;| diff --git a/python/private/python_bootstrap_template.txt b/python/private/python_bootstrap_template.txt|;|-index 0f9c90b3..6d1e2f61 100644|;|+index 0f9c90b3..567bdc88 100644|;| --- a/python/private/python_bootstrap_template.txt|;| +++ b/python/private/python_bootstrap_template.txt|;|-@@ -52,8 +52,16 @@ def GetWindowsPathWithUNCPrefix(path):|;|+@@ -52,7 +52,14 @@ def GetWindowsPathWithUNCPrefix(path):|;|    # removed from common Win32 file and directory functions.|;|    # Related doc: https://docs.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation?tabs=cmd#enable-long-paths-in-windows-10-version-1607-and-later|;|    import platform|;| -  if platform.win32_ver()[1] >= '10.0.14393':|;|--    return path|;| +  version = None|;| +  # The try-except block is needed to fix the flakiness of RBE tests|;| +  # on Windows 2022 using hermetic python 3.12.8.|;| +  try:|;| +    version = platform.win32_ver()[1]|;| +  except (ValueError, KeyError):|;| +    version = platform.win32_ver()[1]|;|-+  finally:|;|-+    if version and version >= '10.0.14393':|;|-+      return path|;|- |;|++  if version and version >= '10.0.14393':|;|+     return path|;|+|;|    # import sysconfig only now to maintain python 2.6 compatibility|;|-   import sysconfig || PR#90121 - third_party/xla/third_party/py/rules_python.patch: @@ -72,25 +72,22 @@ index 774c24d1..91e59f9b 100644|;|  }|;| |;| diff --git a/python/private/python_bootstrap_template.txt b/python/private/python_bootstrap_template.txt|;|-index 0f9c90b3..6d1e2f61 100644|;|+index 0f9c90b3..567bdc88 100644|;| --- a/python/private/python_bootstrap_template.txt|;| +++ b/python/private/python_bootstrap_template.txt|;|-@@ -52,8 +52,16 @@ def GetWindowsPathWithUNCPrefix(path):|;|+@@ -52,7 +52,14 @@ def GetWindowsPathWithUNCPrefix(path):|;|    # removed from common Win32 file and directory functions.|;|    # Related doc: https://docs.microsoft.com/en-us/windows/win32/fileio/maximum-file-path-limitation?tabs=cmd#enable-long-paths-in-windows-10-version-1607-and-later|;|    import platform|;| -  if platform.win32_ver()[1] >= '10.0.14393':|;|--    return path|;| +  version = None|;| +  # The try-except block is needed to fix the flakiness of RBE tests|;| +  # on Windows 2022 using hermetic python 3.12.8.|;| +  try:|;| +    version = platform.win32_ver()[1]|;| +  except (ValueError, KeyError):|;| +    version = platform.win32_ver()[1]|;|-+  finally:|;|-+    if version and version >= '10.0.14393':|;|-+      return path|;|- |;|++  if version and version >= '10.0.14393':|;|+     return path|;|+|;|    # import sysconfig only now to maintain python 2.6 compatibility|;|-   import sysconfig","PR #24255: Fixed rules_python patch for python 3.14

Imported from GitHub PR https://github.com/openxla/xla/pull/24255

Returning from finally clause raises SyntaxWarning in python 3.14

cc @hawkinsp
Copybara import of the project:

--
2f7a929473cc67b3498ed88df4ab8e080e7def0f by vfdev-5 <vfdev.5@gmail.com>:

Fixed rules_python patch for python 3.14

Returning from finally clause raises SyntaxWarning in python 3.14

Merging this change closes #24255

PiperOrigin-RevId: 741203333"
tensorflow/tensorflow,jreiffers,24158,Xla devices,This PR constructs XLA_GPU devices according to session configuration settings allowing users to control XLA_GPU devices with session options. This solves the issues with multiple TF processes in a host.,"I couldn't be able to find why windows tests failed but probably unrelated with this pr. @ymodak @jlebar do you agree? || > I couldn't be able to find why windows tests failed but probably unrelated with this pr. @ymodak @jlebar do you agree?

Yes.  I am trying to submit this now, but it takes some effort on our side. || @jlebar I didn't mean to push, I just wanted to know if it break something unintentionally. || @jlebar it looks like this is only a partial solution and I have to implement suppression of stream executors as well. Let me update this PR before you merge so that it is complete solution. || The PR is already in the process of being merged.  Let's just create a new one.",closed,2018-12-05T00:32:58+00:00,2018-12-05T22:41:14+00:00,samikama,"cla: yes, ready to pull",1,"PR#90109 - third_party/xla/xla/hlo/ir/hlo_computation.h: @@ -215,8 +215,6 @@ class HloComputation {|;|     // unreachable, and its instruction is set to null. We still need to regard|;|     // such computations as fusion computations for HLO scheduling purposes.|;|     kFusion,|;|-    // This computation is a collective computation.|;|-    kCollective,|;|     // This computation is a conditional branch computation.|;|     kConditional,|;|     // Last Value for range checking.|;|@@ -805,23 +803,6 @@ class HloComputation {|;|     SetInstruction(fusion_instruction, InstructionType::kFusion)|;|;   }|;| |;|-  // Returns if this computation is a to_apply region of a collective.|;|-  bool IsCollectiveCalledComputation() const {|;|-    return instruction_type() == InstructionType::kCollective|;|;-  }|;|-|;|-  // Returns the owning collective call instruction, or nullptr if this is not a|;|-  // collective call computation.|;|-  HloInstruction* CollectiveCallInstruction() const {|;|-    return instruction_type() == InstructionType::kCollective ? instruction()|;|-                                                              : nullptr|;|;-  }|;|-|;|-  void SetCollectiveCallInstruction(|;|-      HloInstruction* collective_call_instruction) {|;|-    SetInstruction(collective_call_instruction, InstructionType::kCollective)|;|;-  }|;|-|;|   // Returns if this computation is a branch computation of a conditional.|;|   [[deprecated(|;|       ""This is broken. Use CallGraph::GetComputationCallers() instead"")]] || PR#90109 - third_party/xla/xla/hlo/ir/hlo_instructions.cc: @@ -1028,7 +1028,6 @@ HloAllReduceInstructionBase::HloAllReduceInstructionBase(|;|                                constrain_layout, channel_id),|;|       use_global_device_ids_(use_global_device_ids) {|;|   AppendComputation(reduce_computation)|;|;-  reduce_computation->SetCollectiveCallInstruction(this)|;|; }|;| |;| HloInstructionProto HloAllReduceInstructionBase::ToProto() const { || PR#90109 - third_party/xla/xla/hlo/transforms/simplifiers/BUILD: @@ -218,14 +218,13 @@ cc_library(|;|     hdrs = [""hlo_computation_deduplicator.h""],|;|     deps = [|;|         ""//xla:shape_util"",|;|-        ""//xla:status_macros"",|;|-        ""//xla:util"",|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/pass:hlo_pass"",|;|+        ""//xla/hlo/utils:hlo_query"",|;|+        ""@com_google_absl//absl/algorithm:container"",|;|         ""@com_google_absl//absl/container:flat_hash_map"",|;|         ""@com_google_absl//absl/container:flat_hash_set"",|;|         ""@com_google_absl//absl/status:statusor"",|;|-        ""@com_google_absl//absl/strings"",|;|         ""@com_google_absl//absl/strings:string_view"",|;|         ""@local_tsl//tsl/platform:logging"",|;|     ], || PR#90109 - third_party/xla/xla/hlo/transforms/simplifiers/flatten_call_graph.cc: @@ -137,12 +137,6 @@ absl::Status AnnotateNode(const CallGraphNode& node) {|;|       for (HloComputation* computation : instruction->called_computations()) {|;|         computation->SetFusionInstruction(instruction)|;|;       }|;|-|;|-    } else if (hlo_query::IsCollectiveCommunicationOp(instruction->opcode())) {|;|-      for (HloComputation* computation : instruction->called_computations()) {|;|-        computation->SetCollectiveCallInstruction(instruction)|;|;-      }|;|-|;|     } else if (instruction->opcode() == HloOpcode::kConditional) {|;|       for (HloComputation* branch : instruction->branch_computations()) {|;|         branch->SetConditionalCallInstruction(instruction); || PR#90109 - third_party/xla/xla/hlo/transforms/simplifiers/hlo_computation_deduplicator.cc: @@ -18,12 +18,14 @@ limitations under the License.|;| #include <string>|;| #include <utility>|;| |;|+#include ""absl/algorithm/container.h""|;| #include ""absl/container/flat_hash_map.h""|;| #include ""absl/container/flat_hash_set.h""|;| #include ""absl/status/statusor.h""|;| #include ""absl/strings/string_view.h""|;| #include ""xla/hlo/ir/hlo_computation.h""|;| #include ""xla/hlo/ir/hlo_instruction.h""|;|+#include ""xla/hlo/utils/hlo_query.h""|;| #include ""xla/shape_util.h""|;| #include ""tsl/platform/logging.h""|;| |;|@@ -91,9 +93,17 @@ absl::StatusOr<bool> HloComputationDeduplicator::Run(|;|     // with large number of instructions or large-size constants due to increase|;|     // in time taken to stringify.|;|     if (comp->IsEntryComputation() || comp->instruction_count() > 128 |||;|-        ContainsLargeConstants(comp) || comp->IsCollectiveCalledComputation()) {|;|+        ContainsLargeConstants(comp)) {|;|       continue|;|;     }|;|+    // Don't deduplicate collectives and non-collectives.|;|+    if (absl::c_any_of(|;|+            comp->caller_instructions(), [](const HloInstruction* instr) {|;|+              return hlo_query::IsCollectiveCommunicationOp(instr->opcode())|;|;+            })) {|;|+      continue|;|;+    }|;|+|;|     std::string comp_str = comp->ToString(options)|;|;     auto poss_dup = unique_comps.find(comp_str)|;|;     if (poss_dup != unique_comps.end() && || PR#90109 - third_party/xla/xla/service/all_reduce_promotion.cc: @@ -62,7 +62,6 @@ std::unique_ptr<HloInstruction> CloneAllReduce(|;|     return inst->GetModule()->AddEmbeddedComputation(promoted.Build())|;|;   }()|;|;   new_inst->set_to_apply(to_apply_promoted)|;|;-  to_apply_promoted->SetCollectiveCallInstruction(new_inst.get())|;|;   return new_inst|;|; }|;|  || PR#90109 - third_party/xla/xla/service/hlo_instruction_test.cc: @@ -2458,9 +2458,8 @@ TEST_F(HloInstructionTest, PreserveOperandPrecisionOnCloneConv) {|;|   auto* conv = module->entry_computation()->root_instruction()|;|; |;|   auto clone = conv->Clone()|;|;-  EXPECT_THAT(|;|-      clone->precision_config().operand_precision(),|;|-      ::testing::ElementsAre(PrecisionConfig::HIGH, PrecisionConfig::DEFAULT))|;|;+  EXPECT_THAT(clone->precision_config().operand_precision(),|;|+              ElementsAre(PrecisionConfig::HIGH, PrecisionConfig::DEFAULT))|;|; }|;| |;| TEST_F(HloInstructionTest, ReuseReshapeOfFusionParameter) {|;|@@ -2597,9 +2596,8 @@ TEST_F(HloInstructionTest, VerifyToApplyRegionPointsToReduceScatter) {|;|   // the reduce-scatter instruction.|;|   for (HloComputation* comp : module->MakeComputationPostOrder()) {|;|     if (!comp->IsEntryComputation()) {|;|-      EXPECT_TRUE(comp->IsCollectiveCalledComputation())|;|;-      EXPECT_EQ(comp->CollectiveCallInstruction(),|;|-                module->entry_computation()->root_instruction())|;|;+      EXPECT_THAT(comp->caller_instructions(),|;|+                  ElementsAre(module->entry_computation()->root_instruction()))|;|;     }|;|   }|;| }|;|@@ -2635,9 +2633,8 @@ TEST_F(HloInstructionTest, VerifyToApplyRegionPointsToAllReduce) {|;|   // the all-reduce instruction.|;|   for (HloComputation* comp : module->MakeComputationPostOrder()) {|;|     if (!comp->IsEntryComputation()) {|;|-      EXPECT_TRUE(comp->IsCollectiveCalledComputation())|;|;-      EXPECT_EQ(comp->CollectiveCallInstruction(),|;|-                module->entry_computation()->root_instruction())|;|;+      EXPECT_THAT(comp->caller_instructions(),|;|+                  ElementsAre(module->entry_computation()->root_instruction()))|;|;     }|;|   }|;| } || PR#90109 - third_party/xla/xla/service/reduce_scatter_decomposer.cc: @@ -66,7 +66,6 @@ absl::StatusOr<bool> ReduceScatterDecomposer::Run(|;|               rs->operand(0)->shape(), rs->operands(), apply_clone,|;|               rs->device_list(), rs->constrain_layout(), channel_id,|;|               rs->use_global_device_ids()))|;|;-      apply_clone->SetCollectiveCallInstruction(ar)|;|; |;|       // Create start indices for a dynamic slice to decompose the all-reduce|;|       // results. || PR#90109 - third_party/xla/xla/service/spmd/spmd_partitioner.cc: @@ -5005,7 +5005,6 @@ SPMDCollectiveOpsCreator GetDefaultCollectiveOpsCreator(int64_t num_partitions,|;|                 CollectiveDeviceList(device_groups),|;|                 /*constrain_layout=*/false, channel_id,|;|                 /*use_global_device_ids=*/true))|;|;-        reduction_clone->SetCollectiveCallInstruction(all_reduce)|;|;         return all_reduce|;|;       },|;|       [num_replicas, num_partitions](|;|@@ -5022,7 +5021,6 @@ SPMDCollectiveOpsCreator GetDefaultCollectiveOpsCreator(int64_t num_partitions,|;|                     partition_group_list, num_replicas, num_partitions),|;|                 /*constrain_layout=*/false, channel_id,|;|                 /*use_global_device_ids=*/true))|;|;-        reduction_clone->SetCollectiveCallInstruction(all_reduce)|;|;         return all_reduce|;|;       },|;|       [num_partitions](SpmdBuilder* b, HloInstruction* operand,","PR #24158: Remove HloComputation::CollectiveCallInstruction.

Imported from GitHub PR https://github.com/openxla/xla/pull/24158

Step 3/5 of removing InstructionType.
Copybara import of the project:

--
06cee58ab83198ad150420536658764df141a8fc by Johannes Reifferscheid <jreiffers@nvidia.com>:

Remove HloComputation::CollectiveCallInstruction.

Step 3/5 of removing InstructionType.

Merging this change closes #24158

PiperOrigin-RevId: 741143797"
tensorflow/tensorflow,Cjkkkk,24203,Markdown formatting issue in tf.keras.layers.Layer docs,"<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>


**System information**
- TensorFlow version: r1.12
- Doc Link: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer


**Describe the documentation issue**
Below the 'Arguments' list, it looks like there are supposed to be lists of read-only properties and mutable properties, but they render as paragraphs rather than lists.

Seems like the issue is that the parser splits the docstring into sections based on a magic list of keywords, `detail_keywords = '|'.join(['Args', 'Arguments', 'Fields', 'Returns', 'Yields', 'Raises', 'Attributes'])`, and that list does not include the strings 'Read-only properties', or 'Mutable properties'. So it treats everything below ""Arguments"" as part of the list of arguments, and trips over itself.

(There's also some question as to whether these lists should be there at all, or whether this information should be in the [Properties](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#properties) section)

**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**
Not with my current understanding of the docs system. I was able to find a script for generating a markdown index of the docs locally (`tensorflow/tools/docs/generate2.py`), but when I ran it, I got [a markdown file that didn't seem to have the issue I see on the site](https://gist.github.com/colinmorris/0a180ea671e12ccdb65fe6cc9f0319fa). Maybe it's because I used `generate2.py` but the docs on the site are generated by `generate.py`? Maybe the lists are fine in GitHub-flavoured markdown but not whatever engine is used when converting the docs from md to html for the site? (I'll file a separate issue about this meta-documentation issue)",Apologies for the delay in response. You are right about this. Thanks for reporting. || This should be fixed by tomorrow or day-after tomorrow.,closed,2018-12-06T17:33:38+00:00,2020-01-28T23:40:25+00:00,colinmorris,"type:docs-bug, comp:keras",1,"PR#90032 - third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc: @@ -435,7 +435,7 @@ class FlashAttentionBMMScaleBiasSoftmaxBMM : public MultiHeadedAttentionTest {|;|   const std::string  // NOLINT|;|   GetModuleFlash_Attention_Training_BMM1_Bias_Softmax_BMM2_HloString_BF16() {  // NOLINT|;|     const std::string hlo_text = R""(|;|-    HloModule jit__unnamed_wrapped_function_, entry_computation_layout={(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})->(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})}, allow_spmd_sharding_propagation_to_output={true,true,true,true}|;|+    HloModule jit__unnamed_wrapped_function_, entry_computation_layout={(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[6,1024,1024]{2,1,0}, bf16[2,6,1024,64]{3,2,1,0})->(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})}, allow_spmd_sharding_propagation_to_output={true,true,true,true}|;| |;|     region_0.13 {|;|       Arg_0.14 = bf16[] parameter(0)|;|@@ -465,8 +465,9 @@ class FlashAttentionBMMScaleBiasSoftmaxBMM : public MultiHeadedAttentionTest {|;|       Arg_0.1 = bf16[2,6,1024,64]{3,2,1,0} parameter(0), sharding={replicated}|;|       Arg_1.2 = bf16[2,6,64,1024]{3,2,1,0} parameter(1), sharding={replicated}|;|       dot.11 = bf16[2,6,1024,1024]{3,2,1,0} dot(Arg_0.1, Arg_1.2), lhs_batch_dims={0,1}, lhs_contracting_dims={3}, rhs_batch_dims={0,1}, rhs_contracting_dims={2}|;|-      Arg_3.4 = bf16[2,6,1024,1024]{3,2,1,0} parameter(3), sharding={replicated}|;|-      add.12 = bf16[2,6,1024,1024]{3,2,1,0} add(dot.11, Arg_3.4)|;|+      Arg_3.4 = bf16[6,1024,1024]{2,1,0} parameter(3), sharding={replicated}|;|+      broadcast.9 = bf16[2,6,1024,1024]{3,2,1,0} broadcast(Arg_3.4), dimensions={1,2,3}|;|+      add.12 = bf16[2,6,1024,1024]{3,2,1,0} add(dot.11, broadcast.9)|;|       constant.9 = bf16[] constant(-inf)|;|       reduce.17 = bf16[2,6,1024]{2,1,0} reduce(add.12, constant.9), dimensions={3}, to_apply=region_0.13|;|       reshape.18 = bf16[2,6,1024,1]{3,2,1,0} reshape(reduce.17)|;|@@ -525,20 +526,21 @@ class FlashAttentionBMMScaleBiasSoftmaxBMM : public MultiHeadedAttentionTest {|;|   const std::string  // NOLINT|;|   GetModuleFlash_Attention_CuDNN_Training_BMM1_Bias_Softmax_BMM2_HloString_BF16() {  // NOLINT|;|     const std::string hlo_text = R""(|;|-    HloModule jit__unnamed_wrapped_function_, entry_computation_layout={(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})->(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})}, allow_spmd_sharding_propagation_to_output={true,true,true,true}|;|+    HloModule jit__unnamed_wrapped_function_, entry_computation_layout={(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[6,1024,1024]{2,1,0}, bf16[2,6,1024,64]{3,2,1,0})->(bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,64,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0})}, allow_spmd_sharding_propagation_to_output={true,true,true,true}|;| |;|     ENTRY main.72 {|;|       Arg_0.1 = bf16[2,6,1024,64]{3,2,1,0} parameter(0), sharding={replicated}|;|       Arg_1.2 = bf16[2,6,64,1024]{3,2,1,0} parameter(1), sharding={replicated}|;|       transpose = bf16[2,6,1024,64]{3,2,1,0} transpose(Arg_1.2), dimensions={0,1,3,2}|;|       Arg_2.3 = bf16[2,6,1024,64]{3,2,1,0} parameter(2), sharding={replicated}|;|-      Arg_3.4 = bf16[2,6,1024,1024]{3,2,1,0} parameter(3), sharding={replicated}|;|-      fmha-bmm-scale-bias-softmax-bmm = (bf16[2,6,1024,64]{3,2,1,0}, f32[2,6,1024]{2,1,0}, u8[0]{0}) custom-call(Arg_0.1, transpose, Arg_2.3, Arg_3.4), custom_call_target=""__cudnn$fmhaScaleBiasSoftmax"", operand_layout_constraints={bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,1024]{3,2,1,0}}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""cudnn_fmha_backend_config"":{""algorithm"":{""algo_id"":""0"",""math_type"":""TENSOR_OP_MATH"",""tuning_knobs"":{""24"":""0"",""17"":""1""},""is_cudnn_frontend"":true,""workspace_size"":""0""},""fmha_scale"":1,""dropout_rate"":0,""bmm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""3""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""intermediate_tensor_shape"":{""element_type"":""BF16"",""dimensions"":[""2"",""6"",""1024"",""1024""],""tuple_shapes"":[],""layout"":{""dim_level_types"":[],""dim_unique"":[],""dim_ordered"":[],""minor_to_major"":[""3"",""2"",""1"",""0""],""tiles"":[],""tail_padding_alignment_in_elements"":""1"",""element_size_in_bits"":""0"",""memory_space"":""0"",""index_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""pointer_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""dynamic_shape_metadata_prefix_bytes"":""0"",""split_configs"":[]},""is_dynamic_dimension"":[false,false,false,false]},""seed"":""42"",""is_flash_attention"":false,""is_causal_mask"":false,""mask_type"":""NO_MASK"",""force_deterministic"":false,""sliding_window_length"":0},""force_earliest_schedule"":false}|;|+      Arg_3.4 = bf16[6,1024,1024]{2,1,0} parameter(3), sharding={replicated}|;|+      reshape.131 = bf16[1,6,1024,1024]{3,2,1,0} reshape(Arg_3.4)|;|+      fmha-bmm-scale-bias-softmax-bmm = (bf16[2,6,1024,64]{3,2,1,0}, f32[2,6,1024]{2,1,0}, u8[0]{0}) custom-call(Arg_0.1, transpose, Arg_2.3, reshape.131), custom_call_target=""__cudnn$fmhaScaleBiasSoftmax"", operand_layout_constraints={bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[1,6,1024,1024]{3,2,1,0}}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""cudnn_fmha_backend_config"":{""algorithm"":{""algo_id"":""0"",""math_type"":""TENSOR_OP_MATH"",""tuning_knobs"":{""24"":""0"",""17"":""1""},""is_cudnn_frontend"":true,""workspace_size"":""0""},""fmha_scale"":1,""dropout_rate"":0,""bmm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""3""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""intermediate_tensor_shape"":{""element_type"":""BF16"",""dimensions"":[""2"",""6"",""1024"",""1024""],""tuple_shapes"":[],""layout"":{""dim_level_types"":[],""dim_unique"":[],""dim_ordered"":[],""minor_to_major"":[""3"",""2"",""1"",""0""],""tiles"":[],""tail_padding_alignment_in_elements"":""1"",""element_size_in_bits"":""0"",""memory_space"":""0"",""index_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""pointer_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""dynamic_shape_metadata_prefix_bytes"":""0"",""split_configs"":[]},""is_dynamic_dimension"":[false,false,false,false]},""seed"":""42"",""is_flash_attention"":false,""is_causal_mask"":false,""mask_type"":""NO_MASK"",""force_deterministic"":false,""sliding_window_length"":0},""force_earliest_schedule"":false}|;|       get-tuple-element = bf16[2,6,1024,64]{3,2,1,0} get-tuple-element(fmha-bmm-scale-bias-softmax-bmm), index=0|;|       transpose.2 = bf16[2,6,1024,64]{3,2,1,0} transpose(Arg_1.2), dimensions={0,1,3,2}|;|       get-tuple-element.2 = f32[2,6,1024]{2,1,0} get-tuple-element(fmha-bmm-scale-bias-softmax-bmm), index=1|;|       Arg_4.5 = bf16[2,6,1024,64]{3,2,1,0} parameter(4), sharding={replicated}|;|-      fmha-bmm-scale-bias-softmax-bmm-backward = (bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, u8[0]{0}) custom-call(Arg_0.1, transpose.2, Arg_2.3, get-tuple-element.2, Arg_4.5, /*index=5*/Arg_3.4, get-tuple-element), custom_call_target=""__cudnn$fmhaScaleBiasSoftmaxBackward"", operand_layout_constraints={bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, f32[2,6,1024]{2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""cudnn_fmha_backend_config"":{""algorithm"":{""algo_id"":""0"",""math_type"":""TENSOR_OP_MATH"",""tuning_knobs"":{""17"":""1"",""24"":""0""},""is_cudnn_frontend"":true,""workspace_size"":""0""},""fmha_scale"":1,""dropout_rate"":0,""intermediate_tensor_shape"":{""element_type"":""BF16"",""dimensions"":[""2"",""6"",""1024"",""1024""],""tuple_shapes"":[],""layout"":{""dim_level_types"":[],""dim_unique"":[],""dim_ordered"":[],""minor_to_major"":[""3"",""2"",""1"",""0""],""tiles"":[],""tail_padding_alignment_in_elements"":""1"",""element_size_in_bits"":""0"",""memory_space"":""0"",""index_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""pointer_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""dynamic_shape_metadata_prefix_bytes"":""0"",""split_configs"":[]},""is_dynamic_dimension"":[false,false,false,false]},""bmm1_grad_gemm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""2""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm1_grad_gemm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_grad_gemm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""2""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_grad_gemm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""3""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""seed"":""42"",""is_flash_attention"":false,""is_causal_mask"":false,""mask_type"":""NO_MASK"",""force_deterministic"":false,""sliding_window_length"":0},""force_earliest_schedule"":false}|;|+      fmha-bmm-scale-bias-softmax-bmm-backward = (bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, u8[0]{0}) custom-call(Arg_0.1, transpose.2, Arg_2.3, get-tuple-element.2, Arg_4.5, /*index=5*/reshape.131, get-tuple-element), custom_call_target=""__cudnn$fmhaScaleBiasSoftmaxBackward"", operand_layout_constraints={bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, f32[2,6,1024]{2,1,0}, bf16[2,6,1024,64]{3,2,1,0}, bf16[1,6,1024,1024]{3,2,1,0}, bf16[2,6,1024,64]{3,2,1,0}}, backend_config={""operation_queue_id"":""0"",""wait_on_operation_queues"":[],""cudnn_fmha_backend_config"":{""algorithm"":{""algo_id"":""0"",""math_type"":""TENSOR_OP_MATH"",""tuning_knobs"":{""17"":""1"",""24"":""0""},""is_cudnn_frontend"":true,""workspace_size"":""0""},""fmha_scale"":1,""dropout_rate"":0,""intermediate_tensor_shape"":{""element_type"":""BF16"",""dimensions"":[""2"",""6"",""1024"",""1024""],""tuple_shapes"":[],""layout"":{""dim_level_types"":[],""dim_unique"":[],""dim_ordered"":[],""minor_to_major"":[""3"",""2"",""1"",""0""],""tiles"":[],""tail_padding_alignment_in_elements"":""1"",""element_size_in_bits"":""0"",""memory_space"":""0"",""index_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""pointer_primitive_type"":""PRIMITIVE_TYPE_INVALID"",""dynamic_shape_metadata_prefix_bytes"":""0"",""split_configs"":[]},""is_dynamic_dimension"":[false,false,false,false]},""bmm1_grad_gemm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""2""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm1_grad_gemm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_grad_gemm1_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""2""],""rhs_contracting_dimensions"":[""2""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""bmm2_grad_gemm2_dot_dimension_numbers"":{""lhs_contracting_dimensions"":[""3""],""rhs_contracting_dimensions"":[""3""],""lhs_batch_dimensions"":[""0"",""1""],""rhs_batch_dimensions"":[""0"",""1""]},""seed"":""42"",""is_flash_attention"":false,""is_causal_mask"":false,""mask_type"":""NO_MASK"",""force_deterministic"":false,""sliding_window_length"":0},""force_earliest_schedule"":false}|;|       get-tuple-element.3 = bf16[2,6,1024,64]{3,2,1,0} get-tuple-element(fmha-bmm-scale-bias-softmax-bmm-backward), index=0|;|       get-tuple-element.4 = bf16[2,6,1024,64]{3,2,1,0} get-tuple-element(fmha-bmm-scale-bias-softmax-bmm-backward), index=1|;|       transpose.1 = bf16[2,6,64,1024]{3,2,1,0} transpose(get-tuple-element.4), dimensions={0,1,3,2} || PR#90032 - third_party/xla/xla/service/gpu/transforms/cudnn_custom_call_compiler.cc: @@ -255,8 +255,10 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHA(|;|   const Shape &d_bmm2_rhs_shape =|;|       ShapeUtil::GetSubshape(custom_call->shape(), {output_index++})|;|;   bool has_dbias = custom_call->shape().tuple_shapes().size() == 5|;|;+  std::optional<Shape> dbias_shape|;|;   if (has_dbias) {|;|-    ++output_index|;|;+    dbias_shape =|;|+        ShapeUtil::GetSubshape(custom_call->shape(), {output_index++})|;|;   }|;|   // The last one is the workspace.|;|   TF_RET_CHECK(output_index == custom_call->shape().tuple_shapes().size() - 1)|;|;@@ -295,10 +297,15 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHA(|;|                       TensorDescriptorFor(d_bmm2_rhs_shape))|;|; |;|   std::optional<se::dnn::TensorDescriptor> bias|;|;+  std::optional<se::dnn::TensorDescriptor> dbias|;|;   if (bias_shape.has_value()) {|;|     TF_ASSIGN_OR_RETURN(bias, TensorDescriptorFor(*bias_shape))|;|;   }|;| |;|+  if (dbias_shape.has_value()) {|;|+    TF_ASSIGN_OR_RETURN(dbias, TensorDescriptorFor(*dbias_shape))|;|;+  }|;|+|;|   const double dropout_rate = config.dropout_rate()|;|; |;|   TF_ASSIGN_OR_RETURN(CudnnfMHAMaskKind cudnn_mask_type,|;|@@ -312,7 +319,7 @@ absl::StatusOr<se::gpu::CudnnGraph> BuildGraphForCustomCallToBackwardFMHA(|;|       se::gpu::GetCudnnFlashAttentionBackwardOperationGraph(|;|           dnn_support, bmm1_grad_gemm1_rhs, bmm1_grad_gemm2_rhs,|;|           bmm2_grad_gemm1_lhs, bmm2_grad_gemm2_rhs, d_output, d_bmm1_lhs,|;|-          d_bmm1_rhs, d_bmm2_rhs, bias, dropout_rate, config.seed(),|;|+          d_bmm1_rhs, d_bmm2_rhs, bias, dbias, dropout_rate, config.seed(),|;|           config.fmha_scale(), dropout_rate > 0.0, bias != std::nullopt,|;|           dnn_mask_type, force_deterministic, sliding_window_length,|;|           max_seg_per_batch)); || PR#90032 - third_party/xla/xla/stream_executor/cuda/cuda_dnn.cc: @@ -5641,6 +5641,7 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionBackwardOperationGraph(|;|     const dnn::TensorDescriptor& dq_desc, const dnn::TensorDescriptor& dk_desc,|;|     const dnn::TensorDescriptor& dv_desc,|;|     const std::optional<dnn::TensorDescriptor> bias_descriptor,|;|+    const std::optional<dnn::TensorDescriptor> dbias_descriptor,|;|     std::optional<double> dropout_rate, std::optional<int64_t> seed,|;|     double scale, bool use_dropout, bool use_bias, dnn::FMHAMaskKind mask_type,|;|     bool force_deterministic, const int sliding_window_length,|;|@@ -5765,12 +5766,13 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionBackwardOperationGraph(|;|     // shapes [1, 1, s, s], [b, 1, s, s], [b, h, s, s] are not supported for|;|     // dbias calculation but they are supported for forward bias calculation|;|     // Set UID later: this is the last output tuple element.|;|-    if (b == 1 && n == q_n) {|;|+    if (dbias_descriptor != std::nullopt) {|;|+      DCHECK(b == 1 && n == q_n)|;|;       d_bias_tensor =|;|           graph.tensor(Tensor_attributes()|;|                            .set_name(""dBias"")|;|-                           .set_dim(bias_descriptor->dimensions())|;|-                           .set_stride(bias_descriptor->GetLogicalStrides()))|;|;+                           .set_dim(dbias_descriptor->dimensions())|;|+                           .set_stride(dbias_descriptor->GetLogicalStrides()))|;|;       sdpa_backward_options.set_dbias(d_bias_tensor)|;|;     }|;|   } || PR#90032 - third_party/xla/xla/stream_executor/cuda/cuda_dnn.h: @@ -727,7 +727,8 @@ absl::StatusOr<CudnnGraph> GetCudnnFlashAttentionBackwardOperationGraph(|;|     const dnn::MatmulTensorDescriptor& do_desc,|;|     const dnn::TensorDescriptor& dq_desc, const dnn::TensorDescriptor& dk_desc,|;|     const dnn::TensorDescriptor& dv_desc,|;|-    std::optional<dnn::TensorDescriptor> bias_descriptor,|;|+    const std::optional<dnn::TensorDescriptor> bias_descriptor,|;|+    const std::optional<dnn::TensorDescriptor> dbias_descriptor,|;|     std::optional<double> dropout_rate, std::optional<int64_t> seed,|;|     double scale, bool use_dropout, bool use_bias, dnn::FMHAMaskKind mask_type,|;|     bool force_deterministic, int sliding_window_length, int max_seg_per_batch);","PR #24203: [XLA:GPU] fix unintended cuDNN flash attention dbias computation

Imported from GitHub PR https://github.com/openxla/xla/pull/24203

Fix a case where cudnn flash attention dbias is not required but computed. Only calculate dbias when there is dbias descriptor.
Copybara import of the project:

--
14f15487cc33be2d9a80bd7f9a5d95d85346fc60 by cjkkkk <ske@nvidia.com>:

fix unintended dbias computation

Merging this change closes #24203

PiperOrigin-RevId: 741130461"
tensorflow/tensorflow,philipphack,24060,Cpu tensorflow ImportError ,"Dear All ,

I am very new to Python and datascience , I have installed tensorflow cpu from anaconda navigator , but when I am importing tensorflow its showing the following error. also find the system information and conda information below 


**ERROR :** 
ImportError: Traceback (most recent call last):
  File ""C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
************************************************************************************************************
**!conda info**

     active environment : base
    active env location : C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3
            shell level : 1
       user config file : C:\Users\Aashay.bane\.condarc
 populated config files : C:\Users\Aashay.bane\.condarc
          conda version : 4.5.11
    conda-build version : 3.16.3
         python version : 3.6.7.final.0
       base environment : C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3  (writable)
           channel URLs : https://repo.anaconda.com/pkgs/main/win-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/free/win-64
                          https://repo.anaconda.com/pkgs/free/noarch
                          https://repo.anaconda.com/pkgs/r/win-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/pro/win-64
                          https://repo.anaconda.com/pkgs/pro/noarch
                          https://repo.anaconda.com/pkgs/msys2/win-64
                          https://repo.anaconda.com/pkgs/msys2/noarch
          package cache : C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\pkgs
                          C:\Users\Aashay.bane\AppData\Local\conda\conda\pkgs
       envs directories : C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3\envs
                          C:\Users\Aashay.bane\AppData\Local\conda\conda\envs
                          C:\Users\Aashay.bane\.conda\envs
               platform : win-64
             user-agent : conda/4.5.11 requests/2.20.1 CPython/3.6.7 Windows/8.1 Windows/6.3.9600
          administrator : False
             netrc file : None
           offline mode : False
***********************************************************************************************************
!conda list --show-channel-urls
# packages in environment at C:\Users\Aashay.bane\AppData\Local\Continuum\anaconda3:
#
# Name                    Version                   Build  Channel
_ipyw_jlab_nb_ext_conf    0.1.0                    py36_0    defaults
absl-py                   0.6.1                    py36_0    defaults
alabaster                 0.7.12                   py36_0    defaults
anaconda                  5.3.0                    py37_0    defaults
anaconda-client           1.7.2                    py36_0    defaults
anaconda-navigator        1.9.2                    py36_0    defaults
anaconda-project          0.8.2                    py36_0    defaults
appdirs                   1.4.3            py36h28b3542_0    defaults
asn1crypto                0.24.0                   py36_0    defaults
astor                     0.7.1                    py36_0    defaults
astroid                   2.1.0                    py36_0    defaults
astropy                   3.0.5            py36he774522_0    defaults
atomicwrites              1.2.1                    py36_0    defaults
attrs                     18.2.0           py36h28b3542_0    defaults
automat                   0.7.0                    py36_0    defaults
babel                     2.6.0                    py36_0    defaults
backcall                  0.1.0                    py36_0    defaults
backports                 1.0                      py36_1    defaults
backports.os              0.1.1                    py36_0    defaults
backports.shutil_get_terminal_size 1.0.0                    py36_2    defaults
beautifulsoup4            4.6.3                    py36_0    defaults
bitarray                  0.8.3            py36hfa6e2cd_0    defaults
bkcharts                  0.2              py36h7e685f7_0    defaults
blas                      1.0                         mkl    defaults
blaze                     0.11.3                   py36_0    defaults
bleach                    3.0.2                    py36_0    defaults
blosc                     1.14.4               he51fdeb_0    defaults
bokeh                     1.0.2                    py36_0    defaults
boto                      2.49.0                   py36_0    defaults
bottleneck                1.2.1            py36h452e1ab_1    defaults
bzip2                     1.0.6                hfa6e2cd_5    defaults
ca-certificates           2018.03.07                    0    defaults
certifi                   2018.10.15               py36_0    defaults
cffi                      1.11.5           py36h74b6da3_1    defaults
chardet                   3.0.4                    py36_1    defaults
click                     7.0                      py36_0    defaults
cloudpickle               0.6.1                    py36_0    defaults
clyent                    1.2.2                    py36_1    defaults
colorama                  0.4.0                    py36_0    defaults
comtypes                  1.1.7                    py36_0    defaults
conda                     4.5.11                   py36_0    defaults
conda-build               3.16.3                   py36_0    defaults
conda-env                 2.6.0                h36134e3_1    defaults
console_shortcut          0.1.1                         3    defaults
constantly                15.1.0           py36h28b3542_0    defaults
contextlib2               0.5.5            py36he5d52c0_0    defaults
cryptography              2.3.1            py36h74b6da3_0    defaults
cudatoolkit               9.0                           1    defaults
cudnn                     7.1.4                 cuda9.0_0    defaults
curl                      7.61.0               h7602738_0    defaults
cycler                    0.10.0           py36h009560c_0    defaults
cython                    0.29             py36ha925a31_0    defaults
cytoolz                   0.9.0.1          py36hfa6e2cd_1    defaults
dask                      1.0.0                    py36_0    defaults
dask-core                 1.0.0                    py36_0    defaults
datashape                 0.5.4                    py36_1    defaults
decorator                 4.3.0                    py36_0    defaults
defusedxml                0.5.0                    py36_1    defaults
distributed               1.25.0                   py36_0    defaults
docutils                  0.14             py36h6012d8f_0    defaults
entrypoints               0.2.3                    py36_2    defaults
et_xmlfile                1.0.1            py36h3d2d736_0    defaults
fastcache                 1.0.2            py36hfa6e2cd_2    defaults
filelock                  3.0.10                   py36_0    defaults
flask                     1.0.2                    py36_1    defaults
flask-cors                3.0.7                    py36_0    defaults
freetype                  2.9.1                ha9979f8_1    defaults
gast                      0.2.0                    py36_0    defaults
get_terminal_size         1.0.0                h38e98db_0    defaults
gevent                    1.3.7            py36he774522_1    defaults
glob2                     0.6                      py36_1    defaults
greenlet                  0.4.15           py36hfa6e2cd_0    defaults
grpcio                    1.14.1           py36h5c4b210_0    defaults
h5py                      2.8.0            py36h3bdd7fb_2    defaults
hdf5                      1.10.2               hac2f561_1    defaults
heapdict                  1.0.0                    py36_2    defaults
html5lib                  1.0.1                    py36_0    defaults
hyperlink                 18.0.0                   py36_0    defaults
icc_rt                    2017.0.4             h97af966_0    defaults
icu                       58.2                 ha66f8fd_1    defaults
idna                      2.7                      py36_0    defaults
imageio                   2.4.1                    py36_0    defaults
imagesize                 1.1.0                    py36_0    defaults
importlib_metadata        0.6                      py36_0    defaults
incremental               17.5.0                   py36_0    defaults
intel-openmp              2019.0                      118    defaults
ipykernel                 5.1.0            py36h39e3cac_0    defaults
ipython                   7.1.1            py36h39e3cac_0    defaults
ipython_genutils          0.2.0            py36h3c5d0ee_0    defaults
ipywidgets                7.4.2                    py36_0    defaults
isort                     4.3.4                    py36_0    defaults
itsdangerous              1.1.0                    py36_0    defaults
jdcal                     1.4                      py36_0    defaults
jedi                      0.13.1                   py36_0    defaults
jinja2                    2.10                     py36_0    defaults
jpeg                      9b                   hb83a4c4_2    defaults
jsonschema                2.6.0            py36h7636477_0    defaults
jupyter                   1.0.0                    py36_7    defaults
jupyter_client            5.2.3                    py36_0    defaults
jupyter_console           6.0.0                    py36_0    defaults
jupyter_core              4.4.0                    py36_0    defaults
jupyterlab                0.35.3                   py36_0    defaults
jupyterlab_launcher       0.13.1                   py36_0    defaults
jupyterlab_server         0.2.0                    py36_0    defaults
keras-applications        1.0.6                    py36_0    defaults
keras-preprocessing       1.0.5                    py36_0    defaults
keyring                   16.1.0                   py36_0    defaults
kiwisolver                1.0.1            py36h6538335_0    defaults
lazy-object-proxy         1.3.1            py36hfa6e2cd_2    defaults
libarchive                3.3.3                h798a506_1    defaults
libcurl                   7.61.0               h7602738_0    defaults
libiconv                  1.15                 h1df5818_7    defaults
libpng                    1.6.35               h2a8f88b_0    defaults
libprotobuf               3.6.1                h7bd577a_0    defaults
libsodium                 1.0.16               h9d3ae62_0    defaults
libssh2                   1.8.0                hd619d38_4    defaults
libtiff                   4.0.9                h36446d0_2    defaults
libxml2                   2.9.8                hadb2253_1    defaults
libxslt                   1.1.32               hf6f1972_0    defaults
llvmlite                  0.26.0           py36ha925a31_0    defaults
locket                    0.2.0            py36hfed976d_1    defaults
lxml                      4.2.5            py36hef2cd61_0    defaults
lz4-c                     1.8.1.2              h2fa13f4_0    defaults
lzo                       2.10                 h6df0209_2    defaults
m2w64-gcc-libgfortran     5.3.0                         6    defaults
m2w64-gcc-libs            5.3.0                         7    defaults
m2w64-gcc-libs-core       5.3.0                         7    defaults
m2w64-gmp                 6.1.0                         2    defaults
m2w64-libwinpthread-git   5.0.0.4634.697f757               2    defaults
Markdown                  3.0.1                     <pip>
markupsafe                1.1.0            py36he774522_0    defaults
matplotlib                3.0.1            py36hc8f65d3_0    defaults
mccabe                    0.6.1                    py36_1    defaults
menuinst                  1.4.14           py36hfa6e2cd_0    defaults
mistune                   0.8.4            py36he774522_0    defaults
mkl                       2018.0.3                      1    defaults
mkl-service               1.1.2            py36hb217b18_5    defaults
mkl_fft                   1.0.6            py36hdbbee80_0    defaults
mkl_random                1.0.1            py36h77b88f5_1    defaults
more-itertools            4.3.0                    py36_0    defaults
mpmath                    1.0.0                    py36_2    defaults
msgpack-python            0.5.6            py36he980bc4_1    defaults
msys2-conda-epoch         20160418                      1    defaults
multipledispatch          0.6.0                    py36_0    defaults
navigator-updater         0.2.1                    py36_0    defaults
nbconvert                 5.4.0                    py36_1    defaults
nbformat                  4.4.0            py36h3a5bc1b_0    defaults
networkx                  2.2                      py36_1    defaults
nltk                      3.3.0                    py36_0    defaults
nose                      1.3.7                    py36_2    defaults
notebook                  5.7.2                    py36_0    defaults
numba                     0.41.0           py36hf9181ef_0    defaults
numexpr                   2.6.8            py36h9ef55f4_0    defaults
numpy                     1.15.4           py36ha559c80_0    defaults
numpy-base                1.15.4           py36h8128ebf_0    defaults
numpydoc                  0.8.0                    py36_0    defaults
odo                       0.5.1            py36h7560279_0    defaults
olefile                   0.46                     py36_0    defaults
openpyxl                  2.5.9                    py36_0    defaults
openssl                   1.0.2p               hfa6e2cd_0    defaults
packaging                 18.0                     py36_0    defaults
pandas                    0.23.4           py36h830ac7b_0    defaults
pandoc                    1.19.2.1             hb2460c7_1    defaults
pandocfilters             1.4.2                    py36_1    defaults
parso                     0.3.1                    py36_0    defaults
partd                     0.3.9                    py36_0    defaults
path.py                   11.5.0                   py36_0    defaults
pathlib2                  2.3.2                    py36_0    defaults
patsy                     0.5.1                    py36_0    defaults
pep8                      1.7.1                    py36_0    defaults
pickleshare               0.7.5                    py36_0    defaults
pillow                    5.3.0            py36hdc69c19_0    defaults
pip                       18.1                     py36_0    defaults
pkginfo                   1.4.2                    py36_1    defaults
pluggy                    0.8.0                    py36_0    defaults
ply                       3.11                     py36_0    defaults
prometheus_client         0.4.2                    py36_0    defaults
prompt_toolkit            2.0.7                    py36_0    defaults
protobuf                  3.6.1            py36h33f27b4_0    defaults
psutil                    5.4.8            py36he774522_0    defaults
py                        1.7.0                    py36_0    defaults
pyasn1                    0.4.4            py36h28b3542_0    defaults
pyasn1-modules            0.2.2                    py36_0    defaults
pycodestyle               2.4.0                    py36_0    defaults
pycosat                   0.6.3            py36hfa6e2cd_0    defaults
pycparser                 2.19                     py36_0    defaults
pycrypto                  2.6.1            py36hfa6e2cd_9    defaults
pycurl                    7.43.0.2         py36h74b6da3_0    defaults
pyflakes                  2.0.0                    py36_0    defaults
pygments                  2.2.0            py36hb010967_0    defaults
pyhamcrest                1.9.0                    py36_2    defaults
pylint                    2.1.1                    py36_0    defaults
pyodbc                    4.0.24           py36h6538335_0    defaults
pyopenssl                 18.0.0                   py36_0    defaults
pyparsing                 2.3.0                    py36_0    defaults
pyqt                      5.9.2            py36h6538335_2    defaults
pysocks                   1.6.8                    py36_0    defaults
pytables                  3.4.4            py36he6f6034_0    defaults
pytest                    4.0.0                    py36_0    defaults
pytest-arraydiff          0.2              py36h39e3cac_0    defaults
pytest-astropy            0.4.0                    py36_0    defaults
pytest-doctestplus        0.2.0                    py36_0    defaults
pytest-openfiles          0.3.0                    py36_0    defaults
pytest-remotedata         0.3.1                    py36_0    defaults
python                    3.6.7                h33f27b4_1    defaults
python-dateutil           2.7.5                    py36_0    defaults
python-libarchive-c       2.8                      py36_6    defaults
pytz                      2018.7                   py36_0    defaults
pywavelets                1.0.1            py36h8c2d366_0    defaults
pywin32                   223              py36hfa6e2cd_1    defaults
pywinpty                  0.5.4                    py36_0    defaults
pyyaml                    3.13             py36hfa6e2cd_0    defaults
pyzmq                     17.1.2           py36hfa6e2cd_0    defaults
qt                        5.9.6            vc14h1e9a669_2  [vc14]  defaults
qtawesome                 0.5.3                    py36_0    defaults
qtconsole                 4.4.2                    py36_0    defaults
qtpy                      1.5.2                    py36_0    defaults
requests                  2.20.1                   py36_0    defaults
rope                      0.11.0                   py36_0    defaults
ruamel_yaml               0.15.46          py36hfa6e2cd_0    defaults
scikit-image              0.14.0           py36h6538335_1    defaults
scikit-learn              0.20.1           py36hb854c30_0    defaults
scipy                     1.1.0            py36h4f6bf74_1    defaults
seaborn                   0.9.0                    py36_0    defaults
send2trash                1.5.0                    py36_0    defaults
service_identity          17.0.0           py36h28b3542_0    defaults
setuptools                40.6.2                   py36_0    defaults
simplegeneric             0.8.1                    py36_2    defaults
singledispatch            3.4.0.3          py36h17d0c80_0    defaults
sip                       4.19.8           py36h6538335_0    defaults
six                       1.11.0                   py36_1    defaults
snappy                    1.1.7                h777316e_3    defaults
snowballstemmer           1.2.1            py36h763602f_0    defaults
sortedcollections         1.0.1                    py36_0    defaults
sortedcontainers          2.0.5                    py36_0    defaults
sphinx                    1.8.2                    py36_0    defaults
sphinxcontrib             1.0                      py36_1    defaults
sphinxcontrib-websupport  1.1.0                    py36_1    defaults
spyder                    3.3.2                    py36_0    defaults
spyder-kernels            0.3.0                    py36_0    defaults
sqlalchemy                1.2.14           py36he774522_0    defaults
sqlite                    3.24.0               h7602738_0    defaults
statsmodels               0.9.0            py36h452e1ab_0    defaults
sympy                     1.3                      py36_0    defaults
tblib                     1.3.2            py36h30f5020_0    defaults
tensorboard               1.12.0                    <pip>
tensorflow-base           1.12.0          gpu_py36h6e53903_0    defaults
termcolor                 1.1.0                    py36_1    defaults
terminado                 0.8.1                    py36_1    defaults
testpath                  0.4.2                    py36_0    defaults
textblob                  0.15.1                     py_0    conda-forge/label/gcc7
tk                        8.6.8                hfa6e2cd_0    defaults
toolz                     0.9.0                    py36_0    defaults
tornado                   5.1.1            py36hfa6e2cd_0    defaults
tqdm                      4.28.1           py36h28b3542_0    defaults
traitlets                 4.3.2            py36h096827d_0    defaults
twisted                   18.9.0           py36he774522_0    defaults
typed-ast                 1.1.0            py36hfa6e2cd_0    defaults
unicodecsv                0.14.1           py36h6450c06_0    defaults
urllib3                   1.23                     py36_0    defaults
vc                        14.1                 h0510ff6_4    defaults
vs2015_runtime            14.15.26706          h3a45250_0    defaults
wcwidth                   0.1.7            py36h3d5aa90_0    defaults
webencodings              0.5.1                    py36_1    defaults
werkzeug                  0.14.1                   py36_0    defaults
wheel                     0.32.3                   py36_0    defaults
widgetsnbextension        3.4.2                    py36_0    defaults
win_inet_pton             1.0.1                    py36_1    defaults
win_unicode_console       0.5              py36hcdbd4b5_0    defaults
wincertstore              0.2              py36h7fe50ca_0    defaults
winpty                    0.4.3                         4    defaults
wrapt                     1.10.11          py36hfa6e2cd_2    defaults
xlrd                      1.1.0                    py36_1    defaults
xlsxwriter                1.1.2                    py36_0    defaults
xlwings                   0.14.1                   py36_0    defaults
xlwt                      1.3.0            py36h1a4751e_0    defaults
xz                        5.2.4                h2fa13f4_4    defaults
yaml                      0.1.7                hc54c509_2    defaults
zeromq                    4.2.5                he025d50_1    defaults
zict                      0.1.3                    py36_0    defaults
zlib                      1.2.11               h8395fce_2    defaults
zope                      1.0                      py36_1    defaults
zope.interface            4.6.0            py36he774522_0    defaults
zstd                      1.3.3                hfe6a214_0    defaults

***********************************************************************************************************
SYSTEM INFO
Windows 8.1 pro

processor : intel(R) core(TM)-i5-4590cpu @3.30GHz  3.30GHz
RAM : 8gb
SYSTEM TYPE: 64-bit OS, X64-based processor ","Have you tried building Tensorflow with pip using the --upgrade tag? ""pip3 install tensorflow --upgrade"". It might be related to that. If not, I'll dig deeper to find what your problem might be. || @Aashaybane Did you get a chance to try this? Did it solve your issue?

> Have you tried building Tensorflow with pip using the --upgrade tag? ""pip3 install tensorflow --upgrade"". It might be related to that. If not, I'll dig deeper to find what your problem might be.

 || Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!
",closed,2018-11-30T06:26:28+00:00,2018-12-07T18:18:42+00:00,Aashaybane,"stat:awaiting response, type:build/install",1,"PR#90009 - third_party/xla/xla/hlo/analysis/hlo_reachability.h: @@ -60,7 +60,7 @@ class HloReachabilityMap {|;|   // Similar to the above Build operation except that it tries to identify|;|   // paths between instructions that do not contain control instructions|;|   // and multiple operands, i.e., b is_reachable a == true iff|;|-  // b = f(f(f(f(f(a), constant), constant), constant).|;|+  // b = f(f(f(f(f(a), constant), constant), constant), constant).|;|   // Further, the only ops allowed in a path are basic math operations such|;|   // as add, sub, mul, div.|;|   static std::unique_ptr<HloReachabilityMap> BuildWithRestrictions( || PR#90009 - third_party/xla/xla/service/gpu/transforms/BUILD: @@ -962,6 +962,7 @@ cc_library(|;|         ""//xla:shape_util"",|;|         ""//xla:util"",|;|         ""//xla:xla_data_proto_cc"",|;|+        ""//xla/hlo/analysis:hlo_reachability"",|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/pass:hlo_pass"",|;|         ""//xla/service:hlo_creation_utils"", || PR#90009 - third_party/xla/xla/service/gpu/transforms/cudnn_fused_conv_rewriter.cc: @@ -40,6 +40,7 @@ limitations under the License.|;| #include ""absl/strings/string_view.h""|;| #include ""xla/comparison_util.h""|;| #include ""xla/debug_options_flags.h""|;|+#include ""xla/hlo/analysis/hlo_reachability.h""|;| #include ""xla/hlo/ir/hlo_instruction.h""|;| #include ""xla/hlo/ir/hlo_opcode.h""|;| #include ""xla/literal.h""|;|@@ -532,8 +533,8 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|                                std::vector<HloInstruction*>& aux_outputs,|;|                                GraphString& graph_string,|;|                                absl::flat_hash_set<int>& visited_instrs,|;|-                               HloInstruction*& final_instr,|;|-                               int& num_endpoints) {|;|+                               HloInstruction*& final_instr, int& num_endpoints,|;|+                               HloReachabilityMap* reachability) {|;|   // Avoid visiting the same instruction more than once.|;|   if (!visited_instrs.emplace(instr->unique_id()).second) {|;|     return|;|;@@ -568,18 +569,43 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|   //        E - F|;|   //|;|   // Fusion stops at B since the graph would have two endpoints.|;|+|;|+  // External operands of ops eligible for fusion into the cuDNN graph must not|;|+  // be reachable from graph outputs of existing fused ops as this may create a|;|+  // circular dependency between fused and unfused instructions.|;|+  auto eligible_operand =|;|+      [reachability, &aux_outputs](const HloInstruction* operand) -> bool {|;|+    return std::none_of(aux_outputs.begin(), aux_outputs.end(),|;|+                        [reachability, operand](HloInstruction* aux_output) {|;|+                          return reachability->IsReachable(aux_output, operand)|;|;+                        })|;|;+  }|;|;+|;|+  // External operands of existing fused ops must not be reachable from graph|;|+  // outputs of ops eligible for fusion into the cuDNN graph as this may create|;|+  // a circular dependency between fused and unfused instructions.|;|+  auto eligible_aux_output =|;|+      [reachability, &operands](const HloInstruction* aux_output) -> bool {|;|+    return std::none_of(operands.begin(), operands.end(),|;|+                        [reachability, aux_output](HloInstruction* operand) {|;|+                          return reachability->IsReachable(aux_output, operand)|;|;+                        })|;|;+  }|;|;+|;|   int num_new_users = 0|;|;   int num_existing_users = 0|;|;   for (HloInstruction* user : instr->users()) {|;|     HloInstruction *op0, *op1, *op2, *operand0, *operand1|;|;     // Add|;|     if (Match(user,|;|-              m::AddAnyOrder(&op0, m::Op().Is(instr), m::Op(&operand0)))) {|;|+              m::AddAnyOrder(&op0, m::Op().Is(instr), m::Op(&operand0))) &&|;|+        eligible_operand(operand0)) {|;|       if (graph_string.AppendOp(""add"", op0, {instr, operand0})) {|;|         operands.push_back(operand0)|;|;         ++num_new_users|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       } else {|;|         // Since operands only holds ops that are not part of the graph, remove|;|         // instr.|;|@@ -592,24 +618,26 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|     // Scale|;|     if (Match(user, m::MultiplyAnyOrder(&op0, m::Op().Is(instr),|;|                                         m::Broadcast(m::Op(&operand0)))) &&|;|-        ShapeUtil::IsScalar(operand0->shape())) {|;|+        ShapeUtil::IsScalar(operand0->shape()) && eligible_operand(operand0)) {|;|       if (graph_string.AppendOp(""scale"", op0, {instr, operand0})) {|;|         operands.push_back(operand0)|;|;         ++num_new_users|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       }|;|       continue|;|;     }|;|     // Inverse Scale|;|     if (Match(user, m::Divide(&op0, m::Op().Is(instr),|;|                               m::Broadcast(m::Op(&operand0)))) &&|;|-        ShapeUtil::IsScalar(operand0->shape())) {|;|+        ShapeUtil::IsScalar(operand0->shape()) && eligible_operand(operand0)) {|;|       if (graph_string.AppendOp(""invscale"", op0, {instr, operand0})) {|;|         operands.push_back(operand0)|;|;         ++num_new_users|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       }|;|       continue|;|;     }|;|@@ -619,13 +647,15 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|       if (graph_string.AppendOp(""relu"", op0, {instr})) {|;|         ++num_new_users|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       }|;|       continue|;|;     }|;|     //  Maximum of the absolute value (Amax) following ReLU (elided Abs)|;|     if (Match(user, m::Reduce(&op0, m::Op().Is(instr), m::Op())) &&|;|-        graph_string.OpInGraph(instr, ""relu"") && AppliesMaxReduce(op0)) {|;|+        graph_string.OpInGraph(instr, ""relu"") && AppliesMaxReduce(op0) &&|;|+        eligible_aux_output(op0)) {|;|       if (graph_string.AppendOp(""amax"", op0, {instr})) {|;|         aux_outputs.push_back(op0)|;|;         ++num_new_users|;|;@@ -640,14 +670,16 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|                 m::Broadcast(&op0, m::ConstantEffectiveScalar(0)).WithOneUser(),|;|                 m::Op().Is(instr),|;|                 m::Broadcast(&operand0, m::ConstantEffectiveScalar(6))|;|-                    .WithOneUser()))) {|;|+                    .WithOneUser())) &&|;|+        eligible_operand(operand0)) {|;|       if (!graph_string.OpInGraph(op0) && !graph_string.OpInGraph(op1)) {|;|         graph_string.AppendOp(""relu"", op0, {instr})|;|;         graph_string.AppendOp(""min"", op1, {op0, operand0})|;|;         ++num_new_users|;|;         operands.push_back(operand0)|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       }|;|       continue|;|;     }|;|@@ -661,7 +693,8 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|       if (graph_string.AppendOp(""elu"", op0, {instr})) {|;|         num_new_users += 3|;|;         CaptureConvGraphRecursive(user, operands, aux_outputs, graph_string,|;|-                                  visited_instrs, final_instr, num_endpoints)|;|;+                                  visited_instrs, final_instr, num_endpoints,|;|+                                  reachability)|;|;       }|;|       continue|;|;     }|;|@@ -676,13 +709,13 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|         ++num_new_users|;|;         CaptureConvGraphRecursive(users_user, operands, aux_outputs,|;|                                   graph_string, visited_instrs, final_instr,|;|-                                  num_endpoints)|;|;+                                  num_endpoints, reachability)|;|;         continue|;|;       }|;|       // Maximum of the absolute value (Amax)|;|       if (Match(users_user,|;|                 m::Reduce(&op0, m::Abs(m::Op().Is(instr)), m::Op())) &&|;|-          AppliesMaxReduce(op0)) {|;|+          AppliesMaxReduce(op0) && eligible_aux_output(op0)) {|;|         if (graph_string.AppendOp(""amax"", op0, {instr})) {|;|           aux_outputs.push_back(op0)|;|;           ++num_new_users|;|;@@ -704,7 +737,8 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|                         m::MultiplyAnyOrder(|;|                             &op1, m::Op().Is(instr),|;|                             m::Broadcast(m::ConstantEffectiveScalar(&operand1)))|;|-                            .WithOneUser()))) {|;|+                            .WithOneUser())) &&|;|+          eligible_operand(operand0) && eligible_operand(operand1)) {|;|         if (!graph_string.OpInGraph(op0) && !graph_string.OpInGraph(op1) &&|;|             !graph_string.OpInGraph(op2)) {|;|           graph_string.AppendOp(""min"", op0, op2->shape().element_type(),|;|@@ -716,7 +750,7 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|           operands.push_back(operand1)|;|;           CaptureConvGraphRecursive(users_user, operands, aux_outputs,|;|                                     graph_string, visited_instrs, final_instr,|;|-                                    num_endpoints)|;|;+                                    num_endpoints, reachability)|;|;         }|;|         continue|;|;       }|;|@@ -731,11 +765,14 @@ void CaptureConvGraphRecursive(HloInstruction* instr,|;|     ++num_endpoints|;|;   }|;| |;|-  // Since the cuDNN graph cannot have more than one endpoint, do not fuse|;|-  // into the cuDNN convolution Custom Call and roll back the graph when there|;|-  // are multiple endpoints. If the resulting graph still has more than one|;|-  // endpoint, the recursive caller will continue to roll back the graph.|;|-  if (num_endpoints > 1) {|;|+  // Do not fuse into the cuDNN convolution Custom Call and roll back the graph|;|+  // when the number of users eligible for fusion is less than the total number|;|+  // of users of instr. Since the cuDNN graph cannot have more than one|;|+  // endpoint, also roll back the graph when there are multiple endpoints. If|;|+  // the resulting graph still has more than one endpoint, the recursive caller|;|+  // will continue to roll back the graph.|;|+  if (num_new_users + num_existing_users < instr->user_count() |||;|+      num_endpoints > 1) {|;|     graph_string = std::move(init_graph_string)|;|;     operands = init_operands|;|;     aux_outputs = init_aux_outputs|;|;@@ -786,8 +823,11 @@ CaptureConvGraph(HloInstruction* instr, HloInstruction* convolution,|;|   absl::flat_hash_set<int> visited_instrs|;|;   HloInstruction* final_instr|;|;   int num_endpoints = 0|;|;+  std::unique_ptr<HloReachabilityMap> reachability =|;|+      HloReachabilityMap::Build(instr->parent())|;|;   CaptureConvGraphRecursive(instr, operands, aux_outputs, graph_string,|;|-                            visited_instrs, final_instr, num_endpoints)|;|;+                            visited_instrs, final_instr, num_endpoints,|;|+                            reachability.get())|;|;   return std::make_tuple(operands, aux_outputs, graph_string, final_instr)|;|; }|;|  || PR#90009 - third_party/xla/xla/service/gpu/transforms/cudnn_fused_conv_rewriter_test.cc: @@ -1499,6 +1499,58 @@ TEST_F(CudnnFusedConvRewriterTest, TestConvScaledOutputUnsupportedUserF8) {|;|       )"")|;|; }|;| |;|+TEST_F(CudnnFusedConvRewriterTest, TestConvAddOperandReachableFromAmaxF8) {|;|+  MAYBE_SKIP_TEST(""F8"")|;|;+  TestF8(|;|+      // pre_hlo|;|+      R""(|;|+    HloModule Test|;|+|;|+    apply {|;|+      a = f32[] parameter(0)|;|+      b = f32[] parameter(1)|;|+      ROOT c = f32[] maximum(a, b)|;|+    }|;|+|;|+    ENTRY Test {|;|+       input = f8e4m3fn[1,128,6,6] parameter(0)|;|+       filter = f8e4m3fn[3,3,128,16] parameter(1)|;|+       input_scale = f32[] parameter(2)|;|+       input_scale_bcast = f32[1,128,6,6] broadcast(input_scale), dimensions={}|;|+       filter_scale = f32[] parameter(3)|;|+       filter_scale_bcast = f32[3,3,128,16] broadcast(filter_scale), dimensions={}|;|+       input_f32 = f32[1,128,6,6] convert(input)|;|+       input_unscaled = f32[1,128,6,6] multiply(input_f32, input_scale_bcast)|;|+       filter_f32 = f32[3,3,128,16] convert(filter)|;|+       filter_unscaled = f32[3,3,128,16] multiply(filter_f32, filter_scale_bcast)|;|+       conv_a = f32[1,16,6,6] convolution(input_unscaled, filter_unscaled), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01, feature_group_count=1|;|+       z_scale = f32[] parameter(4)|;|+       z_scale_bcast = f32[1,16,6,6] broadcast(z_scale), dimensions={}|;|+       conv_a_scaled = f32[1,16,6,6] multiply(conv_a, z_scale_bcast)|;|+       abs_conv_a = f32[1,16,6,6] abs(conv_a)|;|+       c0 = f32[] constant(-inf)|;|+       amax = f32[] reduce(abs_conv_a, c0), dimensions={0,1,2,3}, to_apply=apply|;|+       amax_bcast = f32[1,16,6,6] broadcast(amax), dimensions={}|;|+       conv_a_scaled_amax = f32[1,16,6,6] add(conv_a_scaled, amax_bcast)|;|+       c1 = f32[] constant(-448.)|;|+       c1_bcast = f32[1,16,6,6] broadcast(c1), dimensions={}|;|+       c2 = f32[] constant(448.)|;|+       c2_bcast = f32[1,16,6,6] broadcast(c2), dimensions={}|;|+       conv_a_clamped = f32[1,16,6,6] clamp(c1_bcast, conv_a_scaled_amax, c2_bcast)|;|+       conv_a_clamped_f8 = f8e4m3fn[1,16,6,6] convert(conv_a_clamped)|;|+       ROOT conv_f8 = (f8e4m3fn[1,16,6,6], f32[]) tuple(conv_a_clamped_f8, amax)|;|+|;|+    })"",|;|+      // custom_call|;|+      R""(|;|+// CHECK: [[cudnn_conv_4_0:%[^ ]+]] = (f32[1,6,6,16]{3,2,1,0}, u8[{{.*}}]{0}) custom-call([[OPERAND0:%[^ ]+]], [[OPERAND1:%[^ ]+]], [[OPERAND2:%[^ ]+]], [[OPERAND3:%[^ ]+]]), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=""__cudnn$convForwardGraph""|;|+    )"",|;|+      // serialized_graph|;|+      R""(|;|+// CHECK: ""serialized_graph"":""[[CONV_UID:[0-9]+]]:[f32]conv();[[SCALE0_UID:[0-9]+]]:[f32]scale([[CONV_UID]]);[[SCALE1_UID:[0-9]+]]:[f32]scale([[SCALE0_UID]]);""|;|+      )"")|;|;+}|;|+|;| TEST_F(CudnnFusedConvRewriterTest, TestConvInt8ToInt8) {|;|   MAYBE_SKIP_TEST(""I8"")|;|;   // max(0, clamp(conv(x, w)))); for int8_t","PR #24060: Exclude Circular Dependencies in FP8 Graph Convolutions

Imported from GitHub PR https://github.com/openxla/xla/pull/24060

Excludes ops with external operands that can be reached from graph outputs of fused ops as well as ops with graph outputs that can reach external operands of fused ops from fusion into graph-based FP8 convolutions. Fusing these ops may lead to circular dependencies between fused and unfused instructions.
Copybara import of the project:

--
5ebb2be3175c310b8e2212c1401d660eb5a36625 by Philipp Hack <phack@nvidia.com>:

Excludes ops that may cause circular dependencies from fusion into graph-based FP8 convolutions.

--
f247a7122b7b9c842142650789905490d388ef4e by Philipp Hack <phack@nvidia.com>:

Excludes ops that may cause circular dependencies from fusion into graph-based FP8 convolutions.

Merging this change closes #24060

PiperOrigin-RevId: 741007457"
tensorflow/tensorflow,chunhsue,89337,Qualcomm AI Engine Direct - Compile QINT16 as QUINT16,"# What
Separate https://github.com/tensorflow/tensorflow/pull/89132 into 2 PRs for better review experience.
This PR only includes ""Compile"" part.
Internal review recorded [here](https://github.com/tensorflow/tensorflow/pull/89132). 
# Tests
`qnn_compiler_plugin_test`
```
[----------] Global test environment tear-down
[==========] 127 tests from 5 test suites ran. (4621 ms total)
[  PASSED  ] 127 tests.
```
`//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:utils_test`
```
[----------] Global test environment tear-down
[==========] 11 tests from 3 test suites ran. (0 ms total)
[  PASSED  ] 11 tests.
```
`//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:all`
```
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:op_wrapper_test (cached) PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:quantize_params_wrapper_test (cached) PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:param_wrapper_test PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:tensor_wrapper_test PASSED in 0.0s
```",,closed,2025-03-17T05:31:36+00:00,2025-03-26T21:33:53+00:00,chunhsue,"ready to pull, size:L",1,"PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin.cc: @@ -31,7 +31,6 @@|;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_model.h""|;|-#include ""tensorflow/lite/experimental/litert/c/litert_op_code.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_macros.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/core/model/model.h""|;|@@ -274,6 +273,13 @@ LiteRtStatus LiteRtCompilerPluginPartition(LiteRtCompilerPlugin compiler_plugin,|;|     std::vector<::qnn::OpWrapper> op_wrappers|;|;     LITERT_RETURN_IF_ERROR(litert::qnn::ConvertOp(|;|         op, tensor_pool, input_tensors, output_tensors, op_wrappers))|;|;+    tensor_pool.ForEach([](::qnn::TensorWrapper& tensor_wrapper) {|;|+      // TODO(chunhsue): Use compile interface to get useQInt16AsQUint16.|;|+      constexpr bool useQInt16AsQUint16 = true|;|;+      if constexpr (useQInt16AsQUint16) {|;|+        tensor_wrapper.ConvertQint16ToQuint16()|;|;+      }|;|+    })|;|;     // Empty op_wrappers means the op is not supported by QNN.|;|     if (op_wrappers.empty()) {|;|       continue; || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin_test.cc: @@ -94,13 +94,13 @@ const auto kSupportedOps =|;|                     kRMSNormModel,|;|                     kSDPAModel,|;|                     kAttentionModel,|;|-                    kTransformerBlockModel|;|-                    // kQSimpleMul16x16Model,|;|-                    // kQMulAdd16x16Model,|;|-                    // kQQueryEinsum16x8Model,|;|-                    // kQKeyEinsum16x8Model,|;|-                    // kQVauleEinsum16x8Model,|;|-                    // kQAttnVecEinsum16x8Model|;|+                    kTransformerBlockModel,|;|+                    kQSimpleMul16x16Model,|;|+                    kQMulAdd16x16Model,|;|+                    kQQueryEinsum16x8Model,|;|+                    kQKeyEinsum16x8Model,|;|+                    kQVauleEinsum16x8Model,|;|+                    kQAttnVecEinsum16x8Model|;|                     )|;|; |;| const auto kSupportedSocModels = Values( || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc: @@ -667,7 +667,7 @@ LiteRtStatus MapGraph(QnnManager& qnn, Qnn_ContextHandle_t context_handle,|;|     dump.clear()|;|;     Dump(*op.Get(), dump)|;|;     std::string s = dump.str()|;|;-    LITERT_LOG(LITERT_INFO, ""%s"", s.data())|;|;+    LITERT_LOG(LITERT_VERBOSE, ""%s"", s.data())|;|; |;|     std::vector<::qnn::TensorWrapperRef> input_tensors|;|;     for (const auto& input : op.Inputs()) {|;|@@ -703,6 +703,11 @@ LiteRtStatus MapGraph(QnnManager& qnn, Qnn_ContextHandle_t context_handle,|;|   // Insert all tensors into Qnn graph and update the id of Qnn_Tensor_t inside.|;|   tensor_pool.ForEach(|;|       [&qnn, &graph_mapper](::qnn::TensorWrapper& tensor_wrapper) {|;|+        // TODO(chunhsue): Use compile interface to get useQInt16AsQUint16.|;|+        constexpr bool useQInt16AsQUint16 = true|;|;+        if constexpr (useQInt16AsQUint16) {|;|+          tensor_wrapper.ConvertQint16ToQuint16()|;|;+        }|;|         qnn.Api()->tensorCreateGraphTensor(graph_mapper.QnnGraph(),|;|                                            &tensor_wrapper.GetQnnTensor())|;|;       }); || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h: @@ -21,10 +21,18 @@ typedef enum LiteRtQnnLogLevel {  // NOLINT(modernize-use-using)|;| typedef struct {  // NOLINT(modernize-use-using)|;|   /// Apply HTP-friendly op builder.|;|   bool useHtpPreferencs|;|;+  /// This option will treat quantized int16 tensor as quantized uint16 tensor|;|+  /// for better backend compatibility.|;|+  bool useQInt16AsQUint16|;|; } LiteRtQnnOptions|;|; |;|-#define LITERT_QNN_OPTIONS_INIT {false, /*useHtpPreferencs*/}|;|-|;|+// clang-format off|;|+#define LITERT_QNN_OPTIONS_INIT      \|;|+  {                                  \|;|+    false,    /*useHtpPreferencs*/   \|;|+    true,     /*useQInt16AsQUint16*/ \|;|+  }|;|+// clang-format on|;| #ifdef __cplusplus|;| }|;| #endif  // __cplusplus || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/BUILD: @@ -28,12 +28,14 @@ cc_library(|;| |;| cc_library(|;|     name = ""miscs"",|;|+    srcs = [""miscs.cc""],|;|     hdrs = [""miscs.h""],|;|     tags = [|;|         # Don't build/test in OS until qnn is available.|;|         ""nobuilder"",|;|     ],|;|     deps = [|;|+        ""@com_google_absl//absl/types:span"",|;|     ],|;| )|;|  || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.cc: @@ -0,0 +1,30 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc. All Rights Reserved.|;|+// SPDX-License-Identifier: Apache-2.0|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""absl/types/span.h""|;|+|;|+namespace qnn {|;|+void ConvertDataFromInt16toUInt16(absl::Span<const std::int16_t> src,|;|+                                  std::vector<std::uint16_t>& dst) {|;|+  dst.clear()|;|;+  dst.reserve(src.size())|;|;+  for (const auto& data : src) {|;|+    dst.emplace_back(data + kUint16ZeroPoint)|;|;+  }|;|+}|;|+|;|+void ConvertDataFromUInt16toInt16(absl::Span<const std::uint16_t> src,|;|+                                  std::vector<std::int16_t>& dst) {|;|+  dst.clear()|;|;+  dst.reserve(src.size())|;|;+  for (const auto& data : src) {|;|+    dst.emplace_back(data - kUint16ZeroPoint)|;|;+  }|;|+}|;|+|;|+}  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h: @@ -4,11 +4,41 @@|;| #ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_|;| #define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_|;| |;|+#include <cmath>|;|+#include <cstdint>|;|+#include <limits>|;|+#include <type_traits>|;|+#include <vector>|;|+|;|+#include ""absl/types/span.h""|;|+|;| namespace qnn {|;| |;|+constexpr uint32_t kUint16ZeroPoint = -std::numeric_limits<std::int16_t>::min()|;|;+|;| template <typename...>|;| inline constexpr bool always_false = false|;|; |;|+template <typename T>|;|+T Quantize(const float val, const float scale, const int32_t zero_point) {|;|+  static_assert(std::is_integral<T>::value,|;|+                ""Integral required in Quantize function."")|;|;+  return std::round(val / scale) + zero_point|;|;+}|;|+|;|+template <typename T>|;|+float Dequantize(const T val, const float scale, const int32_t zero_point) {|;|+  static_assert(std::is_integral<T>::value,|;|+                ""Integral required in Dequantize function."")|;|;+  return scale * (val - zero_point)|;|; }|;| |;|+void ConvertDataFromInt16toUInt16(absl::Span<const std::int16_t> src,|;|+                                  std::vector<std::uint16_t>& dst)|;|;+|;|+void ConvertDataFromUInt16toInt16(absl::Span<const std::uint16_t> src,|;|+                                  std::vector<std::int16_t>& dst)|;|;+|;|+}  // namespace qnn|;|+|;| #endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_ || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/utils_test.cc: @@ -1,13 +1,16 @@|;| // Copyright (c) Qualcomm Innovation Center, Inc. All Rights Reserved.|;| // SPDX-License-Identifier: Apache-2.0|;| |;|+#include <cstdint>|;| #include <cstdio>|;| #include <filesystem>|;| #include <fstream>|;| #include <string>|;| #include <string_view>|;|+#include <vector>|;| |;| #include <gtest/gtest.h>|;|+#include ""absl/types/span.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;|@@ -102,4 +105,46 @@ TEST(MiscTest, TestAlwaysFalse) {|;|   ASSERT_FALSE(::qnn::always_false<long double>)|;|; }|;| |;|+TEST(MiscTests, Quantize) {|;|+  float val = 1|;|;+  float scale = 0.1|;|;+  int32_t zero_point = 1|;|;+  auto q_val = Quantize<std::int8_t>(val, scale, zero_point)|;|;+  EXPECT_EQ(q_val, 11)|;|;+}|;|+|;|+TEST(MiscTests, Dequantize) {|;|+  std::int8_t q_val = 11|;|;+  float scale = 0.1|;|;+  int32_t zero_point = 1|;|;+  auto val = Dequantize(q_val, scale, zero_point)|;|;+  EXPECT_FLOAT_EQ(val, 1)|;|;+}|;|+|;|+TEST(MiscTests, ConvertDataFromInt16toUInt16) {|;|+  constexpr int16_t int16_data[4] = {0, 1, 2, 3}|;|;+  size_t data_len = sizeof(int16_data) / sizeof(int16_data[0])|;|;+  absl::Span int16_span(int16_data, data_len)|;|;+  std::vector<std::uint16_t> uint16_data|;|;+|;|+  ConvertDataFromInt16toUInt16(int16_span, uint16_data)|;|;+  EXPECT_EQ(uint16_data[0], 32768)|;|;+  EXPECT_EQ(uint16_data[1], 32769)|;|;+  EXPECT_EQ(uint16_data[2], 32770)|;|;+  EXPECT_EQ(uint16_data[3], 32771)|;|;+}|;|+|;|+TEST(MiscTests, ConvertDataFromUInt16toInt16) {|;|+  constexpr uint16_t uint16_data[4] = {32768, 32769, 32770, 32771}|;|;+  size_t data_len = sizeof(uint16_data) / sizeof(uint16_data[0])|;|;+  absl::Span uint16_span(uint16_data, data_len)|;|;+  std::vector<std::int16_t> int16_data|;|;+|;|+  ConvertDataFromUInt16toInt16(uint16_span, int16_data)|;|;+  EXPECT_EQ(int16_data[0], 0)|;|;+  EXPECT_EQ(int16_data[1], 1)|;|;+  EXPECT_EQ(int16_data[2], 2)|;|;+  EXPECT_EQ(int16_data[3], 3)|;|;+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.cc: @@ -7,6 +7,8 @@|;| #include <cstddef>|;| #include <cstdint>|;| #include <utility>|;|+#include <vector>|;|+|;| #include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;| |;|@@ -91,4 +93,22 @@ void AxisScaleOffsetQuantizeParamsWrapper::SetAxis(const std::int32_t axis) {|;|   qnn_quantize_param_.axisScaleOffsetEncoding.axis = axis|;|; }|;| |;|+void AxisScaleOffsetQuantizeParamsWrapper::GetScales(|;|+    std::vector<float>& scales) const {|;|+  scales.clear()|;|;+  scales.reserve(scale_offsets_.size())|;|;+  for (size_t i = 0; i < scale_offsets_.size(); ++i) {|;|+    scales.emplace_back(scale_offsets_[i].scale)|;|;+  }|;|+}|;|+|;|+void AxisScaleOffsetQuantizeParamsWrapper::GetZeroPoints(|;|+    std::vector<std::int32_t>& zero_points) const {|;|+  zero_points.clear()|;|;+  zero_points.reserve(scale_offsets_.size())|;|;+  for (size_t i = 0; i < scale_offsets_.size(); ++i) {|;|+    zero_points.emplace_back(-1 * scale_offsets_[i].offset)|;|;+  }|;|+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h: @@ -37,6 +37,14 @@ class ScaleOffsetQuantizeParamsWrapper final {|;| |;|   void CloneTo(Qnn_QuantizeParams_t& dst)|;|; |;|+  float GetScale() const {|;|+    return qnn_quantize_param_.scaleOffsetEncoding.scale|;|;+  }|;|+|;|+  std::int32_t GetZeroPoint() const {|;|+    return -1 * qnn_quantize_param_.scaleOffsetEncoding.offset|;|;+  }|;|+|;|  private:|;|   Qnn_QuantizeParams_t qnn_quantize_param_ = QNN_QUANTIZE_PARAMS_INIT|;|; }|;|;@@ -59,6 +67,10 @@ class AxisScaleOffsetQuantizeParamsWrapper final {|;| |;|   void SetAxis(const std::int32_t axis)|;|; |;|+  void GetScales(std::vector<float>& scales) const|;|;+|;|+  void GetZeroPoints(std::vector<std::int32_t>& zero_points) const|;|;+|;|  private:|;|   Qnn_QuantizeParams_t qnn_quantize_param_ = QNN_QUANTIZE_PARAMS_INIT|;|;   std::vector<Qnn_ScaleOffset_t> scale_offsets_; || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.cc: @@ -3,6 +3,7 @@|;| |;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;| |;|+#include <algorithm>|;| #include <cmath>|;| #include <cstddef>|;| #include <cstdint>|;|@@ -15,8 +16,10 @@|;| #include <variant>|;| #include <vector>|;| |;|+#include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| |;| namespace qnn {|;|@@ -152,10 +155,6 @@ size_t TensorWrapper::GetTensorBytes() const {|;|   return GetDataTypeSize(GetDataType()) * GetTensorNumElements()|;|; }|;| |;|-void TensorWrapper::SetDataType(Qnn_DataType_t data_type) {|;|-  qnn_tensor_.v2.dataType = data_type|;|;-}|;|-|;| bool TensorWrapper::IsPerTensorQuantWithOffsetDiff(|;|     const TensorWrapper& rhs) const {|;|   const auto& lhs_quant = qnn_tensor_.v2.quantizeParams|;|;@@ -214,4 +213,62 @@ void TensorWrapper::SetDataBy(std::uint32_t bytes, const void* data) {|;|   qnn_tensor_.v2.clientBuf.data = owned_data_.data()|;|; }|;| |;|+void TensorWrapper::ConvertQint16ToQuint16() {|;|+  if (GetDataType() != QNN_DATATYPE_SFIXED_POINT_16) {|;|+    return|;|;+  }|;|+|;|+  // adjust static data|;|+  if (IsTensorStatic()) {|;|+    auto int16_data = GetStaticTensorData<std::int16_t>()|;|;+    if (!int16_data.has_value()) {|;|+      QNN_LOG_ERROR(|;|+          ""Cannot convert static QInt16 data to QUint16 data failed since ""|;|+          ""GetStaticTensorData failed."")|;|;+      return|;|;+    }|;|+    QNN_LOG_DEBUG(""Converting static tensor data from QInt16 to QUint16..."")|;|;+    std::vector<std::uint16_t> uint16_data|;|;+    ConvertDataFromInt16toUInt16((*int16_data), uint16_data)|;|;+    std::memcpy(owned_data_.data(),|;|+                reinterpret_cast<const char*>(uint16_data.data()),|;|+                GetTensorBytes())|;|;+    qnn_tensor_.v2.clientBuf.dataSize = owned_data_.size()|;|;+    qnn_tensor_.v2.clientBuf.data = owned_data_.data()|;|;+  }|;|+|;|+  // adjust quant param|;|;+  if (IsPerTensorQuant()) {|;|+    const auto& q_param =|;|+        std::get<ScaleOffsetQuantizeParamsWrapper>(GetQuantParams())|;|;+    quantize_params_.emplace<ScaleOffsetQuantizeParamsWrapper>(|;|+        q_param.GetScale(), q_param.GetZeroPoint() + kUint16ZeroPoint)|;|;+|;|+  } else if (IsPerChannelQuant()) {|;|+    const auto& q_param =|;|+        std::get<AxisScaleOffsetQuantizeParamsWrapper>(GetQuantParams())|;|;+    std::int32_t axis = q_param.GetAxis()|;|;+    std::vector<float> scales|;|;+    q_param.GetScales(scales)|;|;+    std::vector<std::int32_t> zero_points|;|;+    q_param.GetZeroPoints(zero_points)|;|;+    std::for_each(zero_points.begin(), zero_points.end(),|;|+                  [](std::int32_t& val) { val += kUint16ZeroPoint; })|;|;+    quantize_params_.emplace<AxisScaleOffsetQuantizeParamsWrapper>(|;|+        axis, absl::MakeSpan(scales), absl::MakeSpan(zero_points))|;|;+  }|;|+|;|+  std::visit(|;|+      [this](auto&& quantize_params) -> void {|;|+        quantize_params.CloneTo(qnn_tensor_.v2.quantizeParams)|;|;+      },|;|+      quantize_params_)|;|;+|;|+  // change data type here since GetStaticTensorData checks data type|;|+  qnn_tensor_.v2.dataType = QNN_DATATYPE_UFIXED_POINT_16|;|;+  QNN_LOG_DEBUG(|;|+      ""QNN does not fully support QInt16 now, converting to QUint16 for better ""|;|+      ""compatibility."")|;|;+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h: @@ -120,11 +120,21 @@ class TensorWrapper final {|;| |;|   QuantizeParamsWrapperVariant& GetQuantParams() { return quantize_params_; }|;|; |;|-  const bool IsQuant() const {|;|+  bool IsQuant() const {|;|     return !std::holds_alternative<UndefinedQuantizeParamsWrapper>(|;|         quantize_params_)|;|;   }|;|; |;|+  bool IsPerTensorQuant() const {|;|+    return std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+        quantize_params_)|;|;+  }|;|+|;|+  bool IsPerChannelQuant() const {|;|+    return std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|+        quantize_params_)|;|;+  }|;|+|;|   bool IsPerTensorQuantWithOffsetDiff(const TensorWrapper& rhs) const|;|; |;|   bool IsQuant8() const {|;|@@ -142,8 +152,6 @@ class TensorWrapper final {|;| |;|   Qnn_DataType_t GetDataType() const|;|; |;|-  void SetDataType(Qnn_DataType_t data_type)|;|;-|;|   bool IsSubgraphInput() const {|;|     return GetTensorType() == QNN_TENSOR_TYPE_APP_WRITE|;|;   }|;|@@ -281,11 +289,18 @@ class TensorWrapper final {|;| |;|   size_t GetTensorBytes() const|;|; |;|+  void ConvertQint16ToQuint16()|;|;+|;|  private:|;|   Qnn_TensorType_t GetTensorType() const|;|; |;|   void SetDataBy(std::uint32_t bytes, const void* data)|;|; |;|+  bool HasStaticData() const {|;|+    return qnn_tensor_.v2.clientBuf.dataSize != 0 &&|;|+           qnn_tensor_.v2.clientBuf.data != nullptr|;|;+  }|;|+|;|   Qnn_Tensor_t qnn_tensor_{.version = QNN_TENSOR_VERSION_2,|;|                            .v2 = QNN_TENSOR_V2_INIT}|;|;   std::string name_{}|;|;@@ -310,9 +325,8 @@ std::optional<absl::Span<const T>> TensorWrapper::GetStaticTensorData() const {|;|     return std::nullopt|;|;   }|;| |;|-  if (qnn_tensor_.v2.clientBuf.dataSize == 0 |||;|-      qnn_tensor_.v2.clientBuf.data == nullptr) {|;|-    QNN_LOG_ERROR(""Empty StaticTensorData."")|;|;+  if (!HasStaticData()) {|;|+    QNN_LOG_ERROR(""Empty static tensor data."")|;|;     return std::nullopt|;|;   }|;|  || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/BUILD: @@ -37,6 +37,7 @@ cc_test(|;|         ""@com_google_googletest//:gtest_main"",|;|         ""@com_google_absl//absl/types:span"",|;|         # copybara:uncomment ""//third_party/qairt/latest:qnn_lib_headers"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:miscs"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:quantize_params_wrapper"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:tensor_wrapper"",|;|     ], || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/quantize_params_wrapper_test.cc: @@ -78,6 +78,14 @@ TEST(ScaleOffsetQuantizeParamsWrapperTest, MoveConstructorTest) {|;|   EXPECT_EQ(dst.scaleOffsetEncoding.offset, -zero_point)|;|; }|;| |;|+TEST(ScaleOffsetQuantizeParamsWrapperTest, GetterTest) {|;|+  float scale = 1.5f|;|;+  std::int32_t zero_point = 10|;|;+  ScaleOffsetQuantizeParamsWrapper wrapper(scale, zero_point)|;|;+  EXPECT_FLOAT_EQ(wrapper.GetScale(), scale)|;|;+  EXPECT_EQ(wrapper.GetZeroPoint(), zero_point)|;|;+}|;|+|;| TEST(AxisScaleOffsetQuantizeParamsWrapperTest, ConstructorTest) {|;|   std::int32_t axis = 1|;|;   std::vector<float> scales = {1.5f, 2.5f}|;|;@@ -139,5 +147,17 @@ TEST(AxisScaleOffsetQuantizeParamsWrapperTest, MoveConstructorTest) {|;|               -zero_points[i])|;|;   }|;| }|;|+TEST(AxisScaleOffsetQuantizeParamsWrapperTest, GetterTest) {|;|+  std::int32_t axis = 1|;|;+  std::vector<float> scales = {1.5f, 2.5f}|;|;+  std::vector<std::int32_t> zero_points = {10, 20}|;|;+  AxisScaleOffsetQuantizeParamsWrapper wrapper(axis, scales, zero_points)|;|;+  std::vector<float> scales_out|;|;+  wrapper.GetScales(scales_out)|;|;+  EXPECT_EQ(scales, scales_out)|;|;+  std::vector<std::int32_t> zero_points_out|;|;+  wrapper.GetZeroPoints(zero_points_out)|;|;+  EXPECT_EQ(zero_points, zero_points_out)|;|;+}|;| }  // namespace|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/tensor_wrapper_test.cc: @@ -14,6 +14,7 @@|;| #include <gtest/gtest.h>|;| #include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| |;| namespace qnn {|;|@@ -159,25 +160,6 @@ TEST(TensorWrapperTest, QnnTensorTest) {|;|   }|;| }|;| |;|-TEST(TensorWrapperTest, DataTypeTest) {|;|-  TensorWrapper tensor_wrapper{}|;|;-  tensor_wrapper.SetDataType(QNN_DATATYPE_UFIXED_POINT_8)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_UFIXED_POINT_8)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant8())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_SFIXED_POINT_8)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_SFIXED_POINT_8)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant8())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_UFIXED_POINT_16)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_UFIXED_POINT_16)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant16())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_SFIXED_POINT_16)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_SFIXED_POINT_16)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant16())|;|;-}|;|-|;| TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff8BitTest) {|;|   constexpr int kSUFixed8OffsetDiff = 128|;|;   ScaleOffsetQuantizeParamsWrapper wrapper1(1, 0)|;|;@@ -189,11 +171,9 @@ TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff8BitTest) {|;|                                 {}}|;|;   TensorWrapper tensor_wrapper1{0,|;|                                 QNN_TENSOR_TYPE_STATIC,|;|-                                QNN_DATATYPE_UFIXED_POINT_8,|;|+                                QNN_DATATYPE_SFIXED_POINT_8,|;|                                 QuantizeParamsWrapperVariant(wrapper2),|;|                                 {}}|;|;-  EXPECT_FALSE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|;-  tensor_wrapper1.SetDataType(QNN_DATATYPE_SFIXED_POINT_8)|;|;   EXPECT_TRUE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|; }|;| |;|@@ -208,11 +188,9 @@ TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff16BitTest) {|;|                                 {}}|;|;   TensorWrapper tensor_wrapper1{0,|;|                                 QNN_TENSOR_TYPE_STATIC,|;|-                                QNN_DATATYPE_UFIXED_POINT_16,|;|+                                QNN_DATATYPE_SFIXED_POINT_16,|;|                                 QuantizeParamsWrapperVariant(wrapper2),|;|                                 {}}|;|;-  EXPECT_FALSE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|;-  tensor_wrapper1.SetDataType(QNN_DATATYPE_SFIXED_POINT_16)|;|;   EXPECT_TRUE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|; }|;| |;|@@ -280,5 +258,52 @@ TEST(TensorWrapperTest, GetStaticTensorDataTest) {|;|     EXPECT_EQ(tensor_data[i], data[i])|;|;   }|;| }|;|+|;|+TEST(TensorWrapperTest, ConvertQint16ToQuint16Test) {|;|+  std::vector<std::uint32_t> dummy_dims = {1, 1, 3}|;|;+  ScaleOffsetQuantizeParamsWrapper q_param(0.0001, 0)|;|;+  TensorWrapper tensor_wrapper{0, QNN_TENSOR_TYPE_STATIC,|;|+                               QNN_DATATYPE_SFIXED_POINT_16, q_param,|;|+                               dummy_dims}|;|;+|;|+  std::vector<float> data = {1, 2, 3}|;|;+  const auto& int16_q_param_ref = tensor_wrapper.GetQuantParams()|;|;+  EXPECT_TRUE(std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+      int16_q_param_ref))|;|;+  const float int16_scale =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(int16_q_param_ref).GetScale()|;|;+  const std::int32_t int16_zero_point =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(int16_q_param_ref)|;|+          .GetZeroPoint()|;|;+  std::vector<std::int16_t> int16_data|;|;+  for (int i = 0; i < data.size(); ++i) {|;|+    int16_data.emplace_back(|;|+        Quantize<std::int16_t>(data[i], int16_scale, int16_zero_point))|;|;+  }|;|+  tensor_wrapper.SetTensorData<std::int16_t>(|;|+      absl::MakeSpan(int16_data.data(), int16_data.size()))|;|;+|;|+  tensor_wrapper.ConvertQint16ToQuint16()|;|;+|;|+  const auto& uint16_q_param_ref = tensor_wrapper.GetQuantParams()|;|;+  EXPECT_TRUE(std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+      uint16_q_param_ref))|;|;+  const float uint16_scale =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(uint16_q_param_ref).GetScale()|;|;+  const std::int32_t uint16_zero_point =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(uint16_q_param_ref)|;|+          .GetZeroPoint()|;|;+  const auto uint16_data =|;|+      *(tensor_wrapper.GetStaticTensorData<std::uint16_t>())|;|;+  std::vector<float> deq_data|;|;+  for (size_t i = 0; i < data.size(); i++) {|;|+    deq_data.emplace_back(|;|+        Dequantize(uint16_data[i], uint16_scale, uint16_zero_point))|;|;+  }|;|+  ASSERT_EQ(data.size(), deq_data.size())|;|;+  for (size_t i = 0; i < data.size(); ++i) {|;|+    EXPECT_NEAR(data[i], deq_data[i], 1e-3)|;|;+  }|;|+}|;| }  // namespace|;| }  // namespace qnn","Qualcomm AI Engine Direct - Compile QINT16 as QUINT16 || Merge pull request #89337 from jiunkaiy:dev/chunhsue/compile_int16_as_uint16

PiperOrigin-RevId: 740900417"
tensorflow/tensorflow,tensorflower-gardener,89337,Qualcomm AI Engine Direct - Compile QINT16 as QUINT16,"# What
Separate https://github.com/tensorflow/tensorflow/pull/89132 into 2 PRs for better review experience.
This PR only includes ""Compile"" part.
Internal review recorded [here](https://github.com/tensorflow/tensorflow/pull/89132). 
# Tests
`qnn_compiler_plugin_test`
```
[----------] Global test environment tear-down
[==========] 127 tests from 5 test suites ran. (4621 ms total)
[  PASSED  ] 127 tests.
```
`//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:utils_test`
```
[----------] Global test environment tear-down
[==========] 11 tests from 3 test suites ran. (0 ms total)
[  PASSED  ] 11 tests.
```
`//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:all`
```
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:op_wrapper_test (cached) PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:quantize_params_wrapper_test (cached) PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:param_wrapper_test PASSED in 0.0s
//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests:tensor_wrapper_test PASSED in 0.0s
```",,closed,2025-03-17T05:31:36+00:00,2025-03-26T21:33:53+00:00,chunhsue,"ready to pull, size:L",1,"PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin.cc: @@ -31,7 +31,6 @@|;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_model.h""|;|-#include ""tensorflow/lite/experimental/litert/c/litert_op_code.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_macros.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/core/model/model.h""|;|@@ -274,6 +273,13 @@ LiteRtStatus LiteRtCompilerPluginPartition(LiteRtCompilerPlugin compiler_plugin,|;|     std::vector<::qnn::OpWrapper> op_wrappers|;|;     LITERT_RETURN_IF_ERROR(litert::qnn::ConvertOp(|;|         op, tensor_pool, input_tensors, output_tensors, op_wrappers))|;|;+    tensor_pool.ForEach([](::qnn::TensorWrapper& tensor_wrapper) {|;|+      // TODO(chunhsue): Use compile interface to get useQInt16AsQUint16.|;|+      constexpr bool useQInt16AsQUint16 = true|;|;+      if constexpr (useQInt16AsQUint16) {|;|+        tensor_wrapper.ConvertQint16ToQuint16()|;|;+      }|;|+    })|;|;     // Empty op_wrappers means the op is not supported by QNN.|;|     if (op_wrappers.empty()) {|;|       continue; || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin_test.cc: @@ -94,13 +94,13 @@ const auto kSupportedOps =|;|                     kRMSNormModel,|;|                     kSDPAModel,|;|                     kAttentionModel,|;|-                    kTransformerBlockModel|;|-                    // kQSimpleMul16x16Model,|;|-                    // kQMulAdd16x16Model,|;|-                    // kQQueryEinsum16x8Model,|;|-                    // kQKeyEinsum16x8Model,|;|-                    // kQVauleEinsum16x8Model,|;|-                    // kQAttnVecEinsum16x8Model|;|+                    kTransformerBlockModel,|;|+                    kQSimpleMul16x16Model,|;|+                    kQMulAdd16x16Model,|;|+                    kQQueryEinsum16x8Model,|;|+                    kQKeyEinsum16x8Model,|;|+                    kQVauleEinsum16x8Model,|;|+                    kQAttnVecEinsum16x8Model|;|                     )|;|; |;| const auto kSupportedSocModels = Values( || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc: @@ -667,7 +667,7 @@ LiteRtStatus MapGraph(QnnManager& qnn, Qnn_ContextHandle_t context_handle,|;|     dump.clear()|;|;     Dump(*op.Get(), dump)|;|;     std::string s = dump.str()|;|;-    LITERT_LOG(LITERT_INFO, ""%s"", s.data())|;|;+    LITERT_LOG(LITERT_VERBOSE, ""%s"", s.data())|;|; |;|     std::vector<::qnn::TensorWrapperRef> input_tensors|;|;     for (const auto& input : op.Inputs()) {|;|@@ -703,6 +703,11 @@ LiteRtStatus MapGraph(QnnManager& qnn, Qnn_ContextHandle_t context_handle,|;|   // Insert all tensors into Qnn graph and update the id of Qnn_Tensor_t inside.|;|   tensor_pool.ForEach(|;|       [&qnn, &graph_mapper](::qnn::TensorWrapper& tensor_wrapper) {|;|+        // TODO(chunhsue): Use compile interface to get useQInt16AsQUint16.|;|+        constexpr bool useQInt16AsQUint16 = true|;|;+        if constexpr (useQInt16AsQUint16) {|;|+          tensor_wrapper.ConvertQint16ToQuint16()|;|;+        }|;|         qnn.Api()->tensorCreateGraphTensor(graph_mapper.QnnGraph(),|;|                                            &tensor_wrapper.GetQnnTensor())|;|;       }); || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h: @@ -21,10 +21,18 @@ typedef enum LiteRtQnnLogLevel {  // NOLINT(modernize-use-using)|;| typedef struct {  // NOLINT(modernize-use-using)|;|   /// Apply HTP-friendly op builder.|;|   bool useHtpPreferencs|;|;+  /// This option will treat quantized int16 tensor as quantized uint16 tensor|;|+  /// for better backend compatibility.|;|+  bool useQInt16AsQUint16|;|; } LiteRtQnnOptions|;|; |;|-#define LITERT_QNN_OPTIONS_INIT {false, /*useHtpPreferencs*/}|;|-|;|+// clang-format off|;|+#define LITERT_QNN_OPTIONS_INIT      \|;|+  {                                  \|;|+    false,    /*useHtpPreferencs*/   \|;|+    true,     /*useQInt16AsQUint16*/ \|;|+  }|;|+// clang-format on|;| #ifdef __cplusplus|;| }|;| #endif  // __cplusplus || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/BUILD: @@ -28,12 +28,14 @@ cc_library(|;| |;| cc_library(|;|     name = ""miscs"",|;|+    srcs = [""miscs.cc""],|;|     hdrs = [""miscs.h""],|;|     tags = [|;|         # Don't build/test in OS until qnn is available.|;|         ""nobuilder"",|;|     ],|;|     deps = [|;|+        ""@com_google_absl//absl/types:span"",|;|     ],|;| )|;|  || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.cc: @@ -0,0 +1,30 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc. All Rights Reserved.|;|+// SPDX-License-Identifier: Apache-2.0|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""absl/types/span.h""|;|+|;|+namespace qnn {|;|+void ConvertDataFromInt16toUInt16(absl::Span<const std::int16_t> src,|;|+                                  std::vector<std::uint16_t>& dst) {|;|+  dst.clear()|;|;+  dst.reserve(src.size())|;|;+  for (const auto& data : src) {|;|+    dst.emplace_back(data + kUint16ZeroPoint)|;|;+  }|;|+}|;|+|;|+void ConvertDataFromUInt16toInt16(absl::Span<const std::uint16_t> src,|;|+                                  std::vector<std::int16_t>& dst) {|;|+  dst.clear()|;|;+  dst.reserve(src.size())|;|;+  for (const auto& data : src) {|;|+    dst.emplace_back(data - kUint16ZeroPoint)|;|;+  }|;|+}|;|+|;|+}  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h: @@ -4,11 +4,41 @@|;| #ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_|;| #define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_|;| |;|+#include <cmath>|;|+#include <cstdint>|;|+#include <limits>|;|+#include <type_traits>|;|+#include <vector>|;|+|;|+#include ""absl/types/span.h""|;|+|;| namespace qnn {|;| |;|+constexpr uint32_t kUint16ZeroPoint = -std::numeric_limits<std::int16_t>::min()|;|;+|;| template <typename...>|;| inline constexpr bool always_false = false|;|; |;|+template <typename T>|;|+T Quantize(const float val, const float scale, const int32_t zero_point) {|;|+  static_assert(std::is_integral<T>::value,|;|+                ""Integral required in Quantize function."")|;|;+  return std::round(val / scale) + zero_point|;|;+}|;|+|;|+template <typename T>|;|+float Dequantize(const T val, const float scale, const int32_t zero_point) {|;|+  static_assert(std::is_integral<T>::value,|;|+                ""Integral required in Dequantize function."")|;|;+  return scale * (val - zero_point)|;|; }|;| |;|+void ConvertDataFromInt16toUInt16(absl::Span<const std::int16_t> src,|;|+                                  std::vector<std::uint16_t>& dst)|;|;+|;|+void ConvertDataFromUInt16toInt16(absl::Span<const std::uint16_t> src,|;|+                                  std::vector<std::int16_t>& dst)|;|;+|;|+}  // namespace qnn|;|+|;| #endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_UTILS_MISCS_H_ || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/utils_test.cc: @@ -1,13 +1,16 @@|;| // Copyright (c) Qualcomm Innovation Center, Inc. All Rights Reserved.|;| // SPDX-License-Identifier: Apache-2.0|;| |;|+#include <cstdint>|;| #include <cstdio>|;| #include <filesystem>|;| #include <fstream>|;| #include <string>|;| #include <string_view>|;|+#include <vector>|;| |;| #include <gtest/gtest.h>|;|+#include ""absl/types/span.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;|@@ -102,4 +105,46 @@ TEST(MiscTest, TestAlwaysFalse) {|;|   ASSERT_FALSE(::qnn::always_false<long double>)|;|; }|;| |;|+TEST(MiscTests, Quantize) {|;|+  float val = 1|;|;+  float scale = 0.1|;|;+  int32_t zero_point = 1|;|;+  auto q_val = Quantize<std::int8_t>(val, scale, zero_point)|;|;+  EXPECT_EQ(q_val, 11)|;|;+}|;|+|;|+TEST(MiscTests, Dequantize) {|;|+  std::int8_t q_val = 11|;|;+  float scale = 0.1|;|;+  int32_t zero_point = 1|;|;+  auto val = Dequantize(q_val, scale, zero_point)|;|;+  EXPECT_FLOAT_EQ(val, 1)|;|;+}|;|+|;|+TEST(MiscTests, ConvertDataFromInt16toUInt16) {|;|+  constexpr int16_t int16_data[4] = {0, 1, 2, 3}|;|;+  size_t data_len = sizeof(int16_data) / sizeof(int16_data[0])|;|;+  absl::Span int16_span(int16_data, data_len)|;|;+  std::vector<std::uint16_t> uint16_data|;|;+|;|+  ConvertDataFromInt16toUInt16(int16_span, uint16_data)|;|;+  EXPECT_EQ(uint16_data[0], 32768)|;|;+  EXPECT_EQ(uint16_data[1], 32769)|;|;+  EXPECT_EQ(uint16_data[2], 32770)|;|;+  EXPECT_EQ(uint16_data[3], 32771)|;|;+}|;|+|;|+TEST(MiscTests, ConvertDataFromUInt16toInt16) {|;|+  constexpr uint16_t uint16_data[4] = {32768, 32769, 32770, 32771}|;|;+  size_t data_len = sizeof(uint16_data) / sizeof(uint16_data[0])|;|;+  absl::Span uint16_span(uint16_data, data_len)|;|;+  std::vector<std::int16_t> int16_data|;|;+|;|+  ConvertDataFromUInt16toInt16(uint16_span, int16_data)|;|;+  EXPECT_EQ(int16_data[0], 0)|;|;+  EXPECT_EQ(int16_data[1], 1)|;|;+  EXPECT_EQ(int16_data[2], 2)|;|;+  EXPECT_EQ(int16_data[3], 3)|;|;+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.cc: @@ -7,6 +7,8 @@|;| #include <cstddef>|;| #include <cstdint>|;| #include <utility>|;|+#include <vector>|;|+|;| #include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;| |;|@@ -91,4 +93,22 @@ void AxisScaleOffsetQuantizeParamsWrapper::SetAxis(const std::int32_t axis) {|;|   qnn_quantize_param_.axisScaleOffsetEncoding.axis = axis|;|; }|;| |;|+void AxisScaleOffsetQuantizeParamsWrapper::GetScales(|;|+    std::vector<float>& scales) const {|;|+  scales.clear()|;|;+  scales.reserve(scale_offsets_.size())|;|;+  for (size_t i = 0; i < scale_offsets_.size(); ++i) {|;|+    scales.emplace_back(scale_offsets_[i].scale)|;|;+  }|;|+}|;|+|;|+void AxisScaleOffsetQuantizeParamsWrapper::GetZeroPoints(|;|+    std::vector<std::int32_t>& zero_points) const {|;|+  zero_points.clear()|;|;+  zero_points.reserve(scale_offsets_.size())|;|;+  for (size_t i = 0; i < scale_offsets_.size(); ++i) {|;|+    zero_points.emplace_back(-1 * scale_offsets_[i].offset)|;|;+  }|;|+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h: @@ -37,6 +37,14 @@ class ScaleOffsetQuantizeParamsWrapper final {|;| |;|   void CloneTo(Qnn_QuantizeParams_t& dst)|;|; |;|+  float GetScale() const {|;|+    return qnn_quantize_param_.scaleOffsetEncoding.scale|;|;+  }|;|+|;|+  std::int32_t GetZeroPoint() const {|;|+    return -1 * qnn_quantize_param_.scaleOffsetEncoding.offset|;|;+  }|;|+|;|  private:|;|   Qnn_QuantizeParams_t qnn_quantize_param_ = QNN_QUANTIZE_PARAMS_INIT|;|; }|;|;@@ -59,6 +67,10 @@ class AxisScaleOffsetQuantizeParamsWrapper final {|;| |;|   void SetAxis(const std::int32_t axis)|;|; |;|+  void GetScales(std::vector<float>& scales) const|;|;+|;|+  void GetZeroPoints(std::vector<std::int32_t>& zero_points) const|;|;+|;|  private:|;|   Qnn_QuantizeParams_t qnn_quantize_param_ = QNN_QUANTIZE_PARAMS_INIT|;|;   std::vector<Qnn_ScaleOffset_t> scale_offsets_; || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.cc: @@ -3,6 +3,7 @@|;| |;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;| |;|+#include <algorithm>|;| #include <cmath>|;| #include <cstddef>|;| #include <cstdint>|;|@@ -15,8 +16,10 @@|;| #include <variant>|;| #include <vector>|;| |;|+#include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| |;| namespace qnn {|;|@@ -152,10 +155,6 @@ size_t TensorWrapper::GetTensorBytes() const {|;|   return GetDataTypeSize(GetDataType()) * GetTensorNumElements()|;|; }|;| |;|-void TensorWrapper::SetDataType(Qnn_DataType_t data_type) {|;|-  qnn_tensor_.v2.dataType = data_type|;|;-}|;|-|;| bool TensorWrapper::IsPerTensorQuantWithOffsetDiff(|;|     const TensorWrapper& rhs) const {|;|   const auto& lhs_quant = qnn_tensor_.v2.quantizeParams|;|;@@ -214,4 +213,62 @@ void TensorWrapper::SetDataBy(std::uint32_t bytes, const void* data) {|;|   qnn_tensor_.v2.clientBuf.data = owned_data_.data()|;|; }|;| |;|+void TensorWrapper::ConvertQint16ToQuint16() {|;|+  if (GetDataType() != QNN_DATATYPE_SFIXED_POINT_16) {|;|+    return|;|;+  }|;|+|;|+  // adjust static data|;|+  if (IsTensorStatic()) {|;|+    auto int16_data = GetStaticTensorData<std::int16_t>()|;|;+    if (!int16_data.has_value()) {|;|+      QNN_LOG_ERROR(|;|+          ""Cannot convert static QInt16 data to QUint16 data failed since ""|;|+          ""GetStaticTensorData failed."")|;|;+      return|;|;+    }|;|+    QNN_LOG_DEBUG(""Converting static tensor data from QInt16 to QUint16..."")|;|;+    std::vector<std::uint16_t> uint16_data|;|;+    ConvertDataFromInt16toUInt16((*int16_data), uint16_data)|;|;+    std::memcpy(owned_data_.data(),|;|+                reinterpret_cast<const char*>(uint16_data.data()),|;|+                GetTensorBytes())|;|;+    qnn_tensor_.v2.clientBuf.dataSize = owned_data_.size()|;|;+    qnn_tensor_.v2.clientBuf.data = owned_data_.data()|;|;+  }|;|+|;|+  // adjust quant param|;|;+  if (IsPerTensorQuant()) {|;|+    const auto& q_param =|;|+        std::get<ScaleOffsetQuantizeParamsWrapper>(GetQuantParams())|;|;+    quantize_params_.emplace<ScaleOffsetQuantizeParamsWrapper>(|;|+        q_param.GetScale(), q_param.GetZeroPoint() + kUint16ZeroPoint)|;|;+|;|+  } else if (IsPerChannelQuant()) {|;|+    const auto& q_param =|;|+        std::get<AxisScaleOffsetQuantizeParamsWrapper>(GetQuantParams())|;|;+    std::int32_t axis = q_param.GetAxis()|;|;+    std::vector<float> scales|;|;+    q_param.GetScales(scales)|;|;+    std::vector<std::int32_t> zero_points|;|;+    q_param.GetZeroPoints(zero_points)|;|;+    std::for_each(zero_points.begin(), zero_points.end(),|;|+                  [](std::int32_t& val) { val += kUint16ZeroPoint; })|;|;+    quantize_params_.emplace<AxisScaleOffsetQuantizeParamsWrapper>(|;|+        axis, absl::MakeSpan(scales), absl::MakeSpan(zero_points))|;|;+  }|;|+|;|+  std::visit(|;|+      [this](auto&& quantize_params) -> void {|;|+        quantize_params.CloneTo(qnn_tensor_.v2.quantizeParams)|;|;+      },|;|+      quantize_params_)|;|;+|;|+  // change data type here since GetStaticTensorData checks data type|;|+  qnn_tensor_.v2.dataType = QNN_DATATYPE_UFIXED_POINT_16|;|;+  QNN_LOG_DEBUG(|;|+      ""QNN does not fully support QInt16 now, converting to QUint16 for better ""|;|+      ""compatibility."")|;|;+}|;|+|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h: @@ -120,11 +120,21 @@ class TensorWrapper final {|;| |;|   QuantizeParamsWrapperVariant& GetQuantParams() { return quantize_params_; }|;|; |;|-  const bool IsQuant() const {|;|+  bool IsQuant() const {|;|     return !std::holds_alternative<UndefinedQuantizeParamsWrapper>(|;|         quantize_params_)|;|;   }|;|; |;|+  bool IsPerTensorQuant() const {|;|+    return std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+        quantize_params_)|;|;+  }|;|+|;|+  bool IsPerChannelQuant() const {|;|+    return std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|+        quantize_params_)|;|;+  }|;|+|;|   bool IsPerTensorQuantWithOffsetDiff(const TensorWrapper& rhs) const|;|; |;|   bool IsQuant8() const {|;|@@ -142,8 +152,6 @@ class TensorWrapper final {|;| |;|   Qnn_DataType_t GetDataType() const|;|; |;|-  void SetDataType(Qnn_DataType_t data_type)|;|;-|;|   bool IsSubgraphInput() const {|;|     return GetTensorType() == QNN_TENSOR_TYPE_APP_WRITE|;|;   }|;|@@ -281,11 +289,18 @@ class TensorWrapper final {|;| |;|   size_t GetTensorBytes() const|;|; |;|+  void ConvertQint16ToQuint16()|;|;+|;|  private:|;|   Qnn_TensorType_t GetTensorType() const|;|; |;|   void SetDataBy(std::uint32_t bytes, const void* data)|;|; |;|+  bool HasStaticData() const {|;|+    return qnn_tensor_.v2.clientBuf.dataSize != 0 &&|;|+           qnn_tensor_.v2.clientBuf.data != nullptr|;|;+  }|;|+|;|   Qnn_Tensor_t qnn_tensor_{.version = QNN_TENSOR_VERSION_2,|;|                            .v2 = QNN_TENSOR_V2_INIT}|;|;   std::string name_{}|;|;@@ -310,9 +325,8 @@ std::optional<absl::Span<const T>> TensorWrapper::GetStaticTensorData() const {|;|     return std::nullopt|;|;   }|;| |;|-  if (qnn_tensor_.v2.clientBuf.dataSize == 0 |||;|-      qnn_tensor_.v2.clientBuf.data == nullptr) {|;|-    QNN_LOG_ERROR(""Empty StaticTensorData."")|;|;+  if (!HasStaticData()) {|;|+    QNN_LOG_ERROR(""Empty static tensor data."")|;|;     return std::nullopt|;|;   }|;|  || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/BUILD: @@ -37,6 +37,7 @@ cc_test(|;|         ""@com_google_googletest//:gtest_main"",|;|         ""@com_google_absl//absl/types:span"",|;|         # copybara:uncomment ""//third_party/qairt/latest:qnn_lib_headers"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:miscs"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:quantize_params_wrapper"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:tensor_wrapper"",|;|     ], || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/quantize_params_wrapper_test.cc: @@ -78,6 +78,14 @@ TEST(ScaleOffsetQuantizeParamsWrapperTest, MoveConstructorTest) {|;|   EXPECT_EQ(dst.scaleOffsetEncoding.offset, -zero_point)|;|; }|;| |;|+TEST(ScaleOffsetQuantizeParamsWrapperTest, GetterTest) {|;|+  float scale = 1.5f|;|;+  std::int32_t zero_point = 10|;|;+  ScaleOffsetQuantizeParamsWrapper wrapper(scale, zero_point)|;|;+  EXPECT_FLOAT_EQ(wrapper.GetScale(), scale)|;|;+  EXPECT_EQ(wrapper.GetZeroPoint(), zero_point)|;|;+}|;|+|;| TEST(AxisScaleOffsetQuantizeParamsWrapperTest, ConstructorTest) {|;|   std::int32_t axis = 1|;|;   std::vector<float> scales = {1.5f, 2.5f}|;|;@@ -139,5 +147,17 @@ TEST(AxisScaleOffsetQuantizeParamsWrapperTest, MoveConstructorTest) {|;|               -zero_points[i])|;|;   }|;| }|;|+TEST(AxisScaleOffsetQuantizeParamsWrapperTest, GetterTest) {|;|+  std::int32_t axis = 1|;|;+  std::vector<float> scales = {1.5f, 2.5f}|;|;+  std::vector<std::int32_t> zero_points = {10, 20}|;|;+  AxisScaleOffsetQuantizeParamsWrapper wrapper(axis, scales, zero_points)|;|;+  std::vector<float> scales_out|;|;+  wrapper.GetScales(scales_out)|;|;+  EXPECT_EQ(scales, scales_out)|;|;+  std::vector<std::int32_t> zero_points_out|;|;+  wrapper.GetZeroPoints(zero_points_out)|;|;+  EXPECT_EQ(zero_points, zero_points_out)|;|;+}|;| }  // namespace|;| }  // namespace qnn || PR#89899 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tests/tensor_wrapper_test.cc: @@ -14,6 +14,7 @@|;| #include <gtest/gtest.h>|;| #include ""absl/types/span.h""|;| #include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/miscs.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| |;| namespace qnn {|;|@@ -159,25 +160,6 @@ TEST(TensorWrapperTest, QnnTensorTest) {|;|   }|;| }|;| |;|-TEST(TensorWrapperTest, DataTypeTest) {|;|-  TensorWrapper tensor_wrapper{}|;|;-  tensor_wrapper.SetDataType(QNN_DATATYPE_UFIXED_POINT_8)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_UFIXED_POINT_8)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant8())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_SFIXED_POINT_8)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_SFIXED_POINT_8)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant8())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_UFIXED_POINT_16)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_UFIXED_POINT_16)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant16())|;|;-|;|-  tensor_wrapper.SetDataType(QNN_DATATYPE_SFIXED_POINT_16)|;|;-  EXPECT_EQ(tensor_wrapper.GetDataType(), QNN_DATATYPE_SFIXED_POINT_16)|;|;-  EXPECT_TRUE(tensor_wrapper.IsQuant16())|;|;-}|;|-|;| TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff8BitTest) {|;|   constexpr int kSUFixed8OffsetDiff = 128|;|;   ScaleOffsetQuantizeParamsWrapper wrapper1(1, 0)|;|;@@ -189,11 +171,9 @@ TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff8BitTest) {|;|                                 {}}|;|;   TensorWrapper tensor_wrapper1{0,|;|                                 QNN_TENSOR_TYPE_STATIC,|;|-                                QNN_DATATYPE_UFIXED_POINT_8,|;|+                                QNN_DATATYPE_SFIXED_POINT_8,|;|                                 QuantizeParamsWrapperVariant(wrapper2),|;|                                 {}}|;|;-  EXPECT_FALSE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|;-  tensor_wrapper1.SetDataType(QNN_DATATYPE_SFIXED_POINT_8)|;|;   EXPECT_TRUE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|; }|;| |;|@@ -208,11 +188,9 @@ TEST(TensorWrapperTest, IsPerTensorQuantWithOffsetDiff16BitTest) {|;|                                 {}}|;|;   TensorWrapper tensor_wrapper1{0,|;|                                 QNN_TENSOR_TYPE_STATIC,|;|-                                QNN_DATATYPE_UFIXED_POINT_16,|;|+                                QNN_DATATYPE_SFIXED_POINT_16,|;|                                 QuantizeParamsWrapperVariant(wrapper2),|;|                                 {}}|;|;-  EXPECT_FALSE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|;-  tensor_wrapper1.SetDataType(QNN_DATATYPE_SFIXED_POINT_16)|;|;   EXPECT_TRUE(tensor_wrapper0.IsPerTensorQuantWithOffsetDiff(tensor_wrapper1))|;|; }|;| |;|@@ -280,5 +258,52 @@ TEST(TensorWrapperTest, GetStaticTensorDataTest) {|;|     EXPECT_EQ(tensor_data[i], data[i])|;|;   }|;| }|;|+|;|+TEST(TensorWrapperTest, ConvertQint16ToQuint16Test) {|;|+  std::vector<std::uint32_t> dummy_dims = {1, 1, 3}|;|;+  ScaleOffsetQuantizeParamsWrapper q_param(0.0001, 0)|;|;+  TensorWrapper tensor_wrapper{0, QNN_TENSOR_TYPE_STATIC,|;|+                               QNN_DATATYPE_SFIXED_POINT_16, q_param,|;|+                               dummy_dims}|;|;+|;|+  std::vector<float> data = {1, 2, 3}|;|;+  const auto& int16_q_param_ref = tensor_wrapper.GetQuantParams()|;|;+  EXPECT_TRUE(std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+      int16_q_param_ref))|;|;+  const float int16_scale =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(int16_q_param_ref).GetScale()|;|;+  const std::int32_t int16_zero_point =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(int16_q_param_ref)|;|+          .GetZeroPoint()|;|;+  std::vector<std::int16_t> int16_data|;|;+  for (int i = 0; i < data.size(); ++i) {|;|+    int16_data.emplace_back(|;|+        Quantize<std::int16_t>(data[i], int16_scale, int16_zero_point))|;|;+  }|;|+  tensor_wrapper.SetTensorData<std::int16_t>(|;|+      absl::MakeSpan(int16_data.data(), int16_data.size()))|;|;+|;|+  tensor_wrapper.ConvertQint16ToQuint16()|;|;+|;|+  const auto& uint16_q_param_ref = tensor_wrapper.GetQuantParams()|;|;+  EXPECT_TRUE(std::holds_alternative<ScaleOffsetQuantizeParamsWrapper>(|;|+      uint16_q_param_ref))|;|;+  const float uint16_scale =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(uint16_q_param_ref).GetScale()|;|;+  const std::int32_t uint16_zero_point =|;|+      std::get<ScaleOffsetQuantizeParamsWrapper>(uint16_q_param_ref)|;|+          .GetZeroPoint()|;|;+  const auto uint16_data =|;|+      *(tensor_wrapper.GetStaticTensorData<std::uint16_t>())|;|;+  std::vector<float> deq_data|;|;+  for (size_t i = 0; i < data.size(); i++) {|;|+    deq_data.emplace_back(|;|+        Dequantize(uint16_data[i], uint16_scale, uint16_zero_point))|;|;+  }|;|+  ASSERT_EQ(data.size(), deq_data.size())|;|;+  for (size_t i = 0; i < data.size(); ++i) {|;|+    EXPECT_NEAR(data[i], deq_data[i], 1e-3)|;|;+  }|;|+}|;| }  // namespace|;| }  // namespace qnn","Qualcomm AI Engine Direct - Compile QINT16 as QUINT16 || Merge pull request #89337 from jiunkaiy:dev/chunhsue/compile_int16_as_uint16

PiperOrigin-RevId: 740900417"
tensorflow/tensorflow,jreiffers,24028,TensorFlow estimator train_and_evaluate loss is None after step 0 and model does not train,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 14.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
'1.4.0'
- Python version:
Python 2.7.12
- Bazel version (if compiling from source):
- CUDA/cuDNN version:
Using CPU
**Describe the current behavior**
I've built a tensorflow custom estimator using Keras layers, and it worked fine initially when I used `train_and_evaluate`, but I'm seeing now that when I am using `train_and_evaluate`, it just checkpoints at step 0, the loss being `None` and moves to the evaluate phase. I'm not sure why this is happening, and any suggestions about what to look for would be great
**Describe the expected behavior**
Normal behavior as expected from the `train_and_evaluate` function
**Code to reproduce the issue**
```
# I've wrapped the estimator train_and_evaluate function inside this function:
def train_and_evaluate():    

#     classifier = tf.estimator.Estimator(model_fn = dnn_custom_estimator_v2,
#                                         config = run_config,
#                                         params=hparams)

    classifier = tf.estimator.Estimator(model_fn = dnn_custom_estimator_v2,
                                     params=hparams,
                                     config=run_config)

    train_spec = tf.estimator.TrainSpec(
        input_fn = lambda: csv_input_fn(
            TRAIN_DATA_FILES_PATTERN,
            mode = tf.estimator.ModeKeys.TRAIN,
            num_epochs=1000
        ),
        max_steps=6000,
        hooks=None
    )

    eval_spec = tf.estimator.EvalSpec(
        input_fn = lambda: csv_input_fn(
            TEST_DATA_FILES_PATTERN,
            mode=tf.estimator.ModeKeys.EVAL,
            num_epochs=1  
        ),
        exporters=[tf.estimator.LatestExporter(
            name=""predict"", # the name of the folder in which the model will be exported to under export
            serving_input_receiver_fn=json_serving_input_fn,
            exports_to_keep=1,
            as_text=False)],
        steps=None
    )
    
    tf.estimator.train_and_evaluate(
        estimator=classifier,
        train_spec=train_spec, 
        eval_spec=eval_spec
    )
```
```
# The estimator function:
he_init = tf.keras.initializers.he_normal()

def build_dense_layer(X, n_units=32, activation=tf.keras.activations.relu, initialization=he_init,
                          batch_normalization=False, kernel_regularizer=None, training=False, name=None):
    layer = tf.keras.layers.Dense(n_units,
                              activation=activation,
                              kernel_initializer = he_init,
                              kernel_regularizer = kernel_regularizer,
                              name=name)(X)
    if batch_normalization:
        bn = tf.keras.layers.BatchNormalization(momentum=0.90)
        layer = bn(layer, training=training)

    return layer



def dnn_custom_estimator_v2(features, labels, mode, params):
    in_training = mode == tf.estimator.ModeKeys.TRAIN
    # Returns the feature columns after transforming them
    continuos_feature_cols, dense_vector_feature_cols, embedding_feature_cols, weight_col = get_feature_columns()
    
    ### Build Vector Network
    vec_features = {}
    for feature_name in [some col names]:
        vec_features[feature_name] = features[feature_name]

    vec_net_ip = tf.feature_column.input_layer(vec_features, dense_vector_feature_cols)
    ## Build embedding Network
    embedding_features = {}
    for feature_name in [Column names]:
        embedding_features[feature_name] = features[feature_name]
    weight_col = features['sample_weight']
    embedding_net_ip = tf.feature_column.input_layer(embedding_features, feature_columns = embedding_feature_cols)
    ## Continous feature Network
    continous_cols = [Some column names]

    continous_features = {}
    for feature_name in continous_cols:
        if feature_name != 'sample_weight':
            continous_features[feature_name] = features[feature_name]

    continous_net_ip = tf.feature_column.input_layer(continous_features, feature_columns = continuos_feature_cols)

    ## Merge continous, embedding and vec layers together
    merged_layer = tf.keras.layers.concatenate([vec_net_ip, embedding_net_ip, continous_net_ip])

    ## OP deep dense layer
    output_hidden_1 = build_dense_layer(merged_layer,
                                        n_units=128, training=in_training, 
                                        batch_normalization = False, 
                                        activation = tf.keras.activations.relu, name = 'output_hidden_1')
    output_hidden_2 = build_dense_layer(output_hidden_1, n_units=64, 
                        training=in_training, batch_normalization = False,
                        activation = tf.keras.activations.relu, 
                        name = 'output_hidden_2')
    
    output_hidden_3 = build_dense_layer(output_hidden_2, n_units=32, 
                                    training=in_training, 
                                    batch_normalization = False,
                                activation = tf.keras.activations.relu, name = 'output_hidden_3')
    output_layer_size = len(TARGET_LABELS)

    logits = build_dense_layer(output_hidden_3,
                             n_units=output_layer_size, 
                            activation=None, name='prob_output')
    output = tf.squeeze(logits)

    # Provide an estimator spec for `ModeKeys.PREDICT`.
    if mode == tf.estimator.ModeKeys.PREDICT:
        probabilities = tf.nn.softmax(logits)
        predicted_indices = tf.argmax(probabilities, 1)
        # Convert predicted_indices back into strings
        predictions = {
            'classes': tf.gather(TARGET_LABELS, predicted_indices),
            'scores': probabilities
        }
        export_outputs = {
            'prediction': tf.estimator.export.PredictOutput(predictions)
        }

        # Provide an estimator spec for `ModeKeys.PREDICT` modes.
        return tf.estimator.EstimatorSpec(mode,
                                          predictions=predictions,
                                          export_outputs=export_outputs)

    # Calculate loss using softmax cross entropy
    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(
            logits=logits, labels=labels)
    
    loss = tf.reduce_mean(weight_col*losses)
    
    tf.summary.scalar('loss', loss)

    if mode == tf.estimator.ModeKeys.TRAIN:
        # Create Optimiser
        optimizer = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.9, beta2=0.999,  epsilon=1e-8)

        # Create training operation
        train_op = optimizer.minimize(
            loss=loss, global_step=tf.train.get_global_step())

        # Provide an estimator spec for `ModeKeys.TRAIN` modes.
        return tf.estimator.EstimatorSpec(mode=mode,
                                          loss=loss,
                                          train_op=train_op)


    if mode == tf.estimator.ModeKeys.EVAL:
        probabilities = tf.nn.softmax(logits)
        predicted_indices = tf.argmax(probabilities, 1)

        # Return accuracy and area under ROC curve metrics
        labels_one_hot = tf.one_hot(
            labels,
            depth=len(TARGET_LABELS),
            on_value=True,
            off_value=False,
            dtype=tf.bool
        )

        eval_metric_ops = {
            'accuracy': tf.metrics.accuracy(labels, predicted_indices),
            'auroc': tf.metrics.auc(labels_one_hot, probabilities),
            'precision': tf.metrics.precision(labels, predicted_indices),
            'recall': tf.metrics.recall(labels, predicted_indices)
        }

        # Provide an estimator spec for `ModeKeys.EVAL` modes.
        return tf.estimator.EstimatorSpec(mode,
                                          loss=loss,
                                          eval_metric_ops=eval_metric_ops)
```



**Other info / logs**
The output of `train_and_evaluate` as defined above is this:
```
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': 19830610, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f86f040dc50>, '_model_dir': ' /whereever/model/needs/to/be/saved/model_v2', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
INFO:tensorflow:Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.

* Output from  data input_fn:
================
Input file(s):  /whereever/train/is/data/train_equal_downsample.csv
Batch size: 1024
Epoch Count: 1000
Mode: train
Thread Count: 32
Shuffle: True
================

('target_dtype', <tf.Tensor 'DecodeCSV:9' shape=(?,) dtype=int32>)
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Saving checkpoints for 0 into  /whereever/model/needs/to/be/saved//model.ckpt.
INFO:tensorflow:Loss for final step: None.

* data input_fn:
================
Input file(s):  /whereever/test/is/test_v2.csv
Batch size: 1024
Epoch Count: 1
Mode: eval
Thread Count: 32
Shuffle: False
================

('target_dtype', <tf.Tensor 'DecodeCSV:9' shape=(?,) dtype=int32>)
INFO:tensorflow:Starting evaluation at 2018-11-28-21:52:28
INFO:tensorflow:Restoring parameters from /wherever/model/is/model_v2/model.ckpt-0
INFO:tensorflow:Finished evaluation at 2018-11-28-22:14:58
INFO:tensorflow:Saving dict for global step 0: accuracy = 0.91067266, auroc = 0.94267476, global_step = 0, loss = 0.5579337, precision = 0.14235616, recall = 0.002937618
INFO:tensorflow:Restoring parameters from /wherever/model/is/model_v2/model.ckpt-0
INFO:tensorflow:Assets added to graph.
INFO:tensorflow:No assets to write.
INFO:tensorflow:SavedModel written to: /wherever/model/is/export/predict/temp-1543443300/saved_model.pb

* data input_fn:
================
Input file(s): /wherever/this/file/is/train_equal_downsample.csv
Batch size: 1024
Epoch Count: 1000
Mode: train
Thread Count: 32
Shuffle: True
================

('target_dtype', <tf.Tensor 'DecodeCSV:9' shape=(?,) dtype=int32>)
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Restoring parameters from /whereever/model/needs/to/be/saved/model.ckpt-0
INFO:tensorflow:Saving checkpoints for 0 into  /whereever/model/needs/to/be/saved//model.ckpt.
INFO:tensorflow:Loss for final step: None.
WARNING:tensorflow:No new checkpoint ready for evaluation. Skip the current evaluation pass as evaluation results are expected to be same for the same checkpoint.


RuntimeErrorTraceback (most recent call last)
<ipython-input-52-858f040bdf6d> in <module>()
      6 if(not os.path.exists(output_dir)):
      7     os.makedirs(output_dir)
----> 8 train_and_evaluate()

<ipython-input-51-6feac2ec48d2> in train_and_evaluate()
     36         estimator=classifier,
     37         train_spec=train_spec,
---> 38         eval_spec=eval_spec
     39     )

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.pyc in train_and_evaluate(estimator, train_spec, eval_spec)
    428       config.task_type != run_config_lib.TaskType.EVALUATOR):
    429     logging.info('Running training and evaluation locally (non-distributed).')
--> 430     executor.run_local()
    431     return
    432 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.pyc in run_local(self)
    618       if not metrics:
    619         #  This is unexpected. Training should always end with a new checkpoint.
--> 620         raise RuntimeError('There was no new checkpoint after the training.')
    621 
    622       if _should_stop_local_train(metrics[ops.GraphKeys.GLOBAL_STEP]):

RuntimeError: There was no new checkpoint after the training.


```","Could this be caused by an improperly formatted csv files? || @ssubraveti did you solve this problem?  I met the same case when running TF with big data and it's quite annoying || @ssubraveti @Zhiqiang-Ye How did you solve this problem? I also met this problem. || I'm not sure... I rewrote the estimator from scratch because I wasn't able to find a reason for the bug, and it worked after that 😅 || I found the problem.
You set max steps as max_steps = 6000, yet it is not same as **steps** from tf.estimator.train(... steps,max_steps). As stated in documentation of train_and_evaluate 
[https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate](url)
> Stop condition: In order to support both distributed and non-distributed configuration reliably, the only supported stop condition for model training is train_spec.max_steps. If train_spec.max_steps is None, the model is trained forever. Use with care if the model stop condition is different. For example, assume that the model is expected to be trained with one epoch of training data, and the training input_fn is configured to throw OutOfRangeError after going through one epoch, which stops the Estimator.train. For a three-training-worker distributed configuration, each training worker is likely to go through the whole epoch independently. So, the model will be trained with three epochs of training data instead of one epoch.



which means that once you reach max_steps=6000, training is not resumed anymore and train_and_evaluate returns (None,None) .
Try to remove max_steps and see if this help. Your input_fn has to raise OutOfRangeError once iteration through data set is done. It looks to me that train_and_evaluate does not support control over number of training steps.  || > 
> 
> @ssubraveti @Zhiqiang-Ye How did you solve this problem? I also met this problem.

Hi, I had this problem when my program could not read data from HDFS. As long as it found any data to read, this problem is gone.
My colleague had this problem using old file queue for input. The mysterious solution is to set training max steps to forever.... || @agniszczotka @Zhiqiang-Ye @ssubraveti 

Hi guys, i know super late to resume this convo, but: Same issue here (training loss is None and ""perhaps input is empty or misspecified)!

TF version: 1.15.1

```
train_spec = tf.estimator.TrainSpec(
    input_fn=lambda: read_train(data_folder, params),
    max_steps=None)
```
max_steps was 1400000 before and i tried now to set it to None, but it didnt work for me. My input pipeline looks like this:
```
clvf = CLVFeatures(ignore_crosses=True)

def parse_csv(csv_row):
  columns = tf.decode_csv(csv_row, record_defaults = clvf.get_all_defaults())
  features = dict(zip(clvf.get_all_names(), columns))
  
  for column_name in clvf.get_unused():
    features.pop(column_name)

  target = features.pop(clvf.get_target_name())

  return features, target

#@tf.function
def dataset_input_fn(data_folder, prefix=None, mode=None, params=None, count=None):
  shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False

  filenames = tf.matching_files('{}{}*.csv'.format(data_folder, prefix))
  dataset = tf.data.TextLineDataset(filenames)#skip(1)
  dataset = dataset.map(parse_csv)
  if shuffle:
    dataset = dataset.shuffle(buffer_size=params.buffer_size)
  dataset = dataset.repeat(count=count)
  dataset = dataset.batch(params.batch_size)

  iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)#tf.compat.v1.data.make_one_shot_iterator(dataset)/#tf.compat.v1.data.make_initializable_iterator(dataset)
  
  features, target = iterator.get_next()

  return features, target

def read_train(data_folder, params):
  return dataset_input_fn(
      data_folder=data_folder,
      prefix='train',
      params=params,
      mode=tf.estimator.ModeKeys.TRAIN)


def read_eval(data_folder, params):
  return dataset_input_fn(data_folder=data_folder,
                          prefix='eval',
                          params=params)


def read_test(data_folder, params):
  return dataset_input_fn(data_folder=data_folder,
                          prefix='test',
                          params=params,
                          count=1)
```

I would appreciate some help, so much. This is for school haha thank you!",closed,2018-11-28T22:29:58+00:00,2018-12-10T21:54:04+00:00,ssubraveti,,1,"PR#89893 - third_party/xla/xla/literal.h: @@ -415,7 +415,7 @@ class LiteralBase {|;|           ShapeUtil::ByteSizeOfPrimitiveType(subshape.element_type())|;|;       absl::Span<const int64_t> minor_to_major =|;|           subshape.layout().minor_to_major()|;|;-      DimensionVector elem_index(subshape.dimensions_size())|;|;+      DimensionVector elem_index(subshape.dimensions().size())|;|;       absl::Span<int64_t> elem_index_span(elem_index.data(), elem_index.size())|;|;       int64_t bytes_hashed = 0|;|;       while (bytes_hashed < bytes_to_hash) {|;|@@ -884,7 +884,7 @@ class LiteralBase {|;| |;|     int64_t dynamic_size_buffer_bytes() const {|;|       DCHECK(LayoutUtil::IsDenseArray(*subshape_))|;|;-      return subshape().dimensions_size() * sizeof(DynamicSizeType)|;|;+      return subshape().dimensions().size() * sizeof(DynamicSizeType)|;|;     }|;| |;|     // Gets or sets the subshape of this piece. This reference points to a|;|@@ -1692,7 +1692,7 @@ void LiteralBase::Piece::SerializeData(|;|            primitive_util::NativeToPrimitiveType<NativeT>())|;|;   if (subshape().is_dynamic()) {|;|     absl::Span<const DynamicSizeType> sizes(dynamic_size_buffer(),|;|-                                            subshape().dimensions_size())|;|;+                                            subshape().dimensions().size())|;|;     state.WriteDynamicSizes(sizes)|;|;   }|;|   state.WriteElements(data<NativeT>())|;|;@@ -1705,7 +1705,7 @@ bool LiteralBase::Piece::DeserializeData(|;|            primitive_util::NativeToPrimitiveType<NativeT>())|;|;   if (subshape().is_dynamic()) {|;|     absl::Span<DynamicSizeType> sizes(dynamic_size_buffer(),|;|-                                      subshape().dimensions_size())|;|;+                                      subshape().dimensions().size())|;|;     if (!state.ReadDynamicSizes(sizes)) {|;|       return false|;|;     }|;|@@ -1965,10 +1965,10 @@ TF_ATTRIBUTE_NOINLINE void LiteralBase::EachCell(|;|   if (ShapeUtil::IsZeroElementArray(shape())) {|;|     return|;|;   }|;|-  std::vector<int64_t> indices(shape().dimensions_size(), 0)|;|;+  std::vector<int64_t> indices(shape().dimensions().size(), 0)|;|; |;|   Shape shape_dynamic = shape()|;|;-  for (int64_t i = 0; i < shape_dynamic.dimensions_size(); ++i) {|;|+  for (int64_t i = 0; i < shape_dynamic.dimensions().size(); ++i) {|;|     shape_dynamic.set_dimensions(i, GetDynamicSize(i))|;|;   }|;|   do {|;|@@ -1985,9 +1985,9 @@ TF_ATTRIBUTE_NOINLINE void MutableLiteralBase::MutableEachCell(|;|   if (ShapeUtil::IsZeroElementArray(shape())) {|;|     return|;|;   }|;|-  std::vector<int64_t> indices(shape().dimensions_size(), 0)|;|;+  std::vector<int64_t> indices(shape().dimensions().size(), 0)|;|;   Shape shape_dynamic = shape()|;|;-  for (int64_t i = 0; i < shape_dynamic.dimensions_size(); ++i) {|;|+  for (int64_t i = 0; i < shape_dynamic.dimensions().size(); ++i) {|;|     shape_dynamic.set_dimensions(i, GetDynamicSize(i))|;|;   }|;|   do {|;|@@ -2000,7 +2000,7 @@ TF_ATTRIBUTE_NOINLINE void MutableLiteralBase::PopulateR1(|;|     absl::Span<const NativeT> values) {|;|   CHECK(LayoutUtil::IsDenseArray(shape()))|;|       << __func__ << "" is only supported for dense arrays: "" << shape()|;|;-  CHECK_EQ(shape().dimensions_size(), 1)|;|;+  CHECK_EQ(shape().dimensions().size(), 1)|;|;   if (shape().is_static()) {|;|     CHECK_EQ(ShapeUtil::ElementsIn(shape()), values.size())|;|;   } else {|;|@@ -2017,7 +2017,7 @@ TF_ATTRIBUTE_NOINLINE void MutableLiteralBase::PopulateR2(|;|     std::initializer_list<std::initializer_list<NativeT>> values) {|;|   CHECK(LayoutUtil::IsDenseArray(shape()))|;|       << __func__ << "" is only supported for dense arrays: "" << shape()|;|;-  CHECK_EQ(shape().dimensions_size(), 2)|;|;+  CHECK_EQ(shape().dimensions().size(), 2)|;|;   CHECK_EQ(shape().element_type(),|;|            primitive_util::NativeToPrimitiveType<NativeT>())|;|; |;|@@ -2053,7 +2053,7 @@ TF_ATTRIBUTE_NOINLINE void MutableLiteralBase::PopulateFromArray(|;|   CHECK(shape().IsArray())|;|;   CHECK_EQ(shape().element_type(),|;|            primitive_util::NativeToPrimitiveType<NativeT>())|;|;-  CHECK_EQ(shape().dimensions_size(), values.num_dimensions())|;|;+  CHECK_EQ(shape().dimensions().size(), values.num_dimensions())|;|;   for (int dim = 0; dim < values.num_dimensions(); ++dim) {|;|     int64_t shape_size = shape().is_dynamic_dimension(dim)|;|                              ? GetDynamicSize(dim)|;|@@ -2223,7 +2223,7 @@ Literal LiteralBase::Replicate(int64_t times) const {|;|   CHECK(LayoutUtil::IsDenseArray(shape()))|;|       << __func__ << "" is only supported for dense arrays: "" << shape()|;|;   DimensionVector bounds = {times}|;|;-  bounds.reserve(shape().dimensions_size() + 1)|;|;+  bounds.reserve(shape().dimensions().size() + 1)|;|;   for (int64_t bound : shape().dimensions()) {|;|     bounds.push_back(bound)|;|;   } || PR#89893 - third_party/xla/xla/service/pattern_matcher.h: @@ -954,7 +954,7 @@ class ShapePatternRankImpl {|;|   explicit constexpr ShapePatternRankImpl(int64_t rank) : rank_(rank) {}|;| |;|   bool Match(const ::xla::Shape* shape, MatchOption option) const {|;|-    if (shape->dimensions_size() != rank_) {|;|+    if (shape->dimensions().size() != rank_) {|;|       if (rank_ == 0) {|;|         EXPLAIN << ""Shape is not a scalar""|;|;       } else { || PR#89893 - third_party/xla/xla/shape_util.h: @@ -114,10 +114,9 @@ class ShapeUtil {|;|   template <bool kBoundedDynamicOk>|;|   static inline std::pair<int64_t, bool> ExtentProduct(const Shape& shape) {|;|     DCHECK(shape.IsArray()) << ShapeUtil::HumanString(shape)|;|;-    DCHECK_EQ(shape.dimensions_size(), shape.dimensions_size())|;|;     int64_t product = 1|;|;     bool any_overflows = false|;|;-    for (int dim = 0; dim < shape.dimensions_size(); ++dim) {|;|+    for (int dim = 0; dim < shape.dimensions().size(); ++dim) {|;|       if constexpr (kBoundedDynamicOk) {|;|         if (shape.is_unbounded_dynamic_dimension(dim)) {|;|           continue|;|;@@ -304,7 +303,7 @@ class ShapeUtil {|;|   // Scalar-specific|;| |;|   static bool IsScalar(const Shape& shape) {|;|-    return shape.IsArray() && shape.dimensions_size() == 0|;|;+    return shape.IsArray() && shape.dimensions().size() == 0|;|;   }|;|   static bool IsEffectiveScalar(const Shape& shape) {|;|     return shape.IsArray() && TrueNumDimensions(shape) == 0|;|;@@ -961,8 +960,8 @@ class ShapeUtil {|;| |;|   static absl::Status ForEachIndexWithStatus(|;|       const Shape& shape, const ForEachVisitorFunction& visitor_function) {|;|-    std::vector<int64_t> base(shape.dimensions_size())|;|;-    std::vector<int64_t> incr(shape.dimensions_size(), 1)|;|;+    std::vector<int64_t> base(shape.dimensions().size())|;|;+    std::vector<int64_t> incr(shape.dimensions().size(), 1)|;|;     return ForEachIndexWithStatus(shape, base,|;|                                   /*count=*/shape.dimensions(), incr,|;|                                   visitor_function)|;|;@@ -971,8 +970,8 @@ class ShapeUtil {|;|   static void ForEachIndexNoStatus(|;|       const Shape& shape,|;|       const ForEachVisitorFunctionNoStatus& visitor_function) {|;|-    std::vector<int64_t> base(shape.dimensions_size())|;|;-    std::vector<int64_t> incr(shape.dimensions_size(), 1)|;|;+    std::vector<int64_t> base(shape.dimensions().size())|;|;+    std::vector<int64_t> incr(shape.dimensions().size(), 1)|;|;     ForEachIndexNoStatus(shape, base,|;|                          /*count=*/shape.dimensions(), incr, visitor_function)|;|;   }|;|@@ -1161,7 +1160,7 @@ inline ShapeUtil::ForEachState::ForEachState(const Shape& s,|;|       indexes(b.begin(), b.end()),|;|       indexes_ptr((rank == 0) ? nullptr : indexes.data()),|;|       indexes_span(indexes) {|;|-  CHECK_EQ(shape.dimensions_size(), b.size())|;|;+  CHECK_EQ(shape.dimensions().size(), b.size())|;|;   CHECK_EQ(i.size(), b.size())|;|;   CHECK_EQ(c.size(), b.size())|;|; }","PR #24028: Fix some Shape::rank deprecation warnings.

Imported from GitHub PR https://github.com/openxla/xla/pull/24028

These headers are included from absolutely everywhere, and the warning spam can make it quite hard to see the actual problems.
Copybara import of the project:

--
535c0329ba9bfc3b975a8820d0d9ff15bc8f7718 by Johannes Reifferscheid <jreiffers@nvidia.com>:

Fix some Shape::rank deprecation warnings.

These headers are included from absolutely everywhere, and the warning spam can make it quite hard to see the actual problems.

Merging this change closes #24028

PiperOrigin-RevId: 740833587"
tensorflow/tensorflow,dimvar,24011,[INTEL MKL]Optimize CropAndResizeGradImage Op.,"Optimize CropAndResizeGradImage Op, please review. After optimized, the performance could raise about  20.6% compared to original version. We use parallization(eigen thread pool) to optimize.","@qlzh727 I use newer clang-format 3.9 to check the errors not finding any ones, and I couldn't click into detail link for clang-format errors. Please help me get to know more about it. || let me rerun the build, the previous one seems to be failed due to build system issue. || Any updates? @qlzh727 @rmlarsen  || Any updates? @qlzh727 @rmlarsen  || Any updates? @qlzh727 @rmlarsen || Any updates? @qlzh727 @rmlarsen @agramesh1  || Any updates? @qlzh727 @rmlarsen || Any updates? @qlzh727 @rmlarsen || @rmlarsen is on his holiday until next week. Adding @shpeisman for review. || @qlzh727 Thank you! || Any updates? @qlzh727 @tatianashp  || Ping @tatianashp for review. Thanks. || @qlzh727 Thank you~ || Any updates? @qlzh727 @tatianashp || Any updates? @qlzh727 @tatianashp || Sorry for the very late reply, I have pinged @tatianashp and she will probably reply very soon. || Thank you @qlzh727  || Nagging Reviewer @rmlarsen, @tatianashp: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 15 days with no activity and the `awaiting review` label has been applied. || Any updates? || Sorry for the very late reply, I will ping reviewers again today for this PR. In the meantime, can you resolve the merge conflicts? || @penpornk Your idea is good. For the 'two lambda functions', do you mean by the implementation in my 'change function splitting method' commit? Please review my implementation ~ || Quoting myself to add:
> For example, defining `resize_fn`
> 
> ```c++
> auto resize_fn = (method_name == ""bilinear"")
>     ? <lambda function for ""bilinear"">
>     : <lambda function for ""nearest"">;
> ```
Since each lambda takes multiple lines, you might want to define `resize_fn` this way instead.
```c++
auto resize_fn = <lambda_function_for_bilinear>;
if (method_name == ""nearest"") {
  resize_fn = <lambda_function_for_nearest>;
}
```
 || @penpornk Thank you! Changes done.  || @penpornk No problem! Changes done. || Hi @penpornk @ezhulenev 

@pandaoxin will leave his job this week and start a new career. From now on, I will take over this PR until it's merged.

Is there anything I should do to make the ownership transfer of this PR more smoothly? For example,  re-check CLA? If so, please let me know.

Thank you! || @pandaoxin Sorry for my late response. I wish you all the best on your new journey!

@wenxizhu Since you have committed to the repo before, I believe your CLA is fine. But googlebot will probably complain that there is more than one users contributing to the PR. And both @pandaoxin and you will have to post that you are okay with your commits being used in this PR. || @penpornk I'm sorry @pandaoxin already left his job yesterday, so he won't be able to login his account (it's a company account) to post that comment. Is there any way we can workaround this? || @wenxizhu Sorry for the inconvenience! Let's wait until googlebot complains and I'll ask someone. At worst we'll just open a new PR. || @penpornk Changes applied. Any updates? || @peppornk For the ""additions count"" problem, I already gave my best guess. But since I'm not the author of that code, I also don't know where my guess is correct. Your opinions? || @penpornk Any updates? || @penpornk Changes applied for cost estimation update. Please see my commit for details. || @penpornk You're welcome. And thank you for reivew this PR! || @penpornk Hi, changes made for GPU build. Let's see if it works. || @penpornk Fixed now. || @wenxizhu Thank you for the quick fix! Let's see if it passes now. || The PR is merged in https://github.com/tensorflow/tensorflow/commit/ddf3966936b65186b46cafe52181e0c2af480fae. I'm closing this PR now. Thank you again for your contributions!",closed,2018-11-28T03:17:56+00:00,2019-03-21T06:25:15+00:00,pandaoxin,"cla: yes, ready to pull, comp:mkl, size:M",1,"PR#90050 - third_party/xla/xla/service/gpu/model/hlo_op_profiles_data.h: @@ -23,6 +23,782 @@ namespace gpu {|;| // xla/service/gpu/model:hlo_op_profiler_run|;| |;| constexpr char kDeviceHloOpProfiles[] = R""pb(|;|+  entries {|;|+    key: ""sm_100""  # ""NVIDIA B200""|;|+    value {|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: S8 }|;|+        }|;|+        clock_cycles: 373|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: S8 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: S8 }|;|+        }|;|+        clock_cycles: 153|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: S16 }|;|+        }|;|+        clock_cycles: 369|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: S16 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: S16 }|;|+        }|;|+        clock_cycles: 145|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: S32 }|;|+        }|;|+        clock_cycles: 306|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: S32 }|;|+        }|;|+        clock_cycles: 3|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: S32 }|;|+        }|;|+        clock_cycles: 172|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: S64 }|;|+        }|;|+        clock_cycles: 730|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: S64 }|;|+        }|;|+        clock_cycles: 11|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: S64 }|;|+        }|;|+        clock_cycles: 298|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: U8 }|;|+        }|;|+        clock_cycles: 302|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: U8 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: U8 }|;|+        }|;|+        clock_cycles: 153|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: U16 }|;|+        }|;|+        clock_cycles: 302|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: U16 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: U16 }|;|+        }|;|+        clock_cycles: 149|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: U32 }|;|+        }|;|+        clock_cycles: 125|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: U32 }|;|+        }|;|+        clock_cycles: 3|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: U32 }|;|+        }|;|+        clock_cycles: 172|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: U64 }|;|+        }|;|+        clock_cycles: 628|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: U64 }|;|+        }|;|+        clock_cycles: 11|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: U64 }|;|+        }|;|+        clock_cycles: 298|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cbrt""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 200|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cosine""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 1017|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""erf""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 161|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 106|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential-minus-one""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 216|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 102|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log-plus-one""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 216|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""logistic""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 220|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""rsqrt""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 98|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sine""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 1006|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sqrt""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 98|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""tanh""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 141|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""add""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""atan2""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 400|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 43|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 451|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""subtract""|;|+          shape { element_type: F16 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cbrt""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 180|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cosine""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 1002|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""erf""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 161|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 82|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential-minus-one""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 196|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 165|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log-plus-one""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 200|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""logistic""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 176|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""rsqrt""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 74|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sine""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 990|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sqrt""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 74|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""tanh""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 137|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""add""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""atan2""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 373|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 23|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 463|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""subtract""|;|+          shape { element_type: F32 }|;|+        }|;|+        clock_cycles: 7|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cbrt""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 569|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cosine""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 538|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""erf""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 746|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 314|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential-minus-one""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 385|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 844|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log-plus-one""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 793|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""logistic""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 428|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""rsqrt""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 231|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sine""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 534|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sqrt""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 294|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""tanh""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 459|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""add""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 15|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""atan2""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 829|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 483|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 15|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 1796|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""subtract""|;|+          shape { element_type: F64 }|;|+        }|;|+        clock_cycles: 15|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cosine""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 2511|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 695|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential-minus-one""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 864|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 703|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log-plus-one""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 664|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""logistic""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 2314|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""rsqrt""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 2507|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sine""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 2440|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sqrt""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 4271|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""tanh""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 2444|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""add""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 11|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""atan2""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 6346|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 330|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 31|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 5285|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""subtract""|;|+          shape { element_type: C64 }|;|+        }|;|+        clock_cycles: 11|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""cosine""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 1862|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 1375|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""exponential-minus-one""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 1513|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 3859|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""log-plus-one""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 5985|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""logistic""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 5973|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""rsqrt""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 5792|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sine""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 1878|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""sqrt""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 6602|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""tanh""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 4519|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""add""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 15|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""atan2""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 13310|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""divide""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 2338|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""multiply""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 39|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""power""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 8685|;|+      }|;|+      entries {|;|+        instruction {|;|+          opcode: ""subtract""|;|+          shape { element_type: C128 }|;|+        }|;|+        clock_cycles: 15|;|+      }|;|+    }|;|+  }|;|+|;|   entries {|;|     key: ""sm_90""  # ""NVIDIA H100 80GB HBM3""|;|     value {","PR #24011: HLO op profiles for B200.

Imported from GitHub PR https://github.com/openxla/xla/pull/24011

Copybara import of the project:

--
e270aa00005171d75864d52445d77c3364373954 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

HLO op profiles for B200.

Merging this change closes #24011

PiperOrigin-RevId: 740705931"
tensorflow/tensorflow,shraiysh,24168,What version of Tensorflow  to install with CUDA 9.2 and libcudnn 6.0 ?,"Im upgrading from tensorflow-gpu 1.4 to a recent version but when i try to run tensorflow-gpu 1.12.0 on a cluster which contains Cuda 9.2, i get this error : 

`ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory`

I've tried even tensorflow-gpu 1.10 but it keeps the same error , so i would like to know which version can i install so it can run perfectly with Cuda 9.2 

Thank you",,closed,2018-12-05T10:13:55+00:00,2018-12-05T16:08:32+00:00,saidamirouche,,1,"PR#90031 - third_party/xla/xla/hlo/analysis/BUILD: @@ -176,6 +176,7 @@ xla_cc_test(|;|     deps = [|;|         "":while_loop_analysis"",|;|         ""//xla:comparison_util"",|;|+        ""//xla:literal_util"",|;|         ""//xla:util"",|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/testlib:hlo_hardware_independent_test_base"", || PR#90031 - third_party/xla/xla/hlo/analysis/while_loop_analysis.cc: @@ -699,7 +699,7 @@ optional<int64_t> MatchTrivialLoopTripCount(const HloInstruction* while_op,|;|   int64_t trip_count_step = 0|;|;   if (!Match(while_body_indvar_update,|;|              m::AddAnyOrder(m::Op().Is(while_body_indvar),|;|-                            m::Op(&trip_count_increase_step_instr)))) {|;|+                            m::Constant(&trip_count_increase_step_instr)))) {|;|     if (trip_count_increase_step_instr == nullptr) {|;|       VLOG(2) << ""Pattern-match failed: induction variable is not getting ""|;|                  ""updated by an add operation: "" || PR#90031 - third_party/xla/xla/hlo/analysis/while_loop_analysis_test.cc: @@ -35,6 +35,7 @@ limitations under the License.|;| #include ""xla/hlo/ir/hlo_opcode.h""|;| #include ""xla/hlo/testlib/hlo_hardware_independent_test_base.h""|;| #include ""xla/hlo/testlib/test.h""|;|+#include ""xla/literal_util.h""|;| #include ""xla/service/constant_value.h""|;| #include ""xla/service/value_range.h""|;| #include ""xla/tsl/platform/statusor.h""|;|@@ -1060,5 +1061,66 @@ TEST_F(WhileLoopAnalysisTest, GetIndvarIndexShouldWorkWhenParamIsCopied) {|;|   EXPECT_EQ(GetLoopInductionVarTupleIdx(while_op), 0)|;|; }|;| |;|+TEST_F(WhileLoopAnalysisTest,|;|+       MatchTrivialLoopCountFailsWhenIndvarIsNotIncrementedByConstant) {|;|+  const char* hlo_with_constant = R""(|;|+  HloModule test|;|+  body {|;|+    param.1 = (s32[], s32[]) parameter(0)|;|+    iter.1 = s32[] get-tuple-element(param.1), index=0|;|+    data.1 = s32[] get-tuple-element(param.1), index=1|;|+    c.1 = s32[] constant(1)|;|+    add.1 = s32[] add(iter.1, c.1)|;|+    ROOT tuple = (s32[], s32[]) tuple(add.1, data.1)|;|+  }|;|+  condition {|;|+    param = (s32[], s32[]) parameter(0)|;|+    iter = s32[] get-tuple-element(param), index=0|;|+    c.10 = s32[] constant(10)|;|+    ROOT compare = pred[] compare(iter, c.10), direction=LT|;|+  }|;|+  ENTRY main {|;|+    c0 = s32[] constant(0)|;|+    data = s32[] parameter(0)|;|+    tuple = (s32[], s32[]) tuple(c0, data)|;|+    ROOT while = (s32[], s32[]) while(tuple), body=body, condition=condition|;|+  })""|;|;+  const char* hlo_without_constant = R""(|;|+  HloModule test|;|+  body {|;|+    param.1 = (s32[], s32[]) parameter(0)|;|+    iter.1 = s32[] get-tuple-element(param.1), index=0|;|+    data.1 = s32[] get-tuple-element(param.1), index=1|;|+    add.1 = s32[] add(iter.1, iter.1)|;|+    ROOT tuple = (s32[], s32[]) tuple(add.1, data.1)|;|+  }|;|+  condition {|;|+    param = (s32[], s32[]) parameter(0)|;|+    iter = s32[] get-tuple-element(param), index=0|;|+    c.10 = s32[] constant(10)|;|+    ROOT compare = pred[] compare(iter, c.10), direction=LT|;|+  }|;|+  ENTRY main {|;|+    c1 = s32[] constant(1)|;|+    data = s32[] parameter(0)|;|+    tuple = (s32[], s32[]) tuple(c1, data)|;|+    ROOT while = (s32[], s32[]) while(tuple), body=body, condition=condition|;|+  })""|;|;+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m_with_constant,|;|+                          ParseAndReturnVerifiedModule(hlo_with_constant))|;|;+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m_without_constant,|;|+                          ParseAndReturnVerifiedModule(hlo_without_constant))|;|;+  HloInstruction* while_op_with_constant =|;|+      m_with_constant->entry_computation()->root_instruction()|;|;+  HloInstruction* while_op_without_constant =|;|+      m_without_constant->entry_computation()->root_instruction()|;|;+  std::optional<int64_t> trip_count_with_constant = MatchTrivialLoopTripCount(|;|+      while_op_with_constant, 0, LiteralUtil::CreateR0<int32_t>(0))|;|;+  EXPECT_EQ(trip_count_with_constant, 10)|;|;+  std::optional<int64_t> trip_count_without_constant =|;|+      MatchTrivialLoopTripCount(while_op_without_constant, 0,|;|+                                LiteralUtil::CreateR0<int32_t>(0))|;|;+  EXPECT_EQ(trip_count_without_constant, std::nullopt)|;|;+}|;| }  // namespace|;| }  // namespace xla","PR #24168: Fix while loop analysis when the increment is not a constant

Imported from GitHub PR https://github.com/openxla/xla/pull/24168

Currently this fails with an assert because the checks (matcher) does not look for constants.
Copybara import of the project:

--
392df8825f311a2a9a771310a6874b80655c5fc7 by Shraiysh Vaishay <svaishay@nvidia.com>:

Fix while loop analysis when the increment is not a constant

Currently this fails with an assert because the checks (matcher)
does not look for constants.

Merging this change closes #24168

PiperOrigin-RevId: 740659618"
tensorflow/tensorflow,dimvar,24010,Make var loading logging messages debug from info,"You may load a large amount of variables from a checkpoint and printing them all to ""INFO"" is not very useful as it spams the log.  I propose downgrading these to debug so that they only show up when you are trying to ""debug"" your loading.",Can I get a review on this? || Ping? || Nagging Reviewer @case540: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 74 days with no activity and the `awaiting review` label has been applied. || @mihaimaruseac can you please help review this PR ?,closed,2018-11-27T23:49:34+00:00,2019-04-15T19:34:31+00:00,tadeegan,"cla: yes, ready to pull, size:XS",1,"PR#89914 - third_party/xla/xla/tools/hlo_opt/gpu_specs/b200.txtpb: @@ -0,0 +1,42 @@|;|+# Copyright 2025 The OpenXLA Authors.|;|+#|;|+# Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+# you may not use this file except in compliance with the License.|;|+# You may obtain a copy of the License at|;|+#|;|+#    http://www.apache.org/licenses/LICENSE-2.0|;|+#|;|+# Unless required by applicable law or agreed to in writing, software|;|+# distributed under the License is distributed on an ""AS IS"" BASIS,|;|+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+# See the License for the specific language governing permissions and|;|+# limitations under the License.|;|+|;|+gpu_device_info {|;|+  threads_per_block_limit: 1024|;|+  threads_per_warp: 32|;|+  shared_memory_per_block: 49152|;|+  shared_memory_per_core: 233472|;|+  threads_per_core_limit: 2048|;|+  core_count: 148|;|+  fpus_per_core: 128|;|+  block_dim_limit_x: 2147483647|;|+  block_dim_limit_y: 65535|;|+  block_dim_limit_z: 65535|;|+  memory_bandwidth: 7672320000000|;|+  l2_cache_size: 132644864|;|+  clock_rate_ghz: 1.965|;|+  device_memory_size: 191514673152|;|+  shared_memory_per_block_optin: 232448|;|+  cuda_compute_capability {|;|+    major: 10|;|+  }|;|+  registers_per_core_limit: 65536|;|+  registers_per_block_limit: 65536|;|+}|;|+platform_name: ""CUDA""|;|+dnn_version_info {|;|+  major: 9|;|+  minor: 7|;|+}|;|+device_description_str: ""NVIDIA B200""","PR #24010: Added GPU spec for B200

Imported from GitHub PR https://github.com/openxla/xla/pull/24010

Copybara import of the project:

--
b6fff6e24ef907c0ea43c7f11a5c7f358eaff3d3 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Added GPU spec for B200

Merging this change closes #24010

PiperOrigin-RevId: 740110907"
tensorflow/tensorflow,dimvar,24059,The performance of transpose_conv op in TensorFlow Lite,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
**Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
**Linux Ubuntu 14.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
**Meizu 16th**
- TensorFlow installed from (source or binary):
**benchmark_model is built form source**
- TensorFlow version (use command below):
**master**
- Python version:
**Python 3.5.3**
- Bazel version (if compiling from source):
**0.16.1**
- GCC/Compiler version (if compiling from source):
**4.9.4**
- CUDA/cuDNN version:
**No**
- GPU model and memory:
**N/A**

**Describe the current behavior**
I wanted to deploy a trained model on Android devices with TensorFlow Lite, but it was quite slow.
Then, I profiled the model(.tflite) with the benchmark_model tool, and found that the transpose_conv op took too much time. The summary by node type shown below:
![screenshot from 2018-11-30 11 11 48](https://user-images.githubusercontent.com/21071150/49267677-8f39c600-f496-11e8-9e91-1da5dd9f4603.png)

When I profiled the same model(.pb) used to convert to .tflite, I found that the transpose_conv achieving fast inference speed. The summary by node type shown below:
![screenshot from 2018-11-30 11 04 33](https://user-images.githubusercontent.com/21071150/49269045-d9727580-f49d-11e8-8d4c-84e965350420.png)

It seems like the transpose_conv op in TensorFlow Lite is much slower than that in TensorFlow Mobile?
","This issue is also tracking accuracy and correctness: https://github.com/tensorflow/tensorflow/pull/24151 || Thanks for the report, can you provide the exact build options you used to build `benchmark_model` from source? I'm also assuming this was single-threaded execution? || @jdduke I build benchmark_model according to the document TFLite Model Benchmark Tool.(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark)
bazel build -c opt \
  --config=android_arm \
  --cxxopt='--std=c++11' \
  --copt=-DTFLITE_PROFILING_ENABLED \
  tensorflow/lite/tools/benchmark:benchmark_model || Thanks. More recently we've been recommending ""--config=android_arm64"" to get the most accurate performance numbers, but I suspect the delta remains the same. We'll take a look, though I should note that it looks like TensorFlow Lite is still ~15-20% faster overall for this model?

It would also help if you could either send me the model (or a minimal repro) directly, or at least give the general sizes used here. Thanks! || @jdduke The models shown here:
[models.zip](https://github.com/tensorflow/tensorflow/files/2719886/models.zip)
And I also found that time cost was quite different with execution within the Android app (tflite.run(imgData, outputArray)).
 || > And I also found that time cost was quite different with execution within the Android app (tflite.run(imgData, outputArray)).

Can you add some more details about this? How did the performance differ relative to running the native benchmark_model? Is your imgData a ByteBuffer or multi-dimensional array? || @jdduke The model used to test the difference:
[model.zip](https://github.com/tensorflow/tensorflow/files/2753865/model.zip)
The imgData is ByteBuffer, and the outputArray is multi-dimensional array, according to the TFLite Java Demo. The timecost to run model inference is about 170ms.
But I profiled the model with the benchmark_model tool, the summary by node type shown below:
![screenshot from 2019-01-14 10 23 38](https://user-images.githubusercontent.com/21071150/51094314-bbab6680-17e6-11e9-9f05-035cef2c7d57.png)
The timecost is about 62ms.
I also test the experimental Android APK wrapper for the benchmark model, and the timecost is about 62ms.
Maybe there is bug in tensorflow-lite.aar or benchmark_model tool. Please have a look. || Are you using the same shape with the Java demo and benchmark_model? I'm not able to repro the large discrepancy in latency. You might also check the Java demo you build to make sure it's using the 64-bit libraries. || @jdduke In my environment, I confirmed TF Lite is x3 - x10 slower than TF mobile under same model including transpose_conv op, same in/out shape condition on Windows 64bit / MacOS X / Android arm64.
I will show the detail of the benchmark result within days. || Keep in mind that TF mobile enables threading by default, whereas TF lite does not. Please test TF mobile single-threaded to form an accurate comparison. || Thanks. I've already checked both single and multiple threading with C++ benchmark model tool (not Java demo). || > @jdduke I build benchmark_model according to the document TFLite Model Benchmark Tool.(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark)
> bazel build -c opt 
> --config=android_arm 
> --cxxopt='--std=c++11' 
> --copt=-DTFLITE_PROFILING_ENABLED 
> tensorflow/lite/tools/benchmark:benchmark_model

@ljdang 
when I run benchmark_model, avg time cost displayed, but other is empty like below.
would you help on this ?

============================== Run Order ==============================
                     [node type]          [start]         [first]        [avg ms]            [%]          [cdf%]          [mem KB]      [times called]  [Name]

============================== Top by Computation Time ==============================
                     [node type]          [start]         [first]        [avg ms]            [%]          [cdf%]          [mem KB]      [times called]  [Name]

Number of nodes executed: 0
============================== Summary by node type ==============================
                     [Node type]          [count]         [avg ms]          [avg %]         [cdf %]       [mem KB]      [times called]

",closed,2018-11-30T05:02:14+00:00,2019-02-07T23:37:45+00:00,ljdang,comp:lite,1,"PR#89871 - third_party/xla/xla/service/gpu/gpu_compiler_test_autotune_db.textproto: @@ -105,4 +105,28 @@ results {|;|       nanos: 1|;|     }|;|   }|;|-}|;|\ No newline at end of file|;|+}|;|+results {|;|+  device: ""CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB""|;|+  hlo: ""{\n  tmp_0 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(0)\n  tmp_1 = bf16[] constant({...})\n  tmp_2 = bf16[1,4,32,1024,1024]{4,3,2,1,0} broadcast(bf16[] tmp_1), dimensions={}\n  tmp_3 = bf16[1,4,32,1024,1024]{4,3,2,1,0} multiply(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_0, bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_2)\n  tmp_4 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_3)\n  tmp_5 = bf16[4,32,1024,1024]{3,2,1,0} transpose(bf16[4,32,1024,1024]{3,2,1,0} tmp_4), dimensions={0,1,3,2}\n  tmp_6 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[4,32,1024,1024]{3,2,1,0} tmp_5)\n  tmp_7 = bf16[1,4,32,1024,1024]{4,3,2,1,0} parameter(1)\n  tmp_8 = bf16[128,1024,1024]{2,1,0} bitcast(bf16[1,4,32,1024,1024]{4,3,2,1,0} tmp_7)\n  tmp_9 = bf16[128,1024,1024]{2,1,0} dot(bf16[128,1024,1024]{2,1,0} tmp_6, bf16[128,1024,1024]{2,1,0} tmp_8), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}\n  ROOT tmp_10 = bf16[4,32,1024,1024]{3,2,1,0} bitcast(bf16[128,1024,1024]{2,1,0} tmp_9)\n}""|;|+  result {|;|+    gemm {|;|+      algorithm: -1|;|+    }|;|+    run_time {|;|+      nanos: 1|;|+    }|;|+  }|;|+}|;|+results {|;|+  device: ""CUDA: 10.0, Cores: 148, GPU clock: 1.65 GHz, Memory bandwidth: 8192 GB/s, L2 cache: 126.5 MB"",|;|+  hlo: ""{\n  tmp_0 = f8e4m3fn[12288,4096]{0,1} parameter(0)\n  tmp_1 = f8e4m3fn[4096,16384]{0,1} parameter(1)\n  tmp_2 = bf16[12288,16384]{1,0} dot(f8e4m3fn[12288,4096]{0,1} tmp_0, f8e4m3fn[4096,16384]{0,1} tmp_1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n  tmp_3 = bf16[] constant({...})\n  tmp_4 = bf16[12288,16384]{1,0} broadcast(bf16[] tmp_3), dimensions={}\n  ROOT tmp_5 = bf16[12288,16384]{1,0} multiply(bf16[12288,16384]{1,0} tmp_2, bf16[12288,16384]{1,0} tmp_4)\n}""|;|+  result {|;|+    gemm {|;|+      algorithm: -1|;|+    }|;|+    run_time {|;|+      nanos: 1|;|+    }|;|+  }|;|+}","PR #24059: Add autotuning results to fix gpu_compiler_test for Blackwell

Imported from GitHub PR https://github.com/openxla/xla/pull/24059

Copybara import of the project:

--
4297c120c719c87e9607f3eaf7a0298eead048b2 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Add autotuning results to fix gpu_compiler_test for Blackwell

Merging this change closes #24059

PiperOrigin-RevId: 740042699"
tensorflow/tensorflow,shraiysh,23838,"Updated PR for ""Fold BN after depthwise conv""(#21023)",[Original PR is here](https://github.com/tensorflow/tensorflow/pull/21023),"Could you pull rebase and push again? || @smillius if you could take a quick look, that would be great. Thanks! || @zhaoyongke could you run clang-format-3.6.0 on this? || @drpngx can u provide full command lines for clang-format-3.6.0?  || > @drpngx can u provide full command lines for clang-format-3.6.0?

@drpngx  Any update please ? || You need to download the tool and run it. || > @zhaoyongke could you run clang-format-3.6.0 on this?

@zhaoyongke   Any update please ? || I tried to run clang-format-3.6 on modified files in this PR, nothing meaningful found, only generated the almost same code again with some indent changed.@drpngx @harshini-gadige  || Can someone from Tensorflow team look at this? It would be nice to include this PR in next TF release. || > I tried to run clang-format-3.6 on modified files in this PR, nothing meaningful found, only generated the almost same code again with some indent changed.@drpngx @harshini-gadige

@drpngx  Can  you please suggest the user on this. || Please push the files. Clang format will have nothing meaningful, just
spaces.

On Tue, Dec 4, 2018, 3:34 PM harshini-gadige <notifications@github.com
wrote:

> I tried to run clang-format-3.6 on modified files in this PR, nothing
> meaningful found, only generated the almost same code again with some
> indent changed.@drpngx <https://github.com/drpngx> @harshini-gadige
> <https://github.com/harshini-gadige>
>
> @drpngx <https://github.com/drpngx> Can you please suggest the user on
> this.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/pull/23838#issuecomment-444246567>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AT_SbTUwNARev0zxFHqTjaCu3p2mKo9tks5u1txZgaJpZM4Yn-4A>
> .
>
 || Hi @drpngx @mingxingtan @smillius, 
The only thing left is the code review,  can you guys approve it?  The old PR has been reviewed once already. || Sounds good. Started the test & pull to internal. || Nagging Reviewer @mingxingtan: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.",closed,2018-11-18T15:07:06+00:00,2019-02-04T08:10:39+00:00,zhaoyongke,"cla: yes, ready to pull, size:M",1,"PR#89747 - third_party/xla/xla/backends/gpu/codegen/dynamic_slice_fusion_test.cc: @@ -216,7 +216,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmWithWorkspace) {|;|     %slice.14 = f16[1,8,8]{2,1,0} slice(%p1), slice={[1:2], [0:8], [0:8]}|;|     %bitcast.42 = f16[8,8]{1,0} bitcast(%slice.14)|;| |;|-    ROOT %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|+    %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={""gemm_backend_config"":{|;|         ""alpha_real"":1,|;|@@ -235,6 +235,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmWithWorkspace) {|;|         ""grad_x"":false,|;|         ""grad_y"":false|;|       }}|;|+    ROOT %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -275,8 +276,9 @@ TEST_F(DynamicSliceFusionTest, CublasGemmWithWorkspace) {|;|   ENTRY %main.9 {|;|     %p0 = f16[2,8,8]{2,1,0} parameter(0), sharding={replicated}|;|     %p1 = f16[2,8,8]{2,1,0} parameter(1), sharding={replicated}|;|-    ROOT %fusion.2 = (f16[8,8]{1,0}, s8[256]{0}) fusion(%p0, %p1), kind=kCustom, calls=%fused_computation,|;|+    %fusion.2 = (f16[8,8]{1,0}, s8[256]{0}) fusion(%p0, %p1), kind=kCustom, calls=%fused_computation,|;|         backend_config={""fusion_backend_config"":{""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}}}|;|+    ROOT %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%fusion.2), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(|;|@@ -563,7 +565,7 @@ TEST_F(DynamicSliceFusionTest, OperandIsSlicedGetTupleElement) {|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|     %slice.26 = f32[100,100]{1,0} slice(%get-tuple-element.97), slice={[0:100], [0:100]}|;|-    ROOT %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %get-tuple-element.240),|;|+    %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %get-tuple-element.240),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={|;|         ""gemm_backend_config"":{|;|@@ -584,6 +586,7 @@ TEST_F(DynamicSliceFusionTest, OperandIsSlicedGetTupleElement) {|;|           ""grad_y"":false|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%custom-call.17), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -646,14 +649,15 @@ TEST_F(DynamicSliceFusionTest, OperandIsSlicedGetTupleElement) {|;|         }|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %get-tuple-element.240),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %get-tuple-element.240),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       backend_config={|;|         ""fusion_backend_config"":{|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -779,7 +783,7 @@ TEST_F(DynamicSliceFusionTest, SingleOperandComputation) {|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|     %slice.26 = f32[100,100]{1,0} slice(%get-tuple-element.97), slice={[0:100], [0:100]}|;|-    ROOT %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %slice.26),|;|+    %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %slice.26),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={|;|         ""gemm_backend_config"":{|;|@@ -800,6 +804,7 @@ TEST_F(DynamicSliceFusionTest, SingleOperandComputation) {|;|           ""grad_y"":false|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%custom-call.17), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -861,14 +866,15 @@ TEST_F(DynamicSliceFusionTest, SingleOperandComputation) {|;|         }|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       backend_config={|;|         ""fusion_backend_config"":{|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -888,7 +894,7 @@ TEST_F(DynamicSliceFusionTest, SlicedOperandAliasingOutput) {|;|       %concatenate.12 = f32[200,100]{1,0} concatenate(%get-tuple-element.287, %get-tuple-element.288), dimensions={0}|;|       %slice.30 = f32[100,100]{1,0} slice(%concatenate.12), slice={[20:120], [0:100]}|;|       %slice.34 = f32[100,100]{1,0} slice(%concatenate.12), slice={[99:199], [0:100]}|;|-      ROOT %cublas-gemm.15 = (f32[100,100]{1,0}, s8[120000]{0}) custom-call(%get-tuple-element.287, %slice.30, %slice.34),|;|+      %cublas-gemm.15 = (f32[100,100]{1,0}, s8[120000]{0}) custom-call(%get-tuple-element.287, %slice.30, %slice.34),|;|         custom_call_target=""__cublas$gemm"",|;|         output_to_operand_aliasing={{0}: (2, {})},|;|         backend_config={""gemm_backend_config"":{|;|@@ -908,6 +914,7 @@ TEST_F(DynamicSliceFusionTest, SlicedOperandAliasingOutput) {|;|           ""grad_x"":false,|;|           ""grad_y"":false|;|         }}|;|+      ROOT %get-tuple-element.289 = f32[100,100]{1,0} get-tuple-element(%cublas-gemm.15), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -950,7 +957,7 @@ TEST_F(DynamicSliceFusionTest, SlicedOperandAliasingOutput) {|;|     %get-tuple-element.288 = f32[100,100]{1,0} get-tuple-element(%p0), index=1|;|     %concatenate.12 = f32[200,100]{1,0} concatenate(%get-tuple-element.287, %get-tuple-element.288), dimensions={0}|;|     %slice.34 = f32[100,100]{1,0} slice(%concatenate.12), slice={[99:199], [0:100]}|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[120000]{0}) fusion(%get-tuple-element.287, %slice.34, %concatenate.12),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[120000]{0}) fusion(%get-tuple-element.287, %slice.34, %concatenate.12),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       output_to_operand_aliasing={{0}: (1, {})},|;|@@ -959,6 +966,7 @@ TEST_F(DynamicSliceFusionTest, SlicedOperandAliasingOutput) {|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.289 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -1392,7 +1400,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDynamicWithWorkspace) {|;|     %slice.14 = f16[1,8,8]{2,1,0} dynamic-slice(%p1, %c1_s32, %c0_s32, %c0_s32), dynamic_slice_sizes={1,8,8}|;|     %bitcast.42 = f16[8,8]{1,0} bitcast(%slice.14)|;| |;|-    ROOT %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|+    %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={""gemm_backend_config"":{|;|         ""alpha_real"":1,|;|@@ -1411,6 +1419,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDynamicWithWorkspace) {|;|         ""grad_x"":false,|;|         ""grad_y"":false|;|       }}|;|+    ROOT %gte = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -1455,8 +1464,9 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDynamicWithWorkspace) {|;|     %p1 = f16[2,8,8]{2,1,0} parameter(1), sharding={replicated}|;|     %c1_s32 = s32[] constant(1)|;|     %c0_s32 = s32[] constant(0)|;|-    ROOT %fusion.2 = (f16[8,8]{1,0}, s8[256]{0}) fusion(%p0, %p1, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|+    %fusion.2 = (f16[8,8]{1,0}, s8[256]{0}) fusion(%p0, %p1, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|         backend_config={""fusion_backend_config"":{""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}}}|;|+    ROOT %gte = f16[8,8]{1,0} get-tuple-element(%fusion.2), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(|;|@@ -1681,7 +1691,7 @@ TEST_F(DynamicSliceFusionTest, DynamicOperandIsSlicedGetTupleElement) {|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|     %slice.26 = f32[100,100]{1,0} dynamic-slice(%get-tuple-element.97, %c0_s32, %c0_s32), dynamic_slice_sizes={100,100}|;|-    ROOT %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %get-tuple-element.240),|;|+    %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %get-tuple-element.240),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={|;|         ""gemm_backend_config"":{|;|@@ -1702,6 +1712,7 @@ TEST_F(DynamicSliceFusionTest, DynamicOperandIsSlicedGetTupleElement) {|;|           ""grad_y"":false|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%custom-call.17), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -1766,14 +1777,15 @@ TEST_F(DynamicSliceFusionTest, DynamicOperandIsSlicedGetTupleElement) {|;|         }|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %get-tuple-element.240, %c0_s32),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %get-tuple-element.240, %c0_s32),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       backend_config={|;|         ""fusion_backend_config"":{|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -1906,7 +1918,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSingleOperandComputation) {|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|     %slice.26 = f32[100,100]{1,0} dynamic-slice(%get-tuple-element.97, %c0_s32, %c0_s32), dynamic_slice_sizes={100,100}|;|-    ROOT %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %slice.26),|;|+    %custom-call.17 = (f32[100,100]{1,0}, s8[80000]{0}) custom-call(%slice.26, %slice.26),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={|;|         ""gemm_backend_config"":{|;|@@ -1927,6 +1939,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSingleOperandComputation) {|;|           ""grad_y"":false|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%custom-call.17), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -1990,14 +2003,15 @@ TEST_F(DynamicSliceFusionTest, DynamicSingleOperandComputation) {|;|         }|;|       }|;|     %get-tuple-element.97 = f32[200,100]{1,0} get-tuple-element(%custom-call.16), index=0|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %c0_s32),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[80000]{0}) fusion(%get-tuple-element.97, %c0_s32),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       backend_config={|;|         ""fusion_backend_config"":{|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.221 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -2020,7 +2034,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSlicedOperandAliasingOutput) {|;|       %concatenate.12 = f32[200,100]{1,0} concatenate(%get-tuple-element.287, %get-tuple-element.288), dimensions={0}|;|       %slice.30 = f32[100,100]{1,0} dynamic-slice(%concatenate.12, %c20_s32, %c0_s32), dynamic_slice_sizes={100,100}|;|       %slice.34 = f32[100,100]{1,0} dynamic-slice(%concatenate.12, %c99_s32, %c0_s32), dynamic_slice_sizes={100,100}|;|-      ROOT %cublas-gemm.15 = (f32[100,100]{1,0}, s8[120000]{0}) custom-call(%get-tuple-element.287, %slice.30, %slice.34),|;|+      %cublas-gemm.15 = (f32[100,100]{1,0}, s8[120000]{0}) custom-call(%get-tuple-element.287, %slice.30, %slice.34),|;|         custom_call_target=""__cublas$gemm"",|;|         output_to_operand_aliasing={{0}: (2, {})},|;|         backend_config={""gemm_backend_config"":{|;|@@ -2040,6 +2054,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSlicedOperandAliasingOutput) {|;|           ""grad_x"":false,|;|           ""grad_y"":false|;|         }}|;|+      ROOT %get-tuple-element.289 = f32[100,100]{1,0} get-tuple-element(%cublas-gemm.15), index=0|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -2087,7 +2102,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSlicedOperandAliasingOutput) {|;|     %get-tuple-element.288 = f32[100,100]{1,0} get-tuple-element(%p0), index=1|;|     %concatenate.12 = f32[200,100]{1,0} concatenate(%get-tuple-element.287, %get-tuple-element.288), dimensions={0}|;|     %slice.34 = f32[100,100]{1,0} dynamic-slice(%concatenate.12, %c99_s32, %c0_s32), dynamic_slice_sizes={100,100}|;|-    ROOT %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[120000]{0}) fusion(%get-tuple-element.287, %slice.34, %concatenate.12, %c0_s32, %c20_s32),|;|+    %dynamic-slice-fusion.6 = (f32[100,100]{1,0}, s8[120000]{0}) fusion(%get-tuple-element.287, %slice.34, %concatenate.12, %c0_s32, %c20_s32),|;|       kind=kCustom,|;|       calls=%dynamic-slice-fusion,|;|       output_to_operand_aliasing={{0}: (1, {})},|;|@@ -2096,6 +2111,7 @@ TEST_F(DynamicSliceFusionTest, DynamicSlicedOperandAliasingOutput) {|;|           ""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}|;|         }|;|       }|;|+    ROOT %get-tuple-element.289 = f32[100,100]{1,0} get-tuple-element(%dynamic-slice-fusion.6), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(hlo_ref, hlo_opt, error_spec,|;|@@ -2202,7 +2218,6 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSWithWorkspace) {|;| |;|   const char* hlo_ref = R""(|;|   HloModule jit_slice|;|-|;|   ENTRY %main.9 {|;|     %p0 = f16[2,8,8]{2,1,0} parameter(0)|;|     %p1 = f16[2,8,8]{2,1,0} parameter(1)|;|@@ -2213,7 +2228,6 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSWithWorkspace) {|;|     %bitcast.41 = f16[8,8]{1,0} bitcast(%slice.13)|;|     %slice.14 = f16[1,8,8]{2,1,0} dynamic-slice(%p1, %c1_s32, %c0_s32, %c0_s32), dynamic_slice_sizes={1,8,8}|;|     %bitcast.42 = f16[8,8]{1,0} bitcast(%slice.14)|;|-|;|     %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={""gemm_backend_config"":{|;|@@ -2235,14 +2249,11 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSWithWorkspace) {|;|       }}|;|     %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|     %bitcast.43 = f16[1,8,8]{2,1,0} bitcast(%get-tuple-element.0)|;|-    %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|-    %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|-    ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|+    ROOT %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|   HloModule jit_slice|;|-|;|   %fused_computation {|;|     %p0 = f16[2,8,8]{2,1,0} parameter(0)|;|     %p1 = f16[2,8,8]{2,1,0} parameter(1)|;|@@ -2253,7 +2264,6 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSWithWorkspace) {|;|     %bitcast.41 = f16[8,8]{1,0} bitcast(%slice.13)|;|     %slice.14 = f16[1,8,8]{2,1,0} dynamic-slice(%p1, %c1_s32, %c0_s32, %c0_s32), dynamic_slice_sizes={1,8,8}|;|     %bitcast.42 = f16[8,8]{1,0} bitcast(%slice.14)|;|-|;|     %custom-call.1 = (f16[8,8]{1,0}, s8[256]{0}) custom-call(%bitcast.41, %bitcast.42),|;|       custom_call_target=""__cublas$gemm"",|;|       backend_config={""gemm_backend_config"":{|;|@@ -2279,15 +2289,15 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSWithWorkspace) {|;|     %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|     ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|   }|;|-|;|   ENTRY %main.9 {|;|     %p0 = f16[2,8,8]{2,1,0} parameter(0)|;|     %p1 = f16[2,8,8]{2,1,0} parameter(1)|;|     %p2 = f16[4,8,8]{2,1,0} parameter(2)|;|     %c1_s32 = s32[] constant(1)|;|     %c0_s32 = s32[] constant(0)|;|-    ROOT %fusion.2 = (f16[4,8,8]{2,1,0}, s8[256]{0}) fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|+    %fusion.2 = (f16[4,8,8]{2,1,0}, s8[256]{0}) fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|         backend_config={""fusion_backend_config"":{""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}}}|;|+    ROOT %gte = f16[4,8,8]{2,1,0} get-tuple-element(%fusion.2), index=0|;|   })""|;|; |;|   EXPECT_TRUE(RunAndCompareTwoModules(|;|@@ -2421,9 +2431,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetS32NotConstant) {|;|       }}|;|     %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|     %bitcast.43 = f16[1,8,8]{2,1,0} bitcast(%get-tuple-element.0)|;|-    %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|-    %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|-    ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|+    ROOT %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -2461,9 +2469,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetS32NotConstant) {|;|       }}|;|     %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|     %bitcast.43 = f16[1,8,8]{2,1,0} bitcast(%get-tuple-element.0)|;|-    %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|-    %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|-    ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|+    ROOT %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|   }|;| |;|   ENTRY %main.9 {|;|@@ -2472,7 +2478,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetS32NotConstant) {|;|     %p2 = f16[4,8,8]{2,1,0} parameter(2)|;|     %c1_s32 = s32[] parameter(3)|;|     %c0_s32 = s32[] parameter(4)|;|-    ROOT %fusion.2 = (f16[4,8,8]{2,1,0}, s8[256]{0}) fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|+    ROOT %fusion.2 = f16[4,8,8]{2,1,0} fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|         backend_config={""fusion_backend_config"":{""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}}}|;|   })""|;|; |;|@@ -2518,9 +2524,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetOOB) {|;|       }}|;|     %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|     %bitcast.43 = f16[1,8,8]{2,1,0} bitcast(%get-tuple-element.0)|;|-    %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|-    %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|-    ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|+    ROOT %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|   })""|;|; |;|   const char* hlo_opt = R""(|;|@@ -2558,9 +2562,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetOOB) {|;|       }}|;|     %get-tuple-element.0 = f16[8,8]{1,0} get-tuple-element(%custom-call.1), index=0|;|     %bitcast.43 = f16[1,8,8]{2,1,0} bitcast(%get-tuple-element.0)|;|-    %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|-    %get-tuple-element.1 = s8[256]{0} get-tuple-element(%custom-call.1), index=1|;|-    ROOT %tuple = (f16[4,8,8]{2,1,0}, s8[256]{0}) tuple(%dus, %get-tuple-element.1)|;|+    ROOT %dus = f16[4,8,8]{2,1,0} dynamic-update-slice(%p2, %bitcast.43, %c1_s32, %c0_s32, %c0_s32)|;|   }|;| |;|   ENTRY %main.9 {|;|@@ -2569,7 +2571,7 @@ TEST_F(DynamicSliceFusionTest, CublasGemmDUSOffsetOOB) {|;|     %p2 = f16[4,8,8]{2,1,0} parameter(2)|;|     %c1_s32 = s64[] constant(10)|;|     %c0_s32 = s64[] constant(-1)|;|-    ROOT %fusion.2 = (f16[4,8,8]{2,1,0}, s8[256]{0}) fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|+    ROOT %fusion.2 = f16[4,8,8]{2,1,0} fusion(%p0, %p1, %p2, %c1_s32, %c0_s32), kind=kCustom, calls=%fused_computation,|;|         backend_config={""fusion_backend_config"":{""kind"":""__custom_fusion"",""custom_fusion_config"":{""name"":""dynamic_address_computation""}}}|;|   })""|;|; ","PR #23838: [ds-fusion] Remove workspace checks in dynamic slice fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/23838

The contents of the workspace are not guarenteed to be the same after a cublas gemm operation. We were comparing the contents of the workspace. This patch removes such checks and only looks for the value of the results.
Copybara import of the project:

--
a8d18715ff7cb651409ddb22164f8974da2b2b1e by Shraiysh Vaishay <svaishay@nvidia.com>:

[ds-fusion] Remove workspace checks

The contents of the workspace are not guarenteed to be the same
after a cublas gemm operation. We were comparing the contents of
the workspace. This patch removes such checks and only looks for
the value of the results.

--
c08843019b71307f04a265ac813af2beb9bd78b5 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments

Merging this change closes #23838

PiperOrigin-RevId: 739868436"
tensorflow/tensorflow,tensorflower-gardener,88103,Supports more legalizations and multi-partition,"1. more legalizations 
   a. Batch_MatMul
   b. Mul
   c. Fully_Connected

3. multi-partition supports 
    introduce utils for supporting multi-partition","Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/88103/checks?check_run_id=37825132850) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request. || Hi @neuropilot-captain , Can you please sign and resolve the conflicts? Thank you!",closed,2025-02-26T02:15:34+00:00,2025-03-21T19:25:36+00:00,neuropilot-captain,"comp:lite, size:L",1,"PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/BUILD: @@ -28,7 +28,7 @@ litert_cc_lib_with_mtk(|;|         ""neuron_adapter_api.h"",|;|     ],|;|     tags = [|;|-        # Don't build/test in OS until qnn is available.|;|+        # Don't build/test in OS until neuron is available.|;|         ""nobuilder"",|;|         ""notap"",|;|     ], || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/BUILD: @@ -45,6 +45,9 @@ litert_dynamic_lib(|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:common_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:neuron_litert_schema"",|;|         ""@com_google_absl//absl/strings:str_format"",|;|         ""@com_google_absl//absl/strings:string_view"",|;|     ],|;|@@ -60,20 +63,27 @@ cc_library(|;|         ""notap"",|;|     ],|;|     deps = [|;|-        ""@com_google_absl//absl/strings:string_view"",|;|         # copybara:uncomment ""//third_party/neuro_pilot:latest_host_headers"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|-        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_op_code"",|;|-        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|-        ""//tensorflow/lite/experimental/litert/cc:litert_macros"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|-        ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|-        ""//tensorflow/lite/experimental/litert/core/model"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:add_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:batch_matmul_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:common_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:concat_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:fully_connected_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:gelu_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:mean_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:mul_op_legalization"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:reshape_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:rsqrt_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:softmax_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:sub_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:transpose_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;| |;|@@ -99,6 +109,7 @@ cc_library(|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|         ""//tensorflow/lite/experimental/litert/core/model"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/compiler_plugin.cc: @@ -34,7 +34,10 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/c/litert_compiler_plugin.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/compile_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/create_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema_generated.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| //|;| // Configurations|;|@@ -68,6 +71,20 @@ constexpr std::pair<const char*, const char*> kPluginSocModels[] = {|;| |;| constexpr LiteRtOpCode kSupportedOps[] = {|;|     kLiteRtOpCodeTflAdd,|;|+    kLiteRtOpCodeTflMul,|;|+    kLiteRtOpCodeTflBatchMatmul,|;|+    kLiteRtOpCodeTflFullyConnected,|;|+    kLiteRtOpCodeTflReshape,|;|+    kLiteRtOpCodeTflTranspose,|;|+    kLiteRtOpCodeTflRsqrt,|;|+    kLiteRtOpCodeTflConcatenation,|;|+    kLiteRtOpCodeTflQuantize,|;|+    kLiteRtOpCodeTflSlice,|;|+    kLiteRtOpCodeTflSub,|;|+    kLiteRtOpCodeTflTanh,|;|+    kLiteRtOpCodeTflSoftmax,|;|+    kLiteRtOpCodeTflMean,|;|+    kLiteRtOpCodeTflGelu,|;| }|;|; // clang-format on|;| |;|@@ -140,29 +157,28 @@ LiteRtStatus LiteRtGetCompilerPluginSupportedSocModel(|;| // TODO: Revisit this struct after we extend the compiler plugin API to return|;| // results with more than one single bytecode.|;| struct LiteRtCompiledResultT {|;|-  using Bytecode = std::vector<uint8_t>|;|;-  std::vector<Bytecode> bytecodes|;|;   std::vector<std::string> graph_names|;|;+  neuron::BytecodeBuilder bytebuilder|;|; }|;|; |;| LiteRtStatus LiteRtCompiledResultNumByteCodeModules(|;|     LiteRtCompiledResult compiled_result, LiteRtParamIndex* num_byte_code) {|;|   if (!compiled_result || !num_byte_code) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *num_byte_code = compiled_result->bytecodes.size()|;|;+  *num_byte_code = compiled_result->graph_names.size()|;|;   return kLiteRtStatusOk|;|; }|;| |;| LiteRtStatus LiteRtGetCompiledResultByteCode(|;|     LiteRtCompiledResult compiled_result, LiteRtParamIndex byte_code_idx,|;|     const void** byte_code, size_t* byte_code_size) {|;|   if (!compiled_result || !byte_code || !byte_code_size |||;|-      (byte_code_idx >= compiled_result->bytecodes.size())) {|;|+      (byte_code_idx >= compiled_result->graph_names.size())) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *byte_code = compiled_result->bytecodes[byte_code_idx].data()|;|;-  *byte_code_size = compiled_result->bytecodes[byte_code_idx].size()|;|;+  *byte_code = compiled_result->bytebuilder.GetBytecode().first|;|;+  *byte_code_size = compiled_result->bytebuilder.GetBytecode().second|;|;   return kLiteRtStatusOk|;|; }|;| |;|@@ -190,7 +206,7 @@ LiteRtStatus LiteRtGetNumCompiledResultCalls(|;|   if (!compiled_result || !num_calls) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *num_calls = compiled_result->bytecodes.size()|;|;+  *num_calls = compiled_result->graph_names.size()|;|;   return kLiteRtStatusOk|;|; }|;| |;|@@ -230,7 +246,8 @@ bool IsOpSupported(const litert::Op& op) {|;|   // NOTE: Currently we are demoing by just mapping simple f32 mul ops.  Use a|;|   // very loose guard for now -- only checking if op code is supported.|;|   for (auto supported_op : kSupportedOps) {|;|-    if (op.Code() == supported_op) {|;|+    if (op.Code() == supported_op &&|;|+        litert::mediatek::VerifyCommonOp(op, op.Code())) {|;|       return true|;|;     }|;|   }|;|@@ -326,11 +343,16 @@ LiteRtStatus LiteRtCompilerPluginCompile(|;|       LITERT_LOG(LITERT_INFO, ""%s"", bytecode.Error().Message().c_str())|;|;       return bytecode.Error().Status()|;|;     }|;|-|;|-    result->bytecodes.emplace_back(*bytecode)|;|;+    auto bufferIdx = result->bytebuilder.AddBuffer(|;|+        graph_name, (int8_t*)bytecode->data(), bytecode->size())|;|;+    result->bytebuilder.AddCompiledNetwork(|;|+        graph_name, NeuronSchema::CompiledType_AdapterCache, bufferIdx)|;|;     result->graph_names.emplace_back(graph_name)|;|;   }|;| |;|+  if (!result->bytebuilder.Finish()) {|;|+    return kLiteRtStatusErrorCompilation|;|;+  }|;|   *compiled_result = result.release()|;|;   return kLiteRtStatusOk|;|; } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/create_model.cc: @@ -24,8 +24,21 @@|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/add_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| namespace litert::mediatek {|;| |;|@@ -76,7 +89,62 @@ Expected<NeuronModelPtr> CreateModel(const NeuronAdapterApi& neuron_adapter_api,|;|         status =|;|             LegalizeAddOp(neuron_adapter_api, model->get(), operand_map, op)|;|;         break|;|;-|;|+      case kLiteRtOpCodeTflMul:|;|+        status =|;|+            LegalizeMulOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflBatchMatmul:|;|+        status = LegalizeBatchMatMulOp(neuron_adapter_api, model->get(),|;|+                                       operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflFullyConnected:|;|+        status = LegalizeFullyConnectedOp(neuron_adapter_api, model->get(),|;|+                                          operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflReshape:|;|+        status = LegalizeReshapeOp(neuron_adapter_api, model->get(),|;|+                                   operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflTranspose:|;|+        status = LegalizeTransposeOp(neuron_adapter_api, model->get(),|;|+                                     operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflRsqrt:|;|+        status =|;|+            LegalizeRsqrtOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflConcatenation:|;|+        status =|;|+            LegalizeConcatOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflQuantize:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_QUANTIZE)|;|;+        break|;|;+      case kLiteRtOpCodeTflSlice:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_SLICE)|;|;+        break|;|;+      case kLiteRtOpCodeTflTanh:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_TANH)|;|;+        break|;|;+      case kLiteRtOpCodeTflSub:|;|+        status =|;|+            LegalizeSubOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflSoftmax:|;|+        status = LegalizeSoftmaxOp(neuron_adapter_api, model->get(),|;|+                                   operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflMean:|;|+        status =|;|+            LegalizeMeanOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflGelu:|;|+        status =|;|+            LegalizeGeluOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;       default:|;|         return Error(kLiteRtStatusErrorRuntimeFailure, ""Unsupported op"")|;|;     } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/BUILD: @@ -27,7 +27,9 @@ cc_library(|;|         ""notap"",|;|     ],|;|     deps = [|;|+        ""neuron_utils"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_element_type"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|@@ -36,6 +38,25 @@ cc_library(|;|     ],|;| )|;| |;|+cc_library(|;|+    name = ""neuron_utils"",|;|+    srcs = [""neuron_utils.cc""],|;|+    hdrs = [""neuron_utils.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;| cc_library(|;|     name = ""add_op_legalization"",|;|     srcs = [""add_op_legalization.cc""],|;|@@ -48,6 +69,267 @@ cc_library(|;|     deps = [|;|         ""operand_map"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""mul_op_legalization"",|;|+    srcs = [""mul_op_legalization.cc""],|;|+    hdrs = [""mul_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""batch_matmul_op_legalization"",|;|+    srcs = [""batch_matmul_op_legalization.cc""],|;|+    hdrs = [""batch_matmul_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""fully_connected_op_legalization"",|;|+    srcs = [""fully_connected_op_legalization.cc""],|;|+    hdrs = [""fully_connected_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""reshape_op_legalization"",|;|+    srcs = [""reshape_op_legalization.cc""],|;|+    hdrs = [""reshape_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""transpose_op_legalization"",|;|+    srcs = [""transpose_op_legalization.cc""],|;|+    hdrs = [""transpose_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""rsqrt_op_legalization"",|;|+    srcs = [""rsqrt_op_legalization.cc""],|;|+    hdrs = [""rsqrt_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""concat_op_legalization"",|;|+    srcs = [""concat_op_legalization.cc""],|;|+    hdrs = [""concat_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""quantize_op_legalization"",|;|+    srcs = [""quantize_op_legalization.cc""],|;|+    hdrs = [""quantize_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""common_op_legalization"",|;|+    srcs = [""common_op_legalization.cc""],|;|+    hdrs = [""common_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""sub_op_legalization"",|;|+    srcs = [""sub_op_legalization.cc""],|;|+    hdrs = [""sub_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""softmax_op_legalization"",|;|+    srcs = [""softmax_op_legalization.cc""],|;|+    hdrs = [""softmax_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""mean_op_legalization"",|;|+    srcs = [""mean_op_legalization.cc""],|;|+    hdrs = [""mean_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""gelu_op_legalization"",|;|+    srcs = [""gelu_op_legalization.cc""],|;|+    hdrs = [""gelu_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"", || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/add_op_legalization.cc: @@ -18,6 +18,7 @@|;| #include <vector>|;| |;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|@@ -29,6 +30,7 @@ namespace litert::mediatek {|;| Expected<void> LegalizeAddOp(const NeuronAdapterApi& neuron_adapter_api,|;|                              NeuronModel* model, OperandMap& operand_map,|;|                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Add"")|;|;   std::vector<uint32_t> input_indices|;|;   for (auto& input : op.Inputs()) {|;|     auto id = operand_map.GetOperandIndex(input)|;|;@@ -62,12 +64,10 @@ Expected<void> LegalizeAddOp(const NeuronAdapterApi& neuron_adapter_api,|;|     output_indices.push_back(*id)|;|;   }|;| |;|-  if (neuron_adapter_api.api().model_add_operation(|;|-          model, /*type=*/NEURON_ADD, input_indices.size(),|;|-          input_indices.data(), output_indices.size(),|;|-          output_indices.data()) != NEURON_NO_ERROR) {|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_ADD,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|     return Error(kLiteRtStatusErrorRuntimeFailure,|;|-                 ""Failed to set value of NEURON_ADD fused activation"")|;|;+                 ""Failed to add NEURON_ADD op"")|;|;   }|;| |;|   return {}; || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.cc: @@ -0,0 +1,89 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeBatchMatMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                     NeuronModel* model,|;|+                                     OperandMap& operand_map,|;|+                                     const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize BatchMatMul"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_BATCH_MATMUL operation takes 2 scalar operand, which is used to|;|+  // pass a adjX, adjY value.|;|+  bool tfl_matmul_param_adj_x = 0, tfl_matmul_param_adj_y = 0|;|;+  if (auto status =|;|+          LiteRtGetBatchMatmulAdjXOption(op.Get(), &tfl_matmul_param_adj_x)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get batch matmul adjX"")|;|;+  }|;|+|;|+  if (auto status =|;|+          LiteRtGetBatchMatmulAdjYOption(op.Get(), &tfl_matmul_param_adj_y)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get batch matmul adjY"")|;|;+  }|;|+|;|+  auto adj_x_operand_index = operand_map.AddScalarBool(tfl_matmul_param_adj_x)|;|;+  if (!adj_x_operand_index) {|;|+    return adj_x_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*adj_x_operand_index)|;|;+|;|+  auto adj_j_operand_index = operand_map.AddScalarBool(tfl_matmul_param_adj_y)|;|;+  if (!adj_j_operand_index) {|;|+    return adj_j_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*adj_j_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_BATCH_MATMUL,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_BATCH_MATMUL op"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h: @@ -0,0 +1,33 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeBatchMatMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                     NeuronModel* model,|;|+                                     OperandMap& operand_map,|;|+                                     const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.cc: @@ -0,0 +1,66 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+bool VerifyCommonOp(const litert::Op& op, LiteRtOpCode op_code) {|;|+  // Do some common check|;|+  return true|;|;+}|;|+|;|+Expected<void> LegalizeCommonOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op,|;|+                                NeuronOperationType mtk_operation_type) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Op: %d"", mtk_operation_type)|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/mtk_operation_type,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure, ""Failed to add operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h: @@ -0,0 +1,35 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+bool VerifyCommonOp(const litert::Op& op, LiteRtOpCode op_code)|;|;+|;|+Expected<void> LegalizeCommonOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op,|;|+                                NeuronOperationType mtk_operation_type)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.cc: @@ -0,0 +1,77 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeConcatOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Concate"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_CONCAT operation takes an additional scalar operand, which is used|;|+  // to pass as a axis.|;|+  int32_t axis|;|;+  if (auto status = LiteRtGetConcatenationAxisOption(op.Get(), &axis)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get new shape option"")|;|;+  }|;|+|;|+  auto axis_operand_index = operand_map.AddScalarInt32(axis)|;|;+  if (!axis_operand_index) {|;|+    return axis_operand_index.Error()|;|;+  }|;|+|;|+  input_indices.push_back(*axis_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model,|;|+                        /*type=*/NEURON_CONCATENATION, input_indices,|;|+                        output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_CONCAT operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeConcatOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.cc: @@ -0,0 +1,129 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+#define GET_RANK(op) ((op).RankedTensorType()->Layout().Rank())|;|+#define GET_DIMENSION(op) ((op).RankedTensorType()->Layout().Dimensions())|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeFullyConnectedOp(|;|+    const NeuronAdapterApi& neuron_adapter_api, NeuronModel* model,|;|+    OperandMap& operand_map, const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Fully Connected"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // for beta|;|+  if (input_indices.size() < 3) {|;|+    auto weights_shape = GET_DIMENSION(op.Inputs()[1])|;|;+    std::vector<uint32_t> bias_shape = {|;|+        static_cast<unsigned int>(weights_shape[0])}|;|;+    std::vector<int32_t> bias_data(bias_shape[0], 0)|;|;+    auto bias_data_operand =|;|+        operand_map.AddTensorByType(NEURON_TENSOR_QUANT8_SYMM, bias_shape,|;|+                                    bias_data.data(), bias_data.size() * 1)|;|;+    input_indices.push_back(*bias_data_operand)|;|;+  }|;|+|;|+  // A NEURON_FULLY_CONNECTED operation takes a 4rd scalar operand, which is|;|+  // used to pass a TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status = LiteRtGetFullyConnectedFusedActivationOption(|;|+          op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  auto output_operand = OperandType::Create(op.Outputs()[0])|;|;+  std::vector<uint32_t> output_indices|;|;+|;|+  if (GET_RANK(op.Outputs()[0]) > 2) {|;|+    // if output_operand shape <B, K, N>, reshape to <B * K, N>|;|+    auto last_dim = output_operand->GetDimension().back()|;|;+    auto elements = output_operand->GetElementCount()|;|;+    std::vector<uint32_t> new_dimension = {elements / last_dim, last_dim}|;|;+    if (auto res = output_operand->Reshape(new_dimension); !res) {|;|+      return res.Error()|;|;+    }|;|+    auto intermediate_operand = operand_map.AddOperand(*output_operand)|;|;+    output_indices.push_back(*intermediate_operand)|;|;+  } else {|;|+    auto output_operand = operand_map.GetOperandIndex(op.Outputs()[0])|;|;+    output_indices.push_back(*output_operand)|;|;+    if (!output_operand) {|;|+      return output_operand.Error()|;|;+    }|;|+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model,|;|+                        /*type=*/NEURON_FULLY_CONNECTED, input_indices,|;|+                        output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to set NEURON_FULLY_CONNECTED operation"")|;|;+  }|;|+|;|+  if (GET_RANK(op.Outputs()[0]) > 2) {|;|+    // intermediate as reshape input|;|+    input_indices = {output_indices.back()}|;|;+    auto output_operand = operand_map.GetOperandIndex(op.Outputs()[0])|;|;+    if (!output_operand) {|;|+      return output_operand.Error()|;|;+    }|;|+|;|+    auto dimension = op.Outputs()[0].RankedTensorType()->Layout().Dimensions()|;|;+    std::vector<uint32_t> new_shape(dimension.begin(), dimension.end())|;|;+    std::vector<uint32_t> tensor_shape = {(uint32_t)new_shape.size()}|;|;+    auto new_shape_operand_index = operand_map.AddTensorInt32(|;|+        tensor_shape, new_shape.data(), new_shape.size() * sizeof(int32_t))|;|;+    if (!new_shape_operand_index) {|;|+      return new_shape_operand_index.Error()|;|;+    }|;|+    input_indices.push_back(*new_shape_operand_index)|;|;+    output_indices = {*output_operand}|;|;+    if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RESHAPE,|;|+                          input_indices, output_indices) != NEURON_NO_ERROR) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Failed to add Reshape after FC"")|;|;+    }|;|+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeFullyConnectedOp(|;|+    const NeuronAdapterApi& neuron_adapter_api, NeuronModel* model,|;|+    OperandMap& operand_map, const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.cc: @@ -0,0 +1,70 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+constexpr uint32_t kGeluApproximateTanh = 1|;|;+|;|+Expected<void> LegalizeGeluOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Gelu"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  auto approximate_operand = operand_map.AddScalarUInt32(kGeluApproximateTanh)|;|;+  if (!approximate_operand) {|;|+    return approximate_operand.Error()|;|;+  }|;|+|;|+  input_indices.push_back(*approximate_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_GELU_V2,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add GELU operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeGeluOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.cc: @@ -0,0 +1,75 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMeanOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Mean"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_Mean operation takes an additional scalar operand, which is|;|+  // used to pass a keepdims.|;|+  bool keepdims|;|;+  if (auto status = LiteRtGetMeanKeepDimsOption(op.Get(), &keepdims)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get beta"")|;|;+  }|;|+  LITERT_LOG(LITERT_INFO, ""keepdims: %d"", keepdims)|;|;+  auto keepdims_operand = operand_map.AddScalarInt32(keepdims)|;|;+  if (!keepdims_operand) {|;|+    return keepdims_operand.Error()|;|;+  }|;|+  input_indices.push_back(*keepdims_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_MEAN,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_MEAN operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMeanOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.cc: @@ -0,0 +1,76 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Mul"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_MUL operation takes a 3rd scalar operand, which is used to pass a|;|+  // TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status =|;|+          LiteRtGetMulFusedActivationOption(op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_MUL,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_MUL operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.cc: @@ -0,0 +1,104 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<NeuronTensorType> GetNeuronTensorType(const Tensor& t) {|;|+  auto ranked_tensor_type = t.RankedTensorType()|;|;+  if (!ranked_tensor_type) {|;|+    return ranked_tensor_type.Error()|;|;+  }|;|+|;|+  int32_t mtk_type|;|;+  switch (ranked_tensor_type->ElementType()) {|;|+    case ElementType::Float32:|;|+      mtk_type = NEURON_TENSOR_FLOAT32|;|;+      break|;|;+    case ElementType::Float16:|;|+      mtk_type = NEURON_TENSOR_FLOAT16|;|;+      break|;|;+    case ElementType::Int32:|;|+      mtk_type = NEURON_TENSOR_INT32|;|;+      break|;|;+    case ElementType::Int16:|;|+      if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+        mtk_type = NEURON_TENSOR_QUANT16_SYMM|;|;+      } else {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Int16 is not supported."")|;|;+      }|;|+      break|;|;+    case ElementType::Int8:|;|+      if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+        mtk_type = NEURON_TENSOR_QUANT8_SYMM|;|;+      } else if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+        mtk_type = NEURON_TENSOR_QUANT8_SYMM_PER_CHANNEL|;|;+      } else {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Int8 is not supported."")|;|;+      }|;|+      break|;|;+    default:|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   absl::StrFormat(""Unsupported element type: %d"",|;|+                                   ranked_tensor_type->ElementType()))|;|;+  }|;|+  return mtk_type|;|;+}|;|+|;|+Expected<uint32_t> GetNeuronDataSize(NeuronTensorType type) {|;|+  switch (type) {|;|+    case NEURON_FLOAT32:|;|+    case NEURON_TENSOR_FLOAT32:|;|+    case NEURON_INT32:|;|+    case NEURON_TENSOR_INT32:|;|+      return 4|;|;+    case NEURON_FLOAT16:|;|+    case NEURON_TENSOR_FLOAT16:|;|+    case NEURON_EXT_TENSOR_QUANT16_ASYMM_SIGNED:|;|+      return 2|;|;+    case NEURON_BOOL:|;|+    case NEURON_TENSOR_BOOL8:|;|+    case NEURON_TENSOR_QUANT8_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM_SIGNED:|;|+      return 1|;|;+    default:|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Get Data Size fail for Neuron Type"")|;|;+  }|;|+  return Error(kLiteRtStatusErrorRuntimeFailure, ""Unexpected neuron type"")|;|;+}|;|+|;|+Expected<bool> IsQuantizedType(NeuronTensorType type) {|;|+  switch (type) {|;|+    case NEURON_TENSOR_QUANT16_SYMM:|;|+    case NEURON_TENSOR_QUANT16_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM_SIGNED:|;|+      return true|;|;+  }|;|+  return false|;|;+}|;|+|;|+NeuronReturnCode ModelAddOperation(const NeuronAdapterApi& api,|;|+                                   NeuronModel* model, NeuronOperationType type,|;|+                                   std::vector<uint32_t> input,|;|+                                   std::vector<uint32_t> output) {|;|+  return api.api().model_add_operation(model, type, input.size(), input.data(),|;|+                                       output.size(), output.data())|;|;+}|;|;+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h: @@ -0,0 +1,43 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_|;|+|;|+#include <cstdint>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+using NeuronTensorType = int32_t|;|;+using NeuronReturnCode = int32_t|;|;+|;|+Expected<NeuronTensorType> GetNeuronTensorType(const Tensor& t)|;|;+|;|+Expected<uint32_t> GetNeuronDataSize(NeuronTensorType type)|;|;+|;|+Expected<bool> IsQuantizedType(NeuronTensorType type)|;|;+|;|+NeuronReturnCode ModelAddOperation(const NeuronAdapterApi& api,|;|+                                   NeuronModel* model, NeuronOperationType type,|;|+                                   std::vector<uint32_t> input,|;|+                                   std::vector<uint32_t> output)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.cc: @@ -17,77 +17,21 @@|;| #include <algorithm>|;| #include <cstdint>|;| #include <iterator>|;|+#include <numeric>|;|+#include <optional>|;|+#include <string>|;| #include <utility>|;| #include <vector>|;| |;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_element_type.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;| |;| namespace litert::mediatek {|;| |;|-namespace {|;|-|;|-class OperandType : public NeuronOperandType {|;|- public:|;|-  static Expected<OperandType> Create(const Tensor& t) {|;|-    auto ranked_tensor_type = t.RankedTensorType()|;|;-    if (!ranked_tensor_type) {|;|-      return ranked_tensor_type.Error()|;|;-    }|;|-|;|-    auto tensor_dimensions = ranked_tensor_type->Layout().Dimensions()|;|;-    std::vector<uint32_t> mtk_dimensions|;|;-    mtk_dimensions.reserve(tensor_dimensions.size())|;|;-    std::copy(tensor_dimensions.begin(), tensor_dimensions.end(),|;|-              std::back_inserter(mtk_dimensions))|;|;-|;|-    int32_t mtk_type|;|;-    switch (ranked_tensor_type->ElementType()) {|;|-      case ElementType::Float32:|;|-        mtk_type = NEURON_TENSOR_FLOAT32|;|;-        break|;|;-      case ElementType::Int32:|;|-        mtk_type = NEURON_TENSOR_INT32|;|;-        break|;|;-      default:|;|-        return Error(kLiteRtStatusErrorRuntimeFailure,|;|-                     ""Unsupported element type"")|;|;-    }|;|-|;|-    return OperandType(mtk_type, std::move(mtk_dimensions))|;|;-  }|;|-|;|-  OperandType(const OperandType&) = delete|;|;-|;|-  OperandType(OperandType&& other) : dimensions_(std::move(other.dimensions_)) {|;|-    // Copy all the scalar fields from other.|;|-    *static_cast<NeuronOperandType*>(this) =|;|-        *static_cast<NeuronOperandType*>(&other)|;|;-    // Reset the pointer fields by using own data.|;|-    dimensions = dimensions_.data()|;|;-  }|;|;-|;|-  OperandType& operator=(const OperandType&) = delete|;|;-  OperandType& operator=(OperandType&& other) = delete|;|;-|;|- private:|;|-  explicit OperandType(int32_t mtk_type, std::vector<uint32_t>&& mtk_dimensions)|;|-      : dimensions_(std::move(mtk_dimensions)) {|;|-    this->type = mtk_type|;|;-    this->dimensionCount = dimensions_.size()|;|;-    this->dimensions = dimensions_.data()|;|;-  }|;|;-|;|-  std::vector<uint32_t> dimensions_|;|;-}|;|;-|;|-}  // namespace|;|-|;|-// /////////////////////////////////////////////////////////////////////////////|;|-|;| Expected<uint32_t> OperandMap::Register(const NeuronOperandType& operand_type) {|;|   if (neuron_adapter_api_.api().model_add_operand(model_, &operand_type) !=|;|       NEURON_NO_ERROR) {|;|@@ -108,9 +52,19 @@ Expected<uint32_t> OperandMap::Register(const Tensor& t) {|;|   if (!operand_index) {|;|     return operand_index.Error()|;|;   }|;|+  LITERT_LOG(LITERT_INFO, ""\nOperandIndex: %d"", operand_index.Value())|;|;+  operand_type->Info()|;|; |;|   if (t.HasWeights()) {|;|     auto weights = t.Weights().Bytes()|;|;+    if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+      auto quant_param = operand_type->GetPerChannelQuantParams().Value()|;|;+      if (neuron_adapter_api_.api().model_set_symm_per_channel_quant_params(|;|+              model_, *operand_index, &quant_param) != NEURON_NO_ERROR) {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Failed to set param of per channel quant params"")|;|;+      }|;|+    }|;|     if (neuron_adapter_api_.api().model_set_operand_value(|;|             model_, *operand_index, weights.data(), weights.size()) !=|;|         NEURON_NO_ERROR) { || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h: @@ -17,16 +17,154 @@|;| |;| #include <cstdint>|;| #include <map>|;|+#include <numeric>|;| #include <vector>|;| |;| #include ""absl/container/flat_hash_map.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;| |;| namespace litert::mediatek {|;| |;|+class OperandType : public NeuronOperandType {|;|+ public:|;|+  static Expected<OperandType> Create(const Tensor& t) {|;|+    auto ranked_tensor_type = t.RankedTensorType()|;|;+    if (!ranked_tensor_type) {|;|+      return ranked_tensor_type.Error()|;|;+    }|;|+|;|+    auto tensor_dimensions = ranked_tensor_type->Layout().Dimensions()|;|;+    std::vector<uint32_t> mtk_dimensions|;|;+    mtk_dimensions.reserve(tensor_dimensions.size())|;|;+    std::copy(tensor_dimensions.begin(), tensor_dimensions.end(),|;|+              std::back_inserter(mtk_dimensions))|;|;+|;|+    // tensor type dimensions couldn't be zero.|;|+    if (mtk_dimensions.size() == 0) {|;|+      mtk_dimensions = {|;|+          1,|;|+      }|;|;+    }|;|+|;|+    // BlockWise Quantize is not supported now.|;|+    if (t.HasQuantization() && t.QTypeId() == kLiteRtQuantizationBlockWise) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Doesn't support BlockWise quantize now"")|;|;+    }|;|+|;|+    auto mtk_type = GetNeuronTensorType(t)|;|;+    if (!mtk_type) {|;|+      return mtk_type.Error()|;|;+    }|;|+|;|+    if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+      auto quant_info = t.PerTensorQuantization()|;|;+      LITERT_LOG(LITERT_INFO, ""zeroPoint: %d, scale: %f"", quant_info.zero_point,|;|+                 quant_info.scale)|;|;+      return OperandType(*mtk_type, std::move(mtk_dimensions), quant_info.scale,|;|+                         quant_info.zero_point, std::nullopt)|;|;+    } else if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+      auto quant_info = t.PerChannelQuantization()|;|;+      NeuronSymmPerChannelQuantParams params|;|;+      params.scaleCount = quant_info.num_channels|;|;+      params.scales = quant_info.scales|;|;+      params.channelDim = quant_info.quantized_dimension|;|;+      LITERT_LOG(LITERT_INFO, ""quantized_dimension: %d"",|;|+                 quant_info.quantized_dimension)|;|;+      LITERT_LOG(LITERT_INFO, ""params.channelDim: %d"", params.channelDim)|;|;+      return OperandType(*mtk_type, std::move(mtk_dimensions), 0, 0, params)|;|;+    } else {|;|+      return OperandType(*mtk_type, std::move(mtk_dimensions), /*scale*/ 0,|;|+                         /*zero_point*/ 0, std::nullopt)|;|;+    }|;|+  }|;|+|;|+  void Info() {|;|+    std::string vector = ""[""|;|;+    for (int i = 0; i < dimensionCount; i++) {|;|+      vector += std::to_string(dimensions_[i])|;|;+      vector += "",""|;|;+    }|;|+    vector += ""]""|;|;+    LITERT_LOG(LITERT_INFO,|;|+               ""\n[Type] %d""|;|+               ""\n[zeroPoint]%d""|;|+               ""\n[scale]%f""|;|+               ""\n[dimensionCount]%u""|;|+               ""\n[dimensions]%s\n"",|;|+               type, zeroPoint, scale, dimensionCount, vector.c_str())|;|;+  }|;|+|;|+  OperandType(const OperandType&) = delete|;|;+|;|+  OperandType(OperandType&& other)|;|+      : dimensions_(std::move(other.dimensions_)),|;|+        neuron_per_channel_params_(other.neuron_per_channel_params_) {|;|+    // Copy all the scalar fields from other.|;|+    *static_cast<NeuronOperandType*>(this) =|;|+        *static_cast<NeuronOperandType*>(&other)|;|;+    // Reset the pointer fields by using own data.|;|+    dimensions = dimensions_.data()|;|;+  }|;|;+|;|+  Expected<void> Reshape(std::vector<uint32_t>& shape) {|;|+    auto elements = GetElementCount()|;|;+    if (elements != std::accumulate(shape.begin(), shape.end(), 1,|;|+                                    std::multiplies<uint32_t>())) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""the elements is not the same"")|;|;+    }|;|+    this->dimensions_ = shape|;|;+    this->dimensionCount = this->dimensions_.size()|;|;+    this->dimensions = this->dimensions_.data()|;|;+    return {}|;|;+  }|;|+|;|+  Expected<NeuronSymmPerChannelQuantParams> GetPerChannelQuantParams() {|;|+    if (!neuron_per_channel_params_.has_value()) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure, ""No quant param is set"")|;|;+    }|;|+    return neuron_per_channel_params_.value()|;|;+  }|;|+|;|+  int32_t GetNeuronType() const { return this->type; }|;|+|;|+  std::vector<uint32_t> GetDimension() { return this->dimensions_; }|;|+|;|+  uint32_t GetElementCount() {|;|+    return std::accumulate(dimensions_.begin(), dimensions_.end(), 1,|;|+                           std::multiplies<uint32_t>())|;|;+  }|;|+|;|+  uint32_t GetRank() { return this->dimensions_.size(); }|;|+|;|+  OperandType& operator=(const OperandType&) = delete|;|;+  OperandType& operator=(OperandType&& other) = delete|;|;+|;|+ private:|;|+  explicit OperandType(int32_t mtk_type, std::vector<uint32_t>&& mtk_dimensions,|;|+                       float scale, int32_t zero_point,|;|+                       std::optional<NeuronSymmPerChannelQuantParams> pararms)|;|+      : dimensions_(std::move(mtk_dimensions)),|;|+        neuron_per_channel_params_(pararms) {|;|+    this->scale = scale|;|;+    this->zeroPoint = zero_point|;|;+    this->type = mtk_type|;|;+    this->dimensionCount = dimensions_.size()|;|;+    this->dimensions = dimensions_.data()|;|;+  }|;|+|;|+  std::vector<uint32_t> dimensions_|;|;+|;|+  std::optional<NeuronSymmPerChannelQuantParams> neuron_per_channel_params_ =|;|+      std::nullopt|;|;+}|;|;+|;| // This class takes care of registering Tensors and scalars with a given|;| // NeuronModel and returing their ""operand index"", which is how the MTK SDK|;| // handles them.|;|@@ -42,10 +180,29 @@ class OperandMap {|;|   Expected<uint32_t> AddScalarInt32(int32_t value) {|;|     return AddScalar(NEURON_INT32, value)|;|;   }|;|+  Expected<uint32_t> AddScalarUInt32(uint32_t value) {|;|+    return AddScalar(NEURON_UINT32, value)|;|;+  }|;|   Expected<uint32_t> AddScalarFloat32(float value) {|;|     return AddScalar(NEURON_FLOAT32, value)|;|;   }|;| |;|+  // Add a tensor operand to the model|;|+  Expected<uint32_t> AddTensorInt32(std::vector<uint32_t>& shape,|;|+                                    const void* data, const size_t data_size) {|;|+    return AddTensor(NEURON_TENSOR_INT32, shape, data, data_size)|;|;+  }|;|+|;|+  // Add a tensor operand to the model|;|+  Expected<uint32_t> AddTensorByType(int mtk_type, std::vector<uint32_t>& shape,|;|+                                     const void* data, const size_t data_size) {|;|+    return AddTensor(mtk_type, shape, data, data_size)|;|;+  }|;|+|;|+  Expected<uint32_t> AddOperand(const NeuronOperandType& operand) {|;|+    return Register(operand)|;|;+  }|;|+|;|   // Find the operand index for a given tensor and, if not done already, add the|;|   // tensor as an operand in the model.|;|   Expected<uint32_t> GetOperandIndex(const Tensor& t) {|;|@@ -81,6 +238,26 @@ class OperandMap {|;|     return operand_index|;|;   }|;| |;|+  Expected<uint32_t> AddTensor(int32_t mtk_type,|;|+                               const std::vector<uint32_t>& shape,|;|+                               const void* data, const size_t data_size) {|;|+    const NeuronOperandType scalar_type = {|;|+        .type = mtk_type,|;|+        .dimensionCount = (uint32_t)shape.size(),|;|+        .dimensions = shape.data(),|;|+    }|;|;+    auto operand_index = Register(scalar_type)|;|;+    if (!operand_index) {|;|+      return operand_index.Error()|;|;+    }|;|+    if (neuron_adapter_api_.api().model_set_operand_value(|;|+            model_, *operand_index, data, data_size) != NEURON_NO_ERROR) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Failed to set value of tensor operand"")|;|;+    }|;|+    return operand_index|;|;+  }|;|+|;|   const NeuronAdapterApi& neuron_adapter_api_|;|;   NeuronModel* model_|;|;   int next_operand_index_ = 0; || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeQuantizeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                  NeuronModel* model, OperandMap& operand_map,|;|+                                  const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Quantize"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_QUANTIZE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_QUANTIZE operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeQuantizeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                  NeuronModel* model, OperandMap& operand_map,|;|+                                  const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeReshapeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Reshape"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RESHAPE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_RESHAPE operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeReshapeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeRsqrtOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                               NeuronModel* model, OperandMap& operand_map,|;|+                               const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Rsqrt"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RSQRT,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_RSQRT operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeRsqrtOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                               NeuronModel* model, OperandMap& operand_map,|;|+                               const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.cc: @@ -0,0 +1,74 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSoftmaxOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Softmax"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_Softmax operation takes an additional scalar operand, which is|;|+  // used to pass a Beta value.|;|+  float beta|;|;+  if (auto status = LiteRtGetSoftmaxBetaOption(op.Get(), &beta)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get beta"")|;|;+  }|;|+  auto beta_operand = operand_map.AddScalarFloat32(beta)|;|;+  if (!beta_operand) {|;|+    return beta_operand.Error()|;|;+  }|;|+  input_indices.push_back(*beta_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_SOFTMAX,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_SOFTMAX operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSoftmaxOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.cc: @@ -0,0 +1,76 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSubOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Sub"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_SUB operation takes a 3rd scalar operand, which is used to pass a|;|+  // TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status =|;|+          LiteRtGetSubFusedActivationOption(op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_SUB,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add value of NEURON_SUB fused activation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSubOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeTransposeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                   NeuronModel* model, OperandMap& operand_map,|;|+                                   const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Transpose"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_TRANSPOSE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add reshape operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeTransposeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                   NeuronModel* model, OperandMap& operand_map,|;|+                                   const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/BUILD: @@ -69,6 +69,7 @@ litert_dynamic_lib(|;|         ""//tensorflow/lite/experimental/litert/core/util:tensor_type_util"",|;|         ""//tensorflow/lite/experimental/litert/vendors/c:litert_dispatch_c_api"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/dispatch_api.cc: @@ -33,6 +33,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_device_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_invocation_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| namespace {|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_invocation_context.cc: @@ -30,6 +30,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/c/litert_dispatch.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_device_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| using litert::Error|;|; using litert::Expected|;|;@@ -231,12 +232,31 @@ LiteRtDispatchInvocationContextT::Create(|;|     LiteRtDispatchExecutableType exec_type,|;|     const LiteRtMemBuffer* exec_bytecode_buffer, const char* function_name,|;|     int num_inputs, int num_outputs) {|;|-  auto exec_bytecode_ptr =|;|+  neuron::SchemaResolver resolver|;|;+|;|+  const void* exec_bytecode_ptr =|;|       static_cast<const uint8_t*>(exec_bytecode_buffer->base_addr) +|;|       exec_bytecode_buffer->offset|;|;-  auto model_and_compilation = LoadModelAndCompilation(|;|-      neuron_adapter_api, exec_bytecode_ptr, exec_bytecode_buffer->size,|;|-      num_inputs, num_outputs)|;|;+  auto exec_bytecode_size = exec_bytecode_buffer->size|;|;+  auto res = resolver.Initialize((const uint8_t*)exec_bytecode_ptr,|;|+                                 exec_bytecode_size)|;|;+  if (res.HasValue() && res.Value()) {|;|+    std::string func = function_name != nullptr ? function_name : """"|;|;+    auto graph = resolver.GetCompiledGraph(func)|;|;+    if (!graph.has_value()) {|;|+      return litert::Error(kLiteRtStatusErrorRuntimeFailure,|;|+                           ""Couldn't find the subgraph"")|;|;+    }|;|+    auto compile_graph = graph.value().GetCompiledNetwork()|;|;+    if (!compile_graph) {|;|+      return compile_graph.Error()|;|;+    }|;|+    std::tie(exec_bytecode_ptr, exec_bytecode_size) = compile_graph.Value()|;|;+  }|;|+|;|+  auto model_and_compilation =|;|+      LoadModelAndCompilation(neuron_adapter_api, exec_bytecode_ptr,|;|+                              exec_bytecode_size, num_inputs, num_outputs)|;|;   if (!model_and_compilation) {|;|     return model_and_compilation.Error()|;|;   } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.cc: @@ -131,6 +131,8 @@ litert::Expected<void> NeuronAdapterApi::LoadSymbols(|;|             api_->model_restore_from_compiled_network)|;|;   LOAD_SYMB(NeuronModel_setName, api_->model_set_name)|;|;   LOAD_SYMB(NeuronModel_setOperandValue, api_->model_set_operand_value)|;|;+  LOAD_SYMB(NeuronModel_setOperandSymmPerChannelQuantParams,|;|+            api_->model_set_symm_per_channel_quant_params)|;|;   LOAD_SYMB(Neuron_getVersion, api_->get_version)|;|; |;|   LITERT_LOG(LITERT_INFO, ""NeuronAdapter symbols loaded""); || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h: @@ -141,6 +141,8 @@ struct NeuronAdapterApi::Api {|;|       model_restore_from_compiled_network = nullptr|;|;   decltype(&NeuronModel_setName) model_set_name = nullptr|;|;   decltype(&NeuronModel_setOperandValue) model_set_operand_value = nullptr|;|;+  decltype(&NeuronModel_setOperandSymmPerChannelQuantParams)|;|+      model_set_symm_per_channel_quant_params = nullptr|;|;   decltype(&Neuron_getVersion) get_version = nullptr|;|; }|;|;  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/BUILD: @@ -0,0 +1,43 @@|;|+# Copyright (c) 2025 MediaTek Inc.|;|+#|;|+# Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+# you may not use this file except in compliance with the License.|;|+# You may obtain a copy of the License at|;|+#|;|+#      http://www.apache.org/licenses/LICENSE-2.0|;|+#|;|+# Unless required by applicable law or agreed to in writing, software|;|+# distributed under the License is distributed on an ""AS IS"" BASIS,|;|+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+# See the License for the specific language governing permissions and|;|+# limitations under the License.|;|+|;|+load(""@flatbuffers//:build_defs.bzl"", ""flatbuffer_cc_library"")|;|+load(""//tensorflow:tensorflow.default.bzl"", ""get_compatible_with_portable"")|;|+|;|+package(|;|+    # copybara:uncomment default_applicable_licenses = [""//tensorflow:license""],|;|+    default_visibility = [""//tensorflow/lite/experimental/litert:__subpackages__""],|;|+)|;|+|;|+flatbuffer_cc_library(|;|+    name = ""neuron_litert_schema"",|;|+    srcs = [""neuron_schema.fbs""],|;|+    compatible_with = get_compatible_with_portable(),|;|+)|;|+|;|+cc_library(|;|+    name = ""mediatek_litert_schema"",|;|+    hdrs = [|;|+        ""schema_resolver.h"",|;|+    ],|;|+    visibility = [""//visibility:public""],|;|+    deps = [|;|+        ""neuron_litert_schema"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""@com_google_absl//absl/strings:str_format"",|;|+        ""@flatbuffers//:runtime_cc"",|;|+    ],|;|+) || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema.fbs: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+namespace NeuronSchema|;|;+|;|+enum CompiledType : byte {|;|+  DLA = 0,|;|+  DLB,|;|+  AdapterCache|;|+}|;|+|;|+table Index {|;|+  value: int = -1|;|;+}|;|+|;|+table Identifier {|;|+  value: string|;|;+}|;|+|;|+// BufferIndicate to specify how to point to a buffer|;|+union BufferIndicate {|;|+  Index,|;|+  Identifier,|;|+}|;|+|;|+table Subgraph {|;|+  entry_point: string;       // Entry point of the subgraph|;|+  type: CompiledType;        // Type of the compiled subgraph|;|+  compiled_index: BufferIndicate;       // index to the buffer at Graphs.data|;|+  weight_share_index: [BufferIndicate]; // index to the buffer at Graphs.data[index]. if empty, no weight share.|;|+}|;|+|;|+table Graphs {|;|+  version: short;           // Version of the graph schema|;|+  subgraphs: [Subgraph];    // List of subgraphs|;|+  data: [Buffer]|;|;+  external: ExternalBuffer|;|;+}|;|+|;|+table Buffer {|;|+  identifier: string|;|;+  data: [byte];           // Binary data|;|+}|;|+|;|+// List of external buffer that doesn't store in this schema|;|+table ExternalBuffer {|;|+  identifiers: [string]|;|;+}|;|+|;|+root_type Graphs|;|;\ No newline at end of file || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h: @@ -0,0 +1,184 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_|;|+|;|+#include <cassert>|;|+#include <cstddef>|;|+#include <cstdint>|;|+#include <optional>|;|+#include <string>|;|+#include <unordered_map>|;|+#include <utility>|;|+#include <vector>|;|+|;|+#include ""absl/strings/str_format.h""|;|+#include ""flatbuffers/buffer.h""  // from @flatbuffers|;|+#include ""flatbuffers/flatbuffer_builder.h""  // from @flatbuffers|;|+#include ""flatbuffers/verifier.h""  // from @flatbuffers|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema_generated.h""|;|+|;|+namespace neuron {|;|+|;|+inline bool IsNeuronSchema(const uint8_t* buffer, size_t size) {|;|+  if (buffer == nullptr) {|;|+    return false|;|;+  }|;|+  flatbuffers::Verifier verifier(buffer, size)|;|;+  return NeuronSchema::VerifyGraphsBuffer(verifier)|;|;+}|;|+|;|+class CompiledGraph {|;|+ public:|;|+  CompiledGraph(const NeuronSchema::Graphs& g, const NeuronSchema::Subgraph& s)|;|+      : graph_(g), subgraph_(s) {}|;|;+|;|+  litert::Expected<std::pair<const void*, size_t>> GetCompiledNetwork() {|;|+    // Neuron Adapter doesn't support DLB for now.|;|+    assert(GetCompiledType() != NeuronSchema::CompiledType_DLB)|;|;+    // TODO: Support the external buffer.|;|+    assert(subgraph_.compiled_index_type() ==|;|+           NeuronSchema::BufferIndicate_Index)|;|;+    auto index = subgraph_.compiled_index_as_Index()|;|;+    return GetBuffer(index->value())|;|;+  }|;|+|;|+  NeuronSchema::CompiledType GetCompiledType() { return subgraph_.type(); }|;|+|;|+  litert::Expected<std::pair<const void*, size_t>> GetBuffer(int32_t i) {|;|+    auto array_size = graph_.data()->size()|;|;+    if (i >= array_size) {|;|+      return litert::Error(|;|+          kLiteRtStatusErrorIndexOOB,|;|+          absl::StrFormat(""Buffer array index %d is OOB, the array size : %d"",|;|+                          i, array_size))|;|;+    }|;|+    auto buffer = graph_.data()->Get(i)|;|;+    return std::pair<const void*, size_t>(buffer->data()->data(),|;|+                                          buffer->data()->size())|;|;+  }|;|+|;|+ private:|;|+  const NeuronSchema::Graphs& graph_|;|;+  const NeuronSchema::Subgraph& subgraph_|;|;+}|;|;+|;|+class SchemaResolver {|;|+ public:|;|+  SchemaResolver() = default|;|;+|;|+  litert::Expected<bool> Initialize(const uint8_t* buffer, size_t size) {|;|+    if (!IsNeuronSchema(buffer, size)) {|;|+      return litert::Error(kLiteRtStatusErrorInvalidFlatbuffer,|;|+                           ""buffer is not a valid NeuronSchema"")|;|;+    }|;|+    graph_ = NeuronSchema::GetGraphs(buffer)|;|;+|;|+    auto subgraphs = graph_->subgraphs()|;|;+    for (const auto& subgraph : *subgraphs) {|;|+      auto graph_name = subgraph->entry_point()->str()|;|;+      if (entry_points_.count(graph_name)) {|;|+        // shouldn't have the same name between graphs.|;|+        return false|;|;+      } else {|;|+        LITERT_LOG(LITERT_INFO, ""Found graph: %s"", graph_name.c_str())|;|;+        entry_points_[graph_name] = subgraph|;|;+      }|;|+    }|;|+    LITERT_LOG(LITERT_INFO, ""There are %u subgraphs in the bytecode"",|;|+               entry_points_.size())|;|;+    return true|;|;+  }|;|+|;|+  std::optional<CompiledGraph> GetCompiledGraph(std::string& name) {|;|+    if (entry_points_.count(name) == 0) {|;|+      return std::nullopt|;|;+    }|;|+    return CompiledGraph(*graph_, *entry_points_[name])|;|;+  }|;|;+|;|+ private:|;|+  const NeuronSchema::Graphs* graph_ = nullptr|;|;+|;|+  std::unordered_map<std::string, NeuronSchema::Subgraph const*> entry_points_|;|;+}|;|;+|;|+class BytecodeBuilder {|;|+ public:|;|+  BytecodeBuilder() = default|;|;+|;|+  int32_t AddCompiledNetwork(std::string& entry_point,|;|+                             NeuronSchema::CompiledType type,|;|+                             int32_t buffer_index) {|;|+    auto index = NeuronSchema::CreateIndex(fb_, buffer_index)|;|;+    auto subgraph = NeuronSchema::CreateSubgraph(|;|+        fb_, fb_.CreateString(entry_point), type,|;|+        NeuronSchema::BufferIndicate_Index, index.Union())|;|;+|;|+    subgraphs_.push_back(subgraph)|;|;+    return subgraphs_count_++|;|;+  }|;|;+|;|+  int32_t AddBuffer(std::string& identifier, const std::vector<int8_t>& data) {|;|+    auto buffer =|;|+        NeuronSchema::CreateBufferDirect(fb_, identifier.c_str(), &data)|;|;+    graph_data_.push_back(buffer)|;|;+    return buffer_count_++|;|;+  }|;|+|;|+  int32_t AddBuffer(std::string& identifier, const int8_t* data,|;|+                    size_t length) {|;|+    auto data_offset = fb_.CreateVector(data, length)|;|;+    auto identifier_offset = fb_.CreateString(identifier)|;|;+    auto buffer =|;|+        NeuronSchema::CreateBuffer(fb_, identifier_offset, data_offset)|;|;+    graph_data_.push_back(buffer)|;|;+    return buffer_count_++|;|;+  }|;|+|;|+  bool Finish() {|;|+    auto graphs =|;|+        NeuronSchema::CreateGraphsDirect(fb_, 1, &subgraphs_, &graph_data_)|;|;+    fb_.Finish(graphs)|;|;+    raw_buffer_ = {fb_.GetBufferPointer(), fb_.GetSize()}|;|;+    return true|;|;+  }|;|+|;|+  std::pair<uint8_t*, size_t> GetBytecode() {|;|+    if (!raw_buffer_.has_value()) {|;|+      return {nullptr, 0}|;|;+    }|;|+    return raw_buffer_.value()|;|;+  }|;|+|;|+ private:|;|+  ::flatbuffers::FlatBufferBuilder fb_|;|;+|;|+  std::optional<std::pair<uint8_t*, size_t>> raw_buffer_|;|;+|;|+  std::vector<::flatbuffers::Offset<NeuronSchema::Subgraph>> subgraphs_|;|;+|;|+  std::vector<::flatbuffers::Offset<NeuronSchema::Buffer>> graph_data_|;|;+|;|+  int32_t subgraphs_count_ = 0|;|;+  int32_t buffer_count_ = 0|;|;+}|;|;+|;|+};  // namespace neuron|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_","Supports more legalizations and multi-partition

1. more legalizations:
  a. Batch_MatMul
  b. Mul
  c. Fully_Connected

2. multi-partition supports:
  introduce utils for supporting multi-partition || Merge branch 'tensorflow:master' into upstream_0225 || Support more legalizations for MTK platform

- Added new legalizatios for more operations.
- Introduced common utility functions for neuron. || Fix syntax error of the BUILD || Merge pull request #88103 from neuropilot-captain:upstream_0225

PiperOrigin-RevId: 739261215"
tensorflow/tensorflow,neuropilot-captain,88103,Supports more legalizations and multi-partition,"1. more legalizations 
   a. Batch_MatMul
   b. Mul
   c. Fully_Connected

3. multi-partition supports 
    introduce utils for supporting multi-partition","Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/88103/checks?check_run_id=37825132850) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request. || Hi @neuropilot-captain , Can you please sign and resolve the conflicts? Thank you!",closed,2025-02-26T02:15:34+00:00,2025-03-21T19:25:36+00:00,neuropilot-captain,"comp:lite, size:L",1,"PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/BUILD: @@ -28,7 +28,7 @@ litert_cc_lib_with_mtk(|;|         ""neuron_adapter_api.h"",|;|     ],|;|     tags = [|;|-        # Don't build/test in OS until qnn is available.|;|+        # Don't build/test in OS until neuron is available.|;|         ""nobuilder"",|;|         ""notap"",|;|     ], || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/BUILD: @@ -45,6 +45,9 @@ litert_dynamic_lib(|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:common_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:neuron_litert_schema"",|;|         ""@com_google_absl//absl/strings:str_format"",|;|         ""@com_google_absl//absl/strings:string_view"",|;|     ],|;|@@ -60,20 +63,27 @@ cc_library(|;|         ""notap"",|;|     ],|;|     deps = [|;|-        ""@com_google_absl//absl/strings:string_view"",|;|         # copybara:uncomment ""//third_party/neuro_pilot:latest_host_headers"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|-        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_op_code"",|;|-        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|-        ""//tensorflow/lite/experimental/litert/cc:litert_macros"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|-        ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|-        ""//tensorflow/lite/experimental/litert/core/model"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:add_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:batch_matmul_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:common_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:concat_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:fully_connected_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:gelu_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:mean_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:mul_op_legalization"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:reshape_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:rsqrt_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:softmax_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:sub_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations:transpose_op_legalization"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;| |;|@@ -99,6 +109,7 @@ cc_library(|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model_predicates"",|;|         ""//tensorflow/lite/experimental/litert/core/model"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/compiler_plugin.cc: @@ -34,7 +34,10 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/c/litert_compiler_plugin.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/compile_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/create_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema_generated.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| //|;| // Configurations|;|@@ -68,6 +71,20 @@ constexpr std::pair<const char*, const char*> kPluginSocModels[] = {|;| |;| constexpr LiteRtOpCode kSupportedOps[] = {|;|     kLiteRtOpCodeTflAdd,|;|+    kLiteRtOpCodeTflMul,|;|+    kLiteRtOpCodeTflBatchMatmul,|;|+    kLiteRtOpCodeTflFullyConnected,|;|+    kLiteRtOpCodeTflReshape,|;|+    kLiteRtOpCodeTflTranspose,|;|+    kLiteRtOpCodeTflRsqrt,|;|+    kLiteRtOpCodeTflConcatenation,|;|+    kLiteRtOpCodeTflQuantize,|;|+    kLiteRtOpCodeTflSlice,|;|+    kLiteRtOpCodeTflSub,|;|+    kLiteRtOpCodeTflTanh,|;|+    kLiteRtOpCodeTflSoftmax,|;|+    kLiteRtOpCodeTflMean,|;|+    kLiteRtOpCodeTflGelu,|;| }|;|; // clang-format on|;| |;|@@ -140,29 +157,28 @@ LiteRtStatus LiteRtGetCompilerPluginSupportedSocModel(|;| // TODO: Revisit this struct after we extend the compiler plugin API to return|;| // results with more than one single bytecode.|;| struct LiteRtCompiledResultT {|;|-  using Bytecode = std::vector<uint8_t>|;|;-  std::vector<Bytecode> bytecodes|;|;   std::vector<std::string> graph_names|;|;+  neuron::BytecodeBuilder bytebuilder|;|; }|;|; |;| LiteRtStatus LiteRtCompiledResultNumByteCodeModules(|;|     LiteRtCompiledResult compiled_result, LiteRtParamIndex* num_byte_code) {|;|   if (!compiled_result || !num_byte_code) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *num_byte_code = compiled_result->bytecodes.size()|;|;+  *num_byte_code = compiled_result->graph_names.size()|;|;   return kLiteRtStatusOk|;|; }|;| |;| LiteRtStatus LiteRtGetCompiledResultByteCode(|;|     LiteRtCompiledResult compiled_result, LiteRtParamIndex byte_code_idx,|;|     const void** byte_code, size_t* byte_code_size) {|;|   if (!compiled_result || !byte_code || !byte_code_size |||;|-      (byte_code_idx >= compiled_result->bytecodes.size())) {|;|+      (byte_code_idx >= compiled_result->graph_names.size())) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *byte_code = compiled_result->bytecodes[byte_code_idx].data()|;|;-  *byte_code_size = compiled_result->bytecodes[byte_code_idx].size()|;|;+  *byte_code = compiled_result->bytebuilder.GetBytecode().first|;|;+  *byte_code_size = compiled_result->bytebuilder.GetBytecode().second|;|;   return kLiteRtStatusOk|;|; }|;| |;|@@ -190,7 +206,7 @@ LiteRtStatus LiteRtGetNumCompiledResultCalls(|;|   if (!compiled_result || !num_calls) {|;|     return kLiteRtStatusErrorInvalidArgument|;|;   }|;|-  *num_calls = compiled_result->bytecodes.size()|;|;+  *num_calls = compiled_result->graph_names.size()|;|;   return kLiteRtStatusOk|;|; }|;| |;|@@ -230,7 +246,8 @@ bool IsOpSupported(const litert::Op& op) {|;|   // NOTE: Currently we are demoing by just mapping simple f32 mul ops.  Use a|;|   // very loose guard for now -- only checking if op code is supported.|;|   for (auto supported_op : kSupportedOps) {|;|-    if (op.Code() == supported_op) {|;|+    if (op.Code() == supported_op &&|;|+        litert::mediatek::VerifyCommonOp(op, op.Code())) {|;|       return true|;|;     }|;|   }|;|@@ -326,11 +343,16 @@ LiteRtStatus LiteRtCompilerPluginCompile(|;|       LITERT_LOG(LITERT_INFO, ""%s"", bytecode.Error().Message().c_str())|;|;       return bytecode.Error().Status()|;|;     }|;|-|;|-    result->bytecodes.emplace_back(*bytecode)|;|;+    auto bufferIdx = result->bytebuilder.AddBuffer(|;|+        graph_name, (int8_t*)bytecode->data(), bytecode->size())|;|;+    result->bytebuilder.AddCompiledNetwork(|;|+        graph_name, NeuronSchema::CompiledType_AdapterCache, bufferIdx)|;|;     result->graph_names.emplace_back(graph_name)|;|;   }|;| |;|+  if (!result->bytebuilder.Finish()) {|;|+    return kLiteRtStatusErrorCompilation|;|;+  }|;|   *compiled_result = result.release()|;|;   return kLiteRtStatusOk|;|; } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/create_model.cc: @@ -24,8 +24,21 @@|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/add_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| namespace litert::mediatek {|;| |;|@@ -76,7 +89,62 @@ Expected<NeuronModelPtr> CreateModel(const NeuronAdapterApi& neuron_adapter_api,|;|         status =|;|             LegalizeAddOp(neuron_adapter_api, model->get(), operand_map, op)|;|;         break|;|;-|;|+      case kLiteRtOpCodeTflMul:|;|+        status =|;|+            LegalizeMulOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflBatchMatmul:|;|+        status = LegalizeBatchMatMulOp(neuron_adapter_api, model->get(),|;|+                                       operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflFullyConnected:|;|+        status = LegalizeFullyConnectedOp(neuron_adapter_api, model->get(),|;|+                                          operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflReshape:|;|+        status = LegalizeReshapeOp(neuron_adapter_api, model->get(),|;|+                                   operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflTranspose:|;|+        status = LegalizeTransposeOp(neuron_adapter_api, model->get(),|;|+                                     operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflRsqrt:|;|+        status =|;|+            LegalizeRsqrtOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflConcatenation:|;|+        status =|;|+            LegalizeConcatOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflQuantize:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_QUANTIZE)|;|;+        break|;|;+      case kLiteRtOpCodeTflSlice:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_SLICE)|;|;+        break|;|;+      case kLiteRtOpCodeTflTanh:|;|+        status = LegalizeCommonOp(neuron_adapter_api, model->get(), operand_map,|;|+                                  op, NEURON_TANH)|;|;+        break|;|;+      case kLiteRtOpCodeTflSub:|;|+        status =|;|+            LegalizeSubOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflSoftmax:|;|+        status = LegalizeSoftmaxOp(neuron_adapter_api, model->get(),|;|+                                   operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflMean:|;|+        status =|;|+            LegalizeMeanOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;+      case kLiteRtOpCodeTflGelu:|;|+        status =|;|+            LegalizeGeluOp(neuron_adapter_api, model->get(), operand_map, op)|;|;+        break|;|;       default:|;|         return Error(kLiteRtStatusErrorRuntimeFailure, ""Unsupported op"")|;|;     } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/BUILD: @@ -27,7 +27,9 @@ cc_library(|;|         ""notap"",|;|     ],|;|     deps = [|;|+        ""neuron_utils"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_element_type"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|@@ -36,6 +38,25 @@ cc_library(|;|     ],|;| )|;| |;|+cc_library(|;|+    name = ""neuron_utils"",|;|+    srcs = [""neuron_utils.cc""],|;|+    hdrs = [""neuron_utils.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;| cc_library(|;|     name = ""add_op_legalization"",|;|     srcs = [""add_op_legalization.cc""],|;|@@ -48,6 +69,267 @@ cc_library(|;|     deps = [|;|         ""operand_map"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""mul_op_legalization"",|;|+    srcs = [""mul_op_legalization.cc""],|;|+    hdrs = [""mul_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""batch_matmul_op_legalization"",|;|+    srcs = [""batch_matmul_op_legalization.cc""],|;|+    hdrs = [""batch_matmul_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""fully_connected_op_legalization"",|;|+    srcs = [""fully_connected_op_legalization.cc""],|;|+    hdrs = [""fully_connected_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""reshape_op_legalization"",|;|+    srcs = [""reshape_op_legalization.cc""],|;|+    hdrs = [""reshape_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""transpose_op_legalization"",|;|+    srcs = [""transpose_op_legalization.cc""],|;|+    hdrs = [""transpose_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""rsqrt_op_legalization"",|;|+    srcs = [""rsqrt_op_legalization.cc""],|;|+    hdrs = [""rsqrt_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""concat_op_legalization"",|;|+    srcs = [""concat_op_legalization.cc""],|;|+    hdrs = [""concat_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""quantize_op_legalization"",|;|+    srcs = [""quantize_op_legalization.cc""],|;|+    hdrs = [""quantize_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""common_op_legalization"",|;|+    srcs = [""common_op_legalization.cc""],|;|+    hdrs = [""common_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""sub_op_legalization"",|;|+    srcs = [""sub_op_legalization.cc""],|;|+    hdrs = [""sub_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""softmax_op_legalization"",|;|+    srcs = [""softmax_op_legalization.cc""],|;|+    hdrs = [""softmax_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""mean_op_legalization"",|;|+    srcs = [""mean_op_legalization.cc""],|;|+    hdrs = [""mean_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_model"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+    ],|;|+)|;|+|;|+cc_library(|;|+    name = ""gelu_op_legalization"",|;|+    srcs = [""gelu_op_legalization.cc""],|;|+    hdrs = [""gelu_op_legalization.h""],|;|+    tags = [|;|+        # Don't build/test in OS until MediaTek SDK is available.|;|+        ""nobuilder"",|;|+        ""notap"",|;|+    ],|;|+    deps = [|;|+        ""operand_map"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|         ""//tensorflow/lite/experimental/litert/c:litert_options"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|         ""//tensorflow/lite/experimental/litert/cc:litert_model"", || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/add_op_legalization.cc: @@ -18,6 +18,7 @@|;| #include <vector>|;| |;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|@@ -29,6 +30,7 @@ namespace litert::mediatek {|;| Expected<void> LegalizeAddOp(const NeuronAdapterApi& neuron_adapter_api,|;|                              NeuronModel* model, OperandMap& operand_map,|;|                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Add"")|;|;   std::vector<uint32_t> input_indices|;|;   for (auto& input : op.Inputs()) {|;|     auto id = operand_map.GetOperandIndex(input)|;|;@@ -62,12 +64,10 @@ Expected<void> LegalizeAddOp(const NeuronAdapterApi& neuron_adapter_api,|;|     output_indices.push_back(*id)|;|;   }|;| |;|-  if (neuron_adapter_api.api().model_add_operation(|;|-          model, /*type=*/NEURON_ADD, input_indices.size(),|;|-          input_indices.data(), output_indices.size(),|;|-          output_indices.data()) != NEURON_NO_ERROR) {|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_ADD,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|     return Error(kLiteRtStatusErrorRuntimeFailure,|;|-                 ""Failed to set value of NEURON_ADD fused activation"")|;|;+                 ""Failed to add NEURON_ADD op"")|;|;   }|;| |;|   return {}; || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.cc: @@ -0,0 +1,89 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeBatchMatMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                     NeuronModel* model,|;|+                                     OperandMap& operand_map,|;|+                                     const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize BatchMatMul"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_BATCH_MATMUL operation takes 2 scalar operand, which is used to|;|+  // pass a adjX, adjY value.|;|+  bool tfl_matmul_param_adj_x = 0, tfl_matmul_param_adj_y = 0|;|;+  if (auto status =|;|+          LiteRtGetBatchMatmulAdjXOption(op.Get(), &tfl_matmul_param_adj_x)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get batch matmul adjX"")|;|;+  }|;|+|;|+  if (auto status =|;|+          LiteRtGetBatchMatmulAdjYOption(op.Get(), &tfl_matmul_param_adj_y)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get batch matmul adjY"")|;|;+  }|;|+|;|+  auto adj_x_operand_index = operand_map.AddScalarBool(tfl_matmul_param_adj_x)|;|;+  if (!adj_x_operand_index) {|;|+    return adj_x_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*adj_x_operand_index)|;|;+|;|+  auto adj_j_operand_index = operand_map.AddScalarBool(tfl_matmul_param_adj_y)|;|;+  if (!adj_j_operand_index) {|;|+    return adj_j_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*adj_j_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_BATCH_MATMUL,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_BATCH_MATMUL op"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/batch_matmul_op_legalization.h: @@ -0,0 +1,33 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeBatchMatMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                     NeuronModel* model,|;|+                                     OperandMap& operand_map,|;|+                                     const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_BATCH_MATMUL_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.cc: @@ -0,0 +1,66 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+bool VerifyCommonOp(const litert::Op& op, LiteRtOpCode op_code) {|;|+  // Do some common check|;|+  return true|;|;+}|;|+|;|+Expected<void> LegalizeCommonOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op,|;|+                                NeuronOperationType mtk_operation_type) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Op: %d"", mtk_operation_type)|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/mtk_operation_type,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure, ""Failed to add operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/common_op_legalization.h: @@ -0,0 +1,35 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+bool VerifyCommonOp(const litert::Op& op, LiteRtOpCode op_code)|;|;+|;|+Expected<void> LegalizeCommonOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op,|;|+                                NeuronOperationType mtk_operation_type)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_COMMON_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.cc: @@ -0,0 +1,77 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeConcatOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Concate"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_CONCAT operation takes an additional scalar operand, which is used|;|+  // to pass as a axis.|;|+  int32_t axis|;|;+  if (auto status = LiteRtGetConcatenationAxisOption(op.Get(), &axis)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get new shape option"")|;|;+  }|;|+|;|+  auto axis_operand_index = operand_map.AddScalarInt32(axis)|;|;+  if (!axis_operand_index) {|;|+    return axis_operand_index.Error()|;|;+  }|;|+|;|+  input_indices.push_back(*axis_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model,|;|+                        /*type=*/NEURON_CONCATENATION, input_indices,|;|+                        output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_CONCAT operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/concat_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeConcatOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                NeuronModel* model, OperandMap& operand_map,|;|+                                const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_CONCAT_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.cc: @@ -0,0 +1,129 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+#define GET_RANK(op) ((op).RankedTensorType()->Layout().Rank())|;|+#define GET_DIMENSION(op) ((op).RankedTensorType()->Layout().Dimensions())|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeFullyConnectedOp(|;|+    const NeuronAdapterApi& neuron_adapter_api, NeuronModel* model,|;|+    OperandMap& operand_map, const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Fully Connected"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // for beta|;|+  if (input_indices.size() < 3) {|;|+    auto weights_shape = GET_DIMENSION(op.Inputs()[1])|;|;+    std::vector<uint32_t> bias_shape = {|;|+        static_cast<unsigned int>(weights_shape[0])}|;|;+    std::vector<int32_t> bias_data(bias_shape[0], 0)|;|;+    auto bias_data_operand =|;|+        operand_map.AddTensorByType(NEURON_TENSOR_QUANT8_SYMM, bias_shape,|;|+                                    bias_data.data(), bias_data.size() * 1)|;|;+    input_indices.push_back(*bias_data_operand)|;|;+  }|;|+|;|+  // A NEURON_FULLY_CONNECTED operation takes a 4rd scalar operand, which is|;|+  // used to pass a TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status = LiteRtGetFullyConnectedFusedActivationOption(|;|+          op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  auto output_operand = OperandType::Create(op.Outputs()[0])|;|;+  std::vector<uint32_t> output_indices|;|;+|;|+  if (GET_RANK(op.Outputs()[0]) > 2) {|;|+    // if output_operand shape <B, K, N>, reshape to <B * K, N>|;|+    auto last_dim = output_operand->GetDimension().back()|;|;+    auto elements = output_operand->GetElementCount()|;|;+    std::vector<uint32_t> new_dimension = {elements / last_dim, last_dim}|;|;+    if (auto res = output_operand->Reshape(new_dimension); !res) {|;|+      return res.Error()|;|;+    }|;|+    auto intermediate_operand = operand_map.AddOperand(*output_operand)|;|;+    output_indices.push_back(*intermediate_operand)|;|;+  } else {|;|+    auto output_operand = operand_map.GetOperandIndex(op.Outputs()[0])|;|;+    output_indices.push_back(*output_operand)|;|;+    if (!output_operand) {|;|+      return output_operand.Error()|;|;+    }|;|+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model,|;|+                        /*type=*/NEURON_FULLY_CONNECTED, input_indices,|;|+                        output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to set NEURON_FULLY_CONNECTED operation"")|;|;+  }|;|+|;|+  if (GET_RANK(op.Outputs()[0]) > 2) {|;|+    // intermediate as reshape input|;|+    input_indices = {output_indices.back()}|;|;+    auto output_operand = operand_map.GetOperandIndex(op.Outputs()[0])|;|;+    if (!output_operand) {|;|+      return output_operand.Error()|;|;+    }|;|+|;|+    auto dimension = op.Outputs()[0].RankedTensorType()->Layout().Dimensions()|;|;+    std::vector<uint32_t> new_shape(dimension.begin(), dimension.end())|;|;+    std::vector<uint32_t> tensor_shape = {(uint32_t)new_shape.size()}|;|;+    auto new_shape_operand_index = operand_map.AddTensorInt32(|;|+        tensor_shape, new_shape.data(), new_shape.size() * sizeof(int32_t))|;|;+    if (!new_shape_operand_index) {|;|+      return new_shape_operand_index.Error()|;|;+    }|;|+    input_indices.push_back(*new_shape_operand_index)|;|;+    output_indices = {*output_operand}|;|;+    if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RESHAPE,|;|+                          input_indices, output_indices) != NEURON_NO_ERROR) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Failed to add Reshape after FC"")|;|;+    }|;|+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/fully_connected_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeFullyConnectedOp(|;|+    const NeuronAdapterApi& neuron_adapter_api, NeuronModel* model,|;|+    OperandMap& operand_map, const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_FULLY_CONNECTED_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.cc: @@ -0,0 +1,70 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+constexpr uint32_t kGeluApproximateTanh = 1|;|;+|;|+Expected<void> LegalizeGeluOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Gelu"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  auto approximate_operand = operand_map.AddScalarUInt32(kGeluApproximateTanh)|;|;+  if (!approximate_operand) {|;|+    return approximate_operand.Error()|;|;+  }|;|+|;|+  input_indices.push_back(*approximate_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_GELU_V2,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add GELU operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/gelu_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeGeluOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_GELU_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.cc: @@ -0,0 +1,75 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMeanOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Mean"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_Mean operation takes an additional scalar operand, which is|;|+  // used to pass a keepdims.|;|+  bool keepdims|;|;+  if (auto status = LiteRtGetMeanKeepDimsOption(op.Get(), &keepdims)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get beta"")|;|;+  }|;|+  LITERT_LOG(LITERT_INFO, ""keepdims: %d"", keepdims)|;|;+  auto keepdims_operand = operand_map.AddScalarInt32(keepdims)|;|;+  if (!keepdims_operand) {|;|+    return keepdims_operand.Error()|;|;+  }|;|+  input_indices.push_back(*keepdims_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_MEAN,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_MEAN operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mean_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMeanOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                              NeuronModel* model, OperandMap& operand_map,|;|+                              const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MEAN_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.cc: @@ -0,0 +1,76 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Mul"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_MUL operation takes a 3rd scalar operand, which is used to pass a|;|+  // TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status =|;|+          LiteRtGetMulFusedActivationOption(op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_MUL,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_MUL operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/mul_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeMulOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_MUL_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.cc: @@ -0,0 +1,104 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<NeuronTensorType> GetNeuronTensorType(const Tensor& t) {|;|+  auto ranked_tensor_type = t.RankedTensorType()|;|;+  if (!ranked_tensor_type) {|;|+    return ranked_tensor_type.Error()|;|;+  }|;|+|;|+  int32_t mtk_type|;|;+  switch (ranked_tensor_type->ElementType()) {|;|+    case ElementType::Float32:|;|+      mtk_type = NEURON_TENSOR_FLOAT32|;|;+      break|;|;+    case ElementType::Float16:|;|+      mtk_type = NEURON_TENSOR_FLOAT16|;|;+      break|;|;+    case ElementType::Int32:|;|+      mtk_type = NEURON_TENSOR_INT32|;|;+      break|;|;+    case ElementType::Int16:|;|+      if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+        mtk_type = NEURON_TENSOR_QUANT16_SYMM|;|;+      } else {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Int16 is not supported."")|;|;+      }|;|+      break|;|;+    case ElementType::Int8:|;|+      if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+        mtk_type = NEURON_TENSOR_QUANT8_SYMM|;|;+      } else if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+        mtk_type = NEURON_TENSOR_QUANT8_SYMM_PER_CHANNEL|;|;+      } else {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Int8 is not supported."")|;|;+      }|;|+      break|;|;+    default:|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   absl::StrFormat(""Unsupported element type: %d"",|;|+                                   ranked_tensor_type->ElementType()))|;|;+  }|;|+  return mtk_type|;|;+}|;|+|;|+Expected<uint32_t> GetNeuronDataSize(NeuronTensorType type) {|;|+  switch (type) {|;|+    case NEURON_FLOAT32:|;|+    case NEURON_TENSOR_FLOAT32:|;|+    case NEURON_INT32:|;|+    case NEURON_TENSOR_INT32:|;|+      return 4|;|;+    case NEURON_FLOAT16:|;|+    case NEURON_TENSOR_FLOAT16:|;|+    case NEURON_EXT_TENSOR_QUANT16_ASYMM_SIGNED:|;|+      return 2|;|;+    case NEURON_BOOL:|;|+    case NEURON_TENSOR_BOOL8:|;|+    case NEURON_TENSOR_QUANT8_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM_SIGNED:|;|+      return 1|;|;+    default:|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Get Data Size fail for Neuron Type"")|;|;+  }|;|+  return Error(kLiteRtStatusErrorRuntimeFailure, ""Unexpected neuron type"")|;|;+}|;|+|;|+Expected<bool> IsQuantizedType(NeuronTensorType type) {|;|+  switch (type) {|;|+    case NEURON_TENSOR_QUANT16_SYMM:|;|+    case NEURON_TENSOR_QUANT16_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM:|;|+    case NEURON_TENSOR_QUANT8_ASYMM_SIGNED:|;|+      return true|;|;+  }|;|+  return false|;|;+}|;|+|;|+NeuronReturnCode ModelAddOperation(const NeuronAdapterApi& api,|;|+                                   NeuronModel* model, NeuronOperationType type,|;|+                                   std::vector<uint32_t> input,|;|+                                   std::vector<uint32_t> output) {|;|+  return api.api().model_add_operation(model, type, input.size(), input.data(),|;|+                                       output.size(), output.data())|;|;+}|;|;+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h: @@ -0,0 +1,43 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_|;|+|;|+#include <cstdint>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+using NeuronTensorType = int32_t|;|;+using NeuronReturnCode = int32_t|;|;+|;|+Expected<NeuronTensorType> GetNeuronTensorType(const Tensor& t)|;|;+|;|+Expected<uint32_t> GetNeuronDataSize(NeuronTensorType type)|;|;+|;|+Expected<bool> IsQuantizedType(NeuronTensorType type)|;|;+|;|+NeuronReturnCode ModelAddOperation(const NeuronAdapterApi& api,|;|+                                   NeuronModel* model, NeuronOperationType type,|;|+                                   std::vector<uint32_t> input,|;|+                                   std::vector<uint32_t> output)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_NEURON_UTILS_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.cc: @@ -17,77 +17,21 @@|;| #include <algorithm>|;| #include <cstdint>|;| #include <iterator>|;|+#include <numeric>|;|+#include <optional>|;|+#include <string>|;| #include <utility>|;| #include <vector>|;| |;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_element_type.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;| |;| namespace litert::mediatek {|;| |;|-namespace {|;|-|;|-class OperandType : public NeuronOperandType {|;|- public:|;|-  static Expected<OperandType> Create(const Tensor& t) {|;|-    auto ranked_tensor_type = t.RankedTensorType()|;|;-    if (!ranked_tensor_type) {|;|-      return ranked_tensor_type.Error()|;|;-    }|;|-|;|-    auto tensor_dimensions = ranked_tensor_type->Layout().Dimensions()|;|;-    std::vector<uint32_t> mtk_dimensions|;|;-    mtk_dimensions.reserve(tensor_dimensions.size())|;|;-    std::copy(tensor_dimensions.begin(), tensor_dimensions.end(),|;|-              std::back_inserter(mtk_dimensions))|;|;-|;|-    int32_t mtk_type|;|;-    switch (ranked_tensor_type->ElementType()) {|;|-      case ElementType::Float32:|;|-        mtk_type = NEURON_TENSOR_FLOAT32|;|;-        break|;|;-      case ElementType::Int32:|;|-        mtk_type = NEURON_TENSOR_INT32|;|;-        break|;|;-      default:|;|-        return Error(kLiteRtStatusErrorRuntimeFailure,|;|-                     ""Unsupported element type"")|;|;-    }|;|-|;|-    return OperandType(mtk_type, std::move(mtk_dimensions))|;|;-  }|;|-|;|-  OperandType(const OperandType&) = delete|;|;-|;|-  OperandType(OperandType&& other) : dimensions_(std::move(other.dimensions_)) {|;|-    // Copy all the scalar fields from other.|;|-    *static_cast<NeuronOperandType*>(this) =|;|-        *static_cast<NeuronOperandType*>(&other)|;|;-    // Reset the pointer fields by using own data.|;|-    dimensions = dimensions_.data()|;|;-  }|;|;-|;|-  OperandType& operator=(const OperandType&) = delete|;|;-  OperandType& operator=(OperandType&& other) = delete|;|;-|;|- private:|;|-  explicit OperandType(int32_t mtk_type, std::vector<uint32_t>&& mtk_dimensions)|;|-      : dimensions_(std::move(mtk_dimensions)) {|;|-    this->type = mtk_type|;|;-    this->dimensionCount = dimensions_.size()|;|;-    this->dimensions = dimensions_.data()|;|;-  }|;|;-|;|-  std::vector<uint32_t> dimensions_|;|;-}|;|;-|;|-}  // namespace|;|-|;|-// /////////////////////////////////////////////////////////////////////////////|;|-|;| Expected<uint32_t> OperandMap::Register(const NeuronOperandType& operand_type) {|;|   if (neuron_adapter_api_.api().model_add_operand(model_, &operand_type) !=|;|       NEURON_NO_ERROR) {|;|@@ -108,9 +52,19 @@ Expected<uint32_t> OperandMap::Register(const Tensor& t) {|;|   if (!operand_index) {|;|     return operand_index.Error()|;|;   }|;|+  LITERT_LOG(LITERT_INFO, ""\nOperandIndex: %d"", operand_index.Value())|;|;+  operand_type->Info()|;|; |;|   if (t.HasWeights()) {|;|     auto weights = t.Weights().Bytes()|;|;+    if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+      auto quant_param = operand_type->GetPerChannelQuantParams().Value()|;|;+      if (neuron_adapter_api_.api().model_set_symm_per_channel_quant_params(|;|+              model_, *operand_index, &quant_param) != NEURON_NO_ERROR) {|;|+        return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                     ""Failed to set param of per channel quant params"")|;|;+      }|;|+    }|;|     if (neuron_adapter_api_.api().model_set_operand_value(|;|             model_, *operand_index, weights.data(), weights.size()) !=|;|         NEURON_NO_ERROR) { || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h: @@ -17,16 +17,154 @@|;| |;| #include <cstdint>|;| #include <map>|;|+#include <numeric>|;| #include <vector>|;| |;| #include ""absl/container/flat_hash_map.h""|;| #include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;| #include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/neuron_utils.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;| |;| namespace litert::mediatek {|;| |;|+class OperandType : public NeuronOperandType {|;|+ public:|;|+  static Expected<OperandType> Create(const Tensor& t) {|;|+    auto ranked_tensor_type = t.RankedTensorType()|;|;+    if (!ranked_tensor_type) {|;|+      return ranked_tensor_type.Error()|;|;+    }|;|+|;|+    auto tensor_dimensions = ranked_tensor_type->Layout().Dimensions()|;|;+    std::vector<uint32_t> mtk_dimensions|;|;+    mtk_dimensions.reserve(tensor_dimensions.size())|;|;+    std::copy(tensor_dimensions.begin(), tensor_dimensions.end(),|;|+              std::back_inserter(mtk_dimensions))|;|;+|;|+    // tensor type dimensions couldn't be zero.|;|+    if (mtk_dimensions.size() == 0) {|;|+      mtk_dimensions = {|;|+          1,|;|+      }|;|;+    }|;|+|;|+    // BlockWise Quantize is not supported now.|;|+    if (t.HasQuantization() && t.QTypeId() == kLiteRtQuantizationBlockWise) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Doesn't support BlockWise quantize now"")|;|;+    }|;|+|;|+    auto mtk_type = GetNeuronTensorType(t)|;|;+    if (!mtk_type) {|;|+      return mtk_type.Error()|;|;+    }|;|+|;|+    if (t.QTypeId() == kLiteRtQuantizationPerTensor) {|;|+      auto quant_info = t.PerTensorQuantization()|;|;+      LITERT_LOG(LITERT_INFO, ""zeroPoint: %d, scale: %f"", quant_info.zero_point,|;|+                 quant_info.scale)|;|;+      return OperandType(*mtk_type, std::move(mtk_dimensions), quant_info.scale,|;|+                         quant_info.zero_point, std::nullopt)|;|;+    } else if (t.QTypeId() == kLiteRtQuantizationPerChannel) {|;|+      auto quant_info = t.PerChannelQuantization()|;|;+      NeuronSymmPerChannelQuantParams params|;|;+      params.scaleCount = quant_info.num_channels|;|;+      params.scales = quant_info.scales|;|;+      params.channelDim = quant_info.quantized_dimension|;|;+      LITERT_LOG(LITERT_INFO, ""quantized_dimension: %d"",|;|+                 quant_info.quantized_dimension)|;|;+      LITERT_LOG(LITERT_INFO, ""params.channelDim: %d"", params.channelDim)|;|;+      return OperandType(*mtk_type, std::move(mtk_dimensions), 0, 0, params)|;|;+    } else {|;|+      return OperandType(*mtk_type, std::move(mtk_dimensions), /*scale*/ 0,|;|+                         /*zero_point*/ 0, std::nullopt)|;|;+    }|;|+  }|;|+|;|+  void Info() {|;|+    std::string vector = ""[""|;|;+    for (int i = 0; i < dimensionCount; i++) {|;|+      vector += std::to_string(dimensions_[i])|;|;+      vector += "",""|;|;+    }|;|+    vector += ""]""|;|;+    LITERT_LOG(LITERT_INFO,|;|+               ""\n[Type] %d""|;|+               ""\n[zeroPoint]%d""|;|+               ""\n[scale]%f""|;|+               ""\n[dimensionCount]%u""|;|+               ""\n[dimensions]%s\n"",|;|+               type, zeroPoint, scale, dimensionCount, vector.c_str())|;|;+  }|;|+|;|+  OperandType(const OperandType&) = delete|;|;+|;|+  OperandType(OperandType&& other)|;|+      : dimensions_(std::move(other.dimensions_)),|;|+        neuron_per_channel_params_(other.neuron_per_channel_params_) {|;|+    // Copy all the scalar fields from other.|;|+    *static_cast<NeuronOperandType*>(this) =|;|+        *static_cast<NeuronOperandType*>(&other)|;|;+    // Reset the pointer fields by using own data.|;|+    dimensions = dimensions_.data()|;|;+  }|;|;+|;|+  Expected<void> Reshape(std::vector<uint32_t>& shape) {|;|+    auto elements = GetElementCount()|;|;+    if (elements != std::accumulate(shape.begin(), shape.end(), 1,|;|+                                    std::multiplies<uint32_t>())) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""the elements is not the same"")|;|;+    }|;|+    this->dimensions_ = shape|;|;+    this->dimensionCount = this->dimensions_.size()|;|;+    this->dimensions = this->dimensions_.data()|;|;+    return {}|;|;+  }|;|+|;|+  Expected<NeuronSymmPerChannelQuantParams> GetPerChannelQuantParams() {|;|+    if (!neuron_per_channel_params_.has_value()) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure, ""No quant param is set"")|;|;+    }|;|+    return neuron_per_channel_params_.value()|;|;+  }|;|+|;|+  int32_t GetNeuronType() const { return this->type; }|;|+|;|+  std::vector<uint32_t> GetDimension() { return this->dimensions_; }|;|+|;|+  uint32_t GetElementCount() {|;|+    return std::accumulate(dimensions_.begin(), dimensions_.end(), 1,|;|+                           std::multiplies<uint32_t>())|;|;+  }|;|+|;|+  uint32_t GetRank() { return this->dimensions_.size(); }|;|+|;|+  OperandType& operator=(const OperandType&) = delete|;|;+  OperandType& operator=(OperandType&& other) = delete|;|;+|;|+ private:|;|+  explicit OperandType(int32_t mtk_type, std::vector<uint32_t>&& mtk_dimensions,|;|+                       float scale, int32_t zero_point,|;|+                       std::optional<NeuronSymmPerChannelQuantParams> pararms)|;|+      : dimensions_(std::move(mtk_dimensions)),|;|+        neuron_per_channel_params_(pararms) {|;|+    this->scale = scale|;|;+    this->zeroPoint = zero_point|;|;+    this->type = mtk_type|;|;+    this->dimensionCount = dimensions_.size()|;|;+    this->dimensions = dimensions_.data()|;|;+  }|;|+|;|+  std::vector<uint32_t> dimensions_|;|;+|;|+  std::optional<NeuronSymmPerChannelQuantParams> neuron_per_channel_params_ =|;|+      std::nullopt|;|;+}|;|;+|;| // This class takes care of registering Tensors and scalars with a given|;| // NeuronModel and returing their ""operand index"", which is how the MTK SDK|;| // handles them.|;|@@ -42,10 +180,29 @@ class OperandMap {|;|   Expected<uint32_t> AddScalarInt32(int32_t value) {|;|     return AddScalar(NEURON_INT32, value)|;|;   }|;|+  Expected<uint32_t> AddScalarUInt32(uint32_t value) {|;|+    return AddScalar(NEURON_UINT32, value)|;|;+  }|;|   Expected<uint32_t> AddScalarFloat32(float value) {|;|     return AddScalar(NEURON_FLOAT32, value)|;|;   }|;| |;|+  // Add a tensor operand to the model|;|+  Expected<uint32_t> AddTensorInt32(std::vector<uint32_t>& shape,|;|+                                    const void* data, const size_t data_size) {|;|+    return AddTensor(NEURON_TENSOR_INT32, shape, data, data_size)|;|;+  }|;|+|;|+  // Add a tensor operand to the model|;|+  Expected<uint32_t> AddTensorByType(int mtk_type, std::vector<uint32_t>& shape,|;|+                                     const void* data, const size_t data_size) {|;|+    return AddTensor(mtk_type, shape, data, data_size)|;|;+  }|;|+|;|+  Expected<uint32_t> AddOperand(const NeuronOperandType& operand) {|;|+    return Register(operand)|;|;+  }|;|+|;|   // Find the operand index for a given tensor and, if not done already, add the|;|   // tensor as an operand in the model.|;|   Expected<uint32_t> GetOperandIndex(const Tensor& t) {|;|@@ -81,6 +238,26 @@ class OperandMap {|;|     return operand_index|;|;   }|;| |;|+  Expected<uint32_t> AddTensor(int32_t mtk_type,|;|+                               const std::vector<uint32_t>& shape,|;|+                               const void* data, const size_t data_size) {|;|+    const NeuronOperandType scalar_type = {|;|+        .type = mtk_type,|;|+        .dimensionCount = (uint32_t)shape.size(),|;|+        .dimensions = shape.data(),|;|+    }|;|;+    auto operand_index = Register(scalar_type)|;|;+    if (!operand_index) {|;|+      return operand_index.Error()|;|;+    }|;|+    if (neuron_adapter_api_.api().model_set_operand_value(|;|+            model_, *operand_index, data, data_size) != NEURON_NO_ERROR) {|;|+      return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                   ""Failed to set value of tensor operand"")|;|;+    }|;|+    return operand_index|;|;+  }|;|+|;|   const NeuronAdapterApi& neuron_adapter_api_|;|;   NeuronModel* model_|;|;   int next_operand_index_ = 0; || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeQuantizeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                  NeuronModel* model, OperandMap& operand_map,|;|+                                  const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Quantize"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_QUANTIZE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_QUANTIZE operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/quantize_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeQuantizeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                  NeuronModel* model, OperandMap& operand_map,|;|+                                  const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_QUANTIZE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeReshapeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Reshape"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RESHAPE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_RESHAPE operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/reshape_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeReshapeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RESHAPE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeRsqrtOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                               NeuronModel* model, OperandMap& operand_map,|;|+                               const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Rsqrt"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_RSQRT,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_RSQRT operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/rsqrt_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeRsqrtOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                               NeuronModel* model, OperandMap& operand_map,|;|+                               const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_RSQRT_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.cc: @@ -0,0 +1,74 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSoftmaxOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Softmax"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_Softmax operation takes an additional scalar operand, which is|;|+  // used to pass a Beta value.|;|+  float beta|;|;+  if (auto status = LiteRtGetSoftmaxBetaOption(op.Get(), &beta)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get beta"")|;|;+  }|;|+  auto beta_operand = operand_map.AddScalarFloat32(beta)|;|;+  if (!beta_operand) {|;|+    return beta_operand.Error()|;|;+  }|;|+  input_indices.push_back(*beta_operand)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_SOFTMAX,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add NEURON_SOFTMAX operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/softmax_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSoftmaxOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                 NeuronModel* model, OperandMap& operand_map,|;|+                                 const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SOFTMAX_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.cc: @@ -0,0 +1,76 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSubOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Sub"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  // A NEURON_SUB operation takes a 3rd scalar operand, which is used to pass a|;|+  // TfLiteFusedActivation value.|;|+  uint32_t tfl_fused_activation|;|;+  if (auto status =|;|+          LiteRtGetSubFusedActivationOption(op.Get(), &tfl_fused_activation)|;|;+      status != kLiteRtStatusOk) {|;|+    return Error(status, ""Failed to get fused activation"")|;|;+  }|;|+  auto fused_activation_operand_index =|;|+      operand_map.AddScalarInt32(tfl_fused_activation)|;|;+  if (!fused_activation_operand_index) {|;|+    return fused_activation_operand_index.Error()|;|;+  }|;|+  input_indices.push_back(*fused_activation_operand_index)|;|;+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_SUB,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add value of NEURON_SUB fused activation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/sub_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeSubOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                             NeuronModel* model, OperandMap& operand_map,|;|+                             const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_SUB_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.cc: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h""|;|+|;|+#include <cstdint>|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_options.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeTransposeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                   NeuronModel* model, OperandMap& operand_map,|;|+                                   const litert::Op& op) {|;|+  LITERT_LOG(LITERT_INFO, ""Legalize Transpose"")|;|;+  std::vector<uint32_t> input_indices|;|;+  for (auto& input : op.Inputs()) {|;|+    auto id = operand_map.GetOperandIndex(input)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    input_indices.push_back(*id)|;|;+  }|;|+|;|+  std::vector<uint32_t> output_indices|;|;+  for (auto& output : op.Outputs()) {|;|+    auto id = operand_map.GetOperandIndex(output)|;|;+    if (!id) {|;|+      return id.Error()|;|;+    }|;|+    output_indices.push_back(*id)|;|;+  }|;|+|;|+  if (ModelAddOperation(neuron_adapter_api, model, /*type=*/NEURON_TRANSPOSE,|;|+                        input_indices, output_indices) != NEURON_NO_ERROR) {|;|+    return Error(kLiteRtStatusErrorRuntimeFailure,|;|+                 ""Failed to add reshape operation"")|;|;+  }|;|+|;|+  return {}|;|;+}|;|+|;|+}  // namespace litert::mediatek || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/transpose_op_legalization.h: @@ -0,0 +1,32 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_|;|+|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_model.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/compiler/legalizations/operand_map.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+|;|+namespace litert::mediatek {|;|+|;|+Expected<void> LegalizeTransposeOp(const NeuronAdapterApi& neuron_adapter_api,|;|+                                   NeuronModel* model, OperandMap& operand_map,|;|+                                   const litert::Op& op)|;|;+|;|+}  // namespace litert::mediatek|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_COMPILER_LEGALIZATIONS_TRANSPOSE_OP_LEGALIZATION_H_ || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/BUILD: @@ -69,6 +69,7 @@ litert_dynamic_lib(|;|         ""//tensorflow/lite/experimental/litert/core/util:tensor_type_util"",|;|         ""//tensorflow/lite/experimental/litert/vendors/c:litert_dispatch_c_api"",|;|         ""//tensorflow/lite/experimental/litert/vendors/mediatek:neuron_adapter_api"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/mediatek/schema:mediatek_litert_schema"",|;|     ],|;| )|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/dispatch_api.cc: @@ -33,6 +33,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_device_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_invocation_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| namespace {|;|  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_invocation_context.cc: @@ -30,6 +30,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/c/litert_dispatch.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/dispatch/litert_dispatch_device_context.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h""|;| |;| using litert::Error|;|; using litert::Expected|;|;@@ -231,12 +232,31 @@ LiteRtDispatchInvocationContextT::Create(|;|     LiteRtDispatchExecutableType exec_type,|;|     const LiteRtMemBuffer* exec_bytecode_buffer, const char* function_name,|;|     int num_inputs, int num_outputs) {|;|-  auto exec_bytecode_ptr =|;|+  neuron::SchemaResolver resolver|;|;+|;|+  const void* exec_bytecode_ptr =|;|       static_cast<const uint8_t*>(exec_bytecode_buffer->base_addr) +|;|       exec_bytecode_buffer->offset|;|;-  auto model_and_compilation = LoadModelAndCompilation(|;|-      neuron_adapter_api, exec_bytecode_ptr, exec_bytecode_buffer->size,|;|-      num_inputs, num_outputs)|;|;+  auto exec_bytecode_size = exec_bytecode_buffer->size|;|;+  auto res = resolver.Initialize((const uint8_t*)exec_bytecode_ptr,|;|+                                 exec_bytecode_size)|;|;+  if (res.HasValue() && res.Value()) {|;|+    std::string func = function_name != nullptr ? function_name : """"|;|;+    auto graph = resolver.GetCompiledGraph(func)|;|;+    if (!graph.has_value()) {|;|+      return litert::Error(kLiteRtStatusErrorRuntimeFailure,|;|+                           ""Couldn't find the subgraph"")|;|;+    }|;|+    auto compile_graph = graph.value().GetCompiledNetwork()|;|;+    if (!compile_graph) {|;|+      return compile_graph.Error()|;|;+    }|;|+    std::tie(exec_bytecode_ptr, exec_bytecode_size) = compile_graph.Value()|;|;+  }|;|+|;|+  auto model_and_compilation =|;|+      LoadModelAndCompilation(neuron_adapter_api, exec_bytecode_ptr,|;|+                              exec_bytecode_size, num_inputs, num_outputs)|;|;   if (!model_and_compilation) {|;|     return model_and_compilation.Error()|;|;   } || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.cc: @@ -131,6 +131,8 @@ litert::Expected<void> NeuronAdapterApi::LoadSymbols(|;|             api_->model_restore_from_compiled_network)|;|;   LOAD_SYMB(NeuronModel_setName, api_->model_set_name)|;|;   LOAD_SYMB(NeuronModel_setOperandValue, api_->model_set_operand_value)|;|;+  LOAD_SYMB(NeuronModel_setOperandSymmPerChannelQuantParams,|;|+            api_->model_set_symm_per_channel_quant_params)|;|;   LOAD_SYMB(Neuron_getVersion, api_->get_version)|;|; |;|   LITERT_LOG(LITERT_INFO, ""NeuronAdapter symbols loaded""); || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/neuron_adapter_api.h: @@ -141,6 +141,8 @@ struct NeuronAdapterApi::Api {|;|       model_restore_from_compiled_network = nullptr|;|;   decltype(&NeuronModel_setName) model_set_name = nullptr|;|;   decltype(&NeuronModel_setOperandValue) model_set_operand_value = nullptr|;|;+  decltype(&NeuronModel_setOperandSymmPerChannelQuantParams)|;|+      model_set_symm_per_channel_quant_params = nullptr|;|;   decltype(&Neuron_getVersion) get_version = nullptr|;|; }|;|;  || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/BUILD: @@ -0,0 +1,43 @@|;|+# Copyright (c) 2025 MediaTek Inc.|;|+#|;|+# Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+# you may not use this file except in compliance with the License.|;|+# You may obtain a copy of the License at|;|+#|;|+#      http://www.apache.org/licenses/LICENSE-2.0|;|+#|;|+# Unless required by applicable law or agreed to in writing, software|;|+# distributed under the License is distributed on an ""AS IS"" BASIS,|;|+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+# See the License for the specific language governing permissions and|;|+# limitations under the License.|;|+|;|+load(""@flatbuffers//:build_defs.bzl"", ""flatbuffer_cc_library"")|;|+load(""//tensorflow:tensorflow.default.bzl"", ""get_compatible_with_portable"")|;|+|;|+package(|;|+    # copybara:uncomment default_applicable_licenses = [""//tensorflow:license""],|;|+    default_visibility = [""//tensorflow/lite/experimental/litert:__subpackages__""],|;|+)|;|+|;|+flatbuffer_cc_library(|;|+    name = ""neuron_litert_schema"",|;|+    srcs = [""neuron_schema.fbs""],|;|+    compatible_with = get_compatible_with_portable(),|;|+)|;|+|;|+cc_library(|;|+    name = ""mediatek_litert_schema"",|;|+    hdrs = [|;|+        ""schema_resolver.h"",|;|+    ],|;|+    visibility = [""//visibility:public""],|;|+    deps = [|;|+        ""neuron_litert_schema"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_common"",|;|+        ""//tensorflow/lite/experimental/litert/c:litert_logging"",|;|+        ""//tensorflow/lite/experimental/litert/cc:litert_expected"",|;|+        ""@com_google_absl//absl/strings:str_format"",|;|+        ""@flatbuffers//:runtime_cc"",|;|+    ],|;|+) || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema.fbs: @@ -0,0 +1,61 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+namespace NeuronSchema|;|;+|;|+enum CompiledType : byte {|;|+  DLA = 0,|;|+  DLB,|;|+  AdapterCache|;|+}|;|+|;|+table Index {|;|+  value: int = -1|;|;+}|;|+|;|+table Identifier {|;|+  value: string|;|;+}|;|+|;|+// BufferIndicate to specify how to point to a buffer|;|+union BufferIndicate {|;|+  Index,|;|+  Identifier,|;|+}|;|+|;|+table Subgraph {|;|+  entry_point: string;       // Entry point of the subgraph|;|+  type: CompiledType;        // Type of the compiled subgraph|;|+  compiled_index: BufferIndicate;       // index to the buffer at Graphs.data|;|+  weight_share_index: [BufferIndicate]; // index to the buffer at Graphs.data[index]. if empty, no weight share.|;|+}|;|+|;|+table Graphs {|;|+  version: short;           // Version of the graph schema|;|+  subgraphs: [Subgraph];    // List of subgraphs|;|+  data: [Buffer]|;|;+  external: ExternalBuffer|;|;+}|;|+|;|+table Buffer {|;|+  identifier: string|;|;+  data: [byte];           // Binary data|;|+}|;|+|;|+// List of external buffer that doesn't store in this schema|;|+table ExternalBuffer {|;|+  identifiers: [string]|;|;+}|;|+|;|+root_type Graphs|;|;\ No newline at end of file || PR#89728 - tensorflow/lite/experimental/litert/vendors/mediatek/schema/schema_resolver.h: @@ -0,0 +1,184 @@|;|+// Copyright (c) 2025 MediaTek Inc.|;|+//|;|+// Licensed under the Apache License, Version 2.0 (the ""License"")|;|;+// you may not use this file except in compliance with the License.|;|+// You may obtain a copy of the License at|;|+//|;|+//      http://www.apache.org/licenses/LICENSE-2.0|;|+//|;|+// Unless required by applicable law or agreed to in writing, software|;|+// distributed under the License is distributed on an ""AS IS"" BASIS,|;|+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.|;|+// See the License for the specific language governing permissions and|;|+// limitations under the License.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_|;|+|;|+#include <cassert>|;|+#include <cstddef>|;|+#include <cstdint>|;|+#include <optional>|;|+#include <string>|;|+#include <unordered_map>|;|+#include <utility>|;|+#include <vector>|;|+|;|+#include ""absl/strings/str_format.h""|;|+#include ""flatbuffers/buffer.h""  // from @flatbuffers|;|+#include ""flatbuffers/flatbuffer_builder.h""  // from @flatbuffers|;|+#include ""flatbuffers/verifier.h""  // from @flatbuffers|;|+#include ""tensorflow/lite/experimental/litert/c/litert_common.h""|;|+#include ""tensorflow/lite/experimental/litert/c/litert_logging.h""|;|+#include ""tensorflow/lite/experimental/litert/cc/litert_expected.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/mediatek/schema/neuron_schema_generated.h""|;|+|;|+namespace neuron {|;|+|;|+inline bool IsNeuronSchema(const uint8_t* buffer, size_t size) {|;|+  if (buffer == nullptr) {|;|+    return false|;|;+  }|;|+  flatbuffers::Verifier verifier(buffer, size)|;|;+  return NeuronSchema::VerifyGraphsBuffer(verifier)|;|;+}|;|+|;|+class CompiledGraph {|;|+ public:|;|+  CompiledGraph(const NeuronSchema::Graphs& g, const NeuronSchema::Subgraph& s)|;|+      : graph_(g), subgraph_(s) {}|;|;+|;|+  litert::Expected<std::pair<const void*, size_t>> GetCompiledNetwork() {|;|+    // Neuron Adapter doesn't support DLB for now.|;|+    assert(GetCompiledType() != NeuronSchema::CompiledType_DLB)|;|;+    // TODO: Support the external buffer.|;|+    assert(subgraph_.compiled_index_type() ==|;|+           NeuronSchema::BufferIndicate_Index)|;|;+    auto index = subgraph_.compiled_index_as_Index()|;|;+    return GetBuffer(index->value())|;|;+  }|;|+|;|+  NeuronSchema::CompiledType GetCompiledType() { return subgraph_.type(); }|;|+|;|+  litert::Expected<std::pair<const void*, size_t>> GetBuffer(int32_t i) {|;|+    auto array_size = graph_.data()->size()|;|;+    if (i >= array_size) {|;|+      return litert::Error(|;|+          kLiteRtStatusErrorIndexOOB,|;|+          absl::StrFormat(""Buffer array index %d is OOB, the array size : %d"",|;|+                          i, array_size))|;|;+    }|;|+    auto buffer = graph_.data()->Get(i)|;|;+    return std::pair<const void*, size_t>(buffer->data()->data(),|;|+                                          buffer->data()->size())|;|;+  }|;|+|;|+ private:|;|+  const NeuronSchema::Graphs& graph_|;|;+  const NeuronSchema::Subgraph& subgraph_|;|;+}|;|;+|;|+class SchemaResolver {|;|+ public:|;|+  SchemaResolver() = default|;|;+|;|+  litert::Expected<bool> Initialize(const uint8_t* buffer, size_t size) {|;|+    if (!IsNeuronSchema(buffer, size)) {|;|+      return litert::Error(kLiteRtStatusErrorInvalidFlatbuffer,|;|+                           ""buffer is not a valid NeuronSchema"")|;|;+    }|;|+    graph_ = NeuronSchema::GetGraphs(buffer)|;|;+|;|+    auto subgraphs = graph_->subgraphs()|;|;+    for (const auto& subgraph : *subgraphs) {|;|+      auto graph_name = subgraph->entry_point()->str()|;|;+      if (entry_points_.count(graph_name)) {|;|+        // shouldn't have the same name between graphs.|;|+        return false|;|;+      } else {|;|+        LITERT_LOG(LITERT_INFO, ""Found graph: %s"", graph_name.c_str())|;|;+        entry_points_[graph_name] = subgraph|;|;+      }|;|+    }|;|+    LITERT_LOG(LITERT_INFO, ""There are %u subgraphs in the bytecode"",|;|+               entry_points_.size())|;|;+    return true|;|;+  }|;|+|;|+  std::optional<CompiledGraph> GetCompiledGraph(std::string& name) {|;|+    if (entry_points_.count(name) == 0) {|;|+      return std::nullopt|;|;+    }|;|+    return CompiledGraph(*graph_, *entry_points_[name])|;|;+  }|;|;+|;|+ private:|;|+  const NeuronSchema::Graphs* graph_ = nullptr|;|;+|;|+  std::unordered_map<std::string, NeuronSchema::Subgraph const*> entry_points_|;|;+}|;|;+|;|+class BytecodeBuilder {|;|+ public:|;|+  BytecodeBuilder() = default|;|;+|;|+  int32_t AddCompiledNetwork(std::string& entry_point,|;|+                             NeuronSchema::CompiledType type,|;|+                             int32_t buffer_index) {|;|+    auto index = NeuronSchema::CreateIndex(fb_, buffer_index)|;|;+    auto subgraph = NeuronSchema::CreateSubgraph(|;|+        fb_, fb_.CreateString(entry_point), type,|;|+        NeuronSchema::BufferIndicate_Index, index.Union())|;|;+|;|+    subgraphs_.push_back(subgraph)|;|;+    return subgraphs_count_++|;|;+  }|;|;+|;|+  int32_t AddBuffer(std::string& identifier, const std::vector<int8_t>& data) {|;|+    auto buffer =|;|+        NeuronSchema::CreateBufferDirect(fb_, identifier.c_str(), &data)|;|;+    graph_data_.push_back(buffer)|;|;+    return buffer_count_++|;|;+  }|;|+|;|+  int32_t AddBuffer(std::string& identifier, const int8_t* data,|;|+                    size_t length) {|;|+    auto data_offset = fb_.CreateVector(data, length)|;|;+    auto identifier_offset = fb_.CreateString(identifier)|;|;+    auto buffer =|;|+        NeuronSchema::CreateBuffer(fb_, identifier_offset, data_offset)|;|;+    graph_data_.push_back(buffer)|;|;+    return buffer_count_++|;|;+  }|;|+|;|+  bool Finish() {|;|+    auto graphs =|;|+        NeuronSchema::CreateGraphsDirect(fb_, 1, &subgraphs_, &graph_data_)|;|;+    fb_.Finish(graphs)|;|;+    raw_buffer_ = {fb_.GetBufferPointer(), fb_.GetSize()}|;|;+    return true|;|;+  }|;|+|;|+  std::pair<uint8_t*, size_t> GetBytecode() {|;|+    if (!raw_buffer_.has_value()) {|;|+      return {nullptr, 0}|;|;+    }|;|+    return raw_buffer_.value()|;|;+  }|;|+|;|+ private:|;|+  ::flatbuffers::FlatBufferBuilder fb_|;|;+|;|+  std::optional<std::pair<uint8_t*, size_t>> raw_buffer_|;|;+|;|+  std::vector<::flatbuffers::Offset<NeuronSchema::Subgraph>> subgraphs_|;|;+|;|+  std::vector<::flatbuffers::Offset<NeuronSchema::Buffer>> graph_data_|;|;+|;|+  int32_t subgraphs_count_ = 0|;|;+  int32_t buffer_count_ = 0|;|;+}|;|;+|;|+};  // namespace neuron|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_MEDIATEK_SCHEMA_SCHEMA_RESOLVER_H_","Supports more legalizations and multi-partition

1. more legalizations:
  a. Batch_MatMul
  b. Mul
  c. Fully_Connected

2. multi-partition supports:
  introduce utils for supporting multi-partition || Merge branch 'tensorflow:master' into upstream_0225 || Support more legalizations for MTK platform

- Added new legalizatios for more operations.
- Introduced common utility functions for neuron. || Fix syntax error of the BUILD || Merge pull request #88103 from neuropilot-captain:upstream_0225

PiperOrigin-RevId: 739261215"
tensorflow/tensorflow,jreiffers,24023,ValueError: tf.enable_eager_execution must be called at program startup.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NA
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
1.12.0
- Python version:
3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
9/7
- GPU model and memory:
NVIDIA GTX1080, 8GB

**Describe the current behavior**
Eager execution isn't working on a jupyter notebook with GPU. Have tried restarting the kernel multiple times. I get a ValueError: tf.enable_eager_execution must be called at program startup.

**Describe the expected behavior**
Eager Execution should work. Why isn't it working?

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`import tensorflow as tf
`tf.enable_eager_execution()

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-e43ec884c055> in <module>()
      5 import numpy as np
      6 import tensorflow as tf
----> 7 tf.enable_eager_execution()
      8 from keras import layers
      9 from keras import models

~\AppData\Local\conda\conda\envs\DLCdependencies\lib\site-packages\tensorflow\python\framework\ops.py in enable_eager_execution(config, device_policy, execution_mode)
   5421         device_policy=device_policy,
   5422         execution_mode=execution_mode,
-> 5423         server_def=None)
   5424 
   5425 

~\AppData\Local\conda\conda\envs\DLCdependencies\lib\site-packages\tensorflow\python\framework\ops.py in enable_eager_execution_internal(config, device_policy, execution_mode, server_def)
   5465     if graph_mode_has_been_used:
   5466       raise ValueError(
-> 5467           ""tf.enable_eager_execution must be called at program startup."")
   5468   context.default_execution_mode = context.EAGER_MODE
   5469   # pylint: disable=protected-access

ValueError: tf.enable_eager_execution must be called at program startup.","@Umar-Ayub  Can you please try in the [colab](https://colab.sandbox.google.com/drive/1rCTY1pv9jRG1_SxsOCNlZZRiEYZP5NF5) and let us know if you see the same error ? || Eager Execution is working fine. I was importing a python module which had keras models inside it and that's why the code was failing since placeholders were being defined in that module.  || Are you satisfied with the resolution of your issue?
[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)
[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)",closed,2018-11-28T18:30:21+00:00,2018-11-28T19:41:17+00:00,Umar-Ayub,"stat:awaiting response, type:support, comp:eager",1,"PR#89733 - third_party/xla/xla/hlo/ir/hlo_computation.h: @@ -215,8 +215,6 @@ class HloComputation {|;|     // unreachable, and its instruction is set to null. We still need to regard|;|     // such computations as fusion computations for HLO scheduling purposes.|;|     kFusion,|;|-    // This computation is a custom-call computation.|;|-    kCustomCall,|;|     // This computation is a collective computation.|;|     kCollective,|;|     // This computation is a conditional branch computation.|;|@@ -313,7 +311,7 @@ class HloComputation {|;|   // on a removed instruction before its marked as deleted. If|;|   // ignore_control_dependencies is set to true, if will remove the unused|;|   // operands even when they have control dependencies, and transitively pass|;|-  // the control dependencies from the predecessors to the succesors of the|;|+  // the control dependencies from the predecessors to the successors of the|;|   // removed instructions, so that the logical exeuction order of the remaining|;|   // unremoved instructions are preserved.|;|   absl::Status RemoveInstructionAndUnusedOperands(|;|@@ -807,21 +805,6 @@ class HloComputation {|;|     SetInstruction(fusion_instruction, InstructionType::kFusion)|;|;   }|;| |;|-  // Returns if this computation is a custom-call computation.|;|-  bool IsCustomCallComputation() const {|;|-    return instruction_type() == InstructionType::kCustomCall|;|;-  }|;|-|;|-  // Returns the owning custom call instruction, or nullptr if this is not a|;|-  // custom call computation.|;|-  HloInstruction* CustomCallInstruction() const {|;|-    return instruction_type() == InstructionType::kCustomCall ? instruction()|;|-                                                              : nullptr|;|;-  }|;|-  void SetCustomCallInstruction(HloInstruction* custom_call_instruction) {|;|-    SetInstruction(custom_call_instruction, InstructionType::kCustomCall)|;|;-  }|;|-|;|   // Returns if this computation is a to_apply region of a collective.|;|   bool IsCollectiveCalledComputation() const {|;|     return instruction_type() == InstructionType::kCollective|;|;@@ -961,7 +944,10 @@ class HloComputation {|;|       std::optional<HloOpcode> caller_opcode = std::nullopt) const {|;|     if (const auto* map = GetCallersMap()) {|;|       absl::InlinedVector<HloInstruction*, 1> result|;|;-      for (auto [instr, _] : *map) {|;|+      for (auto [instr, count] : *map) {|;|+        if (count == 0) {|;|+          continue|;|;+        }|;|         if (caller_opcode == std::nullopt |||;|             instr->opcode() == *caller_opcode) {|;|           result.push_back(instr); || PR#89733 - third_party/xla/xla/hlo/ir/hlo_instructions.cc: @@ -400,7 +400,7 @@ HloAsyncStartInstruction::HloAsyncStartInstruction(|;|     HloComputation* async_computation, absl::string_view async_execution_thread)|;|     : HloAsyncInstruction(opcode, shape, operands,|;|                           async_computation->root_instruction()->opcode()) {|;|-  CHECK(!async_computation->IsCustomCallComputation())|;|;+  CHECK(async_computation->caller_instructions(HloOpcode::kCustomCall).empty())|;|;   CHECK(!async_computation->IsFusionComputation())|;|;   CHECK(!async_computation->IsAsyncComputation())|;|;   AppendComputation(async_computation)|;|;@@ -3179,7 +3179,6 @@ HloCustomCallInstruction::HloCustomCallInstruction(|;|       custom_call_schedule_(CustomCallSchedule::SCHEDULE_NONE),|;|       api_version_(api_version) {|;|   set_raw_backend_config_string(std::move(opaque))|;|;-  to_apply->SetCustomCallInstruction(this)|;|; }|;| |;| HloCustomCallInstruction::HloCustomCallInstruction(|;|@@ -3198,9 +3197,6 @@ HloCustomCallInstruction::HloCustomCallInstruction(|;|       custom_call_schedule_(CustomCallSchedule::SCHEDULE_NONE),|;|       api_version_(api_version) {|;|   set_raw_backend_config_string(std::move(opaque))|;|;-  for (auto comp : called_computations) {|;|-    comp->SetCustomCallInstruction(this)|;|;-  }|;| }|;| |;| HloCustomCallInstruction::HloCustomCallInstruction( || PR#89733 - third_party/xla/xla/hlo/transforms/simplifiers/flatten_call_graph.cc: @@ -138,11 +138,6 @@ absl::Status AnnotateNode(const CallGraphNode& node) {|;|         computation->SetFusionInstruction(instruction)|;|;       }|;| |;|-    } else if (instruction->opcode() == HloOpcode::kCustomCall) {|;|-      for (HloComputation* computation : instruction->called_computations()) {|;|-        computation->SetCustomCallInstruction(instruction)|;|;-      }|;|-|;|     } else if (hlo_query::IsCollectiveCommunicationOp(instruction->opcode())) {|;|       for (HloComputation* computation : instruction->called_computations()) {|;|         computation->SetCollectiveCallInstruction(instruction); || PR#89733 - third_party/xla/xla/service/cpu/ir_emitter.cc: @@ -4283,7 +4283,8 @@ bool RecursivelyCheckForCustomCall(|;|     return itr->second|;|;   }|;| |;|-  bool contains_custom_call = computation.IsCustomCallComputation()|;|;+  bool contains_custom_call =|;|+      !computation.caller_instructions(HloOpcode::kCustomCall).empty()|;|; |;|   for (const HloInstruction* instruction : computation.instructions()) {|;|     contains_custom_call |= instruction->opcode() == HloOpcode::kCustomCall; || PR#89733 - third_party/xla/xla/service/gpu/transforms/command_buffer_scheduling.cc: @@ -891,7 +891,7 @@ absl::StatusOr<bool> CommandBufferScheduling::Run(|;|   for (HloComputation* comp : order) {|;|     // Skip special computations that do not have lowering to thunks.|;|     if (comp->IsFusionComputation() || comp->IsAsyncComputation() |||;|-        comp->IsCustomCallComputation())|;|+        !comp->caller_instructions(HloOpcode::kCustomCall).empty())|;|       continue|;|; |;|     // Skip computations that already part of command buffers. || PR#89733 - third_party/xla/xla/service/gpu/transforms/softmax_rewriter_triton.cc: @@ -594,7 +594,7 @@ SoftmaxRewriterTriton::FindAllFusibleNormalizationDiamonds(|;| |;|   for (HloComputation* comp :|;|        module.MakeNonfusionComputations(execution_threads)) {|;|-    if (comp->IsCustomCallComputation()) {|;|+    if (!comp->caller_instructions(HloOpcode::kCustomCall).empty()) {|;|       continue|;|;     }|;|     for (HloInstruction* instr : comp->MakeInstructionPostOrder()) { || PR#89733 - third_party/xla/xla/service/hlo_module_test.cc: @@ -248,8 +248,8 @@ ENTRY entry () -> s32[] {|;|   HloInstruction* cloned_custom_call =|;|       cloned_module->entry_computation()->GetInstructionWithName(""custom-call"")|;|; |;|-  EXPECT_TRUE(cloned_computation->IsCustomCallComputation())|;|;-  EXPECT_EQ(cloned_computation->CustomCallInstruction(), cloned_custom_call)|;|;+  EXPECT_EQ(cloned_computation->GetUniqueCaller(HloOpcode::kCustomCall),|;|+            cloned_custom_call)|;|; }|;| |;| TEST_F(HloModuleTest, CloneCustomCallComputationCalledComputations) {|;|@@ -288,10 +288,10 @@ ENTRY entry () -> s32[] {|;|   HloInstruction* cloned_custom_call =|;|       cloned_module->entry_computation()->GetInstructionWithName(""custom-call"")|;|; |;|-  EXPECT_TRUE(cloned_computation_0->IsCustomCallComputation())|;|;-  EXPECT_EQ(cloned_computation_0->CustomCallInstruction(), cloned_custom_call)|;|;-  EXPECT_TRUE(cloned_computation_1->IsCustomCallComputation())|;|;-  EXPECT_EQ(cloned_computation_1->CustomCallInstruction(), cloned_custom_call)|;|;+  EXPECT_EQ(cloned_computation_0->GetUniqueCaller(HloOpcode::kCustomCall),|;|+            cloned_custom_call)|;|;+  EXPECT_EQ(cloned_computation_1->GetUniqueCaller(HloOpcode::kCustomCall),|;|+            cloned_custom_call)|;|; }|;| |;| TEST_F(HloModuleTest, CloneFusionComputation) {","PR #24023: Remove HloComputation::CustomCallInstruction.

Imported from GitHub PR https://github.com/openxla/xla/pull/24023

Step 2/5 of removing instruction_type. I think kFusion should be last, since it's special (in that it's ""sticky"", you can't tell from instruction_callers whether it's a fusion computation).
Copybara import of the project:

--
90421de53c0dd0258e2bb10e236740a7ef6270e8 by Johannes Reifferscheid <jreiffers@nvidia.com>:

Remove HloComputation::CustomCallInstruction.

Step 2/5 in removing instruction_type. I think kFusion should be last,
since it's special (in that it's ""sticky"", you can't tell from
instruction_callers whether it's a fusion computation).

Merging this change closes #24023

PiperOrigin-RevId: 739174313"
tensorflow/tensorflow,jreiffers,24026,Abs operator not implemented?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora release 28
- TensorFlow installed from (source or binary): binary (conda)
- TensorFlow version (or github SHA if from source): '1.13.0-dev20181127'


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, DEPTHWISE_CONV_2D, L2_NORMALIZATION, MUL, RELU, SQUEEZE, SUB. Here is a list of operators for which you will need custom implementations: Abs.
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
","@utkarsh-VRL  Please refer [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tf_ops_compatibility.md) which gives information about supported ops by TF Lite.
Also #21526 which tracks TFLite ops to be added in future. Thanks !",closed,2018-11-28T19:35:16+00:00,2018-12-13T17:05:44+00:00,utkarsh-VRL,"stat:awaiting response, comp:lite",1,"PR#89732 - third_party/xla/xla/backends/gpu/codegen/BUILD: @@ -29,7 +29,6 @@ cc_library(|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/utils:hlo_traversal"",|;|         ""//xla/service:buffer_assignment"",|;|-        ""//xla/service:call_graph"",|;|         ""//xla/service/gpu:hlo_fusion_analysis"",|;|         ""//xla/service/gpu:ir_emission_utils"",|;|         ""//xla/service/gpu:ir_emitter_context"",|;|@@ -48,7 +47,6 @@ xla_cc_test(|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/testlib:hlo_hardware_independent_test_base"",|;|         ""//xla/hlo/testlib:verified_hlo_module"",|;|-        ""//xla/service:call_graph"",|;|         ""@com_google_absl//absl/status:statusor"",|;|         ""@com_google_absl//absl/strings"",|;|         ""@com_google_googletest//:gtest_main"", || PR#89732 - third_party/xla/xla/backends/gpu/codegen/copy.cc: @@ -29,7 +29,6 @@ limitations under the License.|;| #include ""xla/hlo/utils/hlo_traversal.h""|;| #include ""xla/literal_util.h""|;| #include ""xla/service/buffer_assignment.h""|;|-#include ""xla/service/call_graph.h""|;| #include ""xla/service/gpu/ir_emission_utils.h""|;| #include ""xla/service/gpu/ir_emitter_context.h""|;| #include ""xla/shape.h""|;|@@ -143,13 +142,13 @@ bool IsZeroOffset(const HloInstruction* slice, int dim) {|;| }|;| |;| std::vector<const HloInstruction*> GetCallStack(|;|-    const HloInstruction& instruction, const CallGraph& call_graph) {|;|+    const HloInstruction& instruction) {|;|   const HloInstruction* current = &instruction|;|;   std::vector<const HloInstruction*> stack|;|;   while (current) {|;|     stack.push_back(current)|;|; |;|-    auto callers = call_graph.GetComputationCallers(current->parent())|;|;+    auto callers = current->parent()->caller_instructions()|;|;     if (callers.size() == 1) {|;|       current = callers[0]|;|;     } else {|;|@@ -220,7 +219,7 @@ bool DynamicMemcpyFusion::IsCandidateFusion(|;| |;| std::optional<DynamicMemcpyThunk::MemcpyDescriptor>|;| DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(|;|-    const HloFusionInstruction& fusion, const CallGraph& call_graph) {|;|+    const HloFusionInstruction& fusion) {|;|   if (!IsCandidateFusion(fusion)) {|;|     return std::nullopt|;|;   }|;|@@ -235,7 +234,7 @@ DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(|;| |;|   int first_offset_index = GetFirstOffsetOperandIndex(slice)|;|;   int rank = slice_input_shape.rank()|;|;-  auto stack = GetCallStack(fusion, call_graph)|;|;+  auto stack = GetCallStack(fusion)|;|; |;|   VLOG(5) << ""Preconditions passed, trying to build a memcpy descriptor.""|;|;   DynamicMemcpyThunk::MemcpyDescriptor descriptor; || PR#89732 - third_party/xla/xla/backends/gpu/codegen/copy.h: @@ -23,7 +23,6 @@ limitations under the License.|;| #include ""xla/backends/gpu/runtime/copy_thunk.h""|;| #include ""xla/hlo/ir/hlo_instructions.h""|;| #include ""xla/service/buffer_assignment.h""|;|-#include ""xla/service/call_graph.h""|;| #include ""xla/service/gpu/hlo_fusion_analysis.h""|;| #include ""xla/service/gpu/ir_emitter_context.h""|;| |;|@@ -70,8 +69,7 @@ class DynamicMemcpyFusion : public FusionInterface {|;| |;|   // Attempts to build a memcpy descriptor for the given fusion.|;|   static std::optional<DynamicMemcpyThunk::MemcpyDescriptor>|;|-  GetMemcpyDescriptorForFusion(const HloFusionInstruction& fusion,|;|-                               const CallGraph& call_graph)|;|;+  GetMemcpyDescriptorForFusion(const HloFusionInstruction& fusion)|;|; |;|  private:|;|   const HloFusionAnalysis& analysis_; || PR#89732 - third_party/xla/xla/backends/gpu/codegen/copy_test.cc: @@ -148,9 +148,8 @@ TEST_F(CopyFusionTest, BuildSliceDescriptor) {|;|   TF_ASSERT_OK_AND_ASSIGN(auto module,|;|                           ParseAndReturnVerifiedModule(kSliceMemcpyModule))|;|; |;|-  auto call_graph = CallGraph::Build(module.get(), /*execution_threads=*/{})|;|;   auto descriptor = DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(|;|-      GetFusion(module.get()), *call_graph)|;|;+      GetFusion(module.get()))|;|; |;|   ASSERT_TRUE(descriptor.has_value())|;|;   ASSERT_THAT(descriptor->src_dynamic_offsets, ::testing::SizeIs(1))|;|;@@ -214,9 +213,8 @@ TEST_F(CopyFusionTest, BuildUpdateSliceDescriptor) {|;|   TF_ASSERT_OK_AND_ASSIGN(|;|       auto module, ParseAndReturnVerifiedModule(kUpdateSliceMemcpyModule))|;|; |;|-  auto call_graph = CallGraph::Build(module.get(), /*execution_threads=*/{})|;|;   auto descriptor = DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(|;|-      GetFusion(module.get()), *call_graph)|;|;+      GetFusion(module.get()))|;|; |;|   ASSERT_TRUE(descriptor.has_value())|;|;   EXPECT_THAT(descriptor->src_dynamic_offsets, ::testing::IsEmpty()); || PR#89732 - third_party/xla/xla/backends/gpu/codegen/fusions.cc: @@ -68,7 +68,7 @@ std::optional<std::unique_ptr<FusionInterface>> HloFusionInfo::GetCopyFusion()|;|     }|;| |;|     auto dynamic_memcpy =|;|-        DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(*instr_, call_graph_)|;|;+        DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(*instr_)|;|;     if (dynamic_memcpy) {|;|       return std::make_unique<DynamicMemcpyFusion>(|;|           analysis(), buffer_assignment_, std::move(*dynamic_memcpy)); || PR#89732 - third_party/xla/xla/service/gpu/transforms/fusion_dynamic_memcpy_rewriter.cc: @@ -42,26 +42,14 @@ absl::StatusOr<bool> FusionDynamicMemcpyRewriter::Run(|;|     const absl::flat_hash_set<absl::string_view>& execution_threads) {|;|   bool has_changed = false|;|; |;|-  std::unique_ptr<CallGraph> call_graph = nullptr|;|;-|;|   for (HloComputation* computation : module->computations(execution_threads)) {|;|     if (!computation->IsFusionComputation()) {|;|       continue|;|;     }|;| |;|     HloFusionInstruction* fusion =|;|         ::xla::Cast<HloFusionInstruction>(computation->FusionInstruction())|;|;-    if (!DynamicMemcpyFusion::IsCandidateFusion(*fusion)) {|;|-      continue|;|;-    }|;|-|;|-    // Lazily build the call graph if we find a candidate fusion.|;|-    if (!call_graph) {|;|-      call_graph = CallGraph::Build(module, execution_threads)|;|;-    }|;|-|;|-    if (DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(*fusion,|;|-                                                          *call_graph)) {|;|+    if (DynamicMemcpyFusion::GetMemcpyDescriptorForFusion(*fusion)) {|;|       TF_ASSIGN_OR_RETURN(auto backend_config,|;|                           fusion->backend_config<GpuBackendConfig>())|;|;       backend_config.mutable_fusion_backend_config()->set_kind(","PR #24026: Remove call graph from copy fusion logic.

Imported from GitHub PR https://github.com/openxla/xla/pull/24026

Now that we have a call graph in HloComputation, we no longer need this.
Copybara import of the project:

--
167541256865b05a9239bc37f9ff10c2f8da446a by Johannes Reifferscheid <jreiffers@nvidia.com>:

Remove call graph from copy fusion logic.

Now that we have a call graph in HloComputation, we no longer need this.

Merging this change closes #24026

PiperOrigin-RevId: 739149098"
tensorflow/tensorflow,apivovarov,23056,Losses collection is not thread local so it can't be used inside model_fn call when using MirroredStrategy,"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 'v1.12.0-rc0-0-g1a6dea3' 1.12.0-rc0
- Python version: 3.6
- Bazel version (if compiling from source): 0.18.0
- GCC/Compiler version (if compiling from source): gcc-6 (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
- CUDA/cuDNN version: 10.0/7.3.1.20
- GPU model and memory: GeForce GTX 1080 Ti (11GB)

**Describe the current behavior**

When calling `tf.losses.add_loss` inside model_fn in Estimator API, it is added to the `tf.GraphKeys.LOSSES` collection. `tf.losses.get_total_loss` is aggregating all the losses from the `tf.GraphKeys.LOSSES` collection.

Unfortunately, when using `tf.contrib.distribute.MirroredStrategy` as a distribute strategy, collection is updated from all concurrent `model_fn` calls. This leads to tower losses being aggregated to total loss in other towers as well.

So if we have 4 GPUs with losses L1, L2, L3, L4, Estimator will report total loss as `a * L1 + b * L2 + c * L3 + d* L4` where a,b,c,d depends on the races encountered.

**Describe the expected behavior**

I would expect total loss to be `L1 + L2 + L3 + L4`.

**Code to reproduce the issue**

When running this code, second call to `model_fn` causes assertion that losses collection is empty to fail.

```python
import tensorflow as tf


def model_fn(features, labels, mode):
    loss = tf.abs(features + tf.get_variable('foo', shape=()) - labels)

    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0
    tf.losses.add_loss(loss)

    loss = tf.losses.get_total_loss()
    train_op = tf.train.GradientDescentOptimizer(0.0).minimize(loss)
    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)


def input_fn():
    return tf.data.Dataset.zip((
        tf.data.Dataset.from_tensors(0.).repeat(100),
        tf.data.Dataset.from_tensors(0.).repeat(100)
    ))


distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=2)
config = tf.estimator.RunConfig(train_distribute=distribution)
estimator = tf.estimator.Estimator(model_fn=model_fn, config=config)
estimator.train(input_fn=input_fn)
```


**Other info / logs**

Script output:

```
INFO:tensorflow:Initializing RunConfig with distribution strategies.
INFO:tensorflow:Not using Distribute Coordinator.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpq6v9w4nh
INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpq6v9w4nh', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f27bd939240>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f27bd939f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0
INFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:2
INFO:tensorflow:Device is available but not used by distribute strategy: /device:GPU:3
INFO:tensorflow:Configured nccl all-reduce.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Error reported to Coordinator: 
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 795, in run
    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py"", line 1195, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""<ipython-input-9-57173fdb3adc>"", line 7, in model_fn
    assert len(tf.get_collection(tf.GraphKeys.LOSSES)) == 0
AssertionError
```
","Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Exact command to reproduce || @seemuch  Any update ? || Nothing to update for now. 
I did not have the bandwidth to deal with this yet.  || Any updates on this? || Unfortunately we are focus on 2.0 and Keras integration currently, so will not have the bandwidth to fix 1.x / Estimator issues. I will open this up for contributions if anyone would like to pitch in. || Hi, Could you please migrate from Estimator to Keras API which will enable you to perform the aforementioned tasks, such as [model building](https://www.tensorflow.org/guide/keras/custom_layers_and_models), gradient application, [training](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit), evaluation, and prediction.
Refer Migration guide here https://www.tensorflow.org/guide/migrate/migrating_estimator for more details. Thanks! || This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.
 || Closing as stale. Please reopen if you'd like to work on this further.
",closed,2018-10-17T22:06:01+00:00,2022-12-17T22:12:20+00:00,antifriz,"stat:awaiting response, stale, comp:dist-strat",1,"PR#89726 - third_party/xla/xla/hlo/evaluator/hlo_evaluator.cc: @@ -318,11 +318,11 @@ std::optional<ParamIndexAndValue> TryParsingInstructionAsParameterAndInteger(|;|   }|;|   std::optional<DynamicOrStaticInteger> integer_value =|;|       GetInstructionValueAsInteger(instruction, precomputed_analyses)|;|;-  result.value = std::move(integer_value)|;|;+  result.value = integer_value|;|;   if (!result.IsValid()) {|;|     return std::nullopt|;|;   }|;|-  return std::optional<ParamIndexAndValue>(std::move(result))|;|;+  return result|;|; }|;| |;| // Represents the while loop condition comparison.|;|@@ -377,8 +377,7 @@ std::optional<WhileCondComparisonOrNoOp> PatternMatchLoopCondComparison(|;|   if (!lhs.has_value() || !rhs.has_value()) {|;|     return std::nullopt|;|;   }|;|-  return WhileCondComparison{comparison->comparison_direction(),|;|-                             *std::move(lhs), *std::move(rhs)}|;|;+  return WhileCondComparison{comparison->comparison_direction(), *lhs, *rhs}|;|; }|;| // Finds the while loop condition comparison by matching the loop condition root|;| // with known patterns.|;|@@ -1707,7 +1706,7 @@ absl::Status HloEvaluator::HandleTuple(const HloInstruction* tuple) {|;|     CHECK(new_result.IsDetermined(visitor_shape_index_))|;|;     Literal literal|;|;     TF_RETURN_IF_ERROR(|;|-        literal.CopyFrom(std::move(new_result),|;|+        literal.CopyFrom(new_result,|;|                          /*dest_shape_index=*/visitor_shape_index_,|;|                          /*src_shape_index=*/visitor_shape_index_))|;|;     SetEvaluatedLiteralFor(tuple, std::move(literal)); || PR#89726 - third_party/xla/xla/stream_executor/kernel.h: @@ -220,9 +220,7 @@ class Kernel {|;|       ThreadDim threads, size_t dynamic_shared_memory_bytes) const = 0|;|; |;|   const KernelMetadata &metadata() const { return metadata_; }|;|-  void set_metadata(KernelMetadata metadata) {|;|-    metadata_ = std::move(metadata)|;|;-  }|;|+  void set_metadata(KernelMetadata metadata) { metadata_ = metadata; }|;| |;|   const KernelArgsPacking &args_packing() const { return args_packing_; }|;|   void set_args_packing(KernelArgsPacking args_packing) {","PR #23056: Remove std::move for trivially copyable types

Imported from GitHub PR https://github.com/openxla/xla/pull/23056

Changes:
- Removed unnecessary std::move calls for some trivially_copyable classes
- Literal::CopyFrom expects a reference (&), not an r-value reference (&&). Removed std::move on the first parameter.

Copybara import of the project:

--
6051f15383d63210c313ab712eaa3a00c7b0105f by Alexander Pivovarov <pivovaa@amazon.com>:

Remove std::move for trivially copyable types

Merging this change closes #23056

PiperOrigin-RevId: 739114605"
tensorflow/tensorflow,yliu120,23964,Math ops with Tensorflow Lite C++ and Android NDK,"I have successfully installed Tensorflow Lite (C++/so) into an Android product (NDK). I'm looking for the tensorflow math operations, do they exist in tensorflow lite? Or is the sole purpose of tensorflow lite to run inference on models? I also can't seem to find array_ops.h in the tensorflow repository, is this cross complied from some other language?

TLDR: Does tensorflow lite lack math ops and in order to use them you need the full tensorflow?","In short, YES and NO, there are some math ops in TF Lite. And, no, there is no full tensorflow on Android (as far as I can remember previous TensorFlow Mobile is a subset of TF). For those ops not directly supported by TF Lite you can use something like [flex](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/flexl) in TFLite to use TF ops. Check this [doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/using_select_tf_ops.md) for flex and thie one for  [op list](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tf_ops_compatibility.md) || Closing this issue since explanation given by @freedomtan is correct. Feel free to reopen the issue if have any follow up questions. Thanks! || Are you satisfied with the resolution of your issue?
[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)
[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)",closed,2018-11-26T02:38:00+00:00,2018-12-03T22:51:58+00:00,zimenglyu,"stat:awaiting response, type:support, comp:lite",1,"PR#89677 - third_party/xla/xla/service/call_inliner.cc: @@ -185,19 +185,6 @@ bool InlineInstruction(HloInstruction* instruction) {|;|   return true|;|; }|;| |;|-bool InlineStreamAnnotation(HloInstruction* instruction) {|;|-  if (instruction->GetModule()|;|-          ->config()|;|-          .debug_options()|;|-          .xla_gpu_experimental_stream_annotation()) {|;|-    if (instruction->frontend_attributes().map().contains(|;|-            kXlaStreamAnnotationAttr)) {|;|-      return false|;|;-    }|;|-  }|;|-  return true|;|;-}|;|-|;| }  // namespace|;| |;| /* static */ absl::StatusOr<CallInliner::InlinedInstructionMap>|;|@@ -247,12 +234,19 @@ CallInliner::Inline(HloInstruction* call) {|;| }|;| |;| bool CallInliner::IsInlineableCallOp(HloInstruction* instruction) const {|;|-  return instruction->opcode() == HloOpcode::kCall &&|;|-         !instruction->has_backend_config() &&|;|-         !instruction->parent()->IsAsyncComputation() &&|;|-         InlineInstruction(instruction) && InlineUnderShardy(instruction) &&|;|-         InlineComposites(instruction, composites_to_preserve_) &&|;|-         InlineStreamAnnotation(instruction)|;|;+  bool prerequisite = instruction->opcode() == HloOpcode::kCall &&|;|+                      !instruction->has_backend_config() &&|;|+                      !instruction->parent()->IsAsyncComputation()|;|;+  if (!prerequisite) {|;|+    return false|;|;+  }|;|+  if (!InlineInstruction(instruction)) {|;|+    // Always prioritize user's explicit requests after fulfilling the|;|+    // prerequisites.|;|+    return false|;|;+  }|;|+  return InlineUnderShardy(instruction) &&|;|+         InlineComposites(instruction, composites_to_preserve_)|;|; }|;| |;| absl::StatusOr<bool> CallInliner::Run( || PR#89677 - third_party/xla/xla/service/call_inliner_test.cc: @@ -522,59 +522,6 @@ TEST_F(CallInlinerTest, UseShardManualComputationBodySurroundedNotInlined) {|;|             ""my_model.___call__.fwd.xla.sdy.manual_computation_body_14.1234"")|;|; }|;| |;|-TEST_F(CallInlinerTest, DontInlineStreamAnnotationCall) {|;|-  const absl::string_view hlo_string = R""(|;|-  HloModule composite|;|-|;|-  %add (lhs: f32[]) -> f32[] {|;|-    %lhs = f32[] parameter(0)|;|-    %rhs = f32[] constant(2)|;|-    ROOT %add = f32[] add(f32[] %lhs, f32[] %rhs)|;|-  }|;|-|;|-  %sub (lhs: f32[]) -> f32[] {|;|-    %lhs = f32[] parameter(0)|;|-    %rhs = f32[] constant(1)|;|-    ROOT %sub = f32[] subtract(f32[] %lhs, f32[] %rhs)|;|-  }|;|-|;|-  ENTRY %main () -> f32[] {|;|-    %lhs = f32[] constant(42)|;|-    %call1 = f32[] call(f32[] %lhs), to_apply=%sub, frontend_attributes={_xla_stream_annotation=""1""}|;|-    ROOT %call2 = f32[] call(f32[] %call1), to_apply=%add|;|-  })""|;|;-|;|-  auto debug_options = HloTestBase::GetDebugOptionsForTest()|;|;-  debug_options.set_xla_gpu_experimental_stream_annotation(true)|;|;-  auto module = ParseAndReturnVerifiedModule(hlo_string).value()|;|;-  module->mutable_config().set_debug_options(debug_options)|;|;-  CallInliner call_inliner(/*single_call_site=*/true)|;|;-|;|-  TF_ASSERT_OK_AND_ASSIGN(bool mutated, call_inliner.Run(module.get()))|;|;-  absl::StatusOr<bool> filecheck_result = RunFileCheck(module->ToString({}), R""(|;|-  //CHECK: %lhs.2 = f32[] constant(42)|;|-  //CHECK: %call1 = f32[] call(%lhs.2), to_apply=%sub, frontend_attributes={_xla_stream_annotation=""1""}|;|-  //CHECK: %rhs.2 = f32[] constant(2)|;|-  //CHECK: ROOT %add.1 = f32[] add(%call1, %rhs.2)|;|-  )"")|;|;-  TF_ASSERT_OK(filecheck_result.status())|;|;-  EXPECT_TRUE(*filecheck_result)|;|;-|;|-  ASSERT_TRUE(mutated)|;|;-  ASSERT_EQ(module->entry_computation()->instruction_count(), 4)|;|;-  auto inst = module->entry_computation()->instructions().begin()|;|;-  EXPECT_THAT(*inst, op::Constant())|;|;-  // Check that the annotated call isn't inlined|;|-  ++inst|;|;-  EXPECT_THAT(*inst, op::Call())|;|;-|;|-  // Check that the non-annotated call is still inlined|;|-  ++inst|;|;-  EXPECT_THAT(*inst, op::Constant())|;|;-  ++inst|;|;-  EXPECT_THAT(*inst, op::Add())|;|;-}|;|-|;| TEST_F(CallInlinerTest, ControlDepsPropagateToRootOfInlinedInstructions) {|;|   const char* hlo = R""(|;|   HloModule test","PR #23964: Cleans up call inliner in the XLA shared code path

Imported from GitHub PR https://github.com/openxla/xla/pull/23964

1. Remove all the GPU-specific logic inside Call inliner.
2. Rewrite the IsInlineableCallOp to make the code more readable and less error-prone. The previous impl has some implicit priorities between all the checks and leads to bug.
3. Removes the test for stream annotation.

Discussed with @yashk2810 , actually now we have two controls over the `compute_on` boxes from JAX. The flag in XLA `xla_gpu_experimental_stream_annotation` seems to be confusing and we should remove that.

Because the control is explicitly placed in JAX, but users will get confused if there is another flag to control this.
Copybara import of the project:

--
1ee6a74ec622d2a152e52f3f3e793e6a2f7af256 by Yunlong Liu <yliu120@users.noreply.github.com>:

cleanup

Merging this change closes #23964

PiperOrigin-RevId: 739113714"
tensorflow/tensorflow,dimvar,24004,systemlibs: Unbundle protobuf,"Use system_link_files for protobuf.bzl. The protobuf.bzl file is taken
verbatim from the protobuf repo. This version of protobuf.bzl will only
be used when opting into using the system version of protobuf and is off
by default.

Signed-off-by: Jason Zaman <jason@perfinion.com>

I've had this patch in the Gentoo package for TF for the last several versions and not had any issues reported.
@gunan @angersson for review","Cool, it got merged without any problems. Thanks!",closed,2018-11-27T14:31:50+00:00,2018-12-05T21:51:20+00:00,perfinion,"cla: yes, ready to pull",1,"PR#89690 - third_party/xla/xla/service/gpu/gpu_prim.h: @@ -27,8 +27,6 @@ limitations under the license, the license you must see.|;| #include ""cub/device/device_segmented_radix_sort.cuh""|;| #include ""cub/device/device_segmented_reduce.cuh""|;| #include ""cub/device/device_select.cuh""|;|-#include ""cub/iterator/counting_input_iterator.cuh""|;|-#include ""cub/iterator/transform_input_iterator.cuh""|;| #include ""cub/thread/thread_operators.cuh""|;| #include ""cub/warp/warp_reduce.cuh""|;| #include ""third_party/gpus/cuda/include/cusparse.h""","PR #24004: Remove unused cub headers.

Imported from GitHub PR https://github.com/openxla/xla/pull/24004

Copybara import of the project:

--
0fd44aef3e904b4c0080fc15ecec14a51ac90752 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Remove unused cub headers.

Merging this change closes #24004

PiperOrigin-RevId: 739109352"
tensorflow/tensorflow,Tixxx,23793,Tensorflow exception no module found with pyspark,"When I run a program with tensorflow an pyspark together with spark-submit sample.py it says no module named tensorflow but when I run activate tensorflow and run with python sample.py it says no module named pyspark.

import tensorflow as tf

import pyspark # only run after findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

df = spark.sql('''select 'spark' as hello ''')

df.show()","Just want to check. Did you install pyspark on your system before importing?
> pip install pyspark || Now I have downloaded pyspark and set global variables. Installed
tensorflow using pip3 as well as anaconda but I am facing the issue

On Sat, Nov 17, 2018, 4:32 AM ymodak <notifications@github.com> wrote:

> Just want to check. Did you install pyspark on your system before
> importing?
>
> pip install pyspark
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/tensorflow/tensorflow/issues/23793#issuecomment-439554617>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ALtaV-JbY9oVyiw85LZ2dZFl9LRmzer8ks5uv0P0gaJpZM4Ylsu0>
> .
>
 || This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.

If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!
",closed,2018-11-16T08:11:11+00:00,2018-12-29T00:21:42+00:00,sudeepigntion,type:support,1,"PR#89667 - third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc: @@ -190,6 +190,11 @@ absl::Status CollectivePermuteStartThunk::Initialize(|;|                             params.executor->CreateEvent())|;|;         receiver_barrier_events_.emplace(current_id, std::move(receiver_event))|;|;       }|;|+      if (sender_barrier_events_.find(current_id) ==|;|+          sender_barrier_events_.end()) {|;|+        TF_ASSIGN_OR_RETURN(auto sender_event, params.executor->CreateEvent())|;|;+        sender_barrier_events_.emplace(current_id, std::move(sender_event))|;|;+      }|;|     }|;|     TF_ASSIGN_OR_RETURN(|;|         std::vector<DeviceBufferPair> device_buffers,|;|@@ -273,7 +278,7 @@ absl::Status CollectivePermuteStartThunk::RunCollective(|;|                                 config().replica_groups, config().group_mode))|;|; |;|     auto rendezvous_name = absl::StrFormat(|;|-        ""rendezvous of collective-permute; run_id=%d; op id:%d; ""|;|+        ""rendezvous before calling collective-permute; run_id=%d; op id:%d; ""|;|         ""num_local_participants:%d"",|;|         params.collective_params->run_id.ToInt(), config_.config.op_id,|;|         num_local_participants)|;|;@@ -293,9 +298,48 @@ absl::Status CollectivePermuteStartThunk::RunCollective(|;|     }|;|   }|;| |;|-  return ::xla::gpu::RunCollectivePermute(|;|+  auto status = ::xla::gpu::RunCollectivePermute(|;|       collectives, source_target, device_buffers, stream, comm_handle.comm,|;|       device_string, current_id, use_memcpy, recv_ptr_map_)|;|;+|;|+  if (use_memcpy) {|;|+    std::optional<int64_t> source_id = source_target.source|;|;+    std::optional<int64_t> target_id = source_target.target|;|;+    // After the memcpy p2p is dispatched, the receiver needs to|;|+    // wait for the sender's event before proceeding to ensure|;|+    // data has been copied.|;|+    if (target_id) {|;|+      absl::MutexLock lock(&barrier_mutex_)|;|;+      auto sender_event = sender_barrier_events_.find(current_id)|;|;+      TF_RETURN_IF_ERROR(stream.RecordEvent(sender_event->second.get()))|;|;+    }|;|+    TF_ASSIGN_OR_RETURN(|;|+        size_t num_local_participants,|;|+        GetNumLocalParticipants(*params.collective_params,|;|+                                config().replica_groups, config().group_mode))|;|;+|;|+    auto rendezvous_name = absl::StrFormat(|;|+        ""rendezvous after calling collective-permute; run_id=%d; op id:%d; ""|;|+        ""num_local_participants:%d"",|;|+        params.collective_params->run_id.ToInt(), config_.config.op_id,|;|+        num_local_participants)|;|;+    auto rendezvous_key = CallRendezvousKey{params.collective_params->run_id}|;|;+|;|+    // Perform a rendezvous to make sure all senders have their events|;|+    // recorded.|;|+    Rendezvous(rendezvous_name, rendezvous_key, num_local_participants,|;|+               /*warn_stuck_timeout=*/absl::Seconds(20),|;|+               /*terminate_timeout=*/absl::Seconds(40))|;|;+|;|+    // For receiving side, wait for the recorded event from the sending side.|;|+    if (source_id) {|;|+      absl::MutexLock lock(&barrier_mutex_)|;|;+      auto sender_event = sender_barrier_events_.find(*source_id)|;|;+      TF_RETURN_IF_ERROR(stream.WaitFor(sender_event->second.get()))|;|;+    }|;|+  }|;|+|;|+  return status|;|; }|;| |;| absl::Status RunCollectivePermute( || PR#89667 - third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.h: @@ -122,6 +122,9 @@ class CollectivePermuteStartThunk : public CollectiveThunk {|;|   absl::Mutex barrier_mutex_|;|;   absl::flat_hash_map<int64_t, std::unique_ptr<se::Event>>|;|       receiver_barrier_events_|;|;+  absl::flat_hash_map<int64_t, std::unique_ptr<se::Event>>|;|+      sender_barrier_events_|;|;+|;|   bool p2p_memcpy_enabled_ = false|;|;   int64_t device_count_|;|; }; || PR#89667 - third_party/xla/xla/tests/collective_ops_e2e_test.cc: @@ -2970,5 +2970,93 @@ ENTRY main.49 {|;|     EXPECT_TRUE(LiteralTestUtil::Near(ref_results[i], results[i], error_spec))|;|;   }|;| }|;|+|;|+TEST_F(CollectiveOpsTestE2E, MemcpyP2pLargeMessage) {|;|+  absl::string_view hlo_string = R""(|;|+HloModule MemcpyP2pLargeMessage, entry_computation_layout={(bf16[1024,64000]{1,0})->bf16[1024,64000]{1,0}}, num_partitions=4|;|+|;|+ENTRY main {|;|+  Arg_0.5 = bf16[1024,64000]{1,0} parameter(0)|;|+  collective-permute.0 = bf16[1024,64000]{1,0} collective-permute(Arg_0.5), channel_id=1, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+  collective-permute.1 = bf16[1024,64000]{1,0} collective-permute(collective-permute.0), channel_id=2, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.2 = bf16[1024,64000]{1,0} collective-permute(collective-permute.1), channel_id=3, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.3 = bf16[1024,64000]{1,0} collective-permute(collective-permute.2), channel_id=4, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.4 = bf16[1024,64000]{1,0} collective-permute(collective-permute.3), channel_id=5, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.5 = bf16[1024,64000]{1,0} collective-permute(collective-permute.4), channel_id=6, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.6 = bf16[1024,64000]{1,0} collective-permute(collective-permute.5), channel_id=7, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+  collective-permute.7 = bf16[1024,64000]{1,0} collective-permute(collective-permute.6), channel_id=8, source_target_pairs={{0,3},{1,0},{2,1},{3,2}}|;|+|;|+  constant.0 = bf16[] constant(2)|;|+  broadcast.0 = bf16[1024,64000]{1,0} broadcast(constant.0), dimensions={}|;|+  collective-permute.8 = bf16[1024,64000]{1,0} collective-permute(broadcast.0), channel_id=6, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+  collective-permute.9 = bf16[1024,64000]{1,0} collective-permute(collective-permute.8), channel_id=9, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+  collective-permute.10 = bf16[1024,64000]{1,0} collective-permute(collective-permute.9), channel_id=10, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+  collective-permute.11 = bf16[1024,64000]{1,0} collective-permute(collective-permute.10), channel_id=11, source_target_pairs={{0,1},{1,2},{2,3},{3,0}}|;|+|;|+  ROOT multiply.10 = bf16[1024,64000]{1,0} multiply(collective-permute.7, collective-permute.11)|;|+} // main|;|+)""|;|;+|;|+  const int64_t kNumReplicas = 1|;|;+  const int64_t kNumPartitions = 4|;|;+  if (test_runner().device_count() < kNumReplicas * kNumPartitions) {|;|+    GTEST_SKIP() << ""Test requires at least "" << kNumReplicas * kNumPartitions|;|+                 << "" devices ("" << test_runner().device_count()|;|+                 << "" available)""|;|;+  }|;|+|;|+  HloModuleConfig config = GetModuleConfigForTest(kNumReplicas, kNumPartitions)|;|;+  auto opts = GetDebugOptionsForTest()|;|;+  opts.set_xla_gpu_use_memcpy_local_p2p(true)|;|;+  opts.add_xla_disable_hlo_passes(""gpu-convert-async-collectives-to-sync"")|;|;+|;|+  config.set_debug_options(opts)|;|;+  config.set_use_spmd_partitioning(false)|;|;+  TF_ASSERT_OK_AND_ASSIGN(auto module,|;|+                          ParseAndReturnVerifiedModule(hlo_string, config))|;|;+  auto fake_arguments = xla::MakeFakeArguments(module.get()).value()|;|;+  std::vector<Literal*> fake_ptrs(fake_arguments.size())|;|;+  for (int i = 0; i < fake_arguments.size(); ++i) {|;|+    fake_ptrs[i] = &fake_arguments[i]|;|;+  }|;|+  HloModuleConfig ref_config =|;|+      GetModuleConfigForTest(kNumReplicas, kNumPartitions)|;|;+  auto ref_opts = GetDebugOptionsForTest()|;|;+  ref_opts.set_xla_gpu_use_memcpy_local_p2p(false)|;|;+  ref_config.set_debug_options(ref_opts)|;|;+  TF_ASSERT_OK_AND_ASSIGN(auto ref_module,|;|+                          ParseAndReturnVerifiedModule(hlo_string, ref_config))|;|;+  auto fake_ref_arguments = xla::MakeFakeArguments(ref_module.get()).value()|;|;+  std::vector<Literal*> ref_fake_ptrs(fake_ref_arguments.size())|;|;+  for (int i = 0; i < fake_ref_arguments.size(); ++i) {|;|+    ref_fake_ptrs[i] = &fake_ref_arguments[i]|;|;+  }|;|+|;|+  DeviceAssignment assn(/*replica_count=*/kNumReplicas,|;|+                        /*computation_count=*/kNumPartitions)|;|;+  for (int64_t i = 0; i < kNumPartitions; ++i) {|;|+    assn(0, i) = i|;|;+  }|;|+|;|+  TF_ASSERT_OK_AND_ASSIGN(|;|+      std::vector<Literal> results,|;|+      HloTestBase::ExecuteReplicated(|;|+          std::move(module), fake_ptrs, kNumPartitions, &assn,|;|+          /*run_hlo_passes=*/true, /*use-threads=*/true))|;|;+  ASSERT_EQ(results.size(), kNumPartitions)|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(|;|+      std::vector<Literal> ref_results,|;|+      HloTestBase::ExecuteReplicated(|;|+          std::move(ref_module), ref_fake_ptrs, kNumPartitions, &assn,|;|+          /*run_hlo_passes=*/true, /*use-threads=*/true))|;|;+  ASSERT_EQ(ref_results.size(), kNumPartitions)|;|;+  ErrorSpec error_spec{1e-5, 1e-5}|;|;+  // Expect same results with and without pipelining of collectives.|;|+  for (int i = 0; i < kNumPartitions; ++i) {|;|+    EXPECT_TRUE(LiteralTestUtil::Near(ref_results[i], results[i], error_spec))|;|;+  }|;|+}|;|+|;| }  // namespace|;| }  // namespace xla","PR #23793: Add stream dependency after calling memcpy p2p

Imported from GitHub PR https://github.com/openxla/xla/pull/23793

Currently we have stream dependency to make sure buffers are ready before calling memcpy p2p in collective permute thunks. Post-memcpy sync using stream dep is also needed to make sure all data has been fully written before receiving rank consumes it.
Copybara import of the project:

--
151cf3f35d0c83a11c5929d8040b9603b20ecb7c by TJ Xu <tjx@nvidia.com>:

Add stream dependency after calling memcpy p2p

--
3a8a64369ceb4059b6eb8a455dedbe1c02508088 by TJ Xu <tjx@nvidia.com>:

add a test to reproduce a numeric error

Merging this change closes #23793

PiperOrigin-RevId: 739090824"
tensorflow/tensorflow,jiunkaiy,89210,Qualcomm AI Engine Direct - Provide op optimization,"Summary:
- Support FC->CONV2D optimization
- Add CONV2D op builder with CPU transpose

Test:
- [x] a8w8 Gemma3 compile and execution successfully
- [x] qnn_compiler_plugin_test all pass","Any test results? || > Any test results?

I have left some comments in the first conversation block. Thanks!",closed,2025-03-14T07:08:28+00:00,2025-03-20T18:38:29+00:00,jiunkaiy,"awaiting review, ready to pull, size:L",1,"PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/BUILD: @@ -133,6 +133,7 @@ litert_lib(|;|         ""//tensorflow/lite/experimental/litert/tools:dump"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm:common"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm:qnn_manager"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:common"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:tensor_pool"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:cast_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:concatenation_op_builder"",|;|@@ -142,6 +143,7 @@ litert_lib(|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:elementwise_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:embedding_lookup_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:fully_connected_op_builder"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:fully_connected_op_builder_htp"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:gather_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:gelu_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:hard_swish_op_builder"", || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc: @@ -18,7 +18,9 @@|;| #include <stdbool.h>|;| #include <stdio.h>|;| |;|+#include <algorithm>|;| #include <cstdint>|;|+#include <iterator>|;| #include <sstream>|;| #include <string>|;| #include <vector>|;|@@ -48,6 +50,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/elementwise_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/embedding_lookup_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/gather_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/gelu_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/hard_swish_op_builder.h""|;|@@ -69,6 +72,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/split_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/tanh_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/transpose_op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|@@ -344,8 +348,16 @@ LiteRtStatus ConvertOp(|;|       bool keep_num_dims{}|;|;       LITERT_RETURN_IF_ERROR(LiteRtGetFullyConnectedKeepNumDimsOption(|;|           litert_op.Get(), &keep_num_dims))|;|;-      op_wrappers = ::qnn::BuildFullyConnectedOp(tensor_pool, input_tensors,|;|-                                                 output_tensors, keep_num_dims)|;|;+      // TODO(jiunkaiy): Use compile interface to get useHtpPreferencs.|;|+      constexpr LiteRtQnnOptions qnn_options = LITERT_QNN_OPTIONS_INIT|;|;+      if (qnn_options.useHtpPreferencs) {|;|+        op_wrappers = ::qnn::BuildFullyConnectedOpHtp(|;|+            tensor_pool, input_tensors, output_tensors, keep_num_dims)|;|;+      }|;|+      if (op_wrappers.empty()) {|;|+        op_wrappers = ::qnn::BuildFullyConnectedOp(|;|+            tensor_pool, input_tensors, output_tensors, keep_num_dims)|;|;+      }|;|       break|;|;     }|;|     case LiteRtOpCode::kLiteRtOpCodeTflGather: { || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/BUILD: @@ -21,6 +21,25 @@ cc_library(|;|     ],|;| )|;| |;|+cc_library(|;|+    name = ""fully_connected_op_builder_htp"",|;|+    srcs = [""fully_connected_op_builder_htp.cc""],|;|+    hdrs = [""fully_connected_op_builder_htp.h""],|;|+    tags = [|;|+        # Don't build/test in OS until qnn is available.|;|+        ""nobuilder"",|;|+    ],|;|+    deps = [|;|+        "":op_builder"",|;|+        # copybara:uncomment ""//third_party/qairt/latest:qnn_lib_headers"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:tensor_pool"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:log"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:op_wrapper"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:quantize_params_wrapper"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:tensor_wrapper"",|;|+    ],|;|+)|;|+|;| cc_library(|;|     name = ""elementwise_op_builder"",|;|     srcs = [""elementwise_op_builder.cc""], || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/conv2d_op_builder.cc: @@ -41,7 +41,10 @@ std::vector<OpWrapper> BuildConv2dOp(|;| |;|   // transpose filter|;|   TensorWrapper& filter_tensor = inputs[kFilterIndex]|;|;+  const std::vector<uint32_t>& filters_dims = filter_tensor.GetDims()|;|;   auto& filter_quant_params = filter_tensor.GetQuantParams()|;|;+  std::vector<std::uint32_t> permute_dims{filters_dims[1], filters_dims[2],|;|+                                          filters_dims[3], filters_dims[0]}|;|;   if (std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|           filter_quant_params)) {|;|     auto& axis_quant_params =|;|@@ -50,30 +53,51 @@ std::vector<OpWrapper> BuildConv2dOp(|;|     axis_quant_params.SetAxis(new_axis[axis_quant_params.GetAxis()])|;|;   }|;| |;|-  const std::vector<std::uint32_t> permute_dims{|;|-      filter_tensor.GetDim(kHeightIndex), filter_tensor.GetDim(kWidthIndex),|;|-      filter_tensor.GetDim(kChannelIndex), filter_tensor.GetDim(kBatchIndex)}|;|;-  auto& transposed_filter_tensor =|;|-      tensor_pool.CloneNativeTensorFrom(filter_tensor, permute_dims)|;|;-|;|-  const std::vector<std::uint32_t> permute_shape{4}|;|;-  const std::array<std::uint32_t, 4> permute_data{kHeightIndex, kWidthIndex,|;|-                                                  kChannelIndex, kBatchIndex}|;|;-  auto& permute_tensor = tensor_pool.CreateStaticTensor(|;|-      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, permute_shape,|;|-      sizeof(decltype(permute_data)::value_type) * permute_data.size(),|;|-      permute_data.data())|;|;-|;|-  OpWrapper& transpose_op = CreateOpWrapper(res, QNN_OP_TRANSPOSE)|;|;-  transpose_op.AddInputTensor(filter_tensor)|;|;-  transpose_op.AddOutputTensor(transposed_filter_tensor)|;|;-  transpose_op.AddTensorParam(QNN_OP_TRANSPOSE_PARAM_PERM, permute_tensor)|;|;+  size_t filter_bytes = filter_tensor.GetTensorBytes()|;|;+  TensorWrapper* transposed_filter_tensor = nullptr|;|;+  if (filter_tensor.IsTensorStatic() &&|;|+      filter_tensor.GetDataType() ==|;|+          Qnn_DataType_t::QNN_DATATYPE_SFIXED_POINT_8) {|;|+    auto filter_data = filter_tensor.GetStaticTensorData<std::int8_t>()|;|;+    std::vector<int8_t> transpose_weight_int8|;|;+    TransposeFromOHWIToHWIO(filter_data.value(), filters_dims,|;|+                            transpose_weight_int8)|;|;+    transposed_filter_tensor = &(tensor_pool.CreateStaticTensor(|;|+        filter_tensor.GetDataType(), filter_quant_params, permute_dims,|;|+        filter_bytes, transpose_weight_int8.data()))|;|;+  } else if (filter_tensor.IsTensorStatic() &&|;|+             filter_tensor.GetDataType() ==|;|+                 Qnn_DataType_t::QNN_DATATYPE_UFIXED_POINT_8) {|;|+    auto filter_data = filter_tensor.GetStaticTensorData<std::uint8_t>()|;|;+    std::vector<uint8_t> transpose_weight_uint8|;|;+    TransposeFromOHWIToHWIO(filter_data.value(), filters_dims,|;|+                            transpose_weight_uint8)|;|;+    transposed_filter_tensor = &(tensor_pool.CreateStaticTensor(|;|+        filter_tensor.GetDataType(), filter_quant_params, permute_dims,|;|+        filter_bytes, transpose_weight_uint8.data()))|;|;+  } else {|;|+    transposed_filter_tensor =|;|+        &(tensor_pool.CloneNativeTensorFrom(filter_tensor, permute_dims))|;|;+|;|+    const std::vector<std::uint32_t> permute_shape{4}|;|;+    const std::array<std::uint32_t, 4> permute_data{kHeightIndex, kWidthIndex,|;|+                                                    kChannelIndex, kBatchIndex}|;|;+    auto& permute_tensor = tensor_pool.CreateStaticTensor(|;|+        QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, permute_shape,|;|+        sizeof(decltype(permute_data)::value_type) * permute_data.size(),|;|+        permute_data.data())|;|;+|;|+    OpWrapper& transpose_op = CreateOpWrapper(res, QNN_OP_TRANSPOSE)|;|;+    transpose_op.AddInputTensor(filter_tensor)|;|;+    transpose_op.AddOutputTensor(*transposed_filter_tensor)|;|;+    transpose_op.AddTensorParam(QNN_OP_TRANSPOSE_PARAM_PERM, permute_tensor)|;|;+  }|;| |;|   // conv|;|   OpWrapper& conv_op = CreateOpWrapper(res, QNN_OP_CONV_2D)|;|;   TensorWrapper& input_tensor = inputs[kInputIndex]|;|;   conv_op.AddInputTensor(input_tensor)|;|;-  conv_op.AddInputTensor(transposed_filter_tensor)|;|;+  conv_op.AddInputTensor(*transposed_filter_tensor)|;|;   if (inputs.size() - 1 >= kBiasIndex) {|;|     TensorWrapper& bias_tensor = inputs[kBiasIndex]|;|;     // QNN only support per-tensor quant for bias, || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder.cc: @@ -24,7 +24,6 @@ std::vector<OpWrapper> BuildFullyConnectedOp(|;|     TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|     const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims) {|;|   std::vector<OpWrapper> res|;|;-|;|   OpWrapper& fully_connected_op = CreateOpWrapper(res, QNN_OP_FULLY_CONNECTED)|;|; |;|   TensorWrapper& input_tensor = inputs[0]; || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.cc: @@ -0,0 +1,132 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc.|;|+// All Rights Reserved.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h""|;|+|;|+#include <array>|;|+#include <cstddef>|;|+#include <cstdint>|;|+#include <functional>|;|+#include <variant>|;|+#include <vector>|;|+|;|+#include ""third_party/qairt/latest/include/QNN/QnnOpDef.h""|;|+#include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/tensor_pool.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|+|;|+namespace qnn {|;|+|;|+std::vector<OpWrapper> BuildFullyConnectedOpHtp(|;|+    TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|+    const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims) {|;|+  std::vector<OpWrapper> res|;|;+  QNN_LOG_INFO(""[FullyConnected Optimization] FC -> CONV2D"")|;|;+  // TFLite FC Input: [1, k, n] and Weight: [m, n]|;|+  // QNN Conv2D Input:|;|+  // [batch, height, width, channel_in]|;|+  // -> [1, 1, k, n]|;|+  // QNN Conv2D Weight:|;|+  // [filter_height, filter_width, channel_in / group, channel_out]|;|+  // -> [1, 1, n, m]|;|+  bool is_supported = inputs[0].get().GetRank() == 3 && inputs.size() == 2 &&|;|+                      inputs[1].get().IsTensorStatic()|;|;+  if (!is_supported) {|;|+    QNN_LOG_INFO(""[FullyConnected Optimization] FAILURE: Unsupported Input"")|;|;+    return res|;|;+  }|;|+|;|+  // TFLite FC -> QNN CONV2D:|;|+  // Reshape -> Conv2D -> Reshpae|;|+  TensorWrapper& input_tensor = inputs[0]|;|;+  TensorWrapper& weight_tensor = inputs[1]|;|;+  TensorWrapper& output_tensor = outputs[0]|;|;+  // Reshape|;|+  qnn::OpWrapper& reshape_op_1 = CreateOpWrapper(res, QNN_OP_RESHAPE)|;|;+  reshape_op_1.AddInputTensor(input_tensor)|;|;+  std::vector<uint32_t> conv_input_dims = input_tensor.GetDims()|;|;+  conv_input_dims.insert(conv_input_dims.begin() + 1, 1)|;|;+  qnn::TensorWrapper& conv_input_tensor =|;|+      tensor_pool.CloneNativeTensorFrom(input_tensor, conv_input_dims)|;|;+  reshape_op_1.AddOutputTensor(conv_input_tensor)|;|;+  // Conv2D Input, Weight, and Output|;|+  OpWrapper& conv_op = CreateOpWrapper(res, QNN_OP_CONV_2D)|;|;+  conv_op.AddInputTensor(conv_input_tensor)|;|;+  auto& quant_params = weight_tensor.GetQuantParams()|;|;+  if (std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|+          quant_params)) {|;|+    auto& axis_quant_param =|;|+        std::get<AxisScaleOffsetQuantizeParamsWrapper>(quant_params)|;|;+    axis_quant_param.SetAxis(3)|;|;+  }|;|+  std::vector<uint32_t> weight_dims{1, 1, weight_tensor.GetDim(1),|;|+                                    weight_tensor.GetDim(0)}|;|;+  size_t weight_bytes = weight_tensor.GetTensorBytes()|;|;+  const std::vector<std::uint32_t> transpose_dim{weight_tensor.GetDim(0), 1, 1,|;|+                                                 weight_tensor.GetDim(1)}|;|;+  TensorWrapper* weight|;|;+  if (weight_tensor.GetDataType() == QNN_DATATYPE_SFIXED_POINT_8) {|;|+    std::vector<std::int8_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::int8_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_SFIXED_POINT_16) {|;|+    std::vector<std::int16_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::int16_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_UFIXED_POINT_16) {|;|+    std::vector<std::uint16_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::uint16_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_FLOAT_32) {|;|+    std::vector<float> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<float>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else {|;|+    QNN_LOG_INFO(|;|+        ""[FullyConnected Optimization] FAILURE: Upsupported Weight Datatype"")|;|;+    return {}|;|;+  }|;|+  conv_op.AddInputTensor(*weight)|;|;+  qnn::TensorWrapper& conv_out = tensor_pool.CloneNativeTensorFrom(|;|+      output_tensor, {conv_input_dims[0], conv_input_dims[1],|;|+                      conv_input_dims[2], weight_dims[3]})|;|;+  conv_op.AddOutputTensor(conv_out)|;|;+  // Conv2D Stride|;|+  const std::array<std::uint32_t, 2> stride_data{1, 1}|;|;+  const std::vector<std::uint32_t> stride_shape{2}|;|;+  auto& stride_tensor = tensor_pool.CreateStaticTensor(|;|+      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, stride_shape,|;|+      sizeof(std::uint32_t) * stride_data.size(), stride_data.data())|;|;+  conv_op.AddTensorParam(QNN_OP_DEPTH_WISE_CONV_2D_PARAM_STRIDE, stride_tensor)|;|;+  // Conv2D Padding|;|+  const std::array<std::uint32_t, 4> padding_data = {0, 0, 0, 0}|;|;+  const std::vector<std::uint32_t> padding_shape{2, 2}|;|;+  auto& padding_tensor = tensor_pool.CreateStaticTensor(|;|+      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, padding_shape,|;|+      sizeof(std::uint32_t) * padding_data.size(), padding_data.data())|;|;+  conv_op.AddTensorParam(QNN_OP_CONV_2D_PARAM_PAD_AMOUNT, padding_tensor)|;|;+|;|+  // Reshape|;|+  qnn::OpWrapper& reshape_op_2 = CreateOpWrapper(res, QNN_OP_RESHAPE)|;|;+  reshape_op_2.AddInputTensor(conv_out)|;|;+  reshape_op_2.AddOutputTensor(output_tensor)|;|;+  return res|;|;+}|;|+|;|+}  // namespace qnn || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h: @@ -0,0 +1,21 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc.|;|+// All Rights Reserved.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_|;|+|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/tensor_pool.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|+|;|+namespace qnn {|;|+|;|+std::vector<OpWrapper> BuildFullyConnectedOpHtp(|;|+    TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|+    const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims)|;|;+|;|+}  // namespace qnn|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_ || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.cc: @@ -20,7 +20,7 @@ std::pair<std::uint32_t, std::uint32_t> ComputePaddingBeforeAfter(|;|   // padding_before, padding_after|;|   std::pair<std::uint32_t, std::uint32_t> result{0, 0}|;|;   if (stride == 0) {|;|-    // TODO: error log|;|+    QNN_LOG_ERROR(""Stride is 0"")|;|;     return result|;|;   }|;| |;|@@ -34,8 +34,8 @@ std::pair<std::uint32_t, std::uint32_t> ComputePaddingBeforeAfter(|;|     case PaddingType::Valid:|;|       output_size = (input_size + stride - effective_filter_size) / stride|;|;       break|;|;-    default:  // PaddingType::Unkown|;|-      // TODO: error log|;|+    default:  // PaddingType::Unknown|;|+      QNN_LOG_ERROR(""Unknown padding type"")|;|;       return result|;|;   }|;|  || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.h: @@ -14,7 +14,7 @@|;| namespace qnn {|;| |;| enum class PaddingType {|;|-  Unkown = 0,|;|+  Unknown = 0,|;|   Same,|;|   Valid,|;| }; || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h: @@ -18,6 +18,13 @@ typedef enum LiteRtQnnLogLevel {  // NOLINT(modernize-use-using)|;|   kLogLevelDebug = 5,|;| } LiteRtQnnLogLevel|;|; |;|+typedef struct {  // NOLINT(modernize-use-using)|;|+  /// Apply HTP-friendly op builder.|;|+  bool useHtpPreferencs|;|;+} LiteRtQnnOptions|;|;+|;|+#define LITERT_QNN_OPTIONS_INIT {false, /*useHtpPreferencs*/}|;|+|;| #ifdef __cplusplus|;| }|;| #endif  // __cplusplus || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h: @@ -48,6 +48,37 @@ inline constexpr Qnn_DataType_t GetQnnDataType(const bool is_quant) {|;| |;| std::size_t GetDataTypeSize(const Qnn_DataType_t data_type)|;|; |;|+template <typename T>|;|+void TransposeFromOHWIToHWIO(absl::Span<const T> weight_data,|;|+                             const std::vector<uint32_t>& weight_dims,|;|+                             std::vector<T>& weight_data_transpose) {|;|+  weight_data_transpose.resize(weight_data.size())|;|;+  uint32_t output = weight_dims[0]|;|;+  uint32_t height = weight_dims[1]|;|;+  uint32_t width = weight_dims[2]|;|;+  uint32_t input = weight_dims[3]|;|;+  // OHWI->HWIO|;|+  uint32_t map_o = 0|;|;+  uint32_t map_w = 0|;|;+  uint32_t map_h = 0|;|;+  for (uint32_t index_o = 0; index_o < output; index_o++) {|;|+    map_o = index_o * height * width * input|;|;+    for (uint32_t index_h = 0; index_h < height; index_h++) {|;|+      map_h = index_h * width * input|;|;+      for (uint32_t index_w = 0; index_w < width; index_w++) {|;|+        map_w = index_w * input|;|;+        for (uint32_t index_i = 0; index_i < input; index_i++) {|;|+          T inval = weight_data[map_o + map_h + map_w + index_i]|;|;+          uint32_t index_transpose = index_h * width * input * output +|;|+                                     index_w * input * output +|;|+                                     index_i * output + index_o|;|;+          weight_data_transpose[index_transpose] = inval|;|;+        }|;|+      }|;|+    }|;|+  }|;|+}|;|+|;| class TensorWrapper final {|;|   friend class TensorPool|;|; ","Qualcomm AI Engine Direct - Op optimization

Summary:
- Support FC->CONV2D optimization
- Add CONV2D op builder with CPU transpose || Merge pull request #89210 from jiunkaiy:dev/jiunkaiy/gemma2_fc

PiperOrigin-RevId: 738878336"
tensorflow/tensorflow,tensorflower-gardener,89210,Qualcomm AI Engine Direct - Provide op optimization,"Summary:
- Support FC->CONV2D optimization
- Add CONV2D op builder with CPU transpose

Test:
- [x] a8w8 Gemma3 compile and execution successfully
- [x] qnn_compiler_plugin_test all pass","Any test results? || > Any test results?

I have left some comments in the first conversation block. Thanks!",closed,2025-03-14T07:08:28+00:00,2025-03-20T18:38:29+00:00,jiunkaiy,"awaiting review, ready to pull, size:L",1,"PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/BUILD: @@ -133,6 +133,7 @@ litert_lib(|;|         ""//tensorflow/lite/experimental/litert/tools:dump"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm:common"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm:qnn_manager"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:common"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:tensor_pool"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:cast_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:concatenation_op_builder"",|;|@@ -142,6 +143,7 @@ litert_lib(|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:elementwise_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:embedding_lookup_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:fully_connected_op_builder"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:fully_connected_op_builder_htp"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:gather_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:gelu_op_builder"",|;|         ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders:hard_swish_op_builder"", || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc: @@ -18,7 +18,9 @@|;| #include <stdbool.h>|;| #include <stdio.h>|;| |;|+#include <algorithm>|;| #include <cstdint>|;|+#include <iterator>|;| #include <sstream>|;| #include <string>|;| #include <vector>|;|@@ -48,6 +50,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/elementwise_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/embedding_lookup_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/gather_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/gelu_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/hard_swish_op_builder.h""|;|@@ -69,6 +72,7 @@|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/split_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/tanh_op_builder.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/transpose_op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;| #include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|@@ -344,8 +348,16 @@ LiteRtStatus ConvertOp(|;|       bool keep_num_dims{}|;|;       LITERT_RETURN_IF_ERROR(LiteRtGetFullyConnectedKeepNumDimsOption(|;|           litert_op.Get(), &keep_num_dims))|;|;-      op_wrappers = ::qnn::BuildFullyConnectedOp(tensor_pool, input_tensors,|;|-                                                 output_tensors, keep_num_dims)|;|;+      // TODO(jiunkaiy): Use compile interface to get useHtpPreferencs.|;|+      constexpr LiteRtQnnOptions qnn_options = LITERT_QNN_OPTIONS_INIT|;|;+      if (qnn_options.useHtpPreferencs) {|;|+        op_wrappers = ::qnn::BuildFullyConnectedOpHtp(|;|+            tensor_pool, input_tensors, output_tensors, keep_num_dims)|;|;+      }|;|+      if (op_wrappers.empty()) {|;|+        op_wrappers = ::qnn::BuildFullyConnectedOp(|;|+            tensor_pool, input_tensors, output_tensors, keep_num_dims)|;|;+      }|;|       break|;|;     }|;|     case LiteRtOpCode::kLiteRtOpCodeTflGather: { || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/BUILD: @@ -21,6 +21,25 @@ cc_library(|;|     ],|;| )|;| |;|+cc_library(|;|+    name = ""fully_connected_op_builder_htp"",|;|+    srcs = [""fully_connected_op_builder_htp.cc""],|;|+    hdrs = [""fully_connected_op_builder_htp.h""],|;|+    tags = [|;|+        # Don't build/test in OS until qnn is available.|;|+        ""nobuilder"",|;|+    ],|;|+    deps = [|;|+        "":op_builder"",|;|+        # copybara:uncomment ""//third_party/qairt/latest:qnn_lib_headers"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core:tensor_pool"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils:log"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:op_wrapper"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:quantize_params_wrapper"",|;|+        ""//tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers:tensor_wrapper"",|;|+    ],|;|+)|;|+|;| cc_library(|;|     name = ""elementwise_op_builder"",|;|     srcs = [""elementwise_op_builder.cc""], || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/conv2d_op_builder.cc: @@ -41,7 +41,10 @@ std::vector<OpWrapper> BuildConv2dOp(|;| |;|   // transpose filter|;|   TensorWrapper& filter_tensor = inputs[kFilterIndex]|;|;+  const std::vector<uint32_t>& filters_dims = filter_tensor.GetDims()|;|;   auto& filter_quant_params = filter_tensor.GetQuantParams()|;|;+  std::vector<std::uint32_t> permute_dims{filters_dims[1], filters_dims[2],|;|+                                          filters_dims[3], filters_dims[0]}|;|;   if (std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|           filter_quant_params)) {|;|     auto& axis_quant_params =|;|@@ -50,30 +53,51 @@ std::vector<OpWrapper> BuildConv2dOp(|;|     axis_quant_params.SetAxis(new_axis[axis_quant_params.GetAxis()])|;|;   }|;| |;|-  const std::vector<std::uint32_t> permute_dims{|;|-      filter_tensor.GetDim(kHeightIndex), filter_tensor.GetDim(kWidthIndex),|;|-      filter_tensor.GetDim(kChannelIndex), filter_tensor.GetDim(kBatchIndex)}|;|;-  auto& transposed_filter_tensor =|;|-      tensor_pool.CloneNativeTensorFrom(filter_tensor, permute_dims)|;|;-|;|-  const std::vector<std::uint32_t> permute_shape{4}|;|;-  const std::array<std::uint32_t, 4> permute_data{kHeightIndex, kWidthIndex,|;|-                                                  kChannelIndex, kBatchIndex}|;|;-  auto& permute_tensor = tensor_pool.CreateStaticTensor(|;|-      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, permute_shape,|;|-      sizeof(decltype(permute_data)::value_type) * permute_data.size(),|;|-      permute_data.data())|;|;-|;|-  OpWrapper& transpose_op = CreateOpWrapper(res, QNN_OP_TRANSPOSE)|;|;-  transpose_op.AddInputTensor(filter_tensor)|;|;-  transpose_op.AddOutputTensor(transposed_filter_tensor)|;|;-  transpose_op.AddTensorParam(QNN_OP_TRANSPOSE_PARAM_PERM, permute_tensor)|;|;+  size_t filter_bytes = filter_tensor.GetTensorBytes()|;|;+  TensorWrapper* transposed_filter_tensor = nullptr|;|;+  if (filter_tensor.IsTensorStatic() &&|;|+      filter_tensor.GetDataType() ==|;|+          Qnn_DataType_t::QNN_DATATYPE_SFIXED_POINT_8) {|;|+    auto filter_data = filter_tensor.GetStaticTensorData<std::int8_t>()|;|;+    std::vector<int8_t> transpose_weight_int8|;|;+    TransposeFromOHWIToHWIO(filter_data.value(), filters_dims,|;|+                            transpose_weight_int8)|;|;+    transposed_filter_tensor = &(tensor_pool.CreateStaticTensor(|;|+        filter_tensor.GetDataType(), filter_quant_params, permute_dims,|;|+        filter_bytes, transpose_weight_int8.data()))|;|;+  } else if (filter_tensor.IsTensorStatic() &&|;|+             filter_tensor.GetDataType() ==|;|+                 Qnn_DataType_t::QNN_DATATYPE_UFIXED_POINT_8) {|;|+    auto filter_data = filter_tensor.GetStaticTensorData<std::uint8_t>()|;|;+    std::vector<uint8_t> transpose_weight_uint8|;|;+    TransposeFromOHWIToHWIO(filter_data.value(), filters_dims,|;|+                            transpose_weight_uint8)|;|;+    transposed_filter_tensor = &(tensor_pool.CreateStaticTensor(|;|+        filter_tensor.GetDataType(), filter_quant_params, permute_dims,|;|+        filter_bytes, transpose_weight_uint8.data()))|;|;+  } else {|;|+    transposed_filter_tensor =|;|+        &(tensor_pool.CloneNativeTensorFrom(filter_tensor, permute_dims))|;|;+|;|+    const std::vector<std::uint32_t> permute_shape{4}|;|;+    const std::array<std::uint32_t, 4> permute_data{kHeightIndex, kWidthIndex,|;|+                                                    kChannelIndex, kBatchIndex}|;|;+    auto& permute_tensor = tensor_pool.CreateStaticTensor(|;|+        QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, permute_shape,|;|+        sizeof(decltype(permute_data)::value_type) * permute_data.size(),|;|+        permute_data.data())|;|;+|;|+    OpWrapper& transpose_op = CreateOpWrapper(res, QNN_OP_TRANSPOSE)|;|;+    transpose_op.AddInputTensor(filter_tensor)|;|;+    transpose_op.AddOutputTensor(*transposed_filter_tensor)|;|;+    transpose_op.AddTensorParam(QNN_OP_TRANSPOSE_PARAM_PERM, permute_tensor)|;|;+  }|;| |;|   // conv|;|   OpWrapper& conv_op = CreateOpWrapper(res, QNN_OP_CONV_2D)|;|;   TensorWrapper& input_tensor = inputs[kInputIndex]|;|;   conv_op.AddInputTensor(input_tensor)|;|;-  conv_op.AddInputTensor(transposed_filter_tensor)|;|;+  conv_op.AddInputTensor(*transposed_filter_tensor)|;|;   if (inputs.size() - 1 >= kBiasIndex) {|;|     TensorWrapper& bias_tensor = inputs[kBiasIndex]|;|;     // QNN only support per-tensor quant for bias, || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder.cc: @@ -24,7 +24,6 @@ std::vector<OpWrapper> BuildFullyConnectedOp(|;|     TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|     const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims) {|;|   std::vector<OpWrapper> res|;|;-|;|   OpWrapper& fully_connected_op = CreateOpWrapper(res, QNN_OP_FULLY_CONNECTED)|;|; |;|   TensorWrapper& input_tensor = inputs[0]; || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.cc: @@ -0,0 +1,132 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc.|;|+// All Rights Reserved.|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h""|;|+|;|+#include <array>|;|+#include <cstddef>|;|+#include <cstdint>|;|+#include <functional>|;|+#include <variant>|;|+#include <vector>|;|+|;|+#include ""third_party/qairt/latest/include/QNN/QnnOpDef.h""|;|+#include ""third_party/qairt/latest/include/QNN/QnnTypes.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/tensor_pool.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/utils/log.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/quantize_params_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|+|;|+namespace qnn {|;|+|;|+std::vector<OpWrapper> BuildFullyConnectedOpHtp(|;|+    TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|+    const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims) {|;|+  std::vector<OpWrapper> res|;|;+  QNN_LOG_INFO(""[FullyConnected Optimization] FC -> CONV2D"")|;|;+  // TFLite FC Input: [1, k, n] and Weight: [m, n]|;|+  // QNN Conv2D Input:|;|+  // [batch, height, width, channel_in]|;|+  // -> [1, 1, k, n]|;|+  // QNN Conv2D Weight:|;|+  // [filter_height, filter_width, channel_in / group, channel_out]|;|+  // -> [1, 1, n, m]|;|+  bool is_supported = inputs[0].get().GetRank() == 3 && inputs.size() == 2 &&|;|+                      inputs[1].get().IsTensorStatic()|;|;+  if (!is_supported) {|;|+    QNN_LOG_INFO(""[FullyConnected Optimization] FAILURE: Unsupported Input"")|;|;+    return res|;|;+  }|;|+|;|+  // TFLite FC -> QNN CONV2D:|;|+  // Reshape -> Conv2D -> Reshpae|;|+  TensorWrapper& input_tensor = inputs[0]|;|;+  TensorWrapper& weight_tensor = inputs[1]|;|;+  TensorWrapper& output_tensor = outputs[0]|;|;+  // Reshape|;|+  qnn::OpWrapper& reshape_op_1 = CreateOpWrapper(res, QNN_OP_RESHAPE)|;|;+  reshape_op_1.AddInputTensor(input_tensor)|;|;+  std::vector<uint32_t> conv_input_dims = input_tensor.GetDims()|;|;+  conv_input_dims.insert(conv_input_dims.begin() + 1, 1)|;|;+  qnn::TensorWrapper& conv_input_tensor =|;|+      tensor_pool.CloneNativeTensorFrom(input_tensor, conv_input_dims)|;|;+  reshape_op_1.AddOutputTensor(conv_input_tensor)|;|;+  // Conv2D Input, Weight, and Output|;|+  OpWrapper& conv_op = CreateOpWrapper(res, QNN_OP_CONV_2D)|;|;+  conv_op.AddInputTensor(conv_input_tensor)|;|;+  auto& quant_params = weight_tensor.GetQuantParams()|;|;+  if (std::holds_alternative<AxisScaleOffsetQuantizeParamsWrapper>(|;|+          quant_params)) {|;|+    auto& axis_quant_param =|;|+        std::get<AxisScaleOffsetQuantizeParamsWrapper>(quant_params)|;|;+    axis_quant_param.SetAxis(3)|;|;+  }|;|+  std::vector<uint32_t> weight_dims{1, 1, weight_tensor.GetDim(1),|;|+                                    weight_tensor.GetDim(0)}|;|;+  size_t weight_bytes = weight_tensor.GetTensorBytes()|;|;+  const std::vector<std::uint32_t> transpose_dim{weight_tensor.GetDim(0), 1, 1,|;|+                                                 weight_tensor.GetDim(1)}|;|;+  TensorWrapper* weight|;|;+  if (weight_tensor.GetDataType() == QNN_DATATYPE_SFIXED_POINT_8) {|;|+    std::vector<std::int8_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::int8_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_SFIXED_POINT_16) {|;|+    std::vector<std::int16_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::int16_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_UFIXED_POINT_16) {|;|+    std::vector<std::uint16_t> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<std::uint16_t>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else if (weight_tensor.GetDataType() == QNN_DATATYPE_FLOAT_32) {|;|+    std::vector<float> conv_weight|;|;+    auto fc_weight = weight_tensor.GetStaticTensorData<float>()|;|;+    TransposeFromOHWIToHWIO(fc_weight.value(), transpose_dim, conv_weight)|;|;+    weight = &(tensor_pool.CreateStaticTensor(|;|+        weight_tensor.GetDataType(), quant_params, weight_dims, weight_bytes,|;|+        conv_weight.data()))|;|;+  } else {|;|+    QNN_LOG_INFO(|;|+        ""[FullyConnected Optimization] FAILURE: Upsupported Weight Datatype"")|;|;+    return {}|;|;+  }|;|+  conv_op.AddInputTensor(*weight)|;|;+  qnn::TensorWrapper& conv_out = tensor_pool.CloneNativeTensorFrom(|;|+      output_tensor, {conv_input_dims[0], conv_input_dims[1],|;|+                      conv_input_dims[2], weight_dims[3]})|;|;+  conv_op.AddOutputTensor(conv_out)|;|;+  // Conv2D Stride|;|+  const std::array<std::uint32_t, 2> stride_data{1, 1}|;|;+  const std::vector<std::uint32_t> stride_shape{2}|;|;+  auto& stride_tensor = tensor_pool.CreateStaticTensor(|;|+      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, stride_shape,|;|+      sizeof(std::uint32_t) * stride_data.size(), stride_data.data())|;|;+  conv_op.AddTensorParam(QNN_OP_DEPTH_WISE_CONV_2D_PARAM_STRIDE, stride_tensor)|;|;+  // Conv2D Padding|;|+  const std::array<std::uint32_t, 4> padding_data = {0, 0, 0, 0}|;|;+  const std::vector<std::uint32_t> padding_shape{2, 2}|;|;+  auto& padding_tensor = tensor_pool.CreateStaticTensor(|;|+      QNN_DATATYPE_UINT_32, QuantizeParamsWrapperVariant{}, padding_shape,|;|+      sizeof(std::uint32_t) * padding_data.size(), padding_data.data())|;|;+  conv_op.AddTensorParam(QNN_OP_CONV_2D_PARAM_PAD_AMOUNT, padding_tensor)|;|;+|;|+  // Reshape|;|+  qnn::OpWrapper& reshape_op_2 = CreateOpWrapper(res, QNN_OP_RESHAPE)|;|;+  reshape_op_2.AddInputTensor(conv_out)|;|;+  reshape_op_2.AddOutputTensor(output_tensor)|;|;+  return res|;|;+}|;|+|;|+}  // namespace qnn || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/fully_connected_op_builder_htp.h: @@ -0,0 +1,21 @@|;|+// Copyright (c) Qualcomm Innovation Center, Inc.|;|+// All Rights Reserved.|;|+|;|+#ifndef TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_|;|+#define TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_|;|+|;|+#include <vector>|;|+|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/tensor_pool.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/op_wrapper.h""|;|+#include ""tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h""|;|+|;|+namespace qnn {|;|+|;|+std::vector<OpWrapper> BuildFullyConnectedOpHtp(|;|+    TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,|;|+    const std::vector<TensorWrapperRef>& outputs, const bool keep_num_dims)|;|;+|;|+}  // namespace qnn|;|+|;|+#endif  // TENSORFLOW_LITE_EXPERIMENTAL_LITERT_VENDORS_QUALCOMM_CORE_BUILDERS_FULLY_CONNECTED_OP_BUILDER_HTP_H_ || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.cc: @@ -20,7 +20,7 @@ std::pair<std::uint32_t, std::uint32_t> ComputePaddingBeforeAfter(|;|   // padding_before, padding_after|;|   std::pair<std::uint32_t, std::uint32_t> result{0, 0}|;|;   if (stride == 0) {|;|-    // TODO: error log|;|+    QNN_LOG_ERROR(""Stride is 0"")|;|;     return result|;|;   }|;| |;|@@ -34,8 +34,8 @@ std::pair<std::uint32_t, std::uint32_t> ComputePaddingBeforeAfter(|;|     case PaddingType::Valid:|;|       output_size = (input_size + stride - effective_filter_size) / stride|;|;       break|;|;-    default:  // PaddingType::Unkown|;|-      // TODO: error log|;|+    default:  // PaddingType::Unknown|;|+      QNN_LOG_ERROR(""Unknown padding type"")|;|;       return result|;|;   }|;|  || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/op_builder.h: @@ -14,7 +14,7 @@|;| namespace qnn {|;| |;| enum class PaddingType {|;|-  Unkown = 0,|;|+  Unknown = 0,|;|   Same,|;|   Valid,|;| }; || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/common.h: @@ -18,6 +18,13 @@ typedef enum LiteRtQnnLogLevel {  // NOLINT(modernize-use-using)|;|   kLogLevelDebug = 5,|;| } LiteRtQnnLogLevel|;|; |;|+typedef struct {  // NOLINT(modernize-use-using)|;|+  /// Apply HTP-friendly op builder.|;|+  bool useHtpPreferencs|;|;+} LiteRtQnnOptions|;|;+|;|+#define LITERT_QNN_OPTIONS_INIT {false, /*useHtpPreferencs*/}|;|+|;| #ifdef __cplusplus|;| }|;| #endif  // __cplusplus || PR#89662 - tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.h: @@ -48,6 +48,37 @@ inline constexpr Qnn_DataType_t GetQnnDataType(const bool is_quant) {|;| |;| std::size_t GetDataTypeSize(const Qnn_DataType_t data_type)|;|; |;|+template <typename T>|;|+void TransposeFromOHWIToHWIO(absl::Span<const T> weight_data,|;|+                             const std::vector<uint32_t>& weight_dims,|;|+                             std::vector<T>& weight_data_transpose) {|;|+  weight_data_transpose.resize(weight_data.size())|;|;+  uint32_t output = weight_dims[0]|;|;+  uint32_t height = weight_dims[1]|;|;+  uint32_t width = weight_dims[2]|;|;+  uint32_t input = weight_dims[3]|;|;+  // OHWI->HWIO|;|+  uint32_t map_o = 0|;|;+  uint32_t map_w = 0|;|;+  uint32_t map_h = 0|;|;+  for (uint32_t index_o = 0; index_o < output; index_o++) {|;|+    map_o = index_o * height * width * input|;|;+    for (uint32_t index_h = 0; index_h < height; index_h++) {|;|+      map_h = index_h * width * input|;|;+      for (uint32_t index_w = 0; index_w < width; index_w++) {|;|+        map_w = index_w * input|;|;+        for (uint32_t index_i = 0; index_i < input; index_i++) {|;|+          T inval = weight_data[map_o + map_h + map_w + index_i]|;|;+          uint32_t index_transpose = index_h * width * input * output +|;|+                                     index_w * input * output +|;|+                                     index_i * output + index_o|;|;+          weight_data_transpose[index_transpose] = inval|;|;+        }|;|+      }|;|+    }|;|+  }|;|+}|;|+|;| class TensorWrapper final {|;|   friend class TensorPool|;|; ","Qualcomm AI Engine Direct - Op optimization

Summary:
- Support FC->CONV2D optimization
- Add CONV2D op builder with CPU transpose || Merge pull request #89210 from jiunkaiy:dev/jiunkaiy/gemma2_fc

PiperOrigin-RevId: 738878336"
tensorflow/tensorflow,serach24,23619,tf.contrib.distributions.percentile didn't support eager execution,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):tensorflow-py2-cpu API r1.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
When I using the eager execution. I try this:

```
import tensorflow as tf

tf.enable_eager_execution()

x = tf.constant([1,2,3,4],dtype='float64')
y = tf.contrib.distributions.percentile(x,q=30)
```

will report an error:

> TypeErrorTraceback
> 
>  (most recent call last)
> <ipython-input-1-b7b170c83880> in <module>()
>       4 
>       5 x = tf.constant([1,2,3,4],dtype='float64')
> ----> 6 y = tf.contrib.distributions.percentile(x,q=30)
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.pyc in percentile(x, q, axis, interpolation, keep_dims, validate_args, name)
>     301                        (allowed_interpolations, interpolation))
>     302 
> --> 303   with ops.name_scope(name, [x, q]):
>     304     x = ops.convert_to_tensor(x, name=""x"")
>     305     # Double is needed here and below, else we get the wrong index if the array
> 
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in __enter__(self)
>    5743       else:
>    5744         cache_key = self._name, self._old_name, self._default_name
> -> 5745         if cache_key in name_scope_cache:
>    5746           self._ctx.scope_name = name_scope_cache[cache_key]
>    5747           return self._ctx.scope_name
> 
> TypeError: unhashable type: 'list'

but when I use tf.Session() to run the same code block:

```
import tensorflow as tf
x = tf.constant([1,2,3,4],dtype='float64')
y = tf.contrib.distributions.percentile(x,q=30)
with tf.Session() as sess:
    print sess.run(y)

```
It worked and report that I wanted:
`2.0`

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**

I'm using tensorflow to make some calculate. Eager is very help but this problem stop me to use it.

Thanks for anyone will fix it.","Added PR #23637 for the fix. || The issue has been fixed in:
https://github.com/tensorflow/tensorflow/pull/23637#issuecomment-449498024

Will close the issue now.",closed,2018-11-09T07:12:31+00:00,2018-12-21T21:48:46+00:00,JiangKui007,type:bug,1,"PR#89631 - third_party/xla/xla/service/gpu/ir_emitter_unnested.cc: @@ -1672,10 +1672,12 @@ absl::Status IrEmitterUnnested::EmitSort(const HloSortInstruction* sort) {|;|         sort->operand_count() > 1 ? ShapeIndex({i}) : ShapeIndex({})|;|;     // We assume that the layout of all involved operands and outputs is the|;|     // same.|;|-    TF_RET_CHECK(LayoutUtil::LayoutsInShapesEqual(keys_shape,|;|-                                                  sort->operand(i)->shape()))|;|;+    TF_RET_CHECK(|;|+        LayoutUtil::LayoutsInShapesEqual(keys_shape, sort->operand(i)->shape(),|;|+                                         Layout::Equal().IgnoreMemorySpace()))|;|;     TF_RET_CHECK(LayoutUtil::LayoutsInShapesEqual(|;|-        keys_shape, ShapeUtil::GetSubshape(sort->shape(), shape_index)))|;|;+        keys_shape, ShapeUtil::GetSubshape(sort->shape(), shape_index),|;|+        Layout::Equal().IgnoreMemorySpace()))|;|; |;|     BufferAllocation::Slice destination_buffer|;|;     BufferAllocation::Slice source_address; || PR#89631 - third_party/xla/xla/service/gpu/tests/BUILD: @@ -539,11 +539,12 @@ xla_test(|;|         ""//xla:shape_util"",|;|         ""//xla:types"",|;|         ""//xla:xla_data_proto_cc"",|;|+        ""//xla/hlo/ir:hlo"",|;|+        ""//xla/tsl/platform:statusor"",|;|         ""@com_google_absl//absl/log:check"",|;|         ""@com_google_absl//absl/strings"",|;|         ""@com_google_googletest//:gtest_main"",|;|         ""@eigen_archive//:eigen3"",|;|-        ""@local_tsl//tsl/platform:statusor"",|;|     ],|;| )|;|  || PR#89631 - third_party/xla/xla/service/gpu/tests/sorting_test.cc: @@ -20,22 +20,28 @@ limitations under the License.|;| #include <utility>|;| #include <vector>|;| |;|+#include <gtest/gtest.h>|;| #include ""absl/log/check.h""|;| #include ""absl/strings/ascii.h""|;| #include ""absl/strings/str_cat.h""|;| #include ""absl/strings/string_view.h""|;| #include ""absl/strings/substitute.h""|;| #include ""Eigen/Core""|;| #include ""xla/error_spec.h""|;|+#include ""xla/hlo/ir/hlo_instruction.h""|;|+#include ""xla/hlo/ir/hlo_module.h""|;|+#include ""xla/hlo/ir/hlo_opcode.h""|;|+#include ""xla/layout.h""|;|+#include ""xla/layout_util.h""|;| #include ""xla/literal.h""|;| #include ""xla/literal_util.h""|;| #include ""xla/primitive_util.h""|;| #include ""xla/service/gpu/tests/gpu_codegen_test.h""|;| #include ""xla/shape.h""|;| #include ""xla/shape_util.h""|;|+#include ""xla/tsl/platform/statusor.h""|;| #include ""xla/types.h""|;| #include ""xla/xla_data.pb.h""|;|-#include ""tsl/platform/statusor.h""|;| |;| namespace xla {|;| namespace gpu {|;|@@ -69,6 +75,55 @@ ENTRY TestComputation {|;|   EXPECT_TRUE(RunAndCompareNoHloPasses(hlo_text, ErrorSpec{1e-5, 1e-5}))|;|; }|;| |;|+// Test that verifies the IgnoreMemorySpace option works correctly|;|+TEST_F(SortingTest, LayoutsInShapesEqualWithIgnoreMemorySpace) {|;|+  const char* hlo_text = R""(|;|+HloModule TestModule|;|+|;|+compare {|;|+  p.0.lhs = f32[] parameter(0)|;|+  p.0.rhs = f32[] parameter(1)|;|+  p.1.lhs = f32[] parameter(2)|;|+  p.1.rhs = f32[] parameter(3)|;|+  ROOT lt = pred[] compare(p.0.lhs, p.0.rhs), direction=LT|;|+}|;|+|;|+ENTRY TestComputation {|;|+  data = f32[6] parameter(0)|;|+|;|+  // Create two copies in different memory spaces|;|+  keys = f32[6] copy(data)|;|+  values = f32[6] copy(data)|;|+|;|+  // Sort operation with operands in different memory spaces|;|+  ROOT sort = (f32[6], f32[6]) sort(keys, values), dimensions={0}, to_apply=compare|;|+}|;|+)""|;|;+|;|+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,|;|+                          ParseAndReturnVerifiedModule(hlo_text))|;|;+|;|+  HloInstruction* values =|;|+      module->entry_computation()->GetInstructionWithName(""values"")|;|;+  Shape values_shape = values->shape()|;|;+  values_shape.mutable_layout()->set_memory_space(1)|;|;+  *values->mutable_shape() = values_shape|;|;+|;|+  const HloInstruction* sort = module->entry_computation()->root_instruction()|;|;+  EXPECT_EQ(sort->opcode(), HloOpcode::kSort)|;|;+|;|+  const HloInstruction* keys = sort->operand(0)|;|;+|;|+  EXPECT_FALSE(|;|+      LayoutUtil::LayoutsInShapesEqual(keys->shape(), values->shape()))|;|;+  EXPECT_TRUE(LayoutUtil::LayoutsInShapesEqual(|;|+      keys->shape(), values->shape(), Layout::Equal().IgnoreMemorySpace()))|;|;+|;|+  auto literal = LiteralUtil::CreateR1<float>({1.0, 6.0, 7.0, 0.0, 2.0, 5.0})|;|;+  absl::StatusOr<Literal> executed = Execute(std::move(module), {&literal})|;|;+  EXPECT_TRUE(executed.ok()) << executed.status().message()|;|;+}|;|+|;| // Size of the radix sort tests.|;| static constexpr int kRadixSortTestSize = 100000|;|; ","PR #23619: Fix the EmitSort checking after enabling NVLS and user buffer

Imported from GitHub PR https://github.com/openxla/xla/pull/23619

There is a reported bug from NVIDIA that running Midjourney model triggers XLA error after enabling NVLS and user buffer by setting NCCL_NVLS_ENABLE=1 and --xla_gpu_enable_nccl_user_buffers=true:
```
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: RET_CHECK failure (external/xla/xla/service/gpu/ir_emitter_unnested.cc:1676) LayoutUtil::LayoutsInShapesEqual(keys_shape, sort->operand(i)->shape()).
```
This is because after enabling NVLS and user buffer, one of the operand of `sort` operation is from a different memory space (user buffer), and the previous `LayoutsInShapesEqual` check is too strong to pass as it also checks if operands are from the same memory space.

This MR makes the sort layout check weaker as operands do not have to be in the same memory space as long as they all on the device.
Copybara import of the project:

--
826535264624142999164132f3a873be06019279 by Chenhao Jiang <chenhaoj@nvidia.com>:

Making the sort layout check weaker as operands do not have to be in the same memory space as long as they all on the device.

Merging this change closes #23619

PiperOrigin-RevId: 738761820"
tensorflow/tensorflow,apivovarov,23909,"TFTRT: Add ExpandDims, Squeeze ops and unit tests.","Add conversion for ExpandDims, Squeeze ops, and unit tests for both.

These ops will allow 1D convolutions to be converted.","@azaks2 @smit-hinsu
Could you please review. || So there's good news and bad news.

:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.

:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.

*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*

<!-- need_author_consent --> || Can you rebase this PR wrt master? It's a little hard to review as-is || CLAs look good, thanks!

<!-- ok --> || Hi @trevor-m, would you help to fix this error:

```
error: ignoring return value of function declared with 'warn_unused_result' attribute [-Werror,-Wunused-result]
  TensorShapeUtils::MakeShape(shape, &tensor_shape);
```

Thanks. || > Hi @trevor-m, would you help to fix this error:
> 
> ```
> error: ignoring return value of function declared with 'warn_unused_result' attribute [-Werror,-Wunused-result]
>   TensorShapeUtils::MakeShape(shape, &tensor_shape);
> ```
> Thanks.

Done. Thanks for reviewing! || Thanks @trevor-m. I found that rank_two_test and unary_test are failing, probably because they're using squeeze ops, would you help to double check? If you want to add an op that is unsupported you may use `self.trt_incompatible_op`.",closed,2018-11-21T21:46:39+00:00,2018-12-07T08:16:46+00:00,trevor-m,"cla: yes, ready to pull",1,"PR#89627 - third_party/xla/xla/hlo/ir/hlo_instructions.h: @@ -708,6 +708,7 @@ class HloAllGatherInstruction : public HloCollectiveInstruction {|;| |;|   // Same as HloAllReduceInstruction::use_global_device_ids.|;|   bool use_global_device_ids() const { return use_global_device_ids_; }|;|+  void set_use_global_device_ids(bool value) { use_global_device_ids_ = value; }|;| |;|   // The dimension on which data from different participants are concatenated.|;|   int64_t all_gather_dimension() const { return all_gather_dimension_; }","PR #23909: Add set_use_global_device_ids() to AllGather instr

Imported from GitHub PR https://github.com/openxla/xla/pull/23909

`use_global_device_ids` attribute is defined in both `HloAllReduceInstructionBase` and `HloAllGatherInstruction` classes.

But `HloAllGatherInstruction` lacks a setter method - `set_use_global_device_ids`.

This PR fixes it by adding missing `set_use_global_device_ids` to `HloAllGatherInstruction`.

I could not find any existing tests that validate `set_use_global_device_ids` for AllReduce or ReduceScatter. Therefore, this AllGather PR does not include modifications to unit tests too.
Copybara import of the project:

--
fd3c082776ec27ec16288c397b025daf6bc95874 by Alexander Pivovarov <pivovaa@amazon.com>:

Add set_use_global_device_ids to AllGather instr

Merging this change closes #23909

PiperOrigin-RevId: 738748423"
tensorflow/tensorflow,sergachev,23786,Update graph_transformations.h,typo,Nagging Reviewer @martinwicke: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 15 days with no activity and the `awaiting review` label has been applied.,closed,2018-11-16T06:27:05+00:00,2018-12-06T16:44:29+00:00,siju-samuel,"cla: yes, ready to pull, size:XS",1,"PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/BUILD: @@ -151,6 +151,7 @@ cc_library(|;|         ""//xla/hlo/ir:hlo"",|;|         ""//xla/hlo/parser:hlo_parser"",|;|         ""//xla/hlo/pass:hlo_pass_pipeline"",|;|+        ""//xla/hlo/transforms:while_loop_trip_count_annotator"",|;|         ""//xla/hlo/translate:stablehlo"",|;|         ""//xla/hlo/translate/hlo_to_mhlo:translate"",|;|         ""//xla/pjrt:host_memory_spaces"",|;|@@ -216,6 +217,7 @@ xla_test(|;|         ""data/single_device.hlo"",|;|         ""data/single_device_tupled.hlo"",|;|         ""data/single_gemm_fusion.hlo"",|;|+        ""data/while_with_known_trip_count.hlo"",|;|     ],|;|     tags = [""no_mac""],|;|     deps = [ || PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/data/while_with_known_trip_count.hlo: @@ -0,0 +1,21 @@|;|+condition {|;|+  p = (s32[]) parameter(0)|;|+  cond = s32[] get-tuple-element(p), index=0|;|+  trip_count = s32[] constant(7)|;|+  done = pred[] compare(cond, trip_count), direction=LT|;|+}|;|+|;|+body {|;|+  p = (s32[]) parameter(0)|;|+  cond = s32[] get-tuple-element(p), index=0|;|+  one = s32[] constant(1)|;|+  cond_plus_1 = s32[] add(cond, one)|;|+  t = (s32[]) tuple(cond_plus_1)|;|+}|;|+|;|+main {|;|+  p = s32[] constant(0)|;|+  t = (s32[]) tuple(p)|;|+  w = (s32[]) while(t), condition=condition,|;|+    body=body, backend_config={""known_trip_count"":{""n"":""7""}}|;|+} || PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.cc: @@ -45,6 +45,7 @@ limitations under the License.|;| #include ""xla/hlo/ir/hlo_sharding.h""|;| #include ""xla/hlo/parser/hlo_parser.h""|;| #include ""xla/hlo/pass/hlo_pass_pipeline.h""|;|+#include ""xla/hlo/transforms/while_loop_trip_count_annotator.h""|;| #include ""xla/hlo/translate/hlo_to_mhlo/translate.h""|;| #include ""xla/hlo/translate/stablehlo.h""|;| #include ""xla/layout.h""|;|@@ -782,6 +783,9 @@ absl::Status FunctionalHloRunner::PrepareHloModuleForCompilation(|;|             preproc_options.flatten_conditional,|;|             /*conditional_value=*/|;|             preproc_options.conditional_value})|;|;+    if (preproc_options.annotate_while_loop_trip_count) {|;|+      pipeline.AddPass<WhileLoopTripCountAnnotator>()|;|;+    }|;|     TF_RETURN_IF_ERROR(pipeline.Run(hlo_module).status())|;|;   }|;|   return absl::OkStatus(); || PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner.h: @@ -243,6 +243,9 @@ class FunctionalHloRunner {|;|       return while_execution_count.has_value()|;|;     }|;| |;|+    // Set / update known_trip_count in while loop backend config.|;|+    bool annotate_while_loop_trip_count = false|;|;+|;|     // Is the module the partitioned result of SPMD?|;|     bool is_spmd_partitioned_module() const {|;|       return spmd_partitioned_mode == || PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/functional_hlo_runner_test.cc: @@ -28,6 +28,7 @@ limitations under the License.|;| #include ""absl/status/statusor.h""|;| #include ""absl/strings/match.h""|;| #include ""absl/strings/str_format.h""|;|+#include ""absl/strings/string_view.h""|;| #include ""absl/time/time.h""|;| #include ""xla/debug_options_flags.h""|;| #include ""xla/hlo/testlib/filecheck.h""|;|@@ -58,6 +59,7 @@ namespace xla {|;| namespace {|;| |;| using ::testing::SizeIs|;|;+using ::tsl::testing::IsOkAndHolds|;|; using ::tsl::testing::StatusIs|;|; using HloModuleAndArguments = ::xla::FunctionalHloRunner::HloModuleAndArguments|;|; |;|@@ -343,31 +345,26 @@ TEST_F(FunctionalHloRunnerTest, UseUninitializedInputsWithTupledArguments) {|;|       InputFormat::kText))|;|; }|;| |;|-TEST_F(FunctionalHloRunnerTest, CanCompileWithoutHavingEnoughGpus) {|;|-  // This test corresponds to:|;|-  // --num_replicas=1 --num_partitions=16|;|-  // --run=false --xla_dump_to=dump_dir|;|-|;|+void CompileAndFilecheck(|;|+    absl::string_view hlo_file, absl::string_view pattern,|;|+    const FunctionalHloRunner::PreprocessingOptions& preproc_options,|;|+    const FunctionalHloRunner::HloPassesMode hlo_passes_mode,|;|+    const int num_partitions = 1) {|;|   tsl::Env* env = tsl::Env::Default()|;|;   std::string dump_dir|;|;   ASSERT_TRUE(env->LocalTempFilename(&dump_dir))|;|;   tsl::FileSystem* fs = nullptr|;|;   TF_ASSERT_OK(env->GetFileSystemForFile(dump_dir, &fs))|;|;-|;|-  xla::DebugOptions debug_options|;|;-  FunctionalHloRunner::PreprocessingOptions preproc_options|;|;-  FunctionalHloRunner::RawCompileOptions raw_compile_options|;|;-  raw_compile_options.num_replicas = 1|;|;-  raw_compile_options.num_partitions = 16|;|;-  raw_compile_options.xla_dump_to = dump_dir|;|;-|;|   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<xla::PjRtClient> client,|;|                           GetPjRtClient())|;|;+  FunctionalHloRunner::RawCompileOptions opts|;|;+  opts.hlo_passes_mode = hlo_passes_mode|;|;+  opts.num_partitions = num_partitions|;|;+  opts.xla_dump_to = dump_dir|;|;   TF_EXPECT_OK(FunctionalHloRunner::LoadAndCompile(|;|-      *client, debug_options, preproc_options, raw_compile_options,|;|-      GetHloPath(""sharded_16_devices.hlo""), InputFormat::kText))|;|;+      *client, xla::DebugOptions{}, preproc_options, opts, hlo_file,|;|+      InputFormat::kText))|;|; |;|-  // Check that the sharding was done correctly.|;|   {|;|     std::vector<std::string> after_opt_hlo_paths|;|;     TF_ASSERT_OK(|;|@@ -377,23 +374,43 @@ TEST_F(FunctionalHloRunnerTest, CanCompileWithoutHavingEnoughGpus) {|;|     std::string after_opt_hlo|;|;     TF_ASSERT_OK(|;|         tsl::ReadFileToString(env, after_opt_hlo_paths[0], &after_opt_hlo))|;|;-    absl::StatusOr<bool> file_check_result = RunFileCheck(after_opt_hlo, R""(|;|-      // CHECK: param{{.*}} = f32[16,1]{1,0}|;|-      // CHECK: add{{.*}} = f32[16,1]{1,0}|;|-    )"")|;|;-    TF_ASSERT_OK(file_check_result.status())|;|;-    EXPECT_TRUE(file_check_result.value())|;|;+    EXPECT_THAT(RunFileCheck(after_opt_hlo, pattern), IsOkAndHolds(true))|;|;   }|;| |;|   // Check that the LLVM IR has been generated.|;|-  {|;|+  if (!IsTestingCpu()) {|;|     std::vector<std::string> ir_paths|;|;     TF_ASSERT_OK(fs->GetMatchingPaths(fs->JoinPath(dump_dir, ""*ir-no-opt.ll""),|;|                                       &ir_paths))|;|;     ASSERT_THAT(ir_paths, SizeIs(1))|;|;   }|;| }|;| |;|+TEST_F(FunctionalHloRunnerTest, CanCompileWithoutHavingEnoughGpus) {|;|+  CompileAndFilecheck(GetHloPath(""sharded_16_devices.hlo""),|;|+                      // Check that the sharding was done correctly.|;|+                      R""(|;|+      // CHECK: param{{.*}} = f32[16,1]{1,0}|;|+      // CHECK: add{{.*}} = f32[16,1]{1,0}|;|+    )"",|;|+                      /*preproc_options=*/{},|;|+                      FunctionalHloRunner::HloPassesMode::kStandardCompile,|;|+                      /*num_partitions=*/16)|;|;+}|;|+|;|+TEST_F(FunctionalHloRunnerTest, WhileKnownTripCountGetsCapped) {|;|+  FunctionalHloRunner::PreprocessingOptions opts|;|;+  opts.while_execution_count = 5|;|;+  opts.annotate_while_loop_trip_count = true|;|;+  CompileAndFilecheck(GetHloPath(""while_with_known_trip_count.hlo""),|;|+                      R""(|;|+      // CHECK: constant(5)|;|+      // CHECK: ""known_trip_count"":{""n"":""5""}|;|+    )"",|;|+                      opts,|;|+                      FunctionalHloRunner::HloPassesMode::kRunXLABackendOnly)|;|;+}|;|+|;| // Name of the test binary.|;| static const char* binary_name|;|; constexpr int kNumNodes = 2; || PR#89543 - third_party/xla/xla/tools/multihost_hlo_runner/hlo_runner_main.cc: @@ -218,6 +218,7 @@ static absl::Status RunMultihostHloRunner(int argc, char** argv,|;|   TF_ASSIGN_OR_RETURN(|;|       xla::FunctionalHloRunner::PreprocessingOptions preproc_options,|;|       PreprocessingOptionsFromFlags(opts))|;|;+  preproc_options.annotate_while_loop_trip_count = true|;|;   TF_ASSIGN_OR_RETURN(|;|       xla::FunctionalHloRunner::RawCompileOptions raw_compile_options,|;|       RawCompileOptionsFromFlags(opts));","PR #23786: Multihost HLO runner: fix --while_execution_count behavior.

Imported from GitHub PR https://github.com/openxla/xla/pull/23786

Optimized HLO can have known_trip_count while loop annotation, which has to be updated using WhileLoopTripCountAnnotator after HloControlFlowFlattening to apply the value of while_execution_count at
runtime.
Copybara import of the project:

--
5648a58d78726f116a64030f48dd63835818fbf7 by Ilia Sergachev <isergachev@nvidia.com>:

[NFC] Factor common test logic out into a function.

--
21d4e89aab6fc1dfe66edde6d11eabaec5ea6a84 by Ilia Sergachev <isergachev@nvidia.com>:

Multihost HLO runner: fix --while_execution_count behavior.

Optimized HLO can have known_trip_count while loop annotation, which has
to be updated using WhileLoopTripCountAnnotator after
HloControlFlowFlattening to apply the value of while_execution_count at
runtime.

--
fd93a631e6b818df7d98f29a55b53a8819eae9a3 by Ilia Sergachev <isergachev@nvidia.com>:

Address review request.

Merging this change closes #23786

PiperOrigin-RevId: 738744952"
numpy/numpy,unknown,28599,BUG: .from_dlpack never sets writeable flag,"### Describe the issue:

All arrays imported from dlpacks come out set readonly.

It looks like initially setting the writeable flag was overlooked when flags are passed as `0` at https://github.com/numpy/numpy/blob/9389862162bbd46b5324402d6a08a27bc18ddb7d/numpy/_core/src/multiarray/dlpack.c#L704-L705 and then cleared when already 0 at https://github.com/numpy/numpy/blob/9389862162bbd46b5324402d6a08a27bc18ddb7d/numpy/_core/src/multiarray/dlpack.c#L710-L712 . The flag is never set.

### Reproduce the code example:

```python
import numpy as np
original_array = np.array([0])
imported_array = np.from_dlpack(original_array)
imported_array[0] = 1
imported_array.flags.writeable = True
```

### Error message:

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: assignment destination is read-only
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ValueError: cannot set WRITEABLE flag to True of this array
```

### Python and NumPy Versions:

2.2.4
3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]]

### Runtime Environment:

[{'numpy_version': '2.2.4',
  'python': '3.12.3 (main, Feb  4 2025, 14:48:35) [GCC 13.3.0]',
  'uname': uname_result(system='Linux', node='LAPTOP-JDTFCTMR', release='5.15.167.4-microsoft-standard-WSL2', version='#1 SMP Tue Nov 5 00:21:55 UTC 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3', 'SSE41', 'POPCNT', 'SSE42'],
                      'not_found': ['AVX',
                                    'F16C',
                                    'FMA3',
                                    'AVX2',
                                    'AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Katmai',
  'filepath': '/home/karl3/.local/lib/python3.12/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 3,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

### Context for the issue:

This issue prevents the use of numpy for writing into aliased data from other tensor libraries or in general contexts using the array api. I was implementing a lightweight n-dimensional large integer class, using views to change between unsigned and signed representations.",,closed,2025-03-28T00:26:07+00:00,2025-03-31T19:05:36+00:00,karl3wm,00 - Bug,1,"PR#28600 - numpy/_core/_add_newdocs.py: @@ -1663,8 +1663,8 @@|;|     from_dlpack(x, /, *, device=None, copy=None)|;| |;|     Create a NumPy array from an object implementing the ``__dlpack__``|;|-    protocol. Generally, the returned NumPy array is a read-only view|;|-    of the input object. See [1]_ and [2]_ for more details.|;|+    protocol. Generally, the returned NumPy array is a view of the input|;|+    object. See [1]_ and [2]_ for more details.|;| |;|     Parameters|;|     ---------- || PR#28600 - numpy/_core/src/multiarray/dlpack.c: @@ -601,7 +601,7 @@ from_dlpack(PyObject *NPY_UNUSED(self),|;|             return NULL|;|;         }|;|         dl_tensor = managed->dl_tensor|;|;-        readonly = 0|;|;+        readonly = 1|;|;     }|;| |;|     const int ndim = dl_tensor.ndim|;|;@@ -702,14 +702,13 @@ from_dlpack(PyObject *NPY_UNUSED(self),|;|     }|;| |;|     PyObject *ret = PyArray_NewFromDescr(&PyArray_Type, descr, ndim, shape,|;|-            dl_tensor.strides != NULL ? strides : NULL, data, 0, NULL)|;|;+            dl_tensor.strides != NULL ? strides : NULL, data, readonly ? 0 :|;|+            NPY_ARRAY_WRITEABLE, NULL)|;|;+|;|     if (ret == NULL) {|;|         Py_DECREF(capsule)|;|;         return NULL|;|;     }|;|-    if (readonly) {|;|-        PyArray_CLEARFLAGS((PyArrayObject *)ret, NPY_ARRAY_WRITEABLE)|;|;-    }|;| |;|     PyObject *new_capsule|;|;     if (versioned) { || PR#28600 - numpy/_core/tests/test_dlpack.py: @@ -144,6 +144,17 @@ def test_readonly(self):|;|         y = np.from_dlpack(x)|;|         assert not y.flags.writeable|;| |;|+    def test_writeable(self):|;|+        x_new, x_old = new_and_old_dlpack()|;|+|;|+        # new dlpacks respect writeability|;|+        y = np.from_dlpack(x_new)|;|+        assert y.flags.writeable|;|+|;|+        # old dlpacks are not writeable for backwards compatibility|;|+        y = np.from_dlpack(x_old)|;|+        assert not y.flags.writeable|;|+|;|     def test_ndim0(self):|;|         x = np.array(1.0)|;|         y = np.from_dlpack(x)","BUG: Set writeable flag for writeable dlpacks.

Explicitly set the writeable flag in from_dlpack as the inverse of the
dlpack read_only flag. Previously it was not actually being set.

Additionally, update the readonly logic such that legacy unversioned
DLPacks are never writeable, for compatibility with old behavior.

Fixes #28599"
numpy/numpy,baskargopinath,28446,BUG: Unable to build cython when using `NpyIter_GetIterNext`.,"### Describe the issue:

I am trying to migrate away from using custom cython imports in order to have access to the [Iterator API](https://numpy.org/doc/stable/reference/c-api/iterator.html) declarations at `numpy/ndarrayobject.h` by using the numpy provided ones added in v2.0.0. However if I try to build the project using the file [here](https://github.com/zoj613/polyagamma/blob/update-api/polyagamma/_polyagamma.pyx) I get a build failure. Cc @seberg 

### Reproduce the code example:

```python
pip install -r requirements-dev.txt
	cythonize polyagamma/*.pyx
	pip install -e .
```

### Error message:

```shell
gcc -pthread -B /home/zoj/.local/share/micromamba/envs/polyagamma-dev/compiler_compat -fno-s
trict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/zoj/.local/share/micromamba/envs/polyag
amma-dev/include -fPIC -O2 -isystem /home/zoj/.local/share/micromamba/envs/polyagamma-dev/include 
-fPIC -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -I/tmp/pip-build-env-0bay5vae/overlay/lib/python
3.12/site-packages/numpy/_core/include -I./include -I/home/zoj/.local/share/micromamba/envs/polyag
amma-dev/include/python3.12 -c polyagamma/_polyagamma.c -o /tmp/tmpsbownh73.build-temp/polyagamma/
_polyagamma.o -O2 -std=c99
      polyagamma/_polyagamma.c: In function ‘__pyx_pf_10polyagamma_11_polyagamma_rvs’:
      polyagamma/_polyagamma.c:6265:16: error: assignment to ‘int (**)(NpyIter *)’ {aka ‘int (**)(
struct NpyIter_InternalOnly *)’} from incompatible pointer type ‘int (*)(NpyIter *)’ {aka ‘int (*)
(struct NpyIter_InternalOnly *)’} [-Wincompatible-pointer-types]
       6265 |     __pyx_t_20 = NpyIter_GetIterNext(__pyx_v_it, NULL); if (unlikely(__pyx_t_20 == (
(__pyx_t_5numpy_NpyIter_IterNextFunc *)NULL))) __PYX_ERR(0, 243, __pyx_L57_error)
            |                ^
      polyagamma/_polyagamma.c: In function ‘__pyx_f_10polyagamma_11_polyagamma_dispatch’:
      polyagamma/_polyagamma.c:7507:16: error: assignment to ‘int (**)(NpyIter *)’ {aka ‘int (**)(
struct NpyIter_InternalOnly *)’} from incompatible pointer type ‘int (*)(NpyIter *)’ {aka ‘int (*)
(struct NpyIter_InternalOnly *)’} [-Wincompatible-pointer-types]
       7507 |     __pyx_t_10 = NpyIter_GetIterNext(__pyx_v_it, NULL); if (unlikely(__pyx_t_10 == (
(__pyx_t_5numpy_NpyIter_IterNextFunc *)NULL))) __PYX_ERR(0, 462, __pyx_L11_error)
            |                ^
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/spawn.py"", line 70, in spawn
          subprocess.check_call(cmd, env=_inject_macos_ver(env))
        File ""/home/zoj/.local/share/micromamba/envs/polyagamma-dev/lib/python3.12/subprocess.py"",
 line 413, in check_call
          raise CalledProcessError(retcode, cmd)
      subprocess.CalledProcessError: Command '['/usr/bin/gcc', '-pthread', '-B', '/home/zoj/.local
/share/micromamba/envs/polyagamma-dev/compiler_compat', '-fno-strict-overflow', '-DNDEBUG', '-O2',
 '-Wall', '-fPIC', '-O2', '-isystem', '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/inclu
de', '-fPIC', '-O2', '-isystem', '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/include', 
'-fPIC', '-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION', '-I/tmp/pip-build-env-0bay5vae/overlay/lib
/python3.12/site-packages/numpy/_core/include', '-I./include', '-I/home/zoj/.local/share/micromamb
a/envs/polyagamma-dev/include/python3.12', '-c', 'polyagamma/_polyagamma.c', '-o', '/tmp/tmpsbownh
73.build-temp/polyagamma/_polyagamma.o', '-O2', '-std=c99']' returned non-zero exit status 1.
      
      The above exception was the direct cause of the following exception:
      
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/unixccompiler.py"", line 200, in _compile
          self.spawn(compiler_so + cc_args + [src, '-o', obj] + extra_postargs)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/ccompiler.py"", line 1052, in spawn
          spawn(cmd, dry_run=self.dry_run, **kwargs)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/spawn.py"", line 76, in spawn
          raise DistutilsExecError(
      distutils.errors.DistutilsExecError: command '/usr/bin/gcc' failed with exit code 1
      
      During handling of the above exception, another exception occurred:
      
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 139, in run
          self._create_wheel_file(bdist_wheel)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 340, in _create_wheel_file
          files, mapping = self._run_build_commands(dist_name, unpacked, lib, tmp)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 263, in _run_build_commands
          self._run_build_subcommands()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 290, in _run_build_subcommands
          self.run_command(name)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/cmd.py"", line 339, in run_command
          self.distribution.run_command(command)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/dist.py""
, line 999, in run_command
          super().run_command(command)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/dist.py"", line 1002, in run_command
          cmd_obj.run()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
build_ext.py"", line 99, in run
          _build_ext.run(self)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 365, in run
          self.build_extensions()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 481, in build_extensions
          self._build_extensions_serial()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 507, in _build_extensions_serial
          self.build_extension(ext)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
build_ext.py"", line 264, in build_extension
          _build_ext.build_extension(self, ext)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 562, in build_extension
          objects = self.compiler.compile(
                    ^^^^^^^^^^^^^^^^^^^^^^
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/ccompiler.py"", line 607, in compile
          self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/unixccompiler.py"", line 202, in _compile
          raise CompileError(msg)
      distutils.errors.CompileError: command '/usr/bin/gcc' failed with exit code 1
      /tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.
py:1002: _DebuggingTips: Problem in editable installation.
      !!
      
              ********************************************************************************
              An error happened while installing `polyagamma` in editable mode.
      
              The following steps are recommended to help debug this problem:
      
              - Try to install the project normally, without using the editable mode.
                Does the error still persist?
                (If it does, try fixing the problem before attempting the editable mode).
              - If you are using binary extensions, make sure you have all OS-level
                dependencies installed (e.g. compilers, toolchains, binary libraries, ...).
              - Try the latest version of setuptools (maybe the error was already fixed).
              - If you (or your project dependencies) are using any setuptools extension
                or customization, make sure they support the editable mode.
      
              After following the steps above, if the problem still persists and
              you think this is related to how setuptools handles editable installations,
              please submit a reproducible example
              (see https://stackoverflow.com/help/minimal-reproducible-example) to:
      
                  https://github.com/pypa/setuptools/issues
      
              See https://setuptools.pypa.io/en/latest/userguide/development_mode.html for details
.
              ********************************************************************************
      
      !!
        cmd_obj.run()
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building editable for polyagamma
Failed to build polyagamma
ERROR: Could not build wheels for polyagamma, which is required to install pyproject.toml-based pr
ojects
make: *** [Makefile:14: dev] Error 1
```

### Python and NumPy Versions:

3.12.0 | packaged by conda-forge | (main, Oct  3 2023, 08:43:22) [GCC 12.3.0]

### Runtime Environment:

```
[{'numpy_version': '2.2.3',
  'python': '3.12.0 | packaged by conda-forge | (main, Oct  3 2023, 08:43:22) '
            '[GCC 12.3.0]',
  'uname': uname_result(system='Linux', node='zoj-desktop', release='6.12.17-1-lts', version='#1 S
MP PREEMPT_DYNAMIC Thu, 27 Feb 2025 14:12:30 +0000', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX',
                                'AVX512_CNL',
                                'AVX512_ICL'],
                      'not_found': ['AVX512_KNL', 'AVX512_KNM']}},
 {'architecture': 'SkylakeX',
  'filepath': '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/lib/python3.12/site-packages/
numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 12,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

```

### Context for the issue:

Previously, I was manually importing the cython declarations and defined them like so:
```cython
ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil
cdef extern from ""numpy/ndarrayobject.h"":
 NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL
 ...
```

 as shown [here](https://github.com/zoj613/polyagamma/blob/17bab854fdad69c71c68ac8d6696a2eaa5a1abe8/polyagamma/_polyagamma.pyx#L386-L430). This worked well and I was able to successfully build the project. Now if I use the declarions added in numpy v2.0.0

```
ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil
 NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL
```
I get this build error. I believe this is due to `NpyIter_GetIterNext` returning a pointer to `NpyIter_IterNextFunc` instead of just the type.","Yeah, seems off...  What was the winning combination here?  You added this back then and we changed nothing since then, I think.

And I assumed you had code that successfully used it at the time?

I.e. I am worried that we already have someone manages to use this successfully with the current version, and a change may break them.
If that is not possible, great.  Can you make a PR to change it, including test coverage for this function which was seems missing in the original PR (it does have a bunch of tests though).

Even if there is a weird way it works, we probably should just change it with a release note asking to either pin at build time, or just copy paste the definition as a work-around. || Hmm, from the PR, maybe it really just needs to not use `IterNextFunc *`?  But, that seems like a difference to C maybe (i.e. the cython versioni includes the pointer, C doesn't).  I am not sure if Cython might want that.",closed,2025-03-07T07:54:20+00:00,2025-03-15T13:09:56+00:00,zoj613,00 - Bug,2,"PR#28582 - numpy/__init__.cython-30.pxd: @@ -858,6 +858,14 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|+|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1109,10 +1117,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) noexcept nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1230,9 +1234,12 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|-    NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|-    NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|-                                                        char** errmsg) except NULL|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|+    NpyIter_GetMultiIndexFunc NpyIter_GetGetMultiIndex(NpyIter* it,|;|+                                                       char** errmsg) except NULL|;|     char** NpyIter_GetDataPtrArray(NpyIter* it) nogil|;|     char** NpyIter_GetInitialDataPtrArray(NpyIter* it) nogil|;|     npy_intp* NpyIter_GetIndexPtr(NpyIter* it) || PR#28582 - numpy/__init__.pxd: @@ -773,6 +773,13 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1024,10 +1031,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1145,6 +1148,9 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|     NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|     NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|                                                         char** errmsg) except NULL || PR#28582 - numpy/_core/tests/examples/cython/checks.pyx: @@ -242,6 +242,15 @@ def npyiter_has_multi_index(it: ""nditer""):|;|     return result|;| |;| |;|+def test_get_multi_index_iter_next(it: ""nditer"", cnp.ndarray[cnp.float64_t, ndim=2] arr):|;|+    cdef cnp.NpyIter* cit = npyiter_from_nditer_obj(it)|;|+    cdef cnp.NpyIter_GetMultiIndexFunc get_multi_index = \|;|+        cnp.NpyIter_GetGetMultiIndex(cit, NULL)|;|+    cdef cnp.NpyIter_IterNextFunc iternext = \|;|+        cnp.NpyIter_GetIterNext(cit, NULL)|;|+    return 1|;|+|;|+|;| def npyiter_has_finished(it: ""nditer""):|;|     cdef cnp.NpyIter* cit|;|     try: || PR#28582 - numpy/_core/tests/test_cython.py: @@ -267,6 +267,7 @@ def test_npyiter_api(install_temp):|;|     assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)|;|     assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True|;|     assert checks.get_npyiter_ndim(it) == it.ndim == 2|;|+    assert checks.test_get_multi_index_iter_next(it, arr)|;| |;|     arr2 = np.random.rand(2, 1, 2)|;|     it = np.nditer([arr, arr2]) || PR#28453 - numpy/__init__.cython-30.pxd: @@ -825,6 +825,14 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|+|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1083,10 +1091,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) noexcept nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1204,9 +1208,12 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|-    NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|-    NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|-                                                        char** errmsg) except NULL|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|+    NpyIter_GetMultiIndexFunc NpyIter_GetGetMultiIndex(NpyIter* it,|;|+                                                       char** errmsg) except NULL|;|     char** NpyIter_GetDataPtrArray(NpyIter* it) nogil|;|     char** NpyIter_GetInitialDataPtrArray(NpyIter* it) nogil|;|     npy_intp* NpyIter_GetIndexPtr(NpyIter* it) || PR#28453 - numpy/__init__.pxd: @@ -740,6 +740,13 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -997,10 +1004,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1118,6 +1121,9 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|     NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|     NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|                                                         char** errmsg) except NULL || PR#28453 - numpy/_core/tests/examples/cython/checks.pyx: @@ -242,6 +242,15 @@ def npyiter_has_multi_index(it: ""nditer""):|;|     return result|;| |;| |;|+def test_get_multi_index_iter_next(it: ""nditer"", cnp.ndarray[cnp.float64_t, ndim=2] arr):|;|+    cdef cnp.NpyIter* cit = npyiter_from_nditer_obj(it)|;|+    cdef cnp.NpyIter_GetMultiIndexFunc get_multi_index = \|;|+        cnp.NpyIter_GetGetMultiIndex(cit, NULL)|;|+    cdef cnp.NpyIter_IterNextFunc iternext = \|;|+        cnp.NpyIter_GetIterNext(cit, NULL)|;|+    return 1|;|+|;|+|;| def npyiter_has_finished(it: ""nditer""):|;|     cdef cnp.NpyIter* cit|;|     try: || PR#28453 - numpy/_core/tests/test_cython.py: @@ -267,6 +267,7 @@ def test_npyiter_api(install_temp):|;|     assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)|;|     assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True|;|     assert checks.get_npyiter_ndim(it) == it.ndim == 2|;|+    assert checks.test_get_multi_index_iter_next(it, arr)|;| |;|     arr2 = np.random.rand(2, 1, 2)|;|     it = np.nditer([arr, arr2])","FIX: Correct return type of NpyIter_GetIterNext in Cython declarations (#28446) || MAINT: work around cython limitations, add test || FIX: Correct return type of NpyIter_GetIterNext in Cython declarations (#28446) || MAINT: work around cython limitations, add test"
numpy/numpy,ngoldbaum,28446,BUG: Unable to build cython when using `NpyIter_GetIterNext`.,"### Describe the issue:

I am trying to migrate away from using custom cython imports in order to have access to the [Iterator API](https://numpy.org/doc/stable/reference/c-api/iterator.html) declarations at `numpy/ndarrayobject.h` by using the numpy provided ones added in v2.0.0. However if I try to build the project using the file [here](https://github.com/zoj613/polyagamma/blob/update-api/polyagamma/_polyagamma.pyx) I get a build failure. Cc @seberg 

### Reproduce the code example:

```python
pip install -r requirements-dev.txt
	cythonize polyagamma/*.pyx
	pip install -e .
```

### Error message:

```shell
gcc -pthread -B /home/zoj/.local/share/micromamba/envs/polyagamma-dev/compiler_compat -fno-s
trict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/zoj/.local/share/micromamba/envs/polyag
amma-dev/include -fPIC -O2 -isystem /home/zoj/.local/share/micromamba/envs/polyagamma-dev/include 
-fPIC -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -I/tmp/pip-build-env-0bay5vae/overlay/lib/python
3.12/site-packages/numpy/_core/include -I./include -I/home/zoj/.local/share/micromamba/envs/polyag
amma-dev/include/python3.12 -c polyagamma/_polyagamma.c -o /tmp/tmpsbownh73.build-temp/polyagamma/
_polyagamma.o -O2 -std=c99
      polyagamma/_polyagamma.c: In function ‘__pyx_pf_10polyagamma_11_polyagamma_rvs’:
      polyagamma/_polyagamma.c:6265:16: error: assignment to ‘int (**)(NpyIter *)’ {aka ‘int (**)(
struct NpyIter_InternalOnly *)’} from incompatible pointer type ‘int (*)(NpyIter *)’ {aka ‘int (*)
(struct NpyIter_InternalOnly *)’} [-Wincompatible-pointer-types]
       6265 |     __pyx_t_20 = NpyIter_GetIterNext(__pyx_v_it, NULL); if (unlikely(__pyx_t_20 == (
(__pyx_t_5numpy_NpyIter_IterNextFunc *)NULL))) __PYX_ERR(0, 243, __pyx_L57_error)
            |                ^
      polyagamma/_polyagamma.c: In function ‘__pyx_f_10polyagamma_11_polyagamma_dispatch’:
      polyagamma/_polyagamma.c:7507:16: error: assignment to ‘int (**)(NpyIter *)’ {aka ‘int (**)(
struct NpyIter_InternalOnly *)’} from incompatible pointer type ‘int (*)(NpyIter *)’ {aka ‘int (*)
(struct NpyIter_InternalOnly *)’} [-Wincompatible-pointer-types]
       7507 |     __pyx_t_10 = NpyIter_GetIterNext(__pyx_v_it, NULL); if (unlikely(__pyx_t_10 == (
(__pyx_t_5numpy_NpyIter_IterNextFunc *)NULL))) __PYX_ERR(0, 462, __pyx_L11_error)
            |                ^
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/spawn.py"", line 70, in spawn
          subprocess.check_call(cmd, env=_inject_macos_ver(env))
        File ""/home/zoj/.local/share/micromamba/envs/polyagamma-dev/lib/python3.12/subprocess.py"",
 line 413, in check_call
          raise CalledProcessError(retcode, cmd)
      subprocess.CalledProcessError: Command '['/usr/bin/gcc', '-pthread', '-B', '/home/zoj/.local
/share/micromamba/envs/polyagamma-dev/compiler_compat', '-fno-strict-overflow', '-DNDEBUG', '-O2',
 '-Wall', '-fPIC', '-O2', '-isystem', '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/inclu
de', '-fPIC', '-O2', '-isystem', '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/include', 
'-fPIC', '-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION', '-I/tmp/pip-build-env-0bay5vae/overlay/lib
/python3.12/site-packages/numpy/_core/include', '-I./include', '-I/home/zoj/.local/share/micromamb
a/envs/polyagamma-dev/include/python3.12', '-c', 'polyagamma/_polyagamma.c', '-o', '/tmp/tmpsbownh
73.build-temp/polyagamma/_polyagamma.o', '-O2', '-std=c99']' returned non-zero exit status 1.
      
      The above exception was the direct cause of the following exception:
      
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/unixccompiler.py"", line 200, in _compile
          self.spawn(compiler_so + cc_args + [src, '-o', obj] + extra_postargs)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/ccompiler.py"", line 1052, in spawn
          spawn(cmd, dry_run=self.dry_run, **kwargs)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/spawn.py"", line 76, in spawn
          raise DistutilsExecError(
      distutils.errors.DistutilsExecError: command '/usr/bin/gcc' failed with exit code 1
      
      During handling of the above exception, another exception occurred:
      
      Traceback (most recent call last):
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 139, in run
          self._create_wheel_file(bdist_wheel)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 340, in _create_wheel_file
          files, mapping = self._run_build_commands(dist_name, unpacked, lib, tmp)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 263, in _run_build_commands
          self._run_build_subcommands()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
editable_wheel.py"", line 290, in _run_build_subcommands
          self.run_command(name)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/cmd.py"", line 339, in run_command
          self.distribution.run_command(command)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/dist.py""
, line 999, in run_command
          super().run_command(command)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/dist.py"", line 1002, in run_command
          cmd_obj.run()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
build_ext.py"", line 99, in run
          _build_ext.run(self)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 365, in run
          self.build_extensions()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 481, in build_extensions
          self._build_extensions_serial()
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 507, in _build_extensions_serial
          self.build_extension(ext)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/command/
build_ext.py"", line 264, in build_extension
          _build_ext.build_extension(self, ext)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/command/build_ext.py"", line 562, in build_extension
          objects = self.compiler.compile(
                    ^^^^^^^^^^^^^^^^^^^^^^
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/ccompiler.py"", line 607, in compile
          self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)
        File ""/tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distuti
ls/unixccompiler.py"", line 202, in _compile
          raise CompileError(msg)
      distutils.errors.CompileError: command '/usr/bin/gcc' failed with exit code 1
      /tmp/pip-build-env-0bay5vae/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.
py:1002: _DebuggingTips: Problem in editable installation.
      !!
      
              ********************************************************************************
              An error happened while installing `polyagamma` in editable mode.
      
              The following steps are recommended to help debug this problem:
      
              - Try to install the project normally, without using the editable mode.
                Does the error still persist?
                (If it does, try fixing the problem before attempting the editable mode).
              - If you are using binary extensions, make sure you have all OS-level
                dependencies installed (e.g. compilers, toolchains, binary libraries, ...).
              - Try the latest version of setuptools (maybe the error was already fixed).
              - If you (or your project dependencies) are using any setuptools extension
                or customization, make sure they support the editable mode.
      
              After following the steps above, if the problem still persists and
              you think this is related to how setuptools handles editable installations,
              please submit a reproducible example
              (see https://stackoverflow.com/help/minimal-reproducible-example) to:
      
                  https://github.com/pypa/setuptools/issues
      
              See https://setuptools.pypa.io/en/latest/userguide/development_mode.html for details
.
              ********************************************************************************
      
      !!
        cmd_obj.run()
      error: command '/usr/bin/gcc' failed with exit code 1
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  ERROR: Failed building editable for polyagamma
Failed to build polyagamma
ERROR: Could not build wheels for polyagamma, which is required to install pyproject.toml-based pr
ojects
make: *** [Makefile:14: dev] Error 1
```

### Python and NumPy Versions:

3.12.0 | packaged by conda-forge | (main, Oct  3 2023, 08:43:22) [GCC 12.3.0]

### Runtime Environment:

```
[{'numpy_version': '2.2.3',
  'python': '3.12.0 | packaged by conda-forge | (main, Oct  3 2023, 08:43:22) '
            '[GCC 12.3.0]',
  'uname': uname_result(system='Linux', node='zoj-desktop', release='6.12.17-1-lts', version='#1 S
MP PREEMPT_DYNAMIC Thu, 27 Feb 2025 14:12:30 +0000', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX',
                                'AVX512_CNL',
                                'AVX512_ICL'],
                      'not_found': ['AVX512_KNL', 'AVX512_KNM']}},
 {'architecture': 'SkylakeX',
  'filepath': '/home/zoj/.local/share/micromamba/envs/polyagamma-dev/lib/python3.12/site-packages/
numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 12,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

```

### Context for the issue:

Previously, I was manually importing the cython declarations and defined them like so:
```cython
ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil
cdef extern from ""numpy/ndarrayobject.h"":
 NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL
 ...
```

 as shown [here](https://github.com/zoj613/polyagamma/blob/17bab854fdad69c71c68ac8d6696a2eaa5a1abe8/polyagamma/_polyagamma.pyx#L386-L430). This worked well and I was able to successfully build the project. Now if I use the declarions added in numpy v2.0.0

```
ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil
 NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL
```
I get this build error. I believe this is due to `NpyIter_GetIterNext` returning a pointer to `NpyIter_IterNextFunc` instead of just the type.","Yeah, seems off...  What was the winning combination here?  You added this back then and we changed nothing since then, I think.

And I assumed you had code that successfully used it at the time?

I.e. I am worried that we already have someone manages to use this successfully with the current version, and a change may break them.
If that is not possible, great.  Can you make a PR to change it, including test coverage for this function which was seems missing in the original PR (it does have a bunch of tests though).

Even if there is a weird way it works, we probably should just change it with a release note asking to either pin at build time, or just copy paste the definition as a work-around. || Hmm, from the PR, maybe it really just needs to not use `IterNextFunc *`?  But, that seems like a difference to C maybe (i.e. the cython versioni includes the pointer, C doesn't).  I am not sure if Cython might want that.",closed,2025-03-07T07:54:20+00:00,2025-03-15T13:09:56+00:00,zoj613,00 - Bug,2,"PR#28582 - numpy/__init__.cython-30.pxd: @@ -858,6 +858,14 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|+|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1109,10 +1117,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) noexcept nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1230,9 +1234,12 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|-    NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|-    NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|-                                                        char** errmsg) except NULL|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|+    NpyIter_GetMultiIndexFunc NpyIter_GetGetMultiIndex(NpyIter* it,|;|+                                                       char** errmsg) except NULL|;|     char** NpyIter_GetDataPtrArray(NpyIter* it) nogil|;|     char** NpyIter_GetInitialDataPtrArray(NpyIter* it) nogil|;|     npy_intp* NpyIter_GetIndexPtr(NpyIter* it) || PR#28582 - numpy/__init__.pxd: @@ -773,6 +773,13 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1024,10 +1031,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1145,6 +1148,9 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|     NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|     NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|                                                         char** errmsg) except NULL || PR#28582 - numpy/_core/tests/examples/cython/checks.pyx: @@ -242,6 +242,15 @@ def npyiter_has_multi_index(it: ""nditer""):|;|     return result|;| |;| |;|+def test_get_multi_index_iter_next(it: ""nditer"", cnp.ndarray[cnp.float64_t, ndim=2] arr):|;|+    cdef cnp.NpyIter* cit = npyiter_from_nditer_obj(it)|;|+    cdef cnp.NpyIter_GetMultiIndexFunc get_multi_index = \|;|+        cnp.NpyIter_GetGetMultiIndex(cit, NULL)|;|+    cdef cnp.NpyIter_IterNextFunc iternext = \|;|+        cnp.NpyIter_GetIterNext(cit, NULL)|;|+    return 1|;|+|;|+|;| def npyiter_has_finished(it: ""nditer""):|;|     cdef cnp.NpyIter* cit|;|     try: || PR#28582 - numpy/_core/tests/test_cython.py: @@ -267,6 +267,7 @@ def test_npyiter_api(install_temp):|;|     assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)|;|     assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True|;|     assert checks.get_npyiter_ndim(it) == it.ndim == 2|;|+    assert checks.test_get_multi_index_iter_next(it, arr)|;| |;|     arr2 = np.random.rand(2, 1, 2)|;|     it = np.nditer([arr, arr2]) || PR#28453 - numpy/__init__.cython-30.pxd: @@ -825,6 +825,14 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|+|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -1083,10 +1091,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) noexcept nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1204,9 +1208,12 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|-    NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|-    NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|-                                                        char** errmsg) except NULL|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    NpyIter_IterNextFunc NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|+    NpyIter_GetMultiIndexFunc NpyIter_GetGetMultiIndex(NpyIter* it,|;|+                                                       char** errmsg) except NULL|;|     char** NpyIter_GetDataPtrArray(NpyIter* it) nogil|;|     char** NpyIter_GetInitialDataPtrArray(NpyIter* it) nogil|;|     npy_intp* NpyIter_GetIndexPtr(NpyIter* it) || PR#28453 - numpy/__init__.pxd: @@ -740,6 +740,13 @@ cdef extern from ""numpy/ndarraytypes.h"":|;|         int64_t year|;|         int32_t month, day, hour, min, sec, us, ps, as|;| |;|+    # Iterator API added in v1.6|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|+    # https://github.com/cython/cython/issues/6720|;|+    ctypedef int (*NpyIter_IterNextFunc ""NpyIter_IterNextFunc *"")(NpyIter* it) noexcept nogil|;|+    ctypedef void (*NpyIter_GetMultiIndexFunc ""NpyIter_GetMultiIndexFunc *"")(NpyIter* it, npy_intp* outcoords) noexcept nogil|;| |;| cdef extern from ""numpy/arrayscalars.h"":|;| |;|@@ -997,10 +1004,6 @@ cdef inline NPY_DATETIMEUNIT get_datetime64_unit(object obj) nogil:|;|     return <NPY_DATETIMEUNIT>(<PyDatetimeScalarObject*>obj).obmeta.base|;| |;| |;|-# Iterator API added in v1.6|;|-ctypedef int (*NpyIter_IterNextFunc)(NpyIter* it) noexcept nogil|;|-ctypedef void (*NpyIter_GetMultiIndexFunc)(NpyIter* it, npy_intp* outcoords) noexcept nogil|;|-|;| cdef extern from ""numpy/arrayobject.h"":|;| |;|     ctypedef struct NpyIter:|;|@@ -1118,6 +1121,9 @@ cdef extern from ""numpy/arrayobject.h"":|;|                                         npy_intp* outstrides) except NPY_FAIL|;|     npy_bool NpyIter_IsFirstVisit(NpyIter* it, int iop) nogil|;|     # functions for iterating an NpyIter object|;|+    #|;|+    # These don't match the definition in the C API because Cython can't wrap|;|+    # function pointers that return functions.|;|     NpyIter_IterNextFunc* NpyIter_GetIterNext(NpyIter* it, char** errmsg) except NULL|;|     NpyIter_GetMultiIndexFunc* NpyIter_GetGetMultiIndex(NpyIter* it,|;|                                                         char** errmsg) except NULL || PR#28453 - numpy/_core/tests/examples/cython/checks.pyx: @@ -242,6 +242,15 @@ def npyiter_has_multi_index(it: ""nditer""):|;|     return result|;| |;| |;|+def test_get_multi_index_iter_next(it: ""nditer"", cnp.ndarray[cnp.float64_t, ndim=2] arr):|;|+    cdef cnp.NpyIter* cit = npyiter_from_nditer_obj(it)|;|+    cdef cnp.NpyIter_GetMultiIndexFunc get_multi_index = \|;|+        cnp.NpyIter_GetGetMultiIndex(cit, NULL)|;|+    cdef cnp.NpyIter_IterNextFunc iternext = \|;|+        cnp.NpyIter_GetIterNext(cit, NULL)|;|+    return 1|;|+|;|+|;| def npyiter_has_finished(it: ""nditer""):|;|     cdef cnp.NpyIter* cit|;|     try: || PR#28453 - numpy/_core/tests/test_cython.py: @@ -267,6 +267,7 @@ def test_npyiter_api(install_temp):|;|     assert checks.get_npyiter_size(it) == it.itersize == np.prod(arr.shape)|;|     assert checks.npyiter_has_multi_index(it) == it.has_multi_index == True|;|     assert checks.get_npyiter_ndim(it) == it.ndim == 2|;|+    assert checks.test_get_multi_index_iter_next(it, arr)|;| |;|     arr2 = np.random.rand(2, 1, 2)|;|     it = np.nditer([arr, arr2])","FIX: Correct return type of NpyIter_GetIterNext in Cython declarations (#28446) || MAINT: work around cython limitations, add test || FIX: Correct return type of NpyIter_GetIterNext in Cython declarations (#28446) || MAINT: work around cython limitations, add test"
numpy/numpy,mayeut,28570,BUG: Python 3.13t tests are failing in manylinux_2_28,"### Describe the issue:

Python 3.13t tests are failing in manylinux_2_28

c.f. the last run of the wheel builder workflow on main: https://github.com/numpy/numpy/actions/runs/14014895658

Introduced in https://github.com/numpy/numpy/pull/28436, the last commit did not trigger the wheel builder workflow which probably mislead the reviewer in thinking that everything was ok with gcc-toolset-14.

The analysis of the issue shows that it's a bug in gcc-toolset-14, reported to RH: https://issues.redhat.com/browse/RHEL-84606

 manylinux_2_28 will be patched while waiting for feedback from RH

The difference in tests outcome between Python 3.13t and other Python versions can probably be explained by the version of Cython used and/or generated code for free-threading differs from the non free-threading one.

### Reproduce the code example:

```python
trigger the wheel builder workflow

The failing test does more or less:
python -c 'import numpy; import extending_cpp'
```

### Error message:

```shell
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
    import numpy; import extending_cpp
                  ^^^^^^^^^^^^^^^^^^^^
ImportError: /tmp/pytest-of-root/pytest-0/popen-gw4/test_cython0/random/_examples/cython/build/extending_cpp.cpython-313t-aarch64-linux-gnu.so: undefined symbol: __gxx_personality_v0
```

### Python and NumPy Versions:

main

### Runtime Environment:

manylinux_2_28

### Context for the issue:

_No response_",,closed,2025-03-23T08:01:40+00:00,2025-03-23T14:39:05+00:00,mayeut,00 - Bug,1,"PR#28571 - pyproject.toml: @@ -151,8 +151,13 @@ test-command = ""bash {project}/tools/wheels/cibw_test_command.sh {project}""|;| enable = [""cpython-freethreading"", ""pypy"", ""cpython-prerelease""]|;| |;| [tool.cibuildwheel.linux]|;|-manylinux-x86_64-image = ""manylinux_2_28""|;|-manylinux-aarch64-image = ""manylinux_2_28""|;|+# workaround https://github.com/numpy/numpy/issues/28570 by using|;|+# more recent images than the default ones in cibuildwheel 2.23.1|;|+# TODO remove this workaround once cibuildwheel gets updated to a version > 2.23.1|;|+manylinux-x86_64-image = ""quay.io/pypa/manylinux_2_28:2025.03.23-1""|;|+manylinux-aarch64-image = ""quay.io/pypa/manylinux_2_28:2025.03.23-1""|;|+# manylinux-x86_64-image = ""manylinux_2_28""|;|+# manylinux-aarch64-image = ""manylinux_2_28""|;| musllinux-x86_64-image = ""musllinux_1_2""|;| musllinux-aarch64-image = ""musllinux_1_2""|;| ","BLD: use `manylinux_2_28:2025.03.23-1` [wheel build]

Using `manylinux_2_28:2025.03.23-1` allows to work around an issue in gcc-toolset-14 which leads to failing tests on Python 3.13t."
numpy/numpy,unknown,14925,BUG: Dot product does not check for floating point warning flags,"The `dot` function (unlike ufuncs, and the ufunc based `matmul`, `@`) does not check for floating point warning/error flags. It would probably better if it would, although it is likely not high priority. The example being:

```
np.dot([1,1], [-np.inf, np.inf])
```
Which should be setting the CPU invalid value produced flag on the NaN result, but it is not caught by NumPy.

(phased out from gh-14788)",,closed,2019-11-18T01:59:11+00:00,2025-03-16T11:19:56+00:00,seberg,"00 - Bug, component: numpy._core",1,"PR#28442 - doc/release/upcoming_changes/28442.improvement.rst: @@ -0,0 +1 @@|;|+* ``np.dot`` now reports floating point exceptions. || PR#28442 - numpy/_core/src/common/cblasfuncs.c: @@ -3,13 +3,15 @@|;|  * inner product and dot for numpy arrays|;|  */|;| #define NPY_NO_DEPRECATED_API NPY_API_VERSION|;|+#define _UMATHMODULE|;| #define _MULTIARRAYMODULE|;| |;| #define PY_SSIZE_T_CLEAN|;| #include <Python.h>|;| |;| #include ""numpy/arrayobject.h""|;| #include ""numpy/npy_math.h""|;|+#include ""numpy/ufuncobject.h""|;| #include ""npy_cblas.h""|;| #include ""arraytypes.h""|;| #include ""common.h""|;|@@ -375,6 +377,8 @@ cblas_matrixproduct(int typenum, PyArrayObject *ap1, PyArrayObject *ap2,|;|             return PyArray_Return(result)|;|;     }|;| |;|+    npy_clear_floatstatus_barrier((char *) out_buf)|;|;+|;|     if (ap2shape == _scalar) {|;|         /*|;|          * Multiplication by a scalar -- Level 1 BLAS|;|@@ -689,6 +693,10 @@ cblas_matrixproduct(int typenum, PyArrayObject *ap1, PyArrayObject *ap2,|;|         NPY_END_ALLOW_THREADS|;|;     }|;| |;|+    int fpes = npy_get_floatstatus_barrier((char *) result)|;|;+    if (fpes && PyUFunc_GiveFloatingpointErrors(""dot"", fpes) < 0) {|;|+        goto fail|;|;+    }|;| |;|     Py_DECREF(ap1)|;|;     Py_DECREF(ap2); || PR#28442 - numpy/_core/src/multiarray/multiarraymodule.c: @@ -1085,6 +1085,8 @@ PyArray_MatrixProduct2(PyObject *op1, PyObject *op2, PyArrayObject* out)|;|         Py_DECREF(it1)|;|;         goto fail|;|;     }|;|+|;|+    npy_clear_floatstatus_barrier((char *) result)|;|;     NPY_BEGIN_THREADS_DESCR(PyArray_DESCR(ap2))|;|;     while (it1->index < it1->size) {|;|         while (it2->index < it2->size) {|;|@@ -1102,6 +1104,11 @@ PyArray_MatrixProduct2(PyObject *op1, PyObject *op2, PyArrayObject* out)|;|         /* only for OBJECT arrays */|;|         goto fail|;|;     }|;|+|;|+    int fpes = npy_get_floatstatus_barrier((char *) result)|;|;+    if (fpes && PyUFunc_GiveFloatingpointErrors(""dot"", fpes) < 0) {|;|+        goto fail|;|;+    }|;|     Py_DECREF(ap1)|;|;     Py_DECREF(ap2)|;|;  || PR#28442 - numpy/_core/tests/test_multiarray.py: @@ -3345,6 +3345,30 @@ def test_dot(self):|;|         a.dot(b=b, out=c)|;|         assert_equal(c, np.dot(a, b))|;| |;|+    @pytest.mark.parametrize(""dtype"", [np.half, np.double, np.longdouble])|;|+    @pytest.mark.skipif(IS_WASM, reason=""no wasm fp exception support"")|;|+    def test_dot_errstate(self, dtype):|;|+        a = np.array([1, 1], dtype=dtype)|;|+        b = np.array([-np.inf, np.inf], dtype=dtype)|;|+|;|+        with np.errstate(invalid='raise'):|;|+            # there are two paths, depending on the number of dimensions - test|;|+            # them both|;|+            with pytest.raises(FloatingPointError,|;|+                    match=""invalid value encountered in dot""):|;|+                np.dot(a, b)|;|+|;|+            # test that fp exceptions are properly cleared|;|+            np.dot(a, a)|;|+|;|+            with pytest.raises(FloatingPointError,|;|+                    match=""invalid value encountered in dot""):|;|+                np.dot(a[np.newaxis, np.newaxis, ...],|;|+                       b[np.newaxis, ..., np.newaxis])|;|+|;|+            np.dot(a[np.newaxis, np.newaxis, ...],|;|+                   a[np.newaxis, ..., np.newaxis])|;|+|;|     def test_dot_type_mismatch(self):|;|         c = 1.|;|         A = np.array((1, 1), dtype='i,i')","BUG: Check for floating point exceptions in dot

Currently dot does not check for floating point exceptions, while similar
functions (such as multiply and matmul) do.  Add these checks for consistency.

Note that certain types of floating point exceptions are still not caught:
- Multiplications of 0 with nan or inf are ignored (see #27902)
- Integer overflows are ignored.  These aren't true floating point exceptions,
but the behavior is inconsistent with scalar multiply, i.e.
```
>>> np.int16(32000) * np.int16(3)
<python-input-7>:1: RuntimeWarning: overflow encountered in scalar multiply
  np.int16(32000) * np.int16(3)
np.int16(30464)
>>> np.dot(np.int16(32000), np.int16(3))
np.int16(30464)
```

Fixes #14925 || pr comments || parametrize test, add release note || use generic typenames"
numpy/numpy,ngoldbaum,27786,BUG: poor multithreaded performance scaling for small arrays (nogil),"### Describe the issue:

Using python 3.13 free threading, I observe that multithreaded performance (MFLOPS) scales poorly for numpy array computation, especially on small arrays. For comparison, performance scales well for (1) *multiprocess* computation, and (2) multithreaded/multiprocess *ordinary python list* computation. Although I measure MFLOPS here, I would guess the underlying performance issue is some per-array-access overhead, perhaps a lock that results in thread contention.

In the attached benchmark, the workers are embarrassingly parallel. I create an array/list in each worker thread/process and then do computation on it. I only time the computation, not the setup.

The main takeaway from the plots below is that numpy performance drops dramatically when using 8+ threads in the same process (solid orange line).

The original reporter used an AMD Ryzen Threadripper PRO 5955WX 16-Cores, but @ngoldbaum edited the description and reproducer script and used a Macbook Pro M3 Max to reproduce the original report with the updated script.

![mflops_array_length_100](https://github.com/user-attachments/assets/97898af7-d377-47b0-bc69-daf2d6964eab)


Benchmark text output:

<details>

```
goldbaum at Nathans-MBP in ~/Documents/numpy-experiments
○  PYTHON_GIL=0 python parallel_bench.py --array-length 100 --num-iterations 5000
Python Version: 3.13.0 experimental free-threading build (main, Nov  5 2024, 16:45:19) [Clang 16.0.0 (clang-1600.0.26.3)]
NumPy Version: 2.1.3
os.cpu_count(): 11
1 numpy threads
1 numpy processes
1 list threads
1 list processes
2 numpy threads
2 numpy processes
2 list threads
2 list processes
4 numpy threads
4 numpy processes
4 list threads
4 list processes
8 numpy threads
8 numpy processes
8 list threads
8 list processes
16 numpy threads
16 numpy processes
16 list threads
16 list processes
32 numpy threads
32 numpy processes
32 list threads
32 list processes
64 numpy threads
64 numpy processes
64 list threads
64 list processes
128 numpy threads
128 numpy processes
128 list threads
128 list processes
256 numpy threads
256 numpy processes
256 list threads
256 list processes
512 numpy threads
512 numpy processes
512 list threads
512 list processes
1024 numpy threads
1024 numpy processes
1024 list threads
1024 list processes
2048 numpy threads
2048 numpy processes
2048 list threads
2048 list processes

# Workers  | Numpy Threads           | Numpy Processes         | List Threads            | List Processes
-----------+-------------------------+-------------------------+-------------------------+------------------------
1          | 0.01s, 84.01 MFLOPS     | 0.30s, 3.34 MFLOPS      | 0.01s, 88.63 MFLOPS     | 0.31s, 3.21 MFLOPS
2          | 0.01s, 154.94 MFLOPS    | 0.33s, 6.05 MFLOPS      | 0.01s, 171.32 MFLOPS    | 0.33s, 6.01 MFLOPS
4          | 0.01s, 288.72 MFLOPS    | 0.38s, 10.49 MFLOPS     | 0.01s, 332.36 MFLOPS    | 0.38s, 10.40 MFLOPS
8          | 0.04s, 206.42 MFLOPS    | 0.52s, 15.28 MFLOPS     | 0.02s, 340.70 MFLOPS    | 0.53s, 15.22 MFLOPS
16         | 0.11s, 141.60 MFLOPS    | 1.05s, 15.22 MFLOPS     | 0.02s, 820.67 MFLOPS    | 1.05s, 15.30 MFLOPS
32         | 0.24s, 134.02 MFLOPS    | 2.08s, 15.37 MFLOPS     | 0.02s, 1634.83 MFLOPS   | 2.24s, 14.29 MFLOPS
64         | 0.48s, 132.52 MFLOPS    | 4.06s, 15.78 MFLOPS     | 0.12s, 518.98 MFLOPS    | 4.04s, 15.84 MFLOPS
128        | 2.96s, 43.29 MFLOPS     | 8.07s, 15.87 MFLOPS     | 0.23s, 554.86 MFLOPS    | 8.33s, 15.37 MFLOPS
256        | 15.05s, 17.01 MFLOPS    | N/A                     | 0.45s, 563.20 MFLOPS    | N/A
512        | 49.28s, 10.39 MFLOPS    | N/A                     | 0.23s, 2187.81 MFLOPS   | N/A
1024       | 160.21s, 6.39 MFLOPS    | N/A                     | 1.56s, 657.09 MFLOPS    | N/A
2048       | 599.69s, 3.42 MFLOPS    | N/A                     | 2.58s, 793.79 MFLOPS    | N/A
Plot saved to mflops_array_length_100.png
```

</details>

### Reproduce the code example:

<details>

```python
import time
import threading
import multiprocessing
import numpy as np
import sys
import os
import argparse
import matplotlib.pyplot as plt

def numpy_worker(barrier, array_length, num_iterations):
    """"""Worker function for NumPy computations.""""""
    x = np.arange(array_length, dtype=np.float64)
    barrier.wait()
    for _ in range(num_iterations):
        x += 0.01  # Element-wise operation
        x[0] += x.mean() * 0.01  # Reduction operation

def list_worker(barrier, array_length, num_iterations):
    """"""Worker function for list computations.""""""
    x = [float(xi) for xi in range(array_length)]
    barrier.wait()  # Synchronize start
    for _ in range(num_iterations):
        x = [xi + 0.01 for xi in x]  # Element-wise operation
        x[0] += sum(x) / len(x) * 0.01  # Reduction operation

def launch_workers(worker_func, num_workers, method, array_length, num_iterations):
    """"""Launches workers using threading or multiprocessing.""""""
    if method == 'threads':
        barrier = threading.Barrier(num_workers + 1)
        workers = []
        for _ in range(num_workers):
            t = threading.Thread(target=worker_func, args=(barrier, array_length, num_iterations))
            workers.append(t)
            t.start()
        barrier.wait()  # Synchronize all threads
        start_time = time.time()
        for t in workers:
            t.join()
        end_time = time.time()
    elif method == 'processes':
        # Use a multiprocessing.Event for synchronization
        start_event = multiprocessing.Event()
        workers = []
        for _ in range(num_workers):
            p = multiprocessing.Process(target=worker_func, args=(start_event, array_length, num_iterations))
            workers.append(p)
            p.start()
        start_time = time.time()
        start_event.set()  # Signal all processes to start
        for p in workers:
            p.join()
        end_time = time.time()
    else:
        raise ValueError(""Unknown method"")
    return start_time, end_time

def run_benchmark(kind, method, num_workers, args):
    """"""Runs the benchmark for the specified configuration.""""""
    if kind == 'numpy':
        worker = numpy_worker
    elif kind == 'list':
        worker = list_worker
    else:
        raise ValueError(""Unknown kind"")

    # Start workers and measure time
    start_time, end_time = launch_workers(worker, num_workers, method, args.array_length, args.num_iterations)

    elapsed_time = end_time - start_time
    total_ops = num_workers * args.num_iterations * args.array_length * 2
    mflop_per_sec = total_ops / (elapsed_time * 1e6)
    return elapsed_time, mflop_per_sec

def print_results_table(results, num_workers_list):
    """"""Prints the benchmark results in a formatted table.""""""
    headers = [""# Workers"", ""Numpy Threads"", ""Numpy Processes"", ""List Threads"", ""List Processes""]
    row_format = ""{:<10} | {:<23} | {:<23} | {:<23} | {:<23}""
    separator = ""-"" * 10 + ""-+-"" + ""-+-"".join([""-"" * 23] * 4)

    print()
    print(row_format.format(*headers))
    print(separator)
    for num_workers in num_workers_list:
        row = [str(num_workers)]
        for key in [""numpy_threads"", ""numpy_processes"", ""list_threads"", ""list_processes""]:
            if key in results[num_workers]:
                elapsed, mflop = results[num_workers][key]
                row.append(f""{elapsed:.2f}s, {mflop:.2f} MFLOPS"")
            else:
                row.append(""N/A"")
        print(row_format.format(*row))

def save_plot(plot_data, array_length):
    """"""Generates and saves the benchmark plot.""""""
    plt.figure(figsize=(6.5, 4), tight_layout=True)
    styles = {
        'numpy_threads': ('solid', '#FFA500'),
        'numpy_processes': ('dotted', '#FFA500'),
        'list_threads': ('solid', '#1E90FF'),
        'list_processes': ('dotted', '#1E90FF'),
    }

    for key in plot_data:
        x = plot_data[key]['num_workers']
        y = plot_data[key]['mflop_per_sec']
        linestyle, color = styles[key]
        plt.plot(x, y, linestyle=linestyle, color=color, marker='o', label=key.replace('_', ' ').title(), linewidth=2)

    # add labels for the far-right datapoints
    printed_labels = []
    # Add padding to ensure labels outside the plot fit within the figure
    plt.gcf().subplots_adjust(right=0.8)
    for key in plot_data:
        x = plot_data[key]['num_workers']
        y = plot_data[key]['mflop_per_sec']
        _, color = styles[key]

        # Check if the current value is sufficiently distinct from previously printed labels
        if all(abs(y[-1] - prev) / max(y[-1], prev) > 0.2 for prev in printed_labels):
            # Position the label just outside the right edge of the plot
            x_pos = plt.xlim()[1] * 1.25  # 125% of the x-axis range (outside the plot)
            plt.text(
                x_pos, y[-1], f""{y[-1]:.1f}"",
                fontsize=12, color=color, ha='left', va='center'
            )
            printed_labels.append(y[-1])  # Mark this label as printed
            
    plt.xlabel('Number of Workers', fontsize=14)
    plt.ylabel('MFLOPS', fontsize=14)
    plt.title(f'MFLOPS for array length {array_length}', fontsize=16)
    plt.legend(fontsize=12)
    plt.xscale('log', base=2)
    plt.yscale('log')
    plt.xticks(plot_data['numpy_threads']['num_workers'], labels=plot_data['numpy_threads']['num_workers'], fontsize=12)
    plt.yticks(fontsize=12)
    plt.grid(True, which=""both"", ls=""--"", linewidth=0.5)
    plt.gcf().subplots_adjust(right=0.9, bottom=0.2)
    filename = f'mflops_array_length_{array_length}.png'
    plt.savefig(filename)
    print(f'Plot saved to {filename}')

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Benchmark multithreading and multiprocessing with NumPy and list operations.')
    parser.add_argument('--array-length', type=int, default=1000, help='Length of the arrays/lists used in computations.')
    parser.add_argument('--num-iterations', type=int, default=4000, help='Number of iterations each worker performs.')
    parser.add_argument('--num-workers-list', type=int, nargs='+', default=[1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048], help='List of worker counts to benchmark.')
    args = parser.parse_args()

    print(f""Python Version: {sys.version}"")
    print(f""NumPy Version: {np.__version__}"")
    print(f""os.cpu_count(): {os.cpu_count()}"")

    results = {num_workers: {} for num_workers in args.num_workers_list}
    plot_data = {
        'numpy_threads': {'num_workers': [], 'mflop_per_sec': []},
        'numpy_processes': {'num_workers': [], 'mflop_per_sec': []},
        'list_threads': {'num_workers': [], 'mflop_per_sec': []},
        'list_processes': {'num_workers': [], 'mflop_per_sec': []},
    }

    for num_workers in args.num_workers_list:
        for kind in ['numpy', 'list']:
            for method in ['threads', 'processes']:
                print(num_workers, kind, method)
                if num_workers > 128 and method == 'processes':
                    continue
                elapsed_time, mflop_per_sec = run_benchmark(kind, method, num_workers, args)
                key = f""{kind}_{method}""
                results[num_workers][key] = (elapsed_time, mflop_per_sec)
                plot_data[key]['num_workers'].append(num_workers)
                plot_data[key]['mflop_per_sec'].append(mflop_per_sec)

    print_results_table(results, args.num_workers_list)
    save_plot(plot_data, args.array_length)

```

</details>

### Error message:

_No response_

### Python and NumPy Versions:

2.1.3
3.13.0 experimental free-threading build | packaged by conda-forge | (main, Oct  8 2024, 20:16:19) [GCC 13.3.0]


### Runtime Environment:

<details>

```

[{'numpy_version': '2.1.3',
  'python': '3.13.0 experimental free-threading build | packaged by '
            'conda-forge | (main, Oct  8 2024, 20:16:19) [GCC 13.3.0]',
  'uname': uname_result(system='Linux', node='eric-Lambda-Vector', release='6.8.0-48-generic', version='#48~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  7 11:24:13 UTC 2', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Haswell',
  'filepath': '/home/eric/miniforge3/envs/habitat-lab3-py313/lib/python3.13t/site-packages/numpy.libs/libscipy_openblas64_-ff651d7f.so',
  'internal_api': 'openblas',
  'num_threads': 32,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.27'}]

AMD Ryzen Threadripper PRO 5955WX 16-Cores

```

</details>

### Context for the issue:

Our application is RL training with a [robotics simulator]((https://aihabitat.org/)). We use multiprocessing, with each worker doing mostly-independent CPU-heavy work. I was excited to try python 3.13 free-threading to reduce the cost of gathering results from workers--use multithreading instead of multiprocessing and thus avoid interprocess communication overhead. Instead, I see a big drop in overall performance. We use a lot of small numpy arrays for 3D math (3D positions, 4D rotation quaternions, 4x4 transform matrices, etc.).","Whithout diving in too deeply, are you controlling for the OpenBLAS threading underneath NumPy? You might want to use threadpoolctl or set `OMP_NUM_THREADS=1` || 
> Whithout diving in too deeply, are you controlling for the OpenBLAS threading underneath NumPy? You might want to use threadpoolctl or set `OMP_NUM_THREADS=1`

I tried this and I don't see any significant change in results.

Using `OMP_NUM_THREADS=1`:
```
(habitat-lab3-py313) .../eric/projects/habitat-lab3> OMP_NUM_THREADS=1 PYTHON_GIL=0 pyth
on bench_parallel_numpy2.py --array-length 1000 --num-iterations 5000
Python Version: 3.13.0 experimental free-threading build | packaged by conda-forge | (main, Oct  8 2024, 20:16:19) [GCC 13.3.0]
NumPy Version: 2.1.3
os.cpu_count(): 32

# Workers  | Numpy Threads           | Numpy Processes         | List Threads            | List Processes         
-----------+-------------------------+-------------------------+-------------------------+------------------------
1          | 0.02s, 491.25 MFLOPS    | 0.02s, 435.66 MFLOPS    | 0.16s, 61.01 MFLOPS     | 0.14s, 69.07 MFLOPS    
2          | 0.03s, 690.85 MFLOPS    | 0.02s, 892.60 MFLOPS    | 0.17s, 118.17 MFLOPS    | 0.15s, 136.72 MFLOPS   
4          | 0.03s, 1282.00 MFLOPS   | 0.04s, 1005.90 MFLOPS   | 0.17s, 237.00 MFLOPS    | 0.17s, 234.51 MFLOPS   
8          | 0.03s, 3016.43 MFLOPS   | 0.04s, 1994.34 MFLOPS   | 0.17s, 461.44 MFLOPS    | 0.20s, 406.46 MFLOPS   
16         | 0.07s, 2204.74 MFLOPS   | 0.04s, 4028.53 MFLOPS   | 0.20s, 782.43 MFLOPS    | 0.19s, 835.31 MFLOPS   
32         | 0.75s, 426.18 MFLOPS    | 0.05s, 6079.83 MFLOPS   | 0.32s, 1012.60 MFLOPS   | 0.27s, 1186.59 MFLOPS  
64         | 1.69s, 377.93 MFLOPS    | 0.09s, 6768.71 MFLOPS   | 0.52s, 1227.61 MFLOPS   | 0.57s, 1122.68 MFLOPS  
128        | 11.68s, 109.56 MFLOPS   | 0.18s, 7025.79 MFLOPS   | 1.24s, 1031.60 MFLOPS   | 1.11s, 1150.95 MFLOPS  
Plot saved to mflops_array_length_1000.png
```

Using `with threadpool_limits(limits=1, user_api='blas'):`
```
(habitat-lab3-py313) .../eric/projects/habitat-lab3> git diff -- *bench*
diff --git a/bench_parallel_numpy2.py b/bench_parallel_numpy2.py
index 37ecd80e..6010677b 100644
--- a/bench_parallel_numpy2.py
+++ b/bench_parallel_numpy2.py
@@ -6,6 +6,7 @@ import sys
 import os
 import argparse
 import matplotlib.pyplot as plt
+from threadpoolctl import threadpool_limits
 
 def numpy_worker(sync_func, array_length, num_iterations):
     """"""Worker function for NumPy computations.""""""
@@ -162,14 +163,15 @@ if __name__ == '__main__':
         'list_processes': {'num_workers': [], 'mflop_per_sec': []}
     }
 
-    for num_workers in args.num_workers_list:
-        for kind in ['numpy', 'list']:
-            for method in ['threads', 'processes']:
-                elapsed_time, mflop_per_sec = run_benchmark(kind, method, num_workers, args)
-                key = f""{kind}_{method}""
-                results[num_workers][key] = (elapsed_time, mflop_per_sec)
-                plot_data[key]['num_workers'].append(num_workers)
-                plot_data[key]['mflop_per_sec'].append(mflop_per_sec)
+    with threadpool_limits(limits=1, user_api='blas'):
+        for num_workers in args.num_workers_list:
+            for kind in ['numpy', 'list']:
+                for method in ['threads', 'processes']:
+                    elapsed_time, mflop_per_sec = run_benchmark(kind, method, num_workers, args)
+                    key = f""{kind}_{method}""
+                    results[num_workers][key] = (elapsed_time, mflop_per_sec)
+                    plot_data[key]['num_workers'].append(num_workers)
+                    plot_data[key]['mflop_per_sec'].append(mflop_per_sec)
 
     print_results_table(results, args.num_workers_list)
     save_plot(plot_data, args.array_length)
(habitat-lab3-py313) .../eric/projects/habitat-lab3> PYTHON_GIL=0 python bench_par
allel_numpy2.py --array-length 1000 --num-iterations 5000
Python Version: 3.13.0 experimental free-threading build | packaged by conda-forge | (main, Oct  8 2024, 20:16:19) [GCC 13.3.0]
NumPy Version: 2.1.3
os.cpu_count(): 32

# Workers  | Numpy Threads           | Numpy Processes         | List Threads            | List Processes         
-----------+-------------------------+-------------------------+-------------------------+------------------------
1          | 0.02s, 495.42 MFLOPS    | 0.02s, 439.03 MFLOPS    | 0.17s, 59.29 MFLOPS     | 0.15s, 68.26 MFLOPS    
2          | 0.02s, 972.59 MFLOPS    | 0.02s, 908.35 MFLOPS    | 0.17s, 119.74 MFLOPS    | 0.15s, 136.52 MFLOPS   
4          | 0.02s, 1655.31 MFLOPS   | 0.03s, 1555.79 MFLOPS   | 0.17s, 233.46 MFLOPS    | 0.17s, 235.38 MFLOPS   
8          | 0.04s, 1951.72 MFLOPS   | 0.03s, 3120.99 MFLOPS   | 0.17s, 468.99 MFLOPS    | 0.15s, 528.60 MFLOPS   
16         | 0.07s, 2401.98 MFLOPS   | 0.04s, 3770.33 MFLOPS   | 0.26s, 613.33 MFLOPS    | 0.23s, 688.85 MFLOPS   
32         | 1.02s, 313.50 MFLOPS    | 0.06s, 5601.79 MFLOPS   | 0.30s, 1052.49 MFLOPS   | 0.27s, 1201.13 MFLOPS  
64         | 1.92s, 334.18 MFLOPS    | 0.09s, 6875.34 MFLOPS   | 0.51s, 1266.58 MFLOPS   | 0.58s, 1098.56 MFLOPS  
128        | 12.58s, 101.74 MFLOPS   | 0.18s, 7236.04 MFLOPS   | 1.23s, 1036.92 MFLOPS   | 1.10s, 1165.71 MFLOPS  
Plot saved to mflops_array_length_1000.png
``` || Thanks. Now that I look at this more carefully, it seems there is some thread contention limiting NumPy's performance. Looking only at the ""NumPy Threads"" graphs, they appear to scale ""per call"": i.e. if you divide the mflops by the vector length, the graphs will align. The core calculation `x[0] += x.mean() * 0.01` uses `mean()` which is roughly `y = x.sum(); x[0] += y / np.intp(np.prod(x.shape))`. The call to x.sum() must allocate a new ndarray. for the answer. I wonder what happens if you avoid the allocation by using `x[0] += x.mean(out=y) * 0.01` where `y=np.empty(1, dtype=np.float64)`. || When I run the attached script, I get:

```
AttributeError: Can't get local object 'launch_workers.<locals>.sync_func'
```

My understanding is that closures aren't pickleable and you can't use them with multiprocessing like you're doing with `sync_func` in the multiprocessing case. Did you make some edits before submitting the issue maybe?

That said if I hack the script to skip the multiprocessing benchmark then I am able to reproduce the behavior described in the issue:

![mflops_array_length_10](https://github.com/user-attachments/assets/0cb5ff70-1601-4ed5-a316-953c24aff93d)

 || >it seems there is some thread contention limiting NumPy's performance
>they appear to scale ""per call""

Agreed! Python free-threading has [biased reference counting](https://peps.python.org/pep-0703/#biased-reference-counting) , ""a fast-path for objects owned by the current thread"", I wonder if numpy could do something similar for whatever it's doing per call.

>AttributeError: Can't get local object 'launch_workers.<locals>.sync_func'
>Did you make some edits before submitting the issue maybe?

Hmmm, the script runs as-is for me. Maybe some platform or version difference?

Here's an alternate snippet that just removes the synchronization for the multiprocessing case. So, the timing includes the setup (not just computation), which is sloppy, but you'll still get similar results.

```
def numpy_worker(sync_func, array_length, num_iterations):
    """"""Worker function for NumPy computations.""""""
    x = np.arange(array_length, dtype=np.float64)
    if sync_func:
        sync_func()  # Synchronize start
    for _ in range(num_iterations):
        x += 0.01  # Element-wise operation
        x[0] += x.mean() * 0.01  # Reduction operation

def list_worker(sync_func, array_length, num_iterations):
    """"""Worker function for list computations.""""""
    x = [float(xi) for xi in range(array_length)]
    if sync_func:
        sync_func()  # Synchronize start
    for _ in range(num_iterations):
        x = [xi + 0.01 for xi in x]  # Element-wise operation
        x[0] += sum(x) / len(x) * 0.01  # Reduction operation

def launch_workers(worker_func, num_workers, method, array_length, num_iterations):
    """"""Launches workers using threading or multiprocessing.""""""
    if method == 'threads':
        barrier = threading.Barrier(num_workers + 1)
        def sync_func():
            barrier.wait()
        workers = []
        for _ in range(num_workers):
            t = threading.Thread(target=worker_func, args=(sync_func, array_length, num_iterations))
            workers.append(t)
            t.start()
        barrier.wait()  # Synchronize all threads
        start_time = time.time()
        for t in workers:
            t.join()
        end_time = time.time()
    elif method == 'processes':
        start_time = time.time()
        workers = []
        for _ in range(num_workers):
            p = multiprocessing.Process(target=worker_func, args=(None, array_length, num_iterations))
            workers.append(p)
            p.start()
        for p in workers:
            p.join()
        end_time = time.time()
    else:
        raise ValueError(""Unknown method"")
    return start_time, end_time
``` || Thanks! I wonder if your site environment patches python to use something like `dill` or `cloudpickle` instead of the regular pickle. [e.g.](https://stackoverflow.com/questions/72988091/how-to-pickle-closure).

I'm going to try to profile this today using a few tools to see if this is due to lock contention inside CPython or inside NumPy. If it's due to locking that we added in NumPy to make things thread-safe, maybe we can simply disable it or find a quick fix for the scaling issue. 

It's also probably worth adding documentation to py-free-threading.github.io to help with debugging issues like this. This is the first time this has come up so far in NumPy but doubtless it will happen a lot across the ecosystem. || I rewrote the test script to pass the `threading.Barrier` or `multiprocessing.Event` into the worker function (which avoids the issue with pickling a closure), added some extra prints and skipped the very slow multiprocessing-based runs for large worker counts.

I went ahead and edited the issue description so it only includes one graph and includes working reproducer code, hope you don't mind @eundersander.
 || I've attached a flamegraph I generated using the `cargo-flamegraph` CLI tool, which seems to do a great job of sampling Python C extensions.

![image](https://github.com/user-attachments/assets/ec27e5be-d7af-4717-a3e7-51e8c8d42dc6)

I ran this script:

<details>

```python
import threading

import numpy as np

def numpy_worker(barrier, array_length, num_iterations):
    """"""Worker function for NumPy computations.""""""
    x = np.arange(array_length, dtype=np.float64)
    barrier.wait()
    for _ in range(num_iterations):
        x += 0.01  # Element-wise operation
        x[0] += x.mean() * 0.01  # Reduction operation
    print(f""ended {threading.get_ident()}"")

num_workers = 1024

barrier = threading.Barrier(num_workers + 1)

workers = []
for _ in range(num_workers):
    t = threading.Thread(target=numpy_worker, args=(barrier, 100, 5000))
    workers.append(t)
    t.start()
barrier.wait()

[t.join() for t in workers]
```

</details>

So clearly the way we're using a critical section to lock the ufunc identity cache doesn't scale well:

https://github.com/numpy/numpy/blob/b85a149fea2c005d395772fcc6078ce370a6bcc4/numpy/_core/src/umath/dispatching.c#L979-L983

I wonder how hard it would be to make the ufunc idetity cache per-thread. It's tricky because the cache hangs off of a global ufunc object. If instead we had some kind of thread-local registry mapping ufuncs to the corresponding identity cache that would avoid the need for any kind of locking.

@colesbury I'd appreciate your thoughts here. || Yeah, we should make the fast path of `promote_and_get_info_and_ufuncimpl` scale well. I think the important part is just these few lines, if I understand correctly:

https://github.com/numpy/numpy/blob/b85a149fea2c005d395772fcc6078ce370a6bcc4/numpy/_core/src/umath/dispatching.c#L773-L779

One option is to use a a [readers-writer lock](https://en.wikipedia.org/wiki/Readers%E2%80%93writer_lock). The downsides are:
* They don't necessarily scale that well, even for read-only workloads, because of contention of the count of the number of readers. That may or may not be an issue here. It's hard to know without testing it
* It's not part of the public Python C API or the C standard library. So we might need to use a mix of pthreads and Windows API.

I'll think about it some more. || Yeah, it's basically a custom dict lookup that needs to be safe (and if that fails, we shouldn't worry about speed).
I could imagine that having a custom hashmap is just too terrible in a free-threaded world.  IIRC it was maybe 15%-20% faster for small arrays, but maybe we can (ab)use dicts and still shave off most of that anyway... || Unfortunately it's not just that there's a custom hashmap, the problem is that if you have a cache miss and lots of threads are doing similar ufunc operations then you're almost certain to have races inside `promote_and_get_ufuncimpl` outside of the custom hashmap implementation. || I think that's fine -- we can lock around the other parts. || See https://github.com/numpy/numpy/pull/27859 || See https://github.com/numpy/numpy/pull/27896 for a second try at a fix :)",closed,2024-11-18T07:52:11+00:00,2024-12-05T13:13:32+00:00,eundersander,"00 - Bug, 39 - free-threading",2,"PR#27896 - doc/release/upcoming_changes/27896.performance.rst: @@ -0,0 +1,2 @@|;|+* Improved multithreaded scaling on the free-threaded build when many threads|;|+  simultaneously call the same ufunc operations. || PR#27896 - numpy/_core/code_generators/genapi.py: @@ -85,7 +85,7 @@ def get_processor():|;|              join('multiarray', 'stringdtype', 'static_string.c'),|;|              join('multiarray', 'strfuncs.c'),|;|              join('multiarray', 'usertypes.c'),|;|-             join('umath', 'dispatching.c'),|;|+             join('umath', 'dispatching.cpp'),|;|              join('umath', 'extobj.c'),|;|              join('umath', 'loops.c.src'),|;|              join('umath', 'reduction.c'), || PR#27896 - numpy/_core/code_generators/generate_umath.py: @@ -1592,13 +1592,10 @@ def make_code(funcdict, filename):|;|     #include ""matmul.h""|;|     #include ""clip.h""|;|     #include ""dtypemeta.h""|;|+    #include ""dispatching.h""|;|     #include ""_umath_doc_generated.h""|;| |;|     %s|;|-    /* Returns a borrowed ref of the second value in the matching info tuple */|;|-    PyObject *|;|-    get_info_no_cast(PyUFuncObject *ufunc, PyArray_DTypeMeta *op_dtype,|;|-                     int ndtypes)|;|; |;|     static int|;|     InitOperators(PyObject *dictionary) { || PR#27896 - numpy/_core/include/numpy/ndarraytypes.h: @@ -1,6 +1,10 @@|;| #ifndef NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_|;| #define NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| #include ""npy_common.h""|;| #include ""npy_endian.h""|;| #include ""npy_cpu.h""|;|@@ -1922,4 +1926,8 @@ typedef struct {|;|  */|;| #undef NPY_DEPRECATED_INCLUDES|;| |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_ */ || PR#27896 - numpy/_core/meson.build: @@ -713,7 +713,7 @@ py.extension_module('_multiarray_tests',|;|     src_file.process('src/multiarray/_multiarray_tests.c.src'),|;|     'src/common/mem_overlap.c',|;|     'src/common/npy_argparse.c',|;|-    'src/common/npy_hashtable.c',|;|+    'src/common/npy_hashtable.cpp',|;|     src_file.process('src/common/templ_common.h.src')|;|   ],|;|   c_args: c_args_common,|;|@@ -1042,7 +1042,7 @@ src_multiarray_umath_common = [|;|   'src/common/gil_utils.c',|;|   'src/common/mem_overlap.c',|;|   'src/common/npy_argparse.c',|;|-  'src/common/npy_hashtable.c',|;|+  'src/common/npy_hashtable.cpp',|;|   'src/common/npy_import.c',|;|   'src/common/npy_longdouble.c',|;|   'src/common/ucsnarrow.c',|;|@@ -1153,7 +1153,7 @@ src_umath = umath_gen_headers + [|;|   'src/umath/ufunc_type_resolution.c',|;|   'src/umath/clip.cpp',|;|   'src/umath/clip.h',|;|-  'src/umath/dispatching.c',|;|+  'src/umath/dispatching.cpp',|;|   'src/umath/extobj.c',|;|   'src/umath/legacy_array_method.c',|;|   'src/umath/override.c', || PR#27896 - numpy/_core/src/common/npy_hashtable.cpp: @@ -12,6 +12,9 @@|;|  * case is likely desired.|;|  */|;| |;|+#include <mutex>|;|+#include <shared_mutex>|;|+|;| #include ""templ_common.h""|;| #include ""npy_hashtable.h""|;| |;|@@ -89,7 +92,7 @@ find_item(PyArrayIdentityHash const *tb, PyObject *const *key)|;| NPY_NO_EXPORT PyArrayIdentityHash *|;| PyArrayIdentityHash_New(int key_len)|;| {|;|-    PyArrayIdentityHash *res = PyMem_Malloc(sizeof(PyArrayIdentityHash))|;|;+    PyArrayIdentityHash *res = (PyArrayIdentityHash *)PyMem_Malloc(sizeof(PyArrayIdentityHash))|;|;     if (res == NULL) {|;|         PyErr_NoMemory()|;|;         return NULL|;|;@@ -100,12 +103,21 @@ PyArrayIdentityHash_New(int key_len)|;|     res->size = 4;  /* Start with a size of 4 */|;|     res->nelem = 0|;|; |;|-    res->buckets = PyMem_Calloc(4 * (key_len + 1), sizeof(PyObject *))|;|;+    res->buckets = (PyObject **)PyMem_Calloc(4 * (key_len + 1), sizeof(PyObject *))|;|;     if (res->buckets == NULL) {|;|         PyErr_NoMemory()|;|;         PyMem_Free(res)|;|;         return NULL|;|;     }|;|+|;|+#ifdef Py_GIL_DISABLED|;|+    res->mutex = new(std::nothrow) std::shared_mutex()|;|;+    if (res->mutex == nullptr) {|;|+        PyErr_NoMemory()|;|;+        PyMem_Free(res)|;|;+        return NULL|;|;+    }|;|+#endif|;|     return res|;|; }|;| |;|@@ -115,6 +127,9 @@ PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *tb)|;| {|;|     PyMem_Free(tb->buckets)|;|;     PyMem_Free(tb)|;|;+#ifdef Py_GIL_DISABLED|;|+    delete (std::shared_mutex *)tb->mutex|;|;+#endif|;| }|;| |;| |;|@@ -149,7 +164,7 @@ _resize_if_necessary(PyArrayIdentityHash *tb)|;|     if (npy_mul_sizes_with_overflow(&alloc_size, new_size, tb->key_len + 1)) {|;|         return -1|;|;     }|;|-    tb->buckets = PyMem_Calloc(alloc_size, sizeof(PyObject *))|;|;+    tb->buckets = (PyObject **)PyMem_Calloc(alloc_size, sizeof(PyObject *))|;|;     if (tb->buckets == NULL) {|;|         tb->buckets = old_table|;|;         PyErr_NoMemory(); || PR#27896 - numpy/_core/src/common/npy_hashtable.h: @@ -7,12 +7,19 @@|;| #include ""numpy/ndarraytypes.h""|;| |;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| typedef struct {|;|     int key_len;  /* number of identities used */|;|     /* Buckets stores: val1, key1[0], key1[1], ..., val2, key2[0], ... */|;|     PyObject **buckets|;|;     npy_intp size;  /* current size */|;|     npy_intp nelem;  /* number of elements */|;|+#ifdef Py_GIL_DISABLED|;|+    void *mutex|;|;+#endif|;| } PyArrayIdentityHash|;|; |;| |;|@@ -29,4 +36,8 @@ PyArrayIdentityHash_New(int key_len)|;|; NPY_NO_EXPORT void|;| PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *tb)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_SRC_COMMON_NPY_NPY_HASHTABLE_H_ */ || PR#27896 - numpy/_core/src/multiarray/common.h: @@ -12,6 +12,10 @@|;| #include ""npy_import.h""|;| #include <limits.h>|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| #define error_converting(x)  (((x) == -1) && PyErr_Occurred())|;| |;| #ifdef NPY_ALLOW_THREADS|;|@@ -104,13 +108,13 @@ check_and_adjust_index(npy_intp *index, npy_intp max_item, int axis,|;|         /* Try to be as clear as possible about what went wrong. */|;|         if (axis >= 0) {|;|             PyErr_Format(PyExc_IndexError,|;|-                         ""index %""NPY_INTP_FMT"" is out of bounds ""|;|-                         ""for axis %d with size %""NPY_INTP_FMT,|;|+                         ""index %"" NPY_INTP_FMT"" is out of bounds ""|;|+                         ""for axis %d with size %"" NPY_INTP_FMT,|;|                          *index, axis, max_item)|;|;         } else {|;|             PyErr_Format(PyExc_IndexError,|;|-                         ""index %""NPY_INTP_FMT"" is out of bounds ""|;|-                         ""for size %""NPY_INTP_FMT, *index, max_item)|;|;+                         ""index %"" NPY_INTP_FMT "" is out of bounds ""|;|+                         ""for size %"" NPY_INTP_FMT, *index, max_item)|;|;         }|;|         return -1|;|;     }|;|@@ -163,7 +167,9 @@ check_and_adjust_axis(int *axis, int ndim)|;|  * <https://gcc.gnu.org/bugzilla/show_bug.cgi?id=52023>.|;|  * clang versions < 8.0.0 have the same bug.|;|  */|;|-#if (!defined __STDC_VERSION__ || __STDC_VERSION__ < 201112 \|;|+#ifdef __cplusplus|;|+#define NPY_ALIGNOF(type) alignof(type)|;|+#elif (!defined __STDC_VERSION__ || __STDC_VERSION__ < 201112 \|;|      || (defined __GNUC__ && __GNUC__ < 4 + (__GNUC_MINOR__ < 9) \|;|   && !defined __clang__) \|;|      || (defined __clang__ && __clang_major__ < 8))|;|@@ -347,4 +353,8 @@ new_array_for_sum(PyArrayObject *ap1, PyArrayObject *ap2, PyArrayObject* out,|;|  */|;| #define NPY_ITER_REDUCTION_AXIS(axis) (axis + (1 << (NPY_BITSOF_INT - 2)))|;| |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_SRC_MULTIARRAY_COMMON_H_ */ || PR#27896 - numpy/_core/src/multiarray/npy_static_data.h: @@ -1,6 +1,10 @@|;| #ifndef NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_|;| #define NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| NPY_NO_EXPORT int|;| initialize_static_globals(void)|;|; |;|@@ -168,4 +172,8 @@ NPY_VISIBILITY_HIDDEN extern npy_interned_str_struct npy_interned_str|;|; NPY_VISIBILITY_HIDDEN extern npy_static_pydata_struct npy_static_pydata|;|; NPY_VISIBILITY_HIDDEN extern npy_static_cdata_struct npy_static_cdata|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  // NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_ || PR#27896 - numpy/_core/src/umath/dispatching.cpp: @@ -38,6 +38,9 @@|;| #define _MULTIARRAYMODULE|;| #define _UMATHMODULE|;| |;|+#include <mutex>|;|+#include <shared_mutex>|;|+|;| #define PY_SSIZE_T_CLEAN|;| #include <Python.h>|;| #include <convert_datatype.h>|;|@@ -504,8 +507,9 @@ call_promoter_and_recurse(PyUFuncObject *ufunc, PyObject *info,|;|         PyObject *promoter = PyTuple_GET_ITEM(info, 1)|;|;         if (PyCapsule_CheckExact(promoter)) {|;|             /* We could also go the other way and wrap up the python function... */|;|-            PyArrayMethod_PromoterFunction *promoter_function = PyCapsule_GetPointer(|;|-                    promoter, ""numpy._ufunc_promoter"")|;|;+            PyArrayMethod_PromoterFunction *promoter_function =|;|+                    (PyArrayMethod_PromoterFunction *)PyCapsule_GetPointer(|;|+                            promoter, ""numpy._ufunc_promoter"")|;|;             if (promoter_function == NULL) {|;|                 return NULL|;|;             }|;|@@ -770,8 +774,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|      * 2. Check all registered loops/promoters to find the best match.|;|      * 3. Fall back to the legacy implementation if no match was found.|;|      */|;|-    PyObject *info = PyArrayIdentityHash_GetItem(ufunc->_dispatch_cache,|;|-                (PyObject **)op_dtypes)|;|;+    PyObject *info = PyArrayIdentityHash_GetItem(|;|+            (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+            (PyObject **)op_dtypes)|;|;     if (info != NULL && PyObject_TypeCheck(|;|             PyTuple_GET_ITEM(info, 1), &PyArrayMethod_Type)) {|;|         /* Found the ArrayMethod and NOT a promoter: return it */|;|@@ -793,8 +798,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|              * Found the ArrayMethod and NOT promoter.  Before returning it|;|              * add it to the cache for faster lookup in the future.|;|              */|;|-            if (PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-                    (PyObject **)op_dtypes, info, 0) < 0) {|;|+            if (PyArrayIdentityHash_SetItem(|;|+                        (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                        (PyObject **)op_dtypes, info, 0) < 0) {|;|                 return NULL|;|;             }|;|             return info|;|;@@ -815,8 +821,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|         }|;|         else if (info != NULL) {|;|             /* Add result to the cache using the original types: */|;|-            if (PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-                    (PyObject **)op_dtypes, info, 0) < 0) {|;|+            if (PyArrayIdentityHash_SetItem(|;|+                        (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                        (PyObject **)op_dtypes, info, 0) < 0) {|;|                 return NULL|;|;             }|;|             return info|;|;@@ -882,13 +889,51 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|     }|;| |;|     /* Add this to the cache using the original types: */|;|-    if (cacheable && PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-            (PyObject **)op_dtypes, info, 0) < 0) {|;|+    if (cacheable && PyArrayIdentityHash_SetItem(|;|+                (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                (PyObject **)op_dtypes, info, 0) < 0) {|;|         return NULL|;|;     }|;|     return info|;|; }|;| |;|+#ifdef Py_GIL_DISABLED|;|+/*|;|+ * Fast path for promote_and_get_info_and_ufuncimpl.|;|+ * Acquires a read lock to check for a cache hit and then|;|+ * only acquires a write lock on a cache miss to fill the cache|;|+ */|;|+static inline PyObject *|;|+promote_and_get_info_and_ufuncimpl_with_locking(|;|+        PyUFuncObject *ufunc,|;|+        PyArrayObject *const ops[],|;|+        PyArray_DTypeMeta *signature[],|;|+        PyArray_DTypeMeta *op_dtypes[],|;|+        npy_bool legacy_promotion_is_possible)|;|+{|;|+    std::shared_mutex *mutex = ((std::shared_mutex *)((PyArrayIdentityHash *)ufunc->_dispatch_cache)->mutex)|;|;+    mutex->lock_shared()|;|;+    PyObject *info = PyArrayIdentityHash_GetItem(|;|+            (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+            (PyObject **)op_dtypes)|;|;+    mutex->unlock_shared()|;|;+|;|+    if (info != NULL && PyObject_TypeCheck(|;|+                    PyTuple_GET_ITEM(info, 1), &PyArrayMethod_Type)) {|;|+        /* Found the ArrayMethod and NOT a promoter: return it */|;|+        return info|;|;+    }|;|+|;|+    // cache miss, need to acquire a write lock and recursively calculate the|;|+    // correct dispatch resolution|;|+    mutex->lock()|;|;+    info = promote_and_get_info_and_ufuncimpl(ufunc,|;|+            ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;+    mutex->unlock()|;|;+|;|+    return info|;|;+}|;|+#endif|;| |;| /**|;|  * The central entry-point for the promotion and dispatching machinery.|;|@@ -941,6 +986,8 @@ promote_and_get_ufuncimpl(PyUFuncObject *ufunc,|;| {|;|     int nin = ufunc->nin, nargs = ufunc->nargs|;|;     npy_bool legacy_promotion_is_possible = NPY_TRUE|;|;+    PyObject *all_dtypes = NULL|;|;+    PyArrayMethodObject *method = NULL|;|; |;|     /*|;|      * Get the actual DTypes we operate with by setting op_dtypes[i] from|;|@@ -976,18 +1023,20 @@ promote_and_get_ufuncimpl(PyUFuncObject *ufunc,|;|         }|;|     }|;| |;|-    PyObject *info|;|;-    Py_BEGIN_CRITICAL_SECTION((PyObject *)ufunc)|;|;-    info = promote_and_get_info_and_ufuncimpl(ufunc,|;|+#ifdef Py_GIL_DISABLED|;|+    PyObject *info = promote_and_get_info_and_ufuncimpl_with_locking(ufunc,|;|+            ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;+#else|;|+    PyObject *info = promote_and_get_info_and_ufuncimpl(ufunc,|;|             ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;-    Py_END_CRITICAL_SECTION()|;|;+#endif|;| |;|     if (info == NULL) {|;|         goto handle_error|;|;     }|;| |;|-    PyArrayMethodObject *method = (PyArrayMethodObject *)PyTuple_GET_ITEM(info, 1)|;|;-    PyObject *all_dtypes = PyTuple_GET_ITEM(info, 0)|;|;+    method = (PyArrayMethodObject *)PyTuple_GET_ITEM(info, 1)|;|;+    all_dtypes = PyTuple_GET_ITEM(info, 0)|;|; |;|     /*|;|      * In certain cases (only the logical ufuncs really), the loop we found may|;|@@ -1218,7 +1267,7 @@ install_logical_ufunc_promoter(PyObject *ufunc)|;|     if (dtype_tuple == NULL) {|;|         return -1|;|;     }|;|-    PyObject *promoter = PyCapsule_New(&logical_ufunc_promoter,|;|+    PyObject *promoter = PyCapsule_New((void *)&logical_ufunc_promoter,|;|             ""numpy._ufunc_promoter"", NULL)|;|;     if (promoter == NULL) {|;|         Py_DECREF(dtype_tuple); || PR#27896 - numpy/_core/src/umath/dispatching.h: @@ -43,6 +43,10 @@ object_only_ufunc_promoter(PyObject *ufunc,|;| NPY_NO_EXPORT int|;| install_logical_ufunc_promoter(PyObject *ufunc)|;|; |;|+NPY_NO_EXPORT PyObject *|;|+get_info_no_cast(PyUFuncObject *ufunc, PyArray_DTypeMeta *op_dtype,|;|+                 int ndtypes)|;|;+|;| #ifdef __cplusplus|;| }|;| #endif || PR#27896 - numpy/_core/src/umath/ufunc_object.h: @@ -3,11 +3,18 @@|;| |;| #include <numpy/ufuncobject.h>|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;| |;| NPY_NO_EXPORT const char*|;| ufunc_get_name_cstr(PyUFuncObject *ufunc)|;|; |;| NPY_NO_EXPORT PyObject *|;| PyUFunc_GetDefaultIdentity(PyUFuncObject *ufunc, npy_bool *reorderable)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif || PR#27896 - numpy/_core/src/umath/ufunc_type_resolution.h: @@ -1,6 +1,10 @@|;| #ifndef _NPY_PRIVATE__UFUNC_TYPE_RESOLUTION_H_|;| #define _NPY_PRIVATE__UFUNC_TYPE_RESOLUTION_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| NPY_NO_EXPORT int|;| PyUFunc_SimpleBinaryComparisonTypeResolver(PyUFuncObject *ufunc,|;|                                            NPY_CASTING casting,|;|@@ -142,4 +146,8 @@ PyUFunc_DefaultLegacyInnerLoopSelector(PyUFuncObject *ufunc,|;| NPY_NO_EXPORT int|;| raise_no_loop_found_error(PyUFuncObject *ufunc, PyObject **dtypes)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif || PR#27913 - doc/release/upcoming_changes/27896.performance.rst: @@ -0,0 +1,2 @@|;|+* Improved multithreaded scaling on the free-threaded build when many threads|;|+  simultaneously call the same ufunc operations. || PR#27913 - numpy/_core/code_generators/genapi.py: @@ -85,7 +85,7 @@ def get_processor():|;|              join('multiarray', 'stringdtype', 'static_string.c'),|;|              join('multiarray', 'strfuncs.c'),|;|              join('multiarray', 'usertypes.c'),|;|-             join('umath', 'dispatching.c'),|;|+             join('umath', 'dispatching.cpp'),|;|              join('umath', 'extobj.c'),|;|              join('umath', 'loops.c.src'),|;|              join('umath', 'reduction.c'), || PR#27913 - numpy/_core/code_generators/generate_umath.py: @@ -1592,13 +1592,10 @@ def make_code(funcdict, filename):|;|     #include ""matmul.h""|;|     #include ""clip.h""|;|     #include ""dtypemeta.h""|;|+    #include ""dispatching.h""|;|     #include ""_umath_doc_generated.h""|;| |;|     %s|;|-    /* Returns a borrowed ref of the second value in the matching info tuple */|;|-    PyObject *|;|-    get_info_no_cast(PyUFuncObject *ufunc, PyArray_DTypeMeta *op_dtype,|;|-                     int ndtypes)|;|; |;|     static int|;|     InitOperators(PyObject *dictionary) { || PR#27913 - numpy/_core/include/numpy/ndarraytypes.h: @@ -1,6 +1,10 @@|;| #ifndef NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_|;| #define NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| #include ""npy_common.h""|;| #include ""npy_endian.h""|;| #include ""npy_cpu.h""|;|@@ -1922,4 +1926,8 @@ typedef struct {|;|  */|;| #undef NPY_DEPRECATED_INCLUDES|;| |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_INCLUDE_NUMPY_NDARRAYTYPES_H_ */ || PR#27913 - numpy/_core/meson.build: @@ -713,7 +713,7 @@ py.extension_module('_multiarray_tests',|;|     src_file.process('src/multiarray/_multiarray_tests.c.src'),|;|     'src/common/mem_overlap.c',|;|     'src/common/npy_argparse.c',|;|-    'src/common/npy_hashtable.c',|;|+    'src/common/npy_hashtable.cpp',|;|     src_file.process('src/common/templ_common.h.src')|;|   ],|;|   c_args: c_args_common,|;|@@ -1042,7 +1042,7 @@ src_multiarray_umath_common = [|;|   'src/common/gil_utils.c',|;|   'src/common/mem_overlap.c',|;|   'src/common/npy_argparse.c',|;|-  'src/common/npy_hashtable.c',|;|+  'src/common/npy_hashtable.cpp',|;|   'src/common/npy_import.c',|;|   'src/common/npy_longdouble.c',|;|   'src/common/ucsnarrow.c',|;|@@ -1153,7 +1153,7 @@ src_umath = umath_gen_headers + [|;|   'src/umath/ufunc_type_resolution.c',|;|   'src/umath/clip.cpp',|;|   'src/umath/clip.h',|;|-  'src/umath/dispatching.c',|;|+  'src/umath/dispatching.cpp',|;|   'src/umath/extobj.c',|;|   'src/umath/legacy_array_method.c',|;|   'src/umath/override.c', || PR#27913 - numpy/_core/src/common/npy_hashtable.cpp: @@ -12,6 +12,9 @@|;|  * case is likely desired.|;|  */|;| |;|+#include <mutex>|;|+#include <shared_mutex>|;|+|;| #include ""templ_common.h""|;| #include ""npy_hashtable.h""|;| |;|@@ -89,7 +92,7 @@ find_item(PyArrayIdentityHash const *tb, PyObject *const *key)|;| NPY_NO_EXPORT PyArrayIdentityHash *|;| PyArrayIdentityHash_New(int key_len)|;| {|;|-    PyArrayIdentityHash *res = PyMem_Malloc(sizeof(PyArrayIdentityHash))|;|;+    PyArrayIdentityHash *res = (PyArrayIdentityHash *)PyMem_Malloc(sizeof(PyArrayIdentityHash))|;|;     if (res == NULL) {|;|         PyErr_NoMemory()|;|;         return NULL|;|;@@ -100,12 +103,21 @@ PyArrayIdentityHash_New(int key_len)|;|     res->size = 4;  /* Start with a size of 4 */|;|     res->nelem = 0|;|; |;|-    res->buckets = PyMem_Calloc(4 * (key_len + 1), sizeof(PyObject *))|;|;+    res->buckets = (PyObject **)PyMem_Calloc(4 * (key_len + 1), sizeof(PyObject *))|;|;     if (res->buckets == NULL) {|;|         PyErr_NoMemory()|;|;         PyMem_Free(res)|;|;         return NULL|;|;     }|;|+|;|+#ifdef Py_GIL_DISABLED|;|+    res->mutex = new(std::nothrow) std::shared_mutex()|;|;+    if (res->mutex == nullptr) {|;|+        PyErr_NoMemory()|;|;+        PyMem_Free(res)|;|;+        return NULL|;|;+    }|;|+#endif|;|     return res|;|; }|;| |;|@@ -115,6 +127,9 @@ PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *tb)|;| {|;|     PyMem_Free(tb->buckets)|;|;     PyMem_Free(tb)|;|;+#ifdef Py_GIL_DISABLED|;|+    delete (std::shared_mutex *)tb->mutex|;|;+#endif|;| }|;| |;| |;|@@ -149,7 +164,7 @@ _resize_if_necessary(PyArrayIdentityHash *tb)|;|     if (npy_mul_sizes_with_overflow(&alloc_size, new_size, tb->key_len + 1)) {|;|         return -1|;|;     }|;|-    tb->buckets = PyMem_Calloc(alloc_size, sizeof(PyObject *))|;|;+    tb->buckets = (PyObject **)PyMem_Calloc(alloc_size, sizeof(PyObject *))|;|;     if (tb->buckets == NULL) {|;|         tb->buckets = old_table|;|;         PyErr_NoMemory(); || PR#27913 - numpy/_core/src/common/npy_hashtable.h: @@ -7,12 +7,19 @@|;| #include ""numpy/ndarraytypes.h""|;| |;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| typedef struct {|;|     int key_len;  /* number of identities used */|;|     /* Buckets stores: val1, key1[0], key1[1], ..., val2, key2[0], ... */|;|     PyObject **buckets|;|;     npy_intp size;  /* current size */|;|     npy_intp nelem;  /* number of elements */|;|+#ifdef Py_GIL_DISABLED|;|+    void *mutex|;|;+#endif|;| } PyArrayIdentityHash|;|; |;| |;|@@ -29,4 +36,8 @@ PyArrayIdentityHash_New(int key_len)|;|; NPY_NO_EXPORT void|;| PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *tb)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_SRC_COMMON_NPY_NPY_HASHTABLE_H_ */ || PR#27913 - numpy/_core/src/multiarray/common.h: @@ -12,6 +12,10 @@|;| #include ""npy_import.h""|;| #include <limits.h>|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| #define error_converting(x)  (((x) == -1) && PyErr_Occurred())|;| |;| #ifdef NPY_ALLOW_THREADS|;|@@ -104,13 +108,13 @@ check_and_adjust_index(npy_intp *index, npy_intp max_item, int axis,|;|         /* Try to be as clear as possible about what went wrong. */|;|         if (axis >= 0) {|;|             PyErr_Format(PyExc_IndexError,|;|-                         ""index %""NPY_INTP_FMT"" is out of bounds ""|;|-                         ""for axis %d with size %""NPY_INTP_FMT,|;|+                         ""index %"" NPY_INTP_FMT"" is out of bounds ""|;|+                         ""for axis %d with size %"" NPY_INTP_FMT,|;|                          *index, axis, max_item)|;|;         } else {|;|             PyErr_Format(PyExc_IndexError,|;|-                         ""index %""NPY_INTP_FMT"" is out of bounds ""|;|-                         ""for size %""NPY_INTP_FMT, *index, max_item)|;|;+                         ""index %"" NPY_INTP_FMT "" is out of bounds ""|;|+                         ""for size %"" NPY_INTP_FMT, *index, max_item)|;|;         }|;|         return -1|;|;     }|;|@@ -163,7 +167,9 @@ check_and_adjust_axis(int *axis, int ndim)|;|  * <https://gcc.gnu.org/bugzilla/show_bug.cgi?id=52023>.|;|  * clang versions < 8.0.0 have the same bug.|;|  */|;|-#if (!defined __STDC_VERSION__ || __STDC_VERSION__ < 201112 \|;|+#ifdef __cplusplus|;|+#define NPY_ALIGNOF(type) alignof(type)|;|+#elif (!defined __STDC_VERSION__ || __STDC_VERSION__ < 201112 \|;|      || (defined __GNUC__ && __GNUC__ < 4 + (__GNUC_MINOR__ < 9) \|;|   && !defined __clang__) \|;|      || (defined __clang__ && __clang_major__ < 8))|;|@@ -347,4 +353,8 @@ new_array_for_sum(PyArrayObject *ap1, PyArrayObject *ap2, PyArrayObject* out,|;|  */|;| #define NPY_ITER_REDUCTION_AXIS(axis) (axis + (1 << (NPY_BITSOF_INT - 2)))|;| |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  /* NUMPY_CORE_SRC_MULTIARRAY_COMMON_H_ */ || PR#27913 - numpy/_core/src/multiarray/npy_static_data.h: @@ -1,6 +1,10 @@|;| #ifndef NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_|;| #define NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| NPY_NO_EXPORT int|;| initialize_static_globals(void)|;|; |;|@@ -168,4 +172,8 @@ NPY_VISIBILITY_HIDDEN extern npy_interned_str_struct npy_interned_str|;|; NPY_VISIBILITY_HIDDEN extern npy_static_pydata_struct npy_static_pydata|;|; NPY_VISIBILITY_HIDDEN extern npy_static_cdata_struct npy_static_cdata|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif  // NUMPY_CORE_SRC_MULTIARRAY_STATIC_DATA_H_ || PR#27913 - numpy/_core/src/umath/dispatching.cpp: @@ -38,6 +38,9 @@|;| #define _MULTIARRAYMODULE|;| #define _UMATHMODULE|;| |;|+#include <mutex>|;|+#include <shared_mutex>|;|+|;| #define PY_SSIZE_T_CLEAN|;| #include <Python.h>|;| #include <convert_datatype.h>|;|@@ -504,8 +507,9 @@ call_promoter_and_recurse(PyUFuncObject *ufunc, PyObject *info,|;|         PyObject *promoter = PyTuple_GET_ITEM(info, 1)|;|;         if (PyCapsule_CheckExact(promoter)) {|;|             /* We could also go the other way and wrap up the python function... */|;|-            PyArrayMethod_PromoterFunction *promoter_function = PyCapsule_GetPointer(|;|-                    promoter, ""numpy._ufunc_promoter"")|;|;+            PyArrayMethod_PromoterFunction *promoter_function =|;|+                    (PyArrayMethod_PromoterFunction *)PyCapsule_GetPointer(|;|+                            promoter, ""numpy._ufunc_promoter"")|;|;             if (promoter_function == NULL) {|;|                 return NULL|;|;             }|;|@@ -770,8 +774,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|      * 2. Check all registered loops/promoters to find the best match.|;|      * 3. Fall back to the legacy implementation if no match was found.|;|      */|;|-    PyObject *info = PyArrayIdentityHash_GetItem(ufunc->_dispatch_cache,|;|-                (PyObject **)op_dtypes)|;|;+    PyObject *info = PyArrayIdentityHash_GetItem(|;|+            (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+            (PyObject **)op_dtypes)|;|;     if (info != NULL && PyObject_TypeCheck(|;|             PyTuple_GET_ITEM(info, 1), &PyArrayMethod_Type)) {|;|         /* Found the ArrayMethod and NOT a promoter: return it */|;|@@ -793,8 +798,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|              * Found the ArrayMethod and NOT promoter.  Before returning it|;|              * add it to the cache for faster lookup in the future.|;|              */|;|-            if (PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-                    (PyObject **)op_dtypes, info, 0) < 0) {|;|+            if (PyArrayIdentityHash_SetItem(|;|+                        (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                        (PyObject **)op_dtypes, info, 0) < 0) {|;|                 return NULL|;|;             }|;|             return info|;|;@@ -815,8 +821,9 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|         }|;|         else if (info != NULL) {|;|             /* Add result to the cache using the original types: */|;|-            if (PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-                    (PyObject **)op_dtypes, info, 0) < 0) {|;|+            if (PyArrayIdentityHash_SetItem(|;|+                        (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                        (PyObject **)op_dtypes, info, 0) < 0) {|;|                 return NULL|;|;             }|;|             return info|;|;@@ -882,13 +889,51 @@ promote_and_get_info_and_ufuncimpl(PyUFuncObject *ufunc,|;|     }|;| |;|     /* Add this to the cache using the original types: */|;|-    if (cacheable && PyArrayIdentityHash_SetItem(ufunc->_dispatch_cache,|;|-            (PyObject **)op_dtypes, info, 0) < 0) {|;|+    if (cacheable && PyArrayIdentityHash_SetItem(|;|+                (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+                (PyObject **)op_dtypes, info, 0) < 0) {|;|         return NULL|;|;     }|;|     return info|;|; }|;| |;|+#ifdef Py_GIL_DISABLED|;|+/*|;|+ * Fast path for promote_and_get_info_and_ufuncimpl.|;|+ * Acquires a read lock to check for a cache hit and then|;|+ * only acquires a write lock on a cache miss to fill the cache|;|+ */|;|+static inline PyObject *|;|+promote_and_get_info_and_ufuncimpl_with_locking(|;|+        PyUFuncObject *ufunc,|;|+        PyArrayObject *const ops[],|;|+        PyArray_DTypeMeta *signature[],|;|+        PyArray_DTypeMeta *op_dtypes[],|;|+        npy_bool legacy_promotion_is_possible)|;|+{|;|+    std::shared_mutex *mutex = ((std::shared_mutex *)((PyArrayIdentityHash *)ufunc->_dispatch_cache)->mutex)|;|;+    mutex->lock_shared()|;|;+    PyObject *info = PyArrayIdentityHash_GetItem(|;|+            (PyArrayIdentityHash *)ufunc->_dispatch_cache,|;|+            (PyObject **)op_dtypes)|;|;+    mutex->unlock_shared()|;|;+|;|+    if (info != NULL && PyObject_TypeCheck(|;|+                    PyTuple_GET_ITEM(info, 1), &PyArrayMethod_Type)) {|;|+        /* Found the ArrayMethod and NOT a promoter: return it */|;|+        return info|;|;+    }|;|+|;|+    // cache miss, need to acquire a write lock and recursively calculate the|;|+    // correct dispatch resolution|;|+    mutex->lock()|;|;+    info = promote_and_get_info_and_ufuncimpl(ufunc,|;|+            ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;+    mutex->unlock()|;|;+|;|+    return info|;|;+}|;|+#endif|;| |;| /**|;|  * The central entry-point for the promotion and dispatching machinery.|;|@@ -941,6 +986,8 @@ promote_and_get_ufuncimpl(PyUFuncObject *ufunc,|;| {|;|     int nin = ufunc->nin, nargs = ufunc->nargs|;|;     npy_bool legacy_promotion_is_possible = NPY_TRUE|;|;+    PyObject *all_dtypes = NULL|;|;+    PyArrayMethodObject *method = NULL|;|; |;|     /*|;|      * Get the actual DTypes we operate with by setting op_dtypes[i] from|;|@@ -976,18 +1023,20 @@ promote_and_get_ufuncimpl(PyUFuncObject *ufunc,|;|         }|;|     }|;| |;|-    PyObject *info|;|;-    Py_BEGIN_CRITICAL_SECTION((PyObject *)ufunc)|;|;-    info = promote_and_get_info_and_ufuncimpl(ufunc,|;|+#ifdef Py_GIL_DISABLED|;|+    PyObject *info = promote_and_get_info_and_ufuncimpl_with_locking(ufunc,|;|+            ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;+#else|;|+    PyObject *info = promote_and_get_info_and_ufuncimpl(ufunc,|;|             ops, signature, op_dtypes, legacy_promotion_is_possible)|;|;-    Py_END_CRITICAL_SECTION()|;|;+#endif|;| |;|     if (info == NULL) {|;|         goto handle_error|;|;     }|;| |;|-    PyArrayMethodObject *method = (PyArrayMethodObject *)PyTuple_GET_ITEM(info, 1)|;|;-    PyObject *all_dtypes = PyTuple_GET_ITEM(info, 0)|;|;+    method = (PyArrayMethodObject *)PyTuple_GET_ITEM(info, 1)|;|;+    all_dtypes = PyTuple_GET_ITEM(info, 0)|;|; |;|     /*|;|      * In certain cases (only the logical ufuncs really), the loop we found may|;|@@ -1218,7 +1267,7 @@ install_logical_ufunc_promoter(PyObject *ufunc)|;|     if (dtype_tuple == NULL) {|;|         return -1|;|;     }|;|-    PyObject *promoter = PyCapsule_New(&logical_ufunc_promoter,|;|+    PyObject *promoter = PyCapsule_New((void *)&logical_ufunc_promoter,|;|             ""numpy._ufunc_promoter"", NULL)|;|;     if (promoter == NULL) {|;|         Py_DECREF(dtype_tuple); || PR#27913 - numpy/_core/src/umath/dispatching.h: @@ -43,6 +43,10 @@ object_only_ufunc_promoter(PyObject *ufunc,|;| NPY_NO_EXPORT int|;| install_logical_ufunc_promoter(PyObject *ufunc)|;|; |;|+NPY_NO_EXPORT PyObject *|;|+get_info_no_cast(PyUFuncObject *ufunc, PyArray_DTypeMeta *op_dtype,|;|+                 int ndtypes)|;|;+|;| #ifdef __cplusplus|;| }|;| #endif || PR#27913 - numpy/_core/src/umath/ufunc_object.h: @@ -3,11 +3,18 @@|;| |;| #include <numpy/ufuncobject.h>|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;| |;| NPY_NO_EXPORT const char*|;| ufunc_get_name_cstr(PyUFuncObject *ufunc)|;|; |;| NPY_NO_EXPORT PyObject *|;| PyUFunc_GetDefaultIdentity(PyUFuncObject *ufunc, npy_bool *reorderable)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif || PR#27913 - numpy/_core/src/umath/ufunc_type_resolution.h: @@ -1,6 +1,10 @@|;| #ifndef _NPY_PRIVATE__UFUNC_TYPE_RESOLUTION_H_|;| #define _NPY_PRIVATE__UFUNC_TYPE_RESOLUTION_H_|;| |;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+|;| NPY_NO_EXPORT int|;| PyUFunc_SimpleBinaryComparisonTypeResolver(PyUFuncObject *ufunc,|;|                                            NPY_CASTING casting,|;|@@ -142,4 +146,8 @@ PyUFunc_DefaultLegacyInnerLoopSelector(PyUFuncObject *ufunc,|;| NPY_NO_EXPORT int|;| raise_no_loop_found_error(PyUFuncObject *ufunc, PyObject **dtypes)|;|; |;|+#ifdef __cplusplus|;|+}|;|+#endif|;|+|;| #endif","PERF: add a fast path to ufunc type resolution || MAINT: move dispatching.c to C++ || MAINT: move npy_hashtable to C++ and use std::shared_mutex || MAINT: fix windows linking || MAINT: remove outdated comment || MAINT: only call try_promote on free-threaded build || MAINT: try to give new function a name indicating it uses a mutex || MAINT: only do complicated casting to get a mutex pointer once || MAINT: use std::nothrow to avoid dealing with exceptions || DOC: add changelog || PERF: improve multithreaded ufunc scaling (#27896)

* PERF: add a fast path to ufunc type resolution

* MAINT: move dispatching.c to C++

* MAINT: move npy_hashtable to C++ and use std::shared_mutex

* MAINT: fix windows linking

* MAINT: remove outdated comment

* MAINT: only call try_promote on free-threaded build

Converts dispatching to cpp in order to use `std::shared_mutex` to improve free-threaded scaling.

* MAINT: try to give new function a name indicating it uses a mutex

* MAINT: only do complicated casting to get a mutex pointer once

* MAINT: use std::nothrow to avoid dealing with exceptions

* DOC: add changelog"
numpy/numpy,seberg,19013,DLPack support for NumPy,"## Feature
### Motivation
Currently, any library which needs to exchange data with NumPy needs to have it as a dependency. This issue will allow moving away from that approach to a more Pythonic standards-based approach leveraging the [DLPack Library](https://github.com/dmlc/dlpack), as described in the [Array API standard](https://data-apis.org). This is also mentioned in and a prerequisite for [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html#dlpack-support-for-zero-copy-data-interchange), although it can be discussed and integrated independently of it as well, the only caveat being that if the NEP is accepted; adopting DLPack is a given.

DLPack is a small C header-only library with a stable ABI.

### Changes needed to NumPy
The `numpy.ndarray` type will need to gain two new methods:

* [`__dlpack__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-self-stream-none): This will return a `PyCapsule` with a [DLPack struct](https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L126-L162).
* [`__dlpack_device__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-device-self): This one will always return the CPU device for NumPy.

And the NumPy namespace will gain one extra function:

* [`from_dlpack`](https://data-apis.org/array-api/latest/API_specification/creation_functions.html#from-dlpack-x): This will consume a `PyCapsule` containing a DLPack struct and create a `numpy.ndarray` based on that. It will raise a `RuntimeError` on all unsupported configurations of the object.

Relevant issues/discussion: 

* data-apis/consortium-feedback#1
* [Array API docs](https://data-apis.org/array-api/latest/design_topics/data_interchange.html)
* Links to existing implementations: https://github.com/data-apis/consortium-feedback/issues/1#issuecomment-726066249
* PyTorch in-progress PR: pytorch/pytorch#57110
* Discussion on the DLPack issue tracker: dmlc/dlpack#55

Edit: Previously this issue said `from_dlpack` was a method, that has been corrected.

cc @rgommers @mattip ","For other commenters: the discussion at data-apis/consortium-feedback#1 is quite lengthy but does include answers to many questions like object lifetime management. It is helpful to understand the context. Many of my concerns were addressed there.

A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

I think this can be done separately from #18585. || I have tried to look through the discussion.  I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? – although maybe that is tricky without reference counts).  But maybe there is something about streams or so that I just don't see right now.

Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

For the API, I think, I am still a bit confused about view vs. copy.  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so?  Either as an input `copy={None, True, False}` or as an additional return flag (or even both).
Most of the current protocols don't have this problem, the one that does is `__array__` and it would be nice to have it there!

Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view, that seems like it must at least be easy to check (I guess `np.may_share_memory` might work).  Since there is no good way to ""predict"" what is going to happen.



But, in general I think it just needs a good PR.  Inn the end I don't really want to worry about it too much, if other projects already implemented basically the same thing (and it seems like they did).  So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping. || > I have tried to look through the discussion. I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? 

Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:
```python
# `x` is some array/tensor object
capsule = to_dlpack(x)
x2 = from_dlpack(capsule)
```
At that point you had a (non-useful) PyCapsule object floating around in the users code, and then doing `x3 = from_dlpack(capsule)` somewhere else in the code would of course lead to problems. Using `__dlpack__` avoids this by design. || > Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

I think we can make this a keyword-only argument without breaking compat with the existing protocol, and default it to `None`. Perhaps it can be in a future version, but that may need to be discussed separately.

> Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

I believe not, in that case the allocation still isn't ""aligned"" unfortunately.

> Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view,

For other commenters, this is due to the by-element strides of DLPack instead of the by-bytes. || > A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

This is, indeed, a sticking point. I do not know how to resolve this. Perhaps this restriction could be clarified or removed if the rationale didn't apply to CPU data pointers.

cc @tqchen would you happen to know the answer? || >  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so? Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

Why would we want this? Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops). The protocol tries to return a view for performance reasons, but it may not always be possible for all libraries - and then it will return a view. Having an explicit `copy=` keyword seems like a mistake to me.

 || > Why would we want this?

Usually, performance. Maybe one may want the flexibility of a different path when a view isn't possible, e.g., perform operation in the existing library rather than moving it to a new one using DLPack.

Or, conversely, one may want to specify a copy because in-place ops are needed for an algorithm/function (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Of course, the default would be `None`, i.e., we don't guarantee either and then everything you said applies. || > Usually, performance.

Performance is already optimal, it default to zero copy.

> (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Exactly. That's about zero characters extra, so if you want to do something numpy-specific, use that. There are libraries that don't even have the concept of a view, and the buffer protocol and `__array_interface__` don't have a copy keyword either. Adding a copy keyword doesn't make sense to me.
 || > Performance is already optimal, it defaults to zero copy.

But that is not a stated requirement anywhere, I found yet?  And apparently NumPy cannot always export zero copy (which is fine, but then we need an additional `np.export_dlpack(...)` or `np.ensure_dlpack_exportable` function to do the copy if necessary)?

If the user wants to copy the data, they may have to do so *twice*, because they don't know whether the original array-like was copied already.  Either because the exporter does so always, or because it does so ""if necessary"" like NumPy would apparently.
Further, the buffer protocol also supports signaling read only export.  JAX could use that to allow a no-copy export when given?

> Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops).

Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently?  What about copy on write semantics, or just plain old numpy style usage?

> [The consume only once behavior...] Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:

Fair enough, it might help with memory management.  It also might help a bit to ensure that only a single consumers will end up writing to the data. (I guess this doesn't relaly matter if we assume all exports are zero-copy, though.) || > But that is not a stated requirement anywhere, I found yet? 

Hmm, I'll have a look at where the most obvious place is to mention this. DLPack works just like the buffer protocol, except:
- it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well
- it has device support

> And apparently NumPy cannot always export zero copy

I don't think that is true. And I reviewed the implementations in other libraries like CuPy, MXNet, PyTorch and JAX a while back, and can't remember anything regarding the 256 byte alignment thing.

There may be more exotic libraries that perhaps could be forced to make a copy, e.g. Vaex has a concept of ""virtual columns"" where data is basically a string expression rather than it living in memory. In that case, zero-copy access isn't possible.

Another thing that can happen is that NumPy has, say, an array with odd strides. And then JAX and TensorFlow can't represent that, they only have contiguous arrays internally - hence they make a copy on the consumer side.

But for our purposes, I think there isn't too much magic - just think of it as an enhanced buffer protocol.
 || I hadn't noticed the comment (https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L130) before. It talks about CUDA and OpenCL, and the only mention in the issue tracker is https://github.com/dmlc/dlpack/issues/1#issuecomment-282878582, which talks about vector types like `float4` for accelerators. It's not clear that the comment was meant to apply to CPU.

PEP 3118 also briefly mentions alignment: _"" The default endian is `@` which means native data-types and alignment. If un-aligned, native data-types are requested, then the endian specification is '^'.""_. Requiring alignment maybe makes sense, but why would one need 256-byte alignment on CPU? || Oh wait, this explains it (from issue description of https://github.com/data-apis/consortium-feedback/issues/1):

> Data field mandatory aligns to 256 bytes(for aligned load), allow byte_offset to offset the array if necessary

```C
  /*! \brief The offset in bytes to the beginning pointer to data */
  uint64_t byte_offset;
```
That should solve the issue? || > Further, the buffer protocol also supports signaling read only export. JAX could use that to allow a no-copy export when given?

I think that's more of a problem than a feature in the buffer protocol actually, and it reflects that it was written mostly from a ""NumPy needs/design"" point of view. Most libraries simply do not have a read-only array/tensor data structure, so if you create an array in such a library with `from_dlpack`, what are you supposed to do with a `readonly = 1` flag? || > So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping.

The last point is good - I think `__dlpack__` should just raise an exception for non-native endianness. That byte-swapping is still a prominent chapter in the [NumPy fundamentals section of the user guide](https://numpy.org/devdocs/user/basics.html) makes very little sense, we should just hide that in some obscure corner. || > Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently? 

DLPack is, by design, zero-copy. It's highly unusual for it to _have_ to make a copy on the producer side, the Vaex virtual column is the only example I could think of. And if we add `copy=False` for such corner cases, then that seems like design for the <1% case which makes the whole thing more complex for little benefit. Next will be the `do_a_device_transfer=False`, `readonly=False`, etc. Other protocols also don't do this, and where we do do it (`np.array`) we end up making the super-thin wrapper (`np.asarray`) that removes the keyword again.

> What about copy on write semantics, or just plain old numpy style usage?

Copy-on-write is nice, it's like the one thing I give Matlab a bit of credit for:) That's safe though, and stays within a library that would implement it - no keyword needed.

Plain-old numpy style usage: could be done if you know you are working with 2 libraries that have the same semantics (we don't have any 100% the same, but PyTorch and MXNet are fairly close), and you have full control over the code you write. Then you already have all the tools you need though, again no keyword needed. You can go write ahead and mutate memory that's shared between two libraries.

What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations. || > [NumPy cannot always export zero copy?] I don't think that is true.

> [`byte_offset`] should solve the issue?

Well, those were my main initial questions!   What is the definite answer?

> it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well

This seems just wrong. The buffer protocol has a deleter mechanism, and doesn't even use reference counting itself.  Python puts the result into `memoryview` and a lower level helper objects to *add* custom reference counting on top of that.

It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.
At that point the buffer-protocol may be a bit of a feature creap, but is probably a strict superset of the `__dlpack__` capabilities.

One thing where the two really differ (aside form device support and feature creap in the buffer protcol, and some standardized flags).  From a protocol point of view, I think the only real difference is that the buffer protocol allows the requester to pass simple flags to the exporter.

> [About no readonly flag]  I think that's more of a problem than a feature in the buffer protocol actually

Honestly, now I am just confused and a bit annoyed. How can such a simple flag be a problem, the consumer can easily check it after all and the exporter can always set readonly trivially?  My points do not feel addressed at all unless you make the two requirements: 

1. Any export must be no copy.  (You seem to be fine to make this a soft requirement, but that probably limits some use-cases slightly, or burdens the user with knowing about it.  Which I am fine with, as long as it is very predictable.)
2. Any import must assume that chunk of memory is (consumer) read-only (But the exporter is still allowed to modify it!).

Those are some clear limitations.  If that is the intention: OK, I don't care!  But I do feel it strange to claim that the buffer protocol is bad because it _doesn't_ have this limittion.

Why are view semantics, in-place algorithms accepting a `dlpack` manged object so out of question that you just dismiss them?  What about a visualization library that would like to visualize an array that is being updated in-place?  We had a _long_ discussion about that a while ago with respect to `__array__` and napari!

> And if we add copy=False for such corner cases [...] makes the whole thing more complex

Why?  We do not have to support a `copy=True` specifically (and even if, the exporter could just raise that it doesn't support it).  I was never suggesting a better API. I am only asking the question whether use-cases that would be covered by `copy=...` really not worthwhile supporting.  (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As I _also_ said, it would be completely sufficient to have a two new flags on the *exported* `DLManagedTensor` (or additionally if you shy away from modifying DLpack):

* `shared`: The buffer shares the original exporters data.
* `readonly` the buffer is readonly and may not be modified by the importer

It might be nice for the `napari` use-case to be able to signal the `shared` as well, since it avoids VEAX potentially copying everything, just to throw it away again.

I don't argue for `copy=` itself, I am not trying to create a new API, but there are use-cases that you are dimssing and not allowing. And I think those should be stated clearly and to be honest, I am not yet convinced DLPack gave those use-cases proper thought.

> What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations.  {... and the paragraph above it ...}

Yes, but you are not addressing the questions/use case!  ~If I use numpy but import a JAX array (unknowingly where it came from), I should have to know about NUMPY only.  And that means that numpy has to know about JAX's expectations!  That is the whole point of an exchange protocol to smoothen out such differences!~

If Matlab is copy-on-write, Matlab has to know that the provider (NumPy) may not be, and maybe just copy right away becuase it sees the exported buffer is ""shared"" and ""writeable"".  The other way around, NumPy might want to know that it must not write to the Matlab data.

It seems to me you are dissmissing use-cases because you have an ideal single ~package~ homogeneous world in mind. When we have the chance right here to make the different worlds *not* collide, but rather work together harmoniously.  And all we seem to have to do is to add a few simple flags to the protocol! (maybe only for the exporter, maybe also for the request, I don't care/know).

---

Look, I do not care enough to fight over this:  `__dlpack__` is just another lightweight attribute, we already have like 4 of those. The only churn is the `from_dlpack` classmethod and that probably can deal just fine if a `__dlpack_v2__` happens... || Another argument that is completely fine for me, is if we say: Well, DLPack may grow those features/use-cases in the future, and we will be able to even add a ""requests"" API in the future without problem.
(It might be nice to map out map out how that could grow in the future, but I expect it isn't terribly hard, if we don't mind a `try:/except:` a specially).

At that point, the only thing would need to be to clarify expectations. E.g. copy should not happen, but may.  And whether or not its OK to write to a dlpack array, or we should e.g. default to a `ndarray.from_dlpack(object, writeable=None)` and force the user to pass `writeable=True` if they want to write into the view.  (And we live with potential additional copies, probably.) || > Well, those were my main initial questions! What is the definite answer?

That was 5 comments up, as one line, followed by lots of discussion about adding a `copy=` keyword. I missed that one line. Answer is yes, it solves it. 

> This seems just wrong. The buffer protocol has a deleter mechanism

I dunno, this is what PEP 3118 says as a ""rejected idea"": _Having a ""releaser"" object whose release-buffer was called. This was deemed unacceptable because it caused the protocol to be asymmetric (you called release on something different than you ""got"" the buffer from). It also complicated the protocol without providing a real benefit._. If it does have a deleter mechanism now, maybe that's wrong - or I misunderstood, I haven't looked at the code for ages.

> It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.

This was extensively discussed for about a decade I believe. No one has done it, it's a lot of work to write a new PEP, and I don't see how you would backport it. Putting things in Python itself just means you have to wait years after making any change before you can use it.

It's also kind of a ""proof is in the pudding"": despite the buffer protocol being supported in the language itself, adoption is quite low. Unlike for DLPack, which is much newer.

> I am only asking the question whether use-cases that would be covered by copy=... really not worthwhile supporting. (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As Hameer already pointed out, `x = x.copy()` is equivalent. Hence I don't think that there are unsupported use cases. I do not see any case where NumPy must copy.

> Honestly, now I am just confused and a bit annoyed. ....
> My points do not feel addressed at all unless you make the two requirements: ...
> so out of question that you just dismiss them? 
> Yes, but you are not addressing the questions/use case! 
> there are use-cases that you are dimssing and not allowing. 
>  you have an ideal single ~package~ homogeneous world in mind.

Sebastian, seriously, you are slinging a ton of accusations as well as more API proposals. We have been working on this for months in the DLPack and array-api repos (it's a very much nontrivial topic), with review/contributions by quite a few people with extensive experience using all of DLPack, buffer protocol, and `__array_interface__`/`__cuda_array_interface__`. It seems you're upset about something.  I suggest to take a break from adding more, and use a higher bandwidth call to discuss afterwards if needed.

I'll just repeat for now: I don't think there are unsupported use cases, and hence I'm also not ""dismissing"" them. I just tried to answer questions as best I could. || I believe there are some (admittedly rare) cases I see where NumPy must copy: The strides inside DLPack assume a unit of array elements, and those inside NumPy assume a unit of bytes, which is more flexible. One can find cases where zero-copy isn't possible, and one can see these if all elements of `arr.strides` aren't a multiple of `arr.dtype.itemsize`. Concrete examples I can find are:

1. Slicing weirdly and then viewing (I was unable to make this work, even if it was theoretically possible within NumPy's framework):
    ```python
    >>> np.ones((4, 5), dtype=np.int8)[:, 1:].view(np.int32).strides  # Would otherwise be (20, 5)
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
    ValueError: To change to a dtype of a different size, the array must be C-contiguous
    ```
2. Selecting a field from a structured array (which is already rare):
    ```python
    >>> dt = np.dtype([('int', np.int32), ('byte', np.int8)])
    >>> np.zeros((4,), dtype=dt)['int'].strides
    (5,)
    ```

So, yes, it's possible, rare IMO, and can be easily predicted by checking for `all(s % arr.itemsize == 0 for s in arr.strides)`.

But what I see as the more pressing matter I should clarify is the alignment: Should one just round down the pointer to the next 256 bytes and also add the ""round down"" amount to the offset? || On my cell, so please forgive me for leaving only a drive-by comment: please ignore the alignment stuff. If we are talking about host-device copies, it's an implementation detail (of CUDA, HIP, or any sane memory pool implementation sitting on top). CUDA/HIP's copy APIs do not care about alignments. DLPack does not. CUDA Array Interface does not. No one does.

Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later. || > please ignore the alignment stuff

Thanks for clearing that up Ralf and @leofang, sorry for missing the link to the comment where it was more clearly defined.   I am not concerned about NumPy providing `__dlpack__` then.  Forcing the user to copy on weird strides or dtypes seems totally fine.

> Another thing is I seem to recall we agreed in an Array API meeting is that if a copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

@leofang: If a copy is *never* done, that is good.  My concern is mainly that it should be predictable. Although, *never* might even be nicer.  (The array api says it can return a view or copy, ~but it doesn't specify who would be making that copy, the exporter, importer, or either/both~, I guess the copy is expected to be made by the exporter only currently).

---

@rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself.  Maybe I am late to the party, but maybe can I have a bit of time to think out loud?  I am happy be pointed to a different place/issue, if you think this is a terrible place...

To be clear, I am still just *exploring* limitations, and how those limitations could be removed.  The `copy=` argument is a thing we had discussed for `__array__()` because of napari, so it didn't come out of nowhere, it always addressed at least the napari use-case below.

And yes, I may have had the wrong impression that this API still *could* be modified more easily if new use-cases/problems come up, easier than the buffer-protocol at least.  And just because I am discussing possible new API, doesn't mean I am trying to shut down adding the current as is.

---

The limitations as use-cases, instead of ""missing API"" are:

* ~Napari wants to show a numpy or cupy array that is will be updated in-place by the user.  It would be nice if it can inform the user when a function is not compatible with the input (i.e. the plot will never update if a copy was exported, confusing the user).~  EDIT: I misremembered the napari story.  Pytorch refused to do the copy, napari wanted to force a copy (signal that it is OK if a copy is made).  So, ""napari"" is not right, but we still decide that in-place modification (or viewing of mutable data) via DLPack import is discouraged (the user has to deal with the fact that it will not always work, a library that might want to do it can only document that fact).
* Vaex must copy the data, some algorithm would normally do a copy and work on that in-place.  But if it knows that the data was copied by Vaex during the export, it can skip the _additional_ copy of the data (for performance and not to blow up memory).
* JAX has immutable tensors, but if I do `np.ndarray.from_dlpack(jax_tensor)` what shouldl NumPy do?  If it came from Vaex, or anther library with writeable-view semantics, we can create a normal array view.  But if it is a JAX one, Numpy should either copy the data, or set the array to readonly.  Otherwise, the user might accidentally mutate the input array.
* The opposite: If JAX consumes a writeable-view semantics tensor from NumPy, it _must_ copy to ensure its content is actually immutable? Or does NumPy have to export a copy always (if the array is writeable)?
* Library B wraps a huge read-only memory mapped area and exports it with DLPack to NumPy.  Again, NumPy has to set the read-only flag or allow users to *crash the process* by accidentally writing to the array.

Now you did dismiss a few of these as user-problems, or just not relevant enough (i.e. don't use DLPack if you write in-place algorithms or like writeable-view semantics).  And the unnecessary copy is mitigated by Veax exposing a copy being uncommon, I guess?

But at least some still seem like (small?) user traps to me.  And ~it seems~ we have to at least always set the new array to read-only in NumPy or risk interpreter crashes if a truly readonly buffer is passed (EDIT: but yes the array-standard does mention that non-writing is preferred). So the ""no writeable-view"" actually becomes a hard requirement, rather than a soft preference).

Is adding one or two *bits* of information to DLPack on the table or are all of these small issues that we just want to live with?

---

And with that, sorry for a way too long post... || About the buffer protocol: You are right, I guess.  The buffer protocol has only the ""release function"". And that could be enough to allow deleting the original object, but it is not specified to be a valid. (By passing a new, different ""owner"" object out during buffer creation.  CPython's memoryviews would work with that happily, but NumPy doesn't.)

So yes, unlike DLPack, the buffer protocol doesn't _quite_ allow deleting the original exporting object. So maybe the ""release"" function is not a proper ""delete"" function in that sense. || > @rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself. Maybe I am late to the party, but maybe can I have a bit of time to think out loud? 

This is the thing - if you propose changes on this issue tracker, you're talking to others who then have to spend time responding to your proposals. It's different from ""thinking out loud"" (which I interpret as ""to clarify things for yourself""). For me the appropriate places to take notes or clarify things for myself are a piece of paper, a HackMD doc, my own fork, etc. - and then ask clarifying questions first rather than make new proposals immediately. The bandwidth differential we have (you're full-time on NumPy, I'm struggling to find enough time) makes the impact of that worse.

I think this is an important communication issue that comes up more often that I'd like. It'd be great if we could chat about it a little , maybe a call in the next few days - I'll ping you on Slack.

> And yes, I may have had the wrong impression that this API still could be modified more easily

The DLPack maintainers are quite responsive, and significant changes have already been made to DLPack itself (complex dtypes support, stream support, Python API, renaming struct fields for clarity, etc.). More changes, provided they fit in the DLPack design and have good rationales, are very welcome I'm sure. That said, it'd be great to get some experience with at least a prototype of the current design first - proposing changes not based on any experience with the protocol seems a little odd. || As annoying as it is to be on the receiving end of that, I have found that it has always been the case that the fault was mine, as the proposer. It's not your audience's fault that they weren't following all of your deliberations in real-time that would have shown how you worked out their problem cases. If it's not clearly laid out in the final proposal, it's a fair question. A ton of the PRNG design work went on in the [default `BitGenerator` mega-thread](https://github.com/numpy/numpy/issues/13635), but I'd never refer people back to it except to prove _that_ we did talk about something, not _what_ the answer is. If their question isn't explained on [`numpy.org`](https://numpy.org/doc/stable/reference/random/), then it's a fair one to ask and be answered.

Every new audience is a new discussion. You can short-circuit that discussion by drafting the proposal expansively and clearly. For whatever benefits the DLPack maintainers have gotten by keeping their RFCs strictly in Github issues, it does mean that there's no such document for you to use to forestall questions. || Thanks @rkern, that's all very fair. NEP 47, the array API docs and docs in the DLPack can all certainly be improved. 

> If it's not clearly laid out in the final proposal, it's a fair question.

Definitely, please ask those questions. Ask to see a PR first so you can play with it. And point out which are the important doc gaps to fill. It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal. || > It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal.

Agreed. There can be multiple reasons for the disconnect (the proposal isn't what you think it is, there's a disagreement about what the consequences of the proposal actually are, or there's a disagreement about whether the consequences are desirable). A counter-proposal is only appropriate once the disconnect is revealed, if not resolved.

AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.

```python
x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
y = numpy_dlpack.from_dlpack(some_other_array)
```

Such a prototype package would be useful in production in order to support older versions of numpy, regardless. It's not going to solve all use cases (you won't be able to write ""NEP 47-generic"" functions with it), but a number of use cases involving explicit conversions can be handled. A small third-party prototype will make the discussions concrete and even premature counter-proposals more tolerable to discuss. || First, replying to myself:

> Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#design-topics-data-interchange--page-root) we said ""Zero-copy semantics where possible, making a copy only if needed (e.g. when data is not contiguous in memory). Rationale: performance.""
- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#semantics) we said ""If an array that is accessed via the interchange protocol lives on a device that the requesting library does not support, it is recommended to raise a TypeError""
- [Here](https://github.com/data-apis/array-api/pull/106#issuecomment-759735186) we said the host-device copy is disfavored.

I think it's clear that host-device transfer should raise in NumPy's case. Now, let me move to Robert's above reply:

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Can we please not do this outside NumPy? Two reasons:
1. It is a very small pair of functions (`to_dlpack`/`from_dlpack`) that have been implemented in virtually all other major libraries as far as NEP 47 / Array API is concerned, including CuPy / PyTorch / TensorFlow and JAX. Apart from the deleter behavior which no one got it right in the first shot AFAIK, it actually works ok with little user complaints. I think PyTorch supports CPU tensors so I would recommend to peek at their implementation to see how they handle the CPU-GPU case. Otherwise, it is fairly straightforward to support.
2. @rkern you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result... || No, I saw that. But it's not essential for a prototype that can help work out some of the other details. I'm not saying you should maintain it forever (though it could be useful for working with current versions of numpy). It's noticeably easier to build and evaluate a small prototype package than it is to build and evaluate a branch of numpy, especially if what I want to test is how it relates to other packages, which have their own dependencies on versions of numpy. || I've only skimmed the conversation here, so apologies in advance if I'm repeating things

https://github.com/numpy/numpy/issues/19013#issuecomment-841881506 says

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Are there technical reasons that we can't go through a PEP3118 `memoryview` as an intermediary?

```python
some_buffer = memoryview(some_ndarray)
x = other_array.from_dlpack(pep3118_dlpack.to_dlpack(some_buffer))
y_buffer = pep3118_dlpack.from_dlpack(some_other_array)
y = np.array(y_buffer)
```

That is, could a `pep3118_dlpack` library be written that provides _all_ object supporting PEP3118 with dlpack support, not just `np.ndarray`? Or is it impossible to write `pep3118_dlpack.to_dlpack` and `pep3118_dlpack.from_dlpack` correctly? || @eric-wieser I believe the answer is in https://github.com/numpy/numpy/issues/19013#issuecomment-843735344, 

> you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result...

 || My questions is more along the lines of ""is it possible to 'smuggle' simple `memoryview`s through the dlpack interface and vice versa"", and less about exactly what the conventions around the python API might look like - so I don't think that answers my question. || > Or is it impossible to write pep3118_dlpack.to_dlpack and pep3118_dlpack.from_dlpack correctly?

The feature set is a bit disjunct: the buffer-protocol supports much more, but doesn't support devices, but I don't think that is what you mean?

If there was a `dlpack.DLPackManagedTensor` library, then yeah... NumPy could effectively import that and use `DLPackManagedTensor.from_buffer()` and `memoryview(DLPAckManagedTensor)`  (I am assuming `DLPackManagedTensor` would implement the buffer protocol).

I am not sure the indirection is useful enough?  Hopefully DLPack is just so simple that it doesn't matter too much?   Effectively, NumPy would/could be exactly that library (although not the most elegant implementation)!  As far as I can tell NumPy supports the full set of features that is supported by _both_ DLPack and Memoryview.",closed,2021-05-14T07:43:15+00:00,2021-11-09T19:18:57+00:00,hameerabbasi,"01 - Enhancement, component: numpy._core",1,"PR#19083 - doc/neps/nep-0047-array-api-standard.rst: @@ -338,9 +338,10 @@ the options already present in NumPy are:|;| |;| Adding support for DLPack to NumPy entails:|;| |;|-- Adding a ``ndarray.__dlpack__`` method.|;|-- Adding a ``from_dlpack`` function, which takes as input an object|;|-  supporting ``__dlpack__``, and returns an ``ndarray``.|;|+- Adding a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C|;|+  structure wrapped in a ``PyCapsule``.|;|+- Adding a ``np._from_dlpack(obj)`` function, where ``obj`` supports|;|+  ``__dlpack__()``, and returns an ``ndarray``.|;| |;| DLPack is currently a ~200 LoC header, and is meant to be included directly, so|;| no external dependency is needed. Implementation should be straightforward. || PR#19083 - doc/release/upcoming_changes/19083.new_feature.rst: @@ -0,0 +1,6 @@|;|+Add NEP 47-compatible dlpack support|;|+------------------------------------|;|+|;|+Add a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C structure|;|+wrapped in a ``PyCapsule``. Also add a ``np._from_dlpack(obj)`` function, where|;|+``obj`` supports ``__dlpack__()``, and returns an ``ndarray``. || PR#19083 - numpy/__init__.pyi: @@ -1413,6 +1413,7 @@ _SupportsBuffer = Union[|;| |;| _T = TypeVar(""_T"")|;| _T_co = TypeVar(""_T_co"", covariant=True)|;|+_T_contra = TypeVar(""_T_contra"", contravariant=True)|;| _2Tuple = Tuple[_T, _T]|;| _CastingKind = L[""no"", ""equiv"", ""safe"", ""same_kind"", ""unsafe""]|;| |;|@@ -1432,6 +1433,10 @@ _ArrayTD64_co = NDArray[Union[bool_, integer[Any], timedelta64]]|;| # Introduce an alias for `dtype` to avoid naming conflicts.|;| _dtype = dtype|;| |;|+# `builtins.PyCapsule` unfortunately lacks annotations as of the moment|;|;+# use `Any` as a stopgap measure|;|+_PyCapsule = Any|;|+|;| class _SupportsItem(Protocol[_T_co]):|;|     def item(self, args: Any, /) -> _T_co: ...|;| |;|@@ -2439,6 +2444,12 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeType, _DType_co]):|;|     def __ior__(self: NDArray[signedinteger[_NBit1]], other: _ArrayLikeInt_co) -> NDArray[signedinteger[_NBit1]]: ...|;|     @overload|;|     def __ior__(self: NDArray[object_], other: Any) -> NDArray[object_]: ...|;|+    @overload|;|+    def __ior__(self: NDArray[_ScalarType], other: _RecursiveSequence) -> NDArray[_ScalarType]: ...|;|+    @overload|;|+    def __dlpack__(self: NDArray[number[Any]], *, stream: None = ...) -> _PyCapsule: ...|;|+    @overload|;|+    def __dlpack_device__(self) -> Tuple[int, L[0]]: ...|;| |;|     # Keep `dtype` at the bottom to avoid name conflicts with `np.dtype`|;|     @property|;|@@ -4320,3 +4331,9 @@ class chararray(ndarray[_ShapeType, _CharDType]):|;| |;| # NOTE: Deprecated|;| # class MachAr: ...|;|+|;|+class _SupportsDLPack(Protocol[_T_contra]):|;|+    def __dlpack__(self, *, stream: None | _T_contra = ...) -> _PyCapsule: ...|;|+|;|+def _from_dlpack(__obj: _SupportsDLPack[None]) -> NDArray[Any]: ...|;|+ || PR#19083 - numpy/array_api/__init__.py: @@ -136,7 +136,7 @@|;|     empty,|;|     empty_like,|;|     eye,|;|-    from_dlpack,|;|+    _from_dlpack,|;|     full,|;|     full_like,|;|     linspace,|;|@@ -155,7 +155,7 @@|;|     ""empty"",|;|     ""empty_like"",|;|     ""eye"",|;|-    ""from_dlpack"",|;|+    ""_from_dlpack"",|;|     ""full"",|;|     ""full_like"",|;|     ""linspace"", || PR#19083 - numpy/array_api/_creation_functions.py: @@ -151,7 +151,7 @@ def eye(|;|     return Array._new(np.eye(n_rows, M=n_cols, k=k, dtype=dtype))|;| |;| |;|-def from_dlpack(x: object, /) -> Array:|;|+def _from_dlpack(x: object, /) -> Array:|;|     # Note: dlpack support is not yet implemented on Array|;|     raise NotImplementedError(""DLPack support is not yet implemented"")|;|  || PR#19083 - numpy/core/_add_newdocs.py: @@ -1573,6 +1573,19 @@|;|         array_function_like_doc,|;|     ))|;| |;|+add_newdoc('numpy.core.multiarray', '_from_dlpack',|;|+    """"""|;|+    _from_dlpack(x, /)|;|+|;|+    Create a NumPy array from an object implementing the ``__dlpack__``|;|+    protocol.|;|+|;|+    See Also|;|+    --------|;|+    `Array API documentation|;|+    <https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack>`_|;|+    """""")|;|+|;| add_newdoc('numpy.core', 'fastCopyAndTranspose',|;|     """"""_fastCopyAndTranspose(a)"""""")|;| |;|@@ -2263,6 +2276,15 @@|;| add_newdoc('numpy.core.multiarray', 'ndarray', ('__array_struct__',|;|     """"""Array protocol: C-struct side.""""""))|;| |;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack__',|;|+    """"""a.__dlpack__(*, stream=None)|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;|+|;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack_device__',|;|+    """"""a.__dlpack_device__()|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;| |;| add_newdoc('numpy.core.multiarray', 'ndarray', ('base',|;|     """""" || PR#19083 - numpy/core/code_generators/genapi.py: @@ -41,6 +41,7 @@|;|              join('multiarray', 'datetime_busdaycal.c'),|;|              join('multiarray', 'datetime_strings.c'),|;|              join('multiarray', 'descriptor.c'),|;|+             join('multiarray', 'dlpack.c'),|;|              join('multiarray', 'dtypemeta.c'),|;|              join('multiarray', 'einsum.c.src'),|;|              join('multiarray', 'flagsobject.c'), || PR#19083 - numpy/core/multiarray.py: @@ -14,27 +14,28 @@|;| # do not change them. issue gh-15518|;| # _get_ndarray_c_version is semi-public, on purpose not added to __all__|;| from ._multiarray_umath import (|;|-    _fastCopyAndTranspose, _flagdict, _insert, _reconstruct, _vec_string,|;|-    _ARRAY_API, _monotonicity, _get_ndarray_c_version, _set_madvise_hugepage,|;|+    _fastCopyAndTranspose, _flagdict, _from_dlpack, _insert, _reconstruct,|;|+    _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,|;|+    _set_madvise_hugepage,|;|     )|;| |;| __all__ = [|;|     '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',|;|     'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',|;|     'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',|;|     'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',|;|-    '_flagdict', '_insert', '_reconstruct', '_vec_string', '_monotonicity',|;|-    'add_docstring', 'arange', 'array', 'asarray', 'asanyarray',|;|-    'ascontiguousarray', 'asfortranarray', 'bincount', 'broadcast',|;|-    'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|+    '_flagdict', '_from_dlpack', '_insert', '_reconstruct', '_vec_string',|;|+    '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',|;|+    'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',|;|+    'broadcast', 'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|     'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',|;|     'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',|;|     'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',|;|     'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',|;|-    'frombuffer', 'fromfile', 'fromiter', 'fromstring', 'get_handler_name',|;|-    'inner', 'interp', 'interp_complex', 'is_busday', 'lexsort',|;|-    'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer',|;|-    'nested_iters', 'normalize_axis_index', 'packbits',|;|+    'frombuffer', 'fromfile', 'fromiter', 'fromstring',|;|+    'get_handler_name', 'inner', 'interp', 'interp_complex', 'is_busday',|;|+    'lexsort', 'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray',|;|+    'nditer', 'nested_iters', 'normalize_axis_index', 'packbits',|;|     'promote_types', 'putmask', 'ravel_multi_index', 'result_type', 'scalar',|;|     'set_datetimeparse_function', 'set_legacy_print_mode', 'set_numeric_ops',|;|     'set_string_function', 'set_typeDict', 'shares_memory',|;|@@ -46,6 +47,7 @@|;| scalar.__module__ = 'numpy.core.multiarray'|;| |;| |;|+_from_dlpack.__module__ = 'numpy'|;| arange.__module__ = 'numpy'|;| array.__module__ = 'numpy'|;| asarray.__module__ = 'numpy' || PR#19083 - numpy/core/numeric.py: @@ -13,8 +13,8 @@|;|     WRAP, arange, array, asarray, asanyarray, ascontiguousarray,|;|     asfortranarray, broadcast, can_cast, compare_chararrays,|;|     concatenate, copyto, dot, dtype, empty,|;|-    empty_like, flatiter, frombuffer, fromfile, fromiter, fromstring,|;|-    inner, lexsort, matmul, may_share_memory,|;|+    empty_like, flatiter, frombuffer, _from_dlpack, fromfile, fromiter,|;|+    fromstring, inner, lexsort, matmul, may_share_memory,|;|     min_scalar_type, ndarray, nditer, nested_iters, promote_types,|;|     putmask, result_type, set_numeric_ops, shares_memory, vdot, where,|;|     zeros, normalize_axis_index)|;|@@ -41,7 +41,7 @@|;|     'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',|;|     'arange', 'array', 'asarray', 'asanyarray', 'ascontiguousarray',|;|     'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',|;|-    'fromstring', 'fromfile', 'frombuffer', 'where',|;|+    'fromstring', 'fromfile', 'frombuffer', '_from_dlpack', 'where',|;|     'argwhere', 'copyto', 'concatenate', 'fastCopyAndTranspose', 'lexsort',|;|     'set_numeric_ops', 'can_cast', 'promote_types', 'min_scalar_type',|;|     'result_type', 'isfortran', 'empty_like', 'zeros_like', 'ones_like', || PR#19083 - numpy/core/setup.py: @@ -740,6 +740,7 @@ def gl_if_msvc(build_cmd):|;|     #######################################################################|;| |;|     common_deps = [|;|+            join('src', 'common', 'dlpack', 'dlpack.h'),|;|             join('src', 'common', 'array_assign.h'),|;|             join('src', 'common', 'binop_override.h'),|;|             join('src', 'common', 'cblasfuncs.h'),|;|@@ -749,6 +750,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'common', 'npy_cblas.h'),|;|             join('src', 'common', 'npy_config.h'),|;|             join('src', 'common', 'npy_ctypes.h'),|;|+            join('src', 'common', 'npy_dlpack.h'),|;|             join('src', 'common', 'npy_extint128.h'),|;|             join('src', 'common', 'npy_import.h'),|;|             join('src', 'common', 'npy_hashtable.h'),|;|@@ -881,6 +883,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'multiarray', 'datetime_busday.c'),|;|             join('src', 'multiarray', 'datetime_busdaycal.c'),|;|             join('src', 'multiarray', 'descriptor.c'),|;|+            join('src', 'multiarray', 'dlpack.c'),|;|             join('src', 'multiarray', 'dtypemeta.c'),|;|             join('src', 'multiarray', 'dragon4.c'),|;|             join('src', 'multiarray', 'dtype_transfer.c'), || PR#19083 - numpy/core/src/common/dlpack/dlpack.h: @@ -0,0 +1,201 @@|;|+// Taken from:|;|+// https://github.com/dmlc/dlpack/blob/9b6176fdecb55e9bf39b16f08b96913ed3f275b4/include/dlpack/dlpack.h|;|+/*!|;|+ *  Copyright (c) 2017 by Contributors|;|+ * \file dlpack.h|;|+ * \brief The common header of DLPack.|;|+ */|;|+#ifndef DLPACK_DLPACK_H_|;|+#define DLPACK_DLPACK_H_|;|+|;|+#ifdef __cplusplus|;|+#define DLPACK_EXTERN_C extern ""C""|;|+#else|;|+#define DLPACK_EXTERN_C|;|+#endif|;|+|;|+/*! \brief The current version of dlpack */|;|+#define DLPACK_VERSION 050|;|+|;|+/*! \brief DLPACK_DLL prefix for windows */|;|+#ifdef _WIN32|;|+#ifdef DLPACK_EXPORTS|;|+#define DLPACK_DLL __declspec(dllexport)|;|+#else|;|+#define DLPACK_DLL __declspec(dllimport)|;|+#endif|;|+#else|;|+#define DLPACK_DLL|;|+#endif|;|+|;|+#include <stdint.h>|;|+#include <stddef.h>|;|+|;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+/*!|;|+ * \brief The device type in DLDevice.|;|+ */|;|+typedef enum {|;|+  /*! \brief CPU device */|;|+  kDLCPU = 1,|;|+  /*! \brief CUDA GPU device */|;|+  kDLCUDA = 2,|;|+  /*!|;|+   * \brief Pinned CUDA CPU memory by cudaMallocHost|;|+   */|;|+  kDLCUDAHost = 3,|;|+  /*! \brief OpenCL devices. */|;|+  kDLOpenCL = 4,|;|+  /*! \brief Vulkan buffer for next generation graphics. */|;|+  kDLVulkan = 7,|;|+  /*! \brief Metal for Apple GPU. */|;|+  kDLMetal = 8,|;|+  /*! \brief Verilog simulator buffer */|;|+  kDLVPI = 9,|;|+  /*! \brief ROCm GPUs for AMD GPUs */|;|+  kDLROCM = 10,|;|+  /*!|;|+   * \brief Pinned ROCm CPU memory allocated by hipMallocHost|;|+   */|;|+  kDLROCMHost = 11,|;|+  /*!|;|+   * \brief Reserved extension device type,|;|+   * used for quickly test extension device|;|+   * The semantics can differ depending on the implementation.|;|+   */|;|+  kDLExtDev = 12,|;|+  /*!|;|+   * \brief CUDA managed/unified memory allocated by cudaMallocManaged|;|+   */|;|+  kDLCUDAManaged = 13,|;|+} DLDeviceType|;|;+|;|+/*!|;|+ * \brief A Device for Tensor and operator.|;|+ */|;|+typedef struct {|;|+  /*! \brief The device type used in the device. */|;|+  DLDeviceType device_type|;|;+  /*!|;|+   * \brief The device index.|;|+   * For vanilla CPU memory, pinned memory, or managed memory, this is set to 0.|;|+   */|;|+  int device_id|;|;+} DLDevice|;|;+|;|+/*!|;|+ * \brief The type code options DLDataType.|;|+ */|;|+typedef enum {|;|+  /*! \brief signed integer */|;|+  kDLInt = 0U,|;|+  /*! \brief unsigned integer */|;|+  kDLUInt = 1U,|;|+  /*! \brief IEEE floating point */|;|+  kDLFloat = 2U,|;|+  /*!|;|+   * \brief Opaque handle type, reserved for testing purposes.|;|+   * Frameworks need to agree on the handle data type for the exchange to be well-defined.|;|+   */|;|+  kDLOpaqueHandle = 3U,|;|+  /*! \brief bfloat16 */|;|+  kDLBfloat = 4U,|;|+  /*!|;|+   * \brief complex number|;|+   * (C/C++/Python layout: compact struct per complex number)|;|+   */|;|+  kDLComplex = 5U,|;|+} DLDataTypeCode|;|;+|;|+/*!|;|+ * \brief The data type the tensor can hold.|;|+ *|;|+ *  Examples|;|+ *   - float: type_code = 2, bits = 32, lanes=1|;|+ *   - float4(vectorized 4 float): type_code = 2, bits = 32, lanes=4|;|+ *   - int8: type_code = 0, bits = 8, lanes=1|;|+ *   - std::complex<float>: type_code = 5, bits = 64, lanes = 1|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief Type code of base types.|;|+   * We keep it uint8_t instead of DLDataTypeCode for minimal memory|;|+   * footprint, but the value should be one of DLDataTypeCode enum values.|;|+   * */|;|+  uint8_t code|;|;+  /*!|;|+   * \brief Number of bits, common choices are 8, 16, 32.|;|+   */|;|+  uint8_t bits|;|;+  /*! \brief Number of lanes in the type, used for vector types. */|;|+  uint16_t lanes|;|;+} DLDataType|;|;+|;|+/*!|;|+ * \brief Plain C Tensor object, does not manage memory.|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief The opaque data pointer points to the allocated data. This will be|;|+   * CUDA device pointer or cl_mem handle in OpenCL. This pointer is always|;|+   * aligned to 256 bytes as in CUDA.|;|+   *|;|+   * For given DLTensor, the size of memory required to store the contents of|;|+   * data is calculated as follows:|;|+   *|;|+   * \code{.c}|;|+   * static inline size_t GetDataSize(const DLTensor* t) {|;|+   *   size_t size = 1|;|;+   *   for (tvm_index_t i = 0; i < t->ndim; ++i) {|;|+   *     size *= t->shape[i]|;|;+   *   }|;|+   *   size *= (t->dtype.bits * t->dtype.lanes + 7) / 8|;|;+   *   return size|;|;+   * }|;|+   * \endcode|;|+   */|;|+  void* data|;|;+  /*! \brief The device of the tensor */|;|+  DLDevice device|;|;+  /*! \brief Number of dimensions */|;|+  int ndim|;|;+  /*! \brief The data type of the pointer*/|;|+  DLDataType dtype|;|;+  /*! \brief The shape of the tensor */|;|+  int64_t* shape|;|;+  /*!|;|+   * \brief strides of the tensor (in number of elements, not bytes)|;|+   *  can be NULL, indicating tensor is compact and row-majored.|;|+   */|;|+  int64_t* strides|;|;+  /*! \brief The offset in bytes to the beginning pointer to data */|;|+  uint64_t byte_offset|;|;+} DLTensor|;|;+|;|+/*!|;|+ * \brief C Tensor object, manage memory of DLTensor. This data structure is|;|+ *  intended to facilitate the borrowing of DLTensor by another framework. It is|;|+ *  not meant to transfer the tensor. When the borrowing framework doesn't need|;|+ *  the tensor, it should call the deleter to notify the host that the resource|;|+ *  is no longer needed.|;|+ */|;|+typedef struct DLManagedTensor {|;|+  /*! \brief DLTensor which is being memory managed */|;|+  DLTensor dl_tensor|;|;+  /*! \brief the context of the original host framework of DLManagedTensor in|;|+   *   which DLManagedTensor is used in the framework. It can also be NULL.|;|+   */|;|+  void * manager_ctx|;|;+  /*! \brief Destructor signature void (*)(void*) - this should be called|;|+   *   to destruct manager_ctx which holds the DLManagedTensor. It can be NULL|;|+   *   if there is no way for the caller to provide a reasonable destructor.|;|+   *   The destructors deletes the argument self as well.|;|+   */|;|+  void (*deleter)(struct DLManagedTensor * self)|;|;+} DLManagedTensor|;|;+#ifdef __cplusplus|;|+}  // DLPACK_EXTERN_C|;|+#endif|;|+#endif  // DLPACK_DLPACK_H_ || PR#19083 - numpy/core/src/common/npy_dlpack.h: @@ -0,0 +1,28 @@|;|+#include ""Python.h""|;|+#include ""dlpack/dlpack.h""|;|+|;|+#ifndef NPY_DLPACK_H|;|+#define NPY_DLPACK_H|;|+|;|+// Part of the Array API specification.|;|+#define NPY_DLPACK_CAPSULE_NAME ""dltensor""|;|+#define NPY_DLPACK_USED_CAPSULE_NAME ""used_dltensor""|;|+|;|+// Used internally by NumPy to store a base object|;|+// as it has to release a reference to the original|;|+// capsule.|;|+#define NPY_DLPACK_INTERNAL_CAPSULE_NAME ""numpy_dltensor""|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self, PyObject *const *args, Py_ssize_t len_args,|;|+             PyObject *kwnames)|;|;+|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|;+|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj)|;|;+|;|+#endif || PR#19083 - numpy/core/src/multiarray/dlpack.c: @@ -0,0 +1,408 @@|;|+#define NPY_NO_DEPRECATED_API NPY_API_VERSION|;|+#define _MULTIARRAYMODULE|;|+|;|+#define PY_SSIZE_T_CLEAN|;|+#include <Python.h>|;|+#include <dlpack/dlpack.h>|;|+|;|+#include ""numpy/arrayobject.h""|;|+#include ""common/npy_argparse.h""|;|+|;|+#include ""common/dlpack/dlpack.h""|;|+#include ""common/npy_dlpack.h""|;|+|;|+static void|;|+array_dlpack_deleter(DLManagedTensor *self)|;|+{|;|+    PyArrayObject *array = (PyArrayObject *)self->manager_ctx|;|;+    // This will also free the strides as it's one allocation.|;|+    PyMem_Free(self->dl_tensor.shape)|;|;+    PyMem_Free(self)|;|;+    Py_XDECREF(array)|;|;+}|;|+|;|+/* This is exactly as mandated by dlpack */|;|+static void dlpack_capsule_deleter(PyObject *self) {|;|+    if (PyCapsule_IsValid(self, NPY_DLPACK_USED_CAPSULE_NAME)) {|;|+        return|;|;+    }|;|+|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+/* used internally, almost identical to dlpack_capsule_deleter() */|;|+static void array_dlpack_internal_capsule_deleter(PyObject *self)|;|+{|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+|;|+// This function cannot return NULL, but it can fail,|;|+// So call PyErr_Occurred to check if it failed after|;|+// calling it.|;|+static DLDevice|;|+array_get_dl_device(PyArrayObject *self) {|;|+    DLDevice ret|;|;+    ret.device_type = kDLCPU|;|;+    ret.device_id = 0|;|;+    PyObject *base = PyArray_BASE(self)|;|;+    // The outer if is due to the fact that NumPy arrays are on the CPU|;|+    // by default (if not created from DLPack).|;|+    if (PyCapsule_IsValid(base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)) {|;|+        DLManagedTensor *managed = PyCapsule_GetPointer(|;|+                base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+        if (managed == NULL) {|;|+            return ret|;|;+        }|;|+        return managed->dl_tensor.device|;|;+    }|;|+    return ret|;|;+}|;|+|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self,|;|+        PyObject *const *args, Py_ssize_t len_args, PyObject *kwnames)|;|+{|;|+    PyObject *stream = Py_None|;|;+    NPY_PREPARE_ARGPARSER|;|;+    if (npy_parse_arguments(""__dlpack__"", args, len_args, kwnames,|;|+            ""$stream"", NULL, &stream, NULL, NULL, NULL)) {|;|+        return NULL|;|;+    }|;|+|;|+    if (stream != Py_None) {|;|+        PyErr_SetString(PyExc_RuntimeError, ""NumPy only supports ""|;|+                ""stream=None."")|;|;+        return NULL|;|;+    }|;|+|;|+    if ( !(PyArray_FLAGS(self) & NPY_ARRAY_WRITEABLE)) {|;|+        PyErr_SetString(PyExc_TypeError, ""NumPy currently only supports ""|;|+                ""dlpack for writeable arrays"")|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp itemsize = PyArray_ITEMSIZE(self)|;|;+    int ndim = PyArray_NDIM(self)|;|;+    npy_intp *strides = PyArray_STRIDES(self)|;|;+    npy_intp *shape = PyArray_SHAPE(self)|;|;+|;|+    if (!PyArray_IS_C_CONTIGUOUS(self) && PyArray_SIZE(self) != 1) {|;|+        for (int i = 0; i < ndim; ++i) {|;|+            if (strides[i] % itemsize != 0) {|;|+                PyErr_SetString(PyExc_RuntimeError,|;|+                        ""DLPack only supports strides which are a multiple of ""|;|+                        ""itemsize."")|;|;+                return NULL|;|;+            }|;|+        }|;|+    }|;|+|;|+    DLDataType managed_dtype|;|;+    PyArray_Descr *dtype = PyArray_DESCR(self)|;|;+|;|+    if (PyDataType_ISBYTESWAPPED(dtype)) {|;|+        PyErr_SetString(PyExc_TypeError, ""DLPack only supports native ""|;|+                    ""byte swapping."")|;|;+            return NULL|;|;+    }|;|+|;|+    managed_dtype.bits = 8 * itemsize|;|;+    managed_dtype.lanes = 1|;|;+|;|+    if (PyDataType_ISSIGNED(dtype)) {|;|+        managed_dtype.code = kDLInt|;|;+    }|;|+    else if (PyDataType_ISUNSIGNED(dtype)) {|;|+        managed_dtype.code = kDLUInt|;|;+    }|;|+    else if (PyDataType_ISFLOAT(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 8) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""floating point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLFloat|;|;+    }|;|+    else if (PyDataType_ISCOMPLEX(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 16) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""complex point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLComplex|;|;+    }|;|+    else {|;|+        PyErr_SetString(PyExc_TypeError,|;|+                        ""DLPack only supports signed/unsigned integers, float ""|;|+                        ""and complex dtypes."")|;|;+        return NULL|;|;+    }|;|+|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed = PyMem_Malloc(sizeof(DLManagedTensor))|;|;+    if (managed == NULL) {|;|+        PyErr_NoMemory()|;|;+        return NULL|;|;+    }|;|+|;|+    /*|;|+     * Note: the `dlpack.h` header suggests/standardizes that `data` must be|;|+     * 256-byte aligned.  We ignore this intentionally, because `__dlpack__`|;|+     * standardizes that `byte_offset` must be 0 (for now) to not break pytorch:|;|+     * https://github.com/data-apis/array-api/issues/293#issuecomment-964111413|;|+     *|;|+     * We further assume that exporting fully unaligned data is OK even without|;|+     * `byte_offset` since the standard does not reject it.|;|+     * Presumably, pytorch will support importing `byte_offset != 0` and NumPy|;|+     * can choose to use it starting about 2023.  At that point, it may be|;|+     * that NumPy MUST use `byte_offset` to adhere to the standard (as|;|+     * specified in the header)!|;|+     */|;|+    managed->dl_tensor.data = PyArray_DATA(self)|;|;+    managed->dl_tensor.byte_offset = 0|;|;+    managed->dl_tensor.device = device|;|;+    managed->dl_tensor.dtype = managed_dtype|;|;+|;|+    int64_t *managed_shape_strides = PyMem_Malloc(sizeof(int64_t) * ndim * 2)|;|;+    if (managed_shape_strides == NULL) {|;|+        PyErr_NoMemory()|;|;+        PyMem_Free(managed)|;|;+        return NULL|;|;+    }|;|+|;|+    int64_t *managed_shape = managed_shape_strides|;|;+    int64_t *managed_strides = managed_shape_strides + ndim|;|;+    for (int i = 0; i < ndim; ++i) {|;|+        managed_shape[i] = shape[i]|;|;+        // Strides in DLPack are items; in NumPy are bytes.|;|+        managed_strides[i] = strides[i] / itemsize|;|;+    }|;|+|;|+    managed->dl_tensor.ndim = ndim|;|;+    managed->dl_tensor.shape = managed_shape|;|;+    managed->dl_tensor.strides = NULL|;|;+    if (PyArray_SIZE(self) != 1 && !PyArray_IS_C_CONTIGUOUS(self)) {|;|+        managed->dl_tensor.strides = managed_strides|;|;+    }|;|+    managed->dl_tensor.byte_offset = 0|;|;+    managed->manager_ctx = self|;|;+    managed->deleter = array_dlpack_deleter|;|;+|;|+    PyObject *capsule = PyCapsule_New(managed, NPY_DLPACK_CAPSULE_NAME,|;|+            dlpack_capsule_deleter)|;|;+    if (capsule == NULL) {|;|+        PyMem_Free(managed)|;|;+        PyMem_Free(managed_shape_strides)|;|;+        return NULL|;|;+    }|;|+|;|+    // the capsule holds a reference|;|+    Py_INCREF(self)|;|;+    return capsule|;|;+}|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|+{|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+    return Py_BuildValue(""ii"", device.device_type, device.device_id)|;|;+}|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj) {|;|+    PyObject *capsule = PyObject_CallMethod((PyObject *)obj->ob_type,|;|+            ""__dlpack__"", ""O"", obj)|;|;+    if (capsule == NULL) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(capsule,|;|+        NPY_DLPACK_CAPSULE_NAME)|;|;+|;|+    if (managed == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    const int ndim = managed->dl_tensor.ndim|;|;+    if (ndim > NPY_MAXDIMS) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""maxdims of DLPack tensor is higher than the supported ""|;|+                ""maxdims."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    DLDeviceType device_type = managed->dl_tensor.device.device_type|;|;+    if (device_type != kDLCPU &&|;|+            device_type != kDLCUDAHost &&|;|+            device_type != kDLROCMHost &&|;|+            device_type != kDLCUDAManaged) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported device in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    if (managed->dl_tensor.dtype.lanes != 1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported lanes in DLTensor dtype."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    int typenum = -1|;|;+    const uint8_t bits = managed->dl_tensor.dtype.bits|;|;+    const npy_intp itemsize = bits / 8|;|;+    switch (managed->dl_tensor.dtype.code) {|;|+    case kDLInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_INT8; break|;|;+            case 16: typenum = NPY_INT16; break|;|;+            case 32: typenum = NPY_INT32; break|;|;+            case 64: typenum = NPY_INT64; break|;|;+        }|;|+        break|;|;+    case kDLUInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_UINT8; break|;|;+            case 16: typenum = NPY_UINT16; break|;|;+            case 32: typenum = NPY_UINT32; break|;|;+            case 64: typenum = NPY_UINT64; break|;|;+        }|;|+        break|;|;+    case kDLFloat:|;|+        switch (bits)|;|+        {|;|+            case 16: typenum = NPY_FLOAT16; break|;|;+            case 32: typenum = NPY_FLOAT32; break|;|;+            case 64: typenum = NPY_FLOAT64; break|;|;+        }|;|+        break|;|;+    case kDLComplex:|;|+        switch (bits)|;|+        {|;|+            case 64: typenum = NPY_COMPLEX64; break|;|;+            case 128: typenum = NPY_COMPLEX128; break|;|;+        }|;|+        break|;|;+    }|;|+|;|+    if (typenum == -1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported dtype in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp shape[NPY_MAXDIMS]|;|;+    npy_intp strides[NPY_MAXDIMS]|;|;+|;|+    for (int i = 0; i < ndim; ++i) {|;|+        shape[i] = managed->dl_tensor.shape[i]|;|;+        // DLPack has elements as stride units, NumPy has bytes.|;|+        if (managed->dl_tensor.strides != NULL) {|;|+            strides[i] = managed->dl_tensor.strides[i] * itemsize|;|;+        }|;|+    }|;|+|;|+    char *data = (char *)managed->dl_tensor.data +|;|+            managed->dl_tensor.byte_offset|;|;+|;|+    PyArray_Descr *descr = PyArray_DescrFromType(typenum)|;|;+    if (descr == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *ret = PyArray_NewFromDescr(&PyArray_Type, descr, ndim, shape,|;|+            managed->dl_tensor.strides != NULL ? strides : NULL, data, 0, NULL)|;|;+    if (ret == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *new_capsule = PyCapsule_New(managed,|;|+            NPY_DLPACK_INTERNAL_CAPSULE_NAME,|;|+            array_dlpack_internal_capsule_deleter)|;|;+    if (new_capsule == NULL) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyArray_SetBaseObject((PyArrayObject *)ret, new_capsule) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyCapsule_SetName(capsule, NPY_DLPACK_USED_CAPSULE_NAME) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    Py_DECREF(capsule)|;|;+    return ret|;|;+}|;|+|;|+ || PR#19083 - numpy/core/src/multiarray/methods.c: @@ -26,6 +26,7 @@|;| #include ""shape.h""|;| #include ""strfuncs.h""|;| #include ""array_assign.h""|;|+#include ""npy_dlpack.h""|;| |;| #include ""methods.h""|;| #include ""alloc.h""|;|@@ -2989,5 +2990,13 @@ NPY_NO_EXPORT PyMethodDef array_methods[] = {|;|     {""view"",|;|         (PyCFunction)array_view,|;|         METH_FASTCALL | METH_KEYWORDS, NULL},|;|+    // For data interchange between libraries|;|+    {""__dlpack__"",|;|+        (PyCFunction)array_dlpack,|;|+        METH_FASTCALL | METH_KEYWORDS, NULL},|;|+|;|+    {""__dlpack_device__"",|;|+        (PyCFunction)array_dlpack_device,|;|+        METH_NOARGS, NULL},|;|     {NULL, NULL, 0, NULL}           /* sentinel */|;| }; || PR#19083 - numpy/core/src/multiarray/multiarraymodule.c: @@ -70,6 +70,8 @@ NPY_NO_EXPORT int NPY_NUMUSERTYPES = 0|;|; #include ""get_attr_string.h""|;| #include ""experimental_public_dtype_api.h""  /* _get_experimental_dtype_api */|;| |;|+#include ""npy_dlpack.h""|;|+|;| /*|;|  *****************************************************************************|;|  **                    INCLUDE GENERATED CODE                               **|;|@@ -4231,7 +4233,6 @@ _reload_guard(PyObject *NPY_UNUSED(self)) {|;|     Py_RETURN_NONE|;|; }|;| |;|-|;| static struct PyMethodDef array_module_methods[] = {|;|     {""_get_implementing_args"",|;|         (PyCFunction)array__get_implementing_args,|;|@@ -4445,6 +4446,8 @@ static struct PyMethodDef array_module_methods[] = {|;|     {""_reload_guard"", (PyCFunction)_reload_guard,|;|         METH_NOARGS,|;|         ""Give a warning on reload and big warning in sub-interpreters.""},|;|+    {""_from_dlpack"", (PyCFunction)_from_dlpack,|;|+        METH_O, NULL},|;|     {NULL, NULL, 0, NULL}                /* sentinel */|;| }|;|;  || PR#19083 - numpy/core/tests/test_dlpack.py: @@ -0,0 +1,109 @@|;|+import sys|;|+import pytest|;|+|;|+import numpy as np|;|+from numpy.testing import assert_array_equal, IS_PYPY|;|+|;|+|;|+class TestDLPack:|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_dunder_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = x.__dlpack__()|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    def test_dunder_dlpack_stream(self):|;|+        x = np.arange(5)|;|+        x.__dlpack__(stream=None)|;|+|;|+        with pytest.raises(RuntimeError):|;|+            x.__dlpack__(stream=1)|;|+|;|+    def test_strides_not_multiple_of_itemsize(self):|;|+        dt = np.dtype([('int', np.int32), ('char', np.int8)])|;|+        y = np.zeros((5,), dtype=dt)|;|+        z = y['int']|;|+|;|+        with pytest.raises(RuntimeError):|;|+            np._from_dlpack(z)|;|+|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_from_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = np._from_dlpack(x)|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    @pytest.mark.parametrize(""dtype"", [|;|+        np.int8, np.int16, np.int32, np.int64,|;|+        np.uint8, np.uint16, np.uint32, np.uint64,|;|+        np.float16, np.float32, np.float64,|;|+        np.complex64, np.complex128|;|+    ])|;|+    def test_dtype_passthrough(self, dtype):|;|+        x = np.arange(5, dtype=dtype)|;|+        y = np._from_dlpack(x)|;|+|;|+        assert y.dtype == x.dtype|;|+        assert_array_equal(x, y)|;|+|;|+    def test_invalid_dtype(self):|;|+        x = np.asarray(np.datetime64('2021-05-27'))|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_invalid_byte_swapping(self):|;|+        dt = np.dtype('=i8').newbyteorder()|;|+        x = np.arange(5, dtype=dt)|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_non_contiguous(self):|;|+        x = np.arange(25).reshape((5, 5))|;|+|;|+        y1 = x[0]|;|+        assert_array_equal(y1, np._from_dlpack(y1))|;|+|;|+        y2 = x[:, 0]|;|+        assert_array_equal(y2, np._from_dlpack(y2))|;|+|;|+        y3 = x[1, :]|;|+        assert_array_equal(y3, np._from_dlpack(y3))|;|+|;|+        y4 = x[1]|;|+        assert_array_equal(y4, np._from_dlpack(y4))|;|+|;|+        y5 = np.diagonal(x).copy()|;|+        assert_array_equal(y5, np._from_dlpack(y5))|;|+|;|+    @pytest.mark.parametrize(""ndim"", range(33))|;|+    def test_higher_dims(self, ndim):|;|+        shape = (1,) * ndim|;|+        x = np.zeros(shape, dtype=np.float64)|;|+|;|+        assert shape == np._from_dlpack(x).shape|;|+|;|+    def test_dlpack_device(self):|;|+        x = np.arange(5)|;|+        assert x.__dlpack_device__() == (1, 0)|;|+        assert np._from_dlpack(x).__dlpack_device__() == (1, 0)|;|+|;|+    def dlpack_deleter_exception(self):|;|+        x = np.arange(5)|;|+        _ = x.__dlpack__()|;|+        raise RuntimeError|;|+    |;|+    def test_dlpack_destructor_exception(self):|;|+        with pytest.raises(RuntimeError):|;|+            self.dlpack_deleter_exception()|;|+|;|+    def test_readonly(self):|;|+        x = np.arange(5)|;|+        x.flags.writeable = False|;|+        with pytest.raises(TypeError):|;|+            x.__dlpack__()","ENH: Add the __dlpack__ and __dlpack_device__ methods to ndarray. || ENH, TST: Add the from_dlpack method and test DLPack. || MAINT, BUG: Documentation for DLPack protocol and refcounting bug fixes. || MAINT: Add URL to DLPack GitHub. || MAINT: Split up capsule deleter. || MAINT: Move around code so that there are no more unused warnings. || TST: Improve testing coverage for DLPack. || BUG: Fix handling of C-contiguous and 1-element arrays. || BUG, TST: Device bugfix and test __dl_device__. || MAINT: Robustify dlpack_capsule_deleter and add comments. || BUG: Offset not properly stored/computed. || move dlpack functions to a new file || BUG: fixes from review || Updates

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net>
Co-authored-by: Bas van Beek <43369155+BvB93@users.noreply.github.com> || change from_dlpack to _dlpack, remove unused header || make a.__dlpack__() fail if a is readonly || add release note, error out if offset is used || MAINT: Simplify `byte_offset` handling in dlpack.h and add comment

If `byte_offset = 0` is forced anyway, there is no point in trying
to preserve a previous `data` information from the capsule.
(And probably it should have used a base array also, and not just
a base DLPack capsule, anyway.)"
numpy/numpy,mattip,19013,DLPack support for NumPy,"## Feature
### Motivation
Currently, any library which needs to exchange data with NumPy needs to have it as a dependency. This issue will allow moving away from that approach to a more Pythonic standards-based approach leveraging the [DLPack Library](https://github.com/dmlc/dlpack), as described in the [Array API standard](https://data-apis.org). This is also mentioned in and a prerequisite for [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html#dlpack-support-for-zero-copy-data-interchange), although it can be discussed and integrated independently of it as well, the only caveat being that if the NEP is accepted; adopting DLPack is a given.

DLPack is a small C header-only library with a stable ABI.

### Changes needed to NumPy
The `numpy.ndarray` type will need to gain two new methods:

* [`__dlpack__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-self-stream-none): This will return a `PyCapsule` with a [DLPack struct](https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L126-L162).
* [`__dlpack_device__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-device-self): This one will always return the CPU device for NumPy.

And the NumPy namespace will gain one extra function:

* [`from_dlpack`](https://data-apis.org/array-api/latest/API_specification/creation_functions.html#from-dlpack-x): This will consume a `PyCapsule` containing a DLPack struct and create a `numpy.ndarray` based on that. It will raise a `RuntimeError` on all unsupported configurations of the object.

Relevant issues/discussion: 

* data-apis/consortium-feedback#1
* [Array API docs](https://data-apis.org/array-api/latest/design_topics/data_interchange.html)
* Links to existing implementations: https://github.com/data-apis/consortium-feedback/issues/1#issuecomment-726066249
* PyTorch in-progress PR: pytorch/pytorch#57110
* Discussion on the DLPack issue tracker: dmlc/dlpack#55

Edit: Previously this issue said `from_dlpack` was a method, that has been corrected.

cc @rgommers @mattip ","For other commenters: the discussion at data-apis/consortium-feedback#1 is quite lengthy but does include answers to many questions like object lifetime management. It is helpful to understand the context. Many of my concerns were addressed there.

A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

I think this can be done separately from #18585. || I have tried to look through the discussion.  I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? – although maybe that is tricky without reference counts).  But maybe there is something about streams or so that I just don't see right now.

Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

For the API, I think, I am still a bit confused about view vs. copy.  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so?  Either as an input `copy={None, True, False}` or as an additional return flag (or even both).
Most of the current protocols don't have this problem, the one that does is `__array__` and it would be nice to have it there!

Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view, that seems like it must at least be easy to check (I guess `np.may_share_memory` might work).  Since there is no good way to ""predict"" what is going to happen.



But, in general I think it just needs a good PR.  Inn the end I don't really want to worry about it too much, if other projects already implemented basically the same thing (and it seems like they did).  So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping. || > I have tried to look through the discussion. I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? 

Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:
```python
# `x` is some array/tensor object
capsule = to_dlpack(x)
x2 = from_dlpack(capsule)
```
At that point you had a (non-useful) PyCapsule object floating around in the users code, and then doing `x3 = from_dlpack(capsule)` somewhere else in the code would of course lead to problems. Using `__dlpack__` avoids this by design. || > Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

I think we can make this a keyword-only argument without breaking compat with the existing protocol, and default it to `None`. Perhaps it can be in a future version, but that may need to be discussed separately.

> Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

I believe not, in that case the allocation still isn't ""aligned"" unfortunately.

> Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view,

For other commenters, this is due to the by-element strides of DLPack instead of the by-bytes. || > A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

This is, indeed, a sticking point. I do not know how to resolve this. Perhaps this restriction could be clarified or removed if the rationale didn't apply to CPU data pointers.

cc @tqchen would you happen to know the answer? || >  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so? Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

Why would we want this? Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops). The protocol tries to return a view for performance reasons, but it may not always be possible for all libraries - and then it will return a view. Having an explicit `copy=` keyword seems like a mistake to me.

 || > Why would we want this?

Usually, performance. Maybe one may want the flexibility of a different path when a view isn't possible, e.g., perform operation in the existing library rather than moving it to a new one using DLPack.

Or, conversely, one may want to specify a copy because in-place ops are needed for an algorithm/function (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Of course, the default would be `None`, i.e., we don't guarantee either and then everything you said applies. || > Usually, performance.

Performance is already optimal, it default to zero copy.

> (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Exactly. That's about zero characters extra, so if you want to do something numpy-specific, use that. There are libraries that don't even have the concept of a view, and the buffer protocol and `__array_interface__` don't have a copy keyword either. Adding a copy keyword doesn't make sense to me.
 || > Performance is already optimal, it defaults to zero copy.

But that is not a stated requirement anywhere, I found yet?  And apparently NumPy cannot always export zero copy (which is fine, but then we need an additional `np.export_dlpack(...)` or `np.ensure_dlpack_exportable` function to do the copy if necessary)?

If the user wants to copy the data, they may have to do so *twice*, because they don't know whether the original array-like was copied already.  Either because the exporter does so always, or because it does so ""if necessary"" like NumPy would apparently.
Further, the buffer protocol also supports signaling read only export.  JAX could use that to allow a no-copy export when given?

> Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops).

Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently?  What about copy on write semantics, or just plain old numpy style usage?

> [The consume only once behavior...] Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:

Fair enough, it might help with memory management.  It also might help a bit to ensure that only a single consumers will end up writing to the data. (I guess this doesn't relaly matter if we assume all exports are zero-copy, though.) || > But that is not a stated requirement anywhere, I found yet? 

Hmm, I'll have a look at where the most obvious place is to mention this. DLPack works just like the buffer protocol, except:
- it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well
- it has device support

> And apparently NumPy cannot always export zero copy

I don't think that is true. And I reviewed the implementations in other libraries like CuPy, MXNet, PyTorch and JAX a while back, and can't remember anything regarding the 256 byte alignment thing.

There may be more exotic libraries that perhaps could be forced to make a copy, e.g. Vaex has a concept of ""virtual columns"" where data is basically a string expression rather than it living in memory. In that case, zero-copy access isn't possible.

Another thing that can happen is that NumPy has, say, an array with odd strides. And then JAX and TensorFlow can't represent that, they only have contiguous arrays internally - hence they make a copy on the consumer side.

But for our purposes, I think there isn't too much magic - just think of it as an enhanced buffer protocol.
 || I hadn't noticed the comment (https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L130) before. It talks about CUDA and OpenCL, and the only mention in the issue tracker is https://github.com/dmlc/dlpack/issues/1#issuecomment-282878582, which talks about vector types like `float4` for accelerators. It's not clear that the comment was meant to apply to CPU.

PEP 3118 also briefly mentions alignment: _"" The default endian is `@` which means native data-types and alignment. If un-aligned, native data-types are requested, then the endian specification is '^'.""_. Requiring alignment maybe makes sense, but why would one need 256-byte alignment on CPU? || Oh wait, this explains it (from issue description of https://github.com/data-apis/consortium-feedback/issues/1):

> Data field mandatory aligns to 256 bytes(for aligned load), allow byte_offset to offset the array if necessary

```C
  /*! \brief The offset in bytes to the beginning pointer to data */
  uint64_t byte_offset;
```
That should solve the issue? || > Further, the buffer protocol also supports signaling read only export. JAX could use that to allow a no-copy export when given?

I think that's more of a problem than a feature in the buffer protocol actually, and it reflects that it was written mostly from a ""NumPy needs/design"" point of view. Most libraries simply do not have a read-only array/tensor data structure, so if you create an array in such a library with `from_dlpack`, what are you supposed to do with a `readonly = 1` flag? || > So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping.

The last point is good - I think `__dlpack__` should just raise an exception for non-native endianness. That byte-swapping is still a prominent chapter in the [NumPy fundamentals section of the user guide](https://numpy.org/devdocs/user/basics.html) makes very little sense, we should just hide that in some obscure corner. || > Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently? 

DLPack is, by design, zero-copy. It's highly unusual for it to _have_ to make a copy on the producer side, the Vaex virtual column is the only example I could think of. And if we add `copy=False` for such corner cases, then that seems like design for the <1% case which makes the whole thing more complex for little benefit. Next will be the `do_a_device_transfer=False`, `readonly=False`, etc. Other protocols also don't do this, and where we do do it (`np.array`) we end up making the super-thin wrapper (`np.asarray`) that removes the keyword again.

> What about copy on write semantics, or just plain old numpy style usage?

Copy-on-write is nice, it's like the one thing I give Matlab a bit of credit for:) That's safe though, and stays within a library that would implement it - no keyword needed.

Plain-old numpy style usage: could be done if you know you are working with 2 libraries that have the same semantics (we don't have any 100% the same, but PyTorch and MXNet are fairly close), and you have full control over the code you write. Then you already have all the tools you need though, again no keyword needed. You can go write ahead and mutate memory that's shared between two libraries.

What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations. || > [NumPy cannot always export zero copy?] I don't think that is true.

> [`byte_offset`] should solve the issue?

Well, those were my main initial questions!   What is the definite answer?

> it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well

This seems just wrong. The buffer protocol has a deleter mechanism, and doesn't even use reference counting itself.  Python puts the result into `memoryview` and a lower level helper objects to *add* custom reference counting on top of that.

It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.
At that point the buffer-protocol may be a bit of a feature creap, but is probably a strict superset of the `__dlpack__` capabilities.

One thing where the two really differ (aside form device support and feature creap in the buffer protcol, and some standardized flags).  From a protocol point of view, I think the only real difference is that the buffer protocol allows the requester to pass simple flags to the exporter.

> [About no readonly flag]  I think that's more of a problem than a feature in the buffer protocol actually

Honestly, now I am just confused and a bit annoyed. How can such a simple flag be a problem, the consumer can easily check it after all and the exporter can always set readonly trivially?  My points do not feel addressed at all unless you make the two requirements: 

1. Any export must be no copy.  (You seem to be fine to make this a soft requirement, but that probably limits some use-cases slightly, or burdens the user with knowing about it.  Which I am fine with, as long as it is very predictable.)
2. Any import must assume that chunk of memory is (consumer) read-only (But the exporter is still allowed to modify it!).

Those are some clear limitations.  If that is the intention: OK, I don't care!  But I do feel it strange to claim that the buffer protocol is bad because it _doesn't_ have this limittion.

Why are view semantics, in-place algorithms accepting a `dlpack` manged object so out of question that you just dismiss them?  What about a visualization library that would like to visualize an array that is being updated in-place?  We had a _long_ discussion about that a while ago with respect to `__array__` and napari!

> And if we add copy=False for such corner cases [...] makes the whole thing more complex

Why?  We do not have to support a `copy=True` specifically (and even if, the exporter could just raise that it doesn't support it).  I was never suggesting a better API. I am only asking the question whether use-cases that would be covered by `copy=...` really not worthwhile supporting.  (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As I _also_ said, it would be completely sufficient to have a two new flags on the *exported* `DLManagedTensor` (or additionally if you shy away from modifying DLpack):

* `shared`: The buffer shares the original exporters data.
* `readonly` the buffer is readonly and may not be modified by the importer

It might be nice for the `napari` use-case to be able to signal the `shared` as well, since it avoids VEAX potentially copying everything, just to throw it away again.

I don't argue for `copy=` itself, I am not trying to create a new API, but there are use-cases that you are dimssing and not allowing. And I think those should be stated clearly and to be honest, I am not yet convinced DLPack gave those use-cases proper thought.

> What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations.  {... and the paragraph above it ...}

Yes, but you are not addressing the questions/use case!  ~If I use numpy but import a JAX array (unknowingly where it came from), I should have to know about NUMPY only.  And that means that numpy has to know about JAX's expectations!  That is the whole point of an exchange protocol to smoothen out such differences!~

If Matlab is copy-on-write, Matlab has to know that the provider (NumPy) may not be, and maybe just copy right away becuase it sees the exported buffer is ""shared"" and ""writeable"".  The other way around, NumPy might want to know that it must not write to the Matlab data.

It seems to me you are dissmissing use-cases because you have an ideal single ~package~ homogeneous world in mind. When we have the chance right here to make the different worlds *not* collide, but rather work together harmoniously.  And all we seem to have to do is to add a few simple flags to the protocol! (maybe only for the exporter, maybe also for the request, I don't care/know).

---

Look, I do not care enough to fight over this:  `__dlpack__` is just another lightweight attribute, we already have like 4 of those. The only churn is the `from_dlpack` classmethod and that probably can deal just fine if a `__dlpack_v2__` happens... || Another argument that is completely fine for me, is if we say: Well, DLPack may grow those features/use-cases in the future, and we will be able to even add a ""requests"" API in the future without problem.
(It might be nice to map out map out how that could grow in the future, but I expect it isn't terribly hard, if we don't mind a `try:/except:` a specially).

At that point, the only thing would need to be to clarify expectations. E.g. copy should not happen, but may.  And whether or not its OK to write to a dlpack array, or we should e.g. default to a `ndarray.from_dlpack(object, writeable=None)` and force the user to pass `writeable=True` if they want to write into the view.  (And we live with potential additional copies, probably.) || > Well, those were my main initial questions! What is the definite answer?

That was 5 comments up, as one line, followed by lots of discussion about adding a `copy=` keyword. I missed that one line. Answer is yes, it solves it. 

> This seems just wrong. The buffer protocol has a deleter mechanism

I dunno, this is what PEP 3118 says as a ""rejected idea"": _Having a ""releaser"" object whose release-buffer was called. This was deemed unacceptable because it caused the protocol to be asymmetric (you called release on something different than you ""got"" the buffer from). It also complicated the protocol without providing a real benefit._. If it does have a deleter mechanism now, maybe that's wrong - or I misunderstood, I haven't looked at the code for ages.

> It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.

This was extensively discussed for about a decade I believe. No one has done it, it's a lot of work to write a new PEP, and I don't see how you would backport it. Putting things in Python itself just means you have to wait years after making any change before you can use it.

It's also kind of a ""proof is in the pudding"": despite the buffer protocol being supported in the language itself, adoption is quite low. Unlike for DLPack, which is much newer.

> I am only asking the question whether use-cases that would be covered by copy=... really not worthwhile supporting. (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As Hameer already pointed out, `x = x.copy()` is equivalent. Hence I don't think that there are unsupported use cases. I do not see any case where NumPy must copy.

> Honestly, now I am just confused and a bit annoyed. ....
> My points do not feel addressed at all unless you make the two requirements: ...
> so out of question that you just dismiss them? 
> Yes, but you are not addressing the questions/use case! 
> there are use-cases that you are dimssing and not allowing. 
>  you have an ideal single ~package~ homogeneous world in mind.

Sebastian, seriously, you are slinging a ton of accusations as well as more API proposals. We have been working on this for months in the DLPack and array-api repos (it's a very much nontrivial topic), with review/contributions by quite a few people with extensive experience using all of DLPack, buffer protocol, and `__array_interface__`/`__cuda_array_interface__`. It seems you're upset about something.  I suggest to take a break from adding more, and use a higher bandwidth call to discuss afterwards if needed.

I'll just repeat for now: I don't think there are unsupported use cases, and hence I'm also not ""dismissing"" them. I just tried to answer questions as best I could. || I believe there are some (admittedly rare) cases I see where NumPy must copy: The strides inside DLPack assume a unit of array elements, and those inside NumPy assume a unit of bytes, which is more flexible. One can find cases where zero-copy isn't possible, and one can see these if all elements of `arr.strides` aren't a multiple of `arr.dtype.itemsize`. Concrete examples I can find are:

1. Slicing weirdly and then viewing (I was unable to make this work, even if it was theoretically possible within NumPy's framework):
    ```python
    >>> np.ones((4, 5), dtype=np.int8)[:, 1:].view(np.int32).strides  # Would otherwise be (20, 5)
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
    ValueError: To change to a dtype of a different size, the array must be C-contiguous
    ```
2. Selecting a field from a structured array (which is already rare):
    ```python
    >>> dt = np.dtype([('int', np.int32), ('byte', np.int8)])
    >>> np.zeros((4,), dtype=dt)['int'].strides
    (5,)
    ```

So, yes, it's possible, rare IMO, and can be easily predicted by checking for `all(s % arr.itemsize == 0 for s in arr.strides)`.

But what I see as the more pressing matter I should clarify is the alignment: Should one just round down the pointer to the next 256 bytes and also add the ""round down"" amount to the offset? || On my cell, so please forgive me for leaving only a drive-by comment: please ignore the alignment stuff. If we are talking about host-device copies, it's an implementation detail (of CUDA, HIP, or any sane memory pool implementation sitting on top). CUDA/HIP's copy APIs do not care about alignments. DLPack does not. CUDA Array Interface does not. No one does.

Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later. || > please ignore the alignment stuff

Thanks for clearing that up Ralf and @leofang, sorry for missing the link to the comment where it was more clearly defined.   I am not concerned about NumPy providing `__dlpack__` then.  Forcing the user to copy on weird strides or dtypes seems totally fine.

> Another thing is I seem to recall we agreed in an Array API meeting is that if a copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

@leofang: If a copy is *never* done, that is good.  My concern is mainly that it should be predictable. Although, *never* might even be nicer.  (The array api says it can return a view or copy, ~but it doesn't specify who would be making that copy, the exporter, importer, or either/both~, I guess the copy is expected to be made by the exporter only currently).

---

@rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself.  Maybe I am late to the party, but maybe can I have a bit of time to think out loud?  I am happy be pointed to a different place/issue, if you think this is a terrible place...

To be clear, I am still just *exploring* limitations, and how those limitations could be removed.  The `copy=` argument is a thing we had discussed for `__array__()` because of napari, so it didn't come out of nowhere, it always addressed at least the napari use-case below.

And yes, I may have had the wrong impression that this API still *could* be modified more easily if new use-cases/problems come up, easier than the buffer-protocol at least.  And just because I am discussing possible new API, doesn't mean I am trying to shut down adding the current as is.

---

The limitations as use-cases, instead of ""missing API"" are:

* ~Napari wants to show a numpy or cupy array that is will be updated in-place by the user.  It would be nice if it can inform the user when a function is not compatible with the input (i.e. the plot will never update if a copy was exported, confusing the user).~  EDIT: I misremembered the napari story.  Pytorch refused to do the copy, napari wanted to force a copy (signal that it is OK if a copy is made).  So, ""napari"" is not right, but we still decide that in-place modification (or viewing of mutable data) via DLPack import is discouraged (the user has to deal with the fact that it will not always work, a library that might want to do it can only document that fact).
* Vaex must copy the data, some algorithm would normally do a copy and work on that in-place.  But if it knows that the data was copied by Vaex during the export, it can skip the _additional_ copy of the data (for performance and not to blow up memory).
* JAX has immutable tensors, but if I do `np.ndarray.from_dlpack(jax_tensor)` what shouldl NumPy do?  If it came from Vaex, or anther library with writeable-view semantics, we can create a normal array view.  But if it is a JAX one, Numpy should either copy the data, or set the array to readonly.  Otherwise, the user might accidentally mutate the input array.
* The opposite: If JAX consumes a writeable-view semantics tensor from NumPy, it _must_ copy to ensure its content is actually immutable? Or does NumPy have to export a copy always (if the array is writeable)?
* Library B wraps a huge read-only memory mapped area and exports it with DLPack to NumPy.  Again, NumPy has to set the read-only flag or allow users to *crash the process* by accidentally writing to the array.

Now you did dismiss a few of these as user-problems, or just not relevant enough (i.e. don't use DLPack if you write in-place algorithms or like writeable-view semantics).  And the unnecessary copy is mitigated by Veax exposing a copy being uncommon, I guess?

But at least some still seem like (small?) user traps to me.  And ~it seems~ we have to at least always set the new array to read-only in NumPy or risk interpreter crashes if a truly readonly buffer is passed (EDIT: but yes the array-standard does mention that non-writing is preferred). So the ""no writeable-view"" actually becomes a hard requirement, rather than a soft preference).

Is adding one or two *bits* of information to DLPack on the table or are all of these small issues that we just want to live with?

---

And with that, sorry for a way too long post... || About the buffer protocol: You are right, I guess.  The buffer protocol has only the ""release function"". And that could be enough to allow deleting the original object, but it is not specified to be a valid. (By passing a new, different ""owner"" object out during buffer creation.  CPython's memoryviews would work with that happily, but NumPy doesn't.)

So yes, unlike DLPack, the buffer protocol doesn't _quite_ allow deleting the original exporting object. So maybe the ""release"" function is not a proper ""delete"" function in that sense. || > @rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself. Maybe I am late to the party, but maybe can I have a bit of time to think out loud? 

This is the thing - if you propose changes on this issue tracker, you're talking to others who then have to spend time responding to your proposals. It's different from ""thinking out loud"" (which I interpret as ""to clarify things for yourself""). For me the appropriate places to take notes or clarify things for myself are a piece of paper, a HackMD doc, my own fork, etc. - and then ask clarifying questions first rather than make new proposals immediately. The bandwidth differential we have (you're full-time on NumPy, I'm struggling to find enough time) makes the impact of that worse.

I think this is an important communication issue that comes up more often that I'd like. It'd be great if we could chat about it a little , maybe a call in the next few days - I'll ping you on Slack.

> And yes, I may have had the wrong impression that this API still could be modified more easily

The DLPack maintainers are quite responsive, and significant changes have already been made to DLPack itself (complex dtypes support, stream support, Python API, renaming struct fields for clarity, etc.). More changes, provided they fit in the DLPack design and have good rationales, are very welcome I'm sure. That said, it'd be great to get some experience with at least a prototype of the current design first - proposing changes not based on any experience with the protocol seems a little odd. || As annoying as it is to be on the receiving end of that, I have found that it has always been the case that the fault was mine, as the proposer. It's not your audience's fault that they weren't following all of your deliberations in real-time that would have shown how you worked out their problem cases. If it's not clearly laid out in the final proposal, it's a fair question. A ton of the PRNG design work went on in the [default `BitGenerator` mega-thread](https://github.com/numpy/numpy/issues/13635), but I'd never refer people back to it except to prove _that_ we did talk about something, not _what_ the answer is. If their question isn't explained on [`numpy.org`](https://numpy.org/doc/stable/reference/random/), then it's a fair one to ask and be answered.

Every new audience is a new discussion. You can short-circuit that discussion by drafting the proposal expansively and clearly. For whatever benefits the DLPack maintainers have gotten by keeping their RFCs strictly in Github issues, it does mean that there's no such document for you to use to forestall questions. || Thanks @rkern, that's all very fair. NEP 47, the array API docs and docs in the DLPack can all certainly be improved. 

> If it's not clearly laid out in the final proposal, it's a fair question.

Definitely, please ask those questions. Ask to see a PR first so you can play with it. And point out which are the important doc gaps to fill. It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal. || > It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal.

Agreed. There can be multiple reasons for the disconnect (the proposal isn't what you think it is, there's a disagreement about what the consequences of the proposal actually are, or there's a disagreement about whether the consequences are desirable). A counter-proposal is only appropriate once the disconnect is revealed, if not resolved.

AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.

```python
x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
y = numpy_dlpack.from_dlpack(some_other_array)
```

Such a prototype package would be useful in production in order to support older versions of numpy, regardless. It's not going to solve all use cases (you won't be able to write ""NEP 47-generic"" functions with it), but a number of use cases involving explicit conversions can be handled. A small third-party prototype will make the discussions concrete and even premature counter-proposals more tolerable to discuss. || First, replying to myself:

> Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#design-topics-data-interchange--page-root) we said ""Zero-copy semantics where possible, making a copy only if needed (e.g. when data is not contiguous in memory). Rationale: performance.""
- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#semantics) we said ""If an array that is accessed via the interchange protocol lives on a device that the requesting library does not support, it is recommended to raise a TypeError""
- [Here](https://github.com/data-apis/array-api/pull/106#issuecomment-759735186) we said the host-device copy is disfavored.

I think it's clear that host-device transfer should raise in NumPy's case. Now, let me move to Robert's above reply:

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Can we please not do this outside NumPy? Two reasons:
1. It is a very small pair of functions (`to_dlpack`/`from_dlpack`) that have been implemented in virtually all other major libraries as far as NEP 47 / Array API is concerned, including CuPy / PyTorch / TensorFlow and JAX. Apart from the deleter behavior which no one got it right in the first shot AFAIK, it actually works ok with little user complaints. I think PyTorch supports CPU tensors so I would recommend to peek at their implementation to see how they handle the CPU-GPU case. Otherwise, it is fairly straightforward to support.
2. @rkern you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result... || No, I saw that. But it's not essential for a prototype that can help work out some of the other details. I'm not saying you should maintain it forever (though it could be useful for working with current versions of numpy). It's noticeably easier to build and evaluate a small prototype package than it is to build and evaluate a branch of numpy, especially if what I want to test is how it relates to other packages, which have their own dependencies on versions of numpy. || I've only skimmed the conversation here, so apologies in advance if I'm repeating things

https://github.com/numpy/numpy/issues/19013#issuecomment-841881506 says

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Are there technical reasons that we can't go through a PEP3118 `memoryview` as an intermediary?

```python
some_buffer = memoryview(some_ndarray)
x = other_array.from_dlpack(pep3118_dlpack.to_dlpack(some_buffer))
y_buffer = pep3118_dlpack.from_dlpack(some_other_array)
y = np.array(y_buffer)
```

That is, could a `pep3118_dlpack` library be written that provides _all_ object supporting PEP3118 with dlpack support, not just `np.ndarray`? Or is it impossible to write `pep3118_dlpack.to_dlpack` and `pep3118_dlpack.from_dlpack` correctly? || @eric-wieser I believe the answer is in https://github.com/numpy/numpy/issues/19013#issuecomment-843735344, 

> you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result...

 || My questions is more along the lines of ""is it possible to 'smuggle' simple `memoryview`s through the dlpack interface and vice versa"", and less about exactly what the conventions around the python API might look like - so I don't think that answers my question. || > Or is it impossible to write pep3118_dlpack.to_dlpack and pep3118_dlpack.from_dlpack correctly?

The feature set is a bit disjunct: the buffer-protocol supports much more, but doesn't support devices, but I don't think that is what you mean?

If there was a `dlpack.DLPackManagedTensor` library, then yeah... NumPy could effectively import that and use `DLPackManagedTensor.from_buffer()` and `memoryview(DLPAckManagedTensor)`  (I am assuming `DLPackManagedTensor` would implement the buffer protocol).

I am not sure the indirection is useful enough?  Hopefully DLPack is just so simple that it doesn't matter too much?   Effectively, NumPy would/could be exactly that library (although not the most elegant implementation)!  As far as I can tell NumPy supports the full set of features that is supported by _both_ DLPack and Memoryview.",closed,2021-05-14T07:43:15+00:00,2021-11-09T19:18:57+00:00,hameerabbasi,"01 - Enhancement, component: numpy._core",1,"PR#19083 - doc/neps/nep-0047-array-api-standard.rst: @@ -338,9 +338,10 @@ the options already present in NumPy are:|;| |;| Adding support for DLPack to NumPy entails:|;| |;|-- Adding a ``ndarray.__dlpack__`` method.|;|-- Adding a ``from_dlpack`` function, which takes as input an object|;|-  supporting ``__dlpack__``, and returns an ``ndarray``.|;|+- Adding a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C|;|+  structure wrapped in a ``PyCapsule``.|;|+- Adding a ``np._from_dlpack(obj)`` function, where ``obj`` supports|;|+  ``__dlpack__()``, and returns an ``ndarray``.|;| |;| DLPack is currently a ~200 LoC header, and is meant to be included directly, so|;| no external dependency is needed. Implementation should be straightforward. || PR#19083 - doc/release/upcoming_changes/19083.new_feature.rst: @@ -0,0 +1,6 @@|;|+Add NEP 47-compatible dlpack support|;|+------------------------------------|;|+|;|+Add a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C structure|;|+wrapped in a ``PyCapsule``. Also add a ``np._from_dlpack(obj)`` function, where|;|+``obj`` supports ``__dlpack__()``, and returns an ``ndarray``. || PR#19083 - numpy/__init__.pyi: @@ -1413,6 +1413,7 @@ _SupportsBuffer = Union[|;| |;| _T = TypeVar(""_T"")|;| _T_co = TypeVar(""_T_co"", covariant=True)|;|+_T_contra = TypeVar(""_T_contra"", contravariant=True)|;| _2Tuple = Tuple[_T, _T]|;| _CastingKind = L[""no"", ""equiv"", ""safe"", ""same_kind"", ""unsafe""]|;| |;|@@ -1432,6 +1433,10 @@ _ArrayTD64_co = NDArray[Union[bool_, integer[Any], timedelta64]]|;| # Introduce an alias for `dtype` to avoid naming conflicts.|;| _dtype = dtype|;| |;|+# `builtins.PyCapsule` unfortunately lacks annotations as of the moment|;|;+# use `Any` as a stopgap measure|;|+_PyCapsule = Any|;|+|;| class _SupportsItem(Protocol[_T_co]):|;|     def item(self, args: Any, /) -> _T_co: ...|;| |;|@@ -2439,6 +2444,12 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeType, _DType_co]):|;|     def __ior__(self: NDArray[signedinteger[_NBit1]], other: _ArrayLikeInt_co) -> NDArray[signedinteger[_NBit1]]: ...|;|     @overload|;|     def __ior__(self: NDArray[object_], other: Any) -> NDArray[object_]: ...|;|+    @overload|;|+    def __ior__(self: NDArray[_ScalarType], other: _RecursiveSequence) -> NDArray[_ScalarType]: ...|;|+    @overload|;|+    def __dlpack__(self: NDArray[number[Any]], *, stream: None = ...) -> _PyCapsule: ...|;|+    @overload|;|+    def __dlpack_device__(self) -> Tuple[int, L[0]]: ...|;| |;|     # Keep `dtype` at the bottom to avoid name conflicts with `np.dtype`|;|     @property|;|@@ -4320,3 +4331,9 @@ class chararray(ndarray[_ShapeType, _CharDType]):|;| |;| # NOTE: Deprecated|;| # class MachAr: ...|;|+|;|+class _SupportsDLPack(Protocol[_T_contra]):|;|+    def __dlpack__(self, *, stream: None | _T_contra = ...) -> _PyCapsule: ...|;|+|;|+def _from_dlpack(__obj: _SupportsDLPack[None]) -> NDArray[Any]: ...|;|+ || PR#19083 - numpy/array_api/__init__.py: @@ -136,7 +136,7 @@|;|     empty,|;|     empty_like,|;|     eye,|;|-    from_dlpack,|;|+    _from_dlpack,|;|     full,|;|     full_like,|;|     linspace,|;|@@ -155,7 +155,7 @@|;|     ""empty"",|;|     ""empty_like"",|;|     ""eye"",|;|-    ""from_dlpack"",|;|+    ""_from_dlpack"",|;|     ""full"",|;|     ""full_like"",|;|     ""linspace"", || PR#19083 - numpy/array_api/_creation_functions.py: @@ -151,7 +151,7 @@ def eye(|;|     return Array._new(np.eye(n_rows, M=n_cols, k=k, dtype=dtype))|;| |;| |;|-def from_dlpack(x: object, /) -> Array:|;|+def _from_dlpack(x: object, /) -> Array:|;|     # Note: dlpack support is not yet implemented on Array|;|     raise NotImplementedError(""DLPack support is not yet implemented"")|;|  || PR#19083 - numpy/core/_add_newdocs.py: @@ -1573,6 +1573,19 @@|;|         array_function_like_doc,|;|     ))|;| |;|+add_newdoc('numpy.core.multiarray', '_from_dlpack',|;|+    """"""|;|+    _from_dlpack(x, /)|;|+|;|+    Create a NumPy array from an object implementing the ``__dlpack__``|;|+    protocol.|;|+|;|+    See Also|;|+    --------|;|+    `Array API documentation|;|+    <https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack>`_|;|+    """""")|;|+|;| add_newdoc('numpy.core', 'fastCopyAndTranspose',|;|     """"""_fastCopyAndTranspose(a)"""""")|;| |;|@@ -2263,6 +2276,15 @@|;| add_newdoc('numpy.core.multiarray', 'ndarray', ('__array_struct__',|;|     """"""Array protocol: C-struct side.""""""))|;| |;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack__',|;|+    """"""a.__dlpack__(*, stream=None)|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;|+|;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack_device__',|;|+    """"""a.__dlpack_device__()|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;| |;| add_newdoc('numpy.core.multiarray', 'ndarray', ('base',|;|     """""" || PR#19083 - numpy/core/code_generators/genapi.py: @@ -41,6 +41,7 @@|;|              join('multiarray', 'datetime_busdaycal.c'),|;|              join('multiarray', 'datetime_strings.c'),|;|              join('multiarray', 'descriptor.c'),|;|+             join('multiarray', 'dlpack.c'),|;|              join('multiarray', 'dtypemeta.c'),|;|              join('multiarray', 'einsum.c.src'),|;|              join('multiarray', 'flagsobject.c'), || PR#19083 - numpy/core/multiarray.py: @@ -14,27 +14,28 @@|;| # do not change them. issue gh-15518|;| # _get_ndarray_c_version is semi-public, on purpose not added to __all__|;| from ._multiarray_umath import (|;|-    _fastCopyAndTranspose, _flagdict, _insert, _reconstruct, _vec_string,|;|-    _ARRAY_API, _monotonicity, _get_ndarray_c_version, _set_madvise_hugepage,|;|+    _fastCopyAndTranspose, _flagdict, _from_dlpack, _insert, _reconstruct,|;|+    _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,|;|+    _set_madvise_hugepage,|;|     )|;| |;| __all__ = [|;|     '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',|;|     'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',|;|     'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',|;|     'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',|;|-    '_flagdict', '_insert', '_reconstruct', '_vec_string', '_monotonicity',|;|-    'add_docstring', 'arange', 'array', 'asarray', 'asanyarray',|;|-    'ascontiguousarray', 'asfortranarray', 'bincount', 'broadcast',|;|-    'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|+    '_flagdict', '_from_dlpack', '_insert', '_reconstruct', '_vec_string',|;|+    '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',|;|+    'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',|;|+    'broadcast', 'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|     'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',|;|     'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',|;|     'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',|;|     'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',|;|-    'frombuffer', 'fromfile', 'fromiter', 'fromstring', 'get_handler_name',|;|-    'inner', 'interp', 'interp_complex', 'is_busday', 'lexsort',|;|-    'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer',|;|-    'nested_iters', 'normalize_axis_index', 'packbits',|;|+    'frombuffer', 'fromfile', 'fromiter', 'fromstring',|;|+    'get_handler_name', 'inner', 'interp', 'interp_complex', 'is_busday',|;|+    'lexsort', 'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray',|;|+    'nditer', 'nested_iters', 'normalize_axis_index', 'packbits',|;|     'promote_types', 'putmask', 'ravel_multi_index', 'result_type', 'scalar',|;|     'set_datetimeparse_function', 'set_legacy_print_mode', 'set_numeric_ops',|;|     'set_string_function', 'set_typeDict', 'shares_memory',|;|@@ -46,6 +47,7 @@|;| scalar.__module__ = 'numpy.core.multiarray'|;| |;| |;|+_from_dlpack.__module__ = 'numpy'|;| arange.__module__ = 'numpy'|;| array.__module__ = 'numpy'|;| asarray.__module__ = 'numpy' || PR#19083 - numpy/core/numeric.py: @@ -13,8 +13,8 @@|;|     WRAP, arange, array, asarray, asanyarray, ascontiguousarray,|;|     asfortranarray, broadcast, can_cast, compare_chararrays,|;|     concatenate, copyto, dot, dtype, empty,|;|-    empty_like, flatiter, frombuffer, fromfile, fromiter, fromstring,|;|-    inner, lexsort, matmul, may_share_memory,|;|+    empty_like, flatiter, frombuffer, _from_dlpack, fromfile, fromiter,|;|+    fromstring, inner, lexsort, matmul, may_share_memory,|;|     min_scalar_type, ndarray, nditer, nested_iters, promote_types,|;|     putmask, result_type, set_numeric_ops, shares_memory, vdot, where,|;|     zeros, normalize_axis_index)|;|@@ -41,7 +41,7 @@|;|     'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',|;|     'arange', 'array', 'asarray', 'asanyarray', 'ascontiguousarray',|;|     'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',|;|-    'fromstring', 'fromfile', 'frombuffer', 'where',|;|+    'fromstring', 'fromfile', 'frombuffer', '_from_dlpack', 'where',|;|     'argwhere', 'copyto', 'concatenate', 'fastCopyAndTranspose', 'lexsort',|;|     'set_numeric_ops', 'can_cast', 'promote_types', 'min_scalar_type',|;|     'result_type', 'isfortran', 'empty_like', 'zeros_like', 'ones_like', || PR#19083 - numpy/core/setup.py: @@ -740,6 +740,7 @@ def gl_if_msvc(build_cmd):|;|     #######################################################################|;| |;|     common_deps = [|;|+            join('src', 'common', 'dlpack', 'dlpack.h'),|;|             join('src', 'common', 'array_assign.h'),|;|             join('src', 'common', 'binop_override.h'),|;|             join('src', 'common', 'cblasfuncs.h'),|;|@@ -749,6 +750,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'common', 'npy_cblas.h'),|;|             join('src', 'common', 'npy_config.h'),|;|             join('src', 'common', 'npy_ctypes.h'),|;|+            join('src', 'common', 'npy_dlpack.h'),|;|             join('src', 'common', 'npy_extint128.h'),|;|             join('src', 'common', 'npy_import.h'),|;|             join('src', 'common', 'npy_hashtable.h'),|;|@@ -881,6 +883,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'multiarray', 'datetime_busday.c'),|;|             join('src', 'multiarray', 'datetime_busdaycal.c'),|;|             join('src', 'multiarray', 'descriptor.c'),|;|+            join('src', 'multiarray', 'dlpack.c'),|;|             join('src', 'multiarray', 'dtypemeta.c'),|;|             join('src', 'multiarray', 'dragon4.c'),|;|             join('src', 'multiarray', 'dtype_transfer.c'), || PR#19083 - numpy/core/src/common/dlpack/dlpack.h: @@ -0,0 +1,201 @@|;|+// Taken from:|;|+// https://github.com/dmlc/dlpack/blob/9b6176fdecb55e9bf39b16f08b96913ed3f275b4/include/dlpack/dlpack.h|;|+/*!|;|+ *  Copyright (c) 2017 by Contributors|;|+ * \file dlpack.h|;|+ * \brief The common header of DLPack.|;|+ */|;|+#ifndef DLPACK_DLPACK_H_|;|+#define DLPACK_DLPACK_H_|;|+|;|+#ifdef __cplusplus|;|+#define DLPACK_EXTERN_C extern ""C""|;|+#else|;|+#define DLPACK_EXTERN_C|;|+#endif|;|+|;|+/*! \brief The current version of dlpack */|;|+#define DLPACK_VERSION 050|;|+|;|+/*! \brief DLPACK_DLL prefix for windows */|;|+#ifdef _WIN32|;|+#ifdef DLPACK_EXPORTS|;|+#define DLPACK_DLL __declspec(dllexport)|;|+#else|;|+#define DLPACK_DLL __declspec(dllimport)|;|+#endif|;|+#else|;|+#define DLPACK_DLL|;|+#endif|;|+|;|+#include <stdint.h>|;|+#include <stddef.h>|;|+|;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+/*!|;|+ * \brief The device type in DLDevice.|;|+ */|;|+typedef enum {|;|+  /*! \brief CPU device */|;|+  kDLCPU = 1,|;|+  /*! \brief CUDA GPU device */|;|+  kDLCUDA = 2,|;|+  /*!|;|+   * \brief Pinned CUDA CPU memory by cudaMallocHost|;|+   */|;|+  kDLCUDAHost = 3,|;|+  /*! \brief OpenCL devices. */|;|+  kDLOpenCL = 4,|;|+  /*! \brief Vulkan buffer for next generation graphics. */|;|+  kDLVulkan = 7,|;|+  /*! \brief Metal for Apple GPU. */|;|+  kDLMetal = 8,|;|+  /*! \brief Verilog simulator buffer */|;|+  kDLVPI = 9,|;|+  /*! \brief ROCm GPUs for AMD GPUs */|;|+  kDLROCM = 10,|;|+  /*!|;|+   * \brief Pinned ROCm CPU memory allocated by hipMallocHost|;|+   */|;|+  kDLROCMHost = 11,|;|+  /*!|;|+   * \brief Reserved extension device type,|;|+   * used for quickly test extension device|;|+   * The semantics can differ depending on the implementation.|;|+   */|;|+  kDLExtDev = 12,|;|+  /*!|;|+   * \brief CUDA managed/unified memory allocated by cudaMallocManaged|;|+   */|;|+  kDLCUDAManaged = 13,|;|+} DLDeviceType|;|;+|;|+/*!|;|+ * \brief A Device for Tensor and operator.|;|+ */|;|+typedef struct {|;|+  /*! \brief The device type used in the device. */|;|+  DLDeviceType device_type|;|;+  /*!|;|+   * \brief The device index.|;|+   * For vanilla CPU memory, pinned memory, or managed memory, this is set to 0.|;|+   */|;|+  int device_id|;|;+} DLDevice|;|;+|;|+/*!|;|+ * \brief The type code options DLDataType.|;|+ */|;|+typedef enum {|;|+  /*! \brief signed integer */|;|+  kDLInt = 0U,|;|+  /*! \brief unsigned integer */|;|+  kDLUInt = 1U,|;|+  /*! \brief IEEE floating point */|;|+  kDLFloat = 2U,|;|+  /*!|;|+   * \brief Opaque handle type, reserved for testing purposes.|;|+   * Frameworks need to agree on the handle data type for the exchange to be well-defined.|;|+   */|;|+  kDLOpaqueHandle = 3U,|;|+  /*! \brief bfloat16 */|;|+  kDLBfloat = 4U,|;|+  /*!|;|+   * \brief complex number|;|+   * (C/C++/Python layout: compact struct per complex number)|;|+   */|;|+  kDLComplex = 5U,|;|+} DLDataTypeCode|;|;+|;|+/*!|;|+ * \brief The data type the tensor can hold.|;|+ *|;|+ *  Examples|;|+ *   - float: type_code = 2, bits = 32, lanes=1|;|+ *   - float4(vectorized 4 float): type_code = 2, bits = 32, lanes=4|;|+ *   - int8: type_code = 0, bits = 8, lanes=1|;|+ *   - std::complex<float>: type_code = 5, bits = 64, lanes = 1|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief Type code of base types.|;|+   * We keep it uint8_t instead of DLDataTypeCode for minimal memory|;|+   * footprint, but the value should be one of DLDataTypeCode enum values.|;|+   * */|;|+  uint8_t code|;|;+  /*!|;|+   * \brief Number of bits, common choices are 8, 16, 32.|;|+   */|;|+  uint8_t bits|;|;+  /*! \brief Number of lanes in the type, used for vector types. */|;|+  uint16_t lanes|;|;+} DLDataType|;|;+|;|+/*!|;|+ * \brief Plain C Tensor object, does not manage memory.|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief The opaque data pointer points to the allocated data. This will be|;|+   * CUDA device pointer or cl_mem handle in OpenCL. This pointer is always|;|+   * aligned to 256 bytes as in CUDA.|;|+   *|;|+   * For given DLTensor, the size of memory required to store the contents of|;|+   * data is calculated as follows:|;|+   *|;|+   * \code{.c}|;|+   * static inline size_t GetDataSize(const DLTensor* t) {|;|+   *   size_t size = 1|;|;+   *   for (tvm_index_t i = 0; i < t->ndim; ++i) {|;|+   *     size *= t->shape[i]|;|;+   *   }|;|+   *   size *= (t->dtype.bits * t->dtype.lanes + 7) / 8|;|;+   *   return size|;|;+   * }|;|+   * \endcode|;|+   */|;|+  void* data|;|;+  /*! \brief The device of the tensor */|;|+  DLDevice device|;|;+  /*! \brief Number of dimensions */|;|+  int ndim|;|;+  /*! \brief The data type of the pointer*/|;|+  DLDataType dtype|;|;+  /*! \brief The shape of the tensor */|;|+  int64_t* shape|;|;+  /*!|;|+   * \brief strides of the tensor (in number of elements, not bytes)|;|+   *  can be NULL, indicating tensor is compact and row-majored.|;|+   */|;|+  int64_t* strides|;|;+  /*! \brief The offset in bytes to the beginning pointer to data */|;|+  uint64_t byte_offset|;|;+} DLTensor|;|;+|;|+/*!|;|+ * \brief C Tensor object, manage memory of DLTensor. This data structure is|;|+ *  intended to facilitate the borrowing of DLTensor by another framework. It is|;|+ *  not meant to transfer the tensor. When the borrowing framework doesn't need|;|+ *  the tensor, it should call the deleter to notify the host that the resource|;|+ *  is no longer needed.|;|+ */|;|+typedef struct DLManagedTensor {|;|+  /*! \brief DLTensor which is being memory managed */|;|+  DLTensor dl_tensor|;|;+  /*! \brief the context of the original host framework of DLManagedTensor in|;|+   *   which DLManagedTensor is used in the framework. It can also be NULL.|;|+   */|;|+  void * manager_ctx|;|;+  /*! \brief Destructor signature void (*)(void*) - this should be called|;|+   *   to destruct manager_ctx which holds the DLManagedTensor. It can be NULL|;|+   *   if there is no way for the caller to provide a reasonable destructor.|;|+   *   The destructors deletes the argument self as well.|;|+   */|;|+  void (*deleter)(struct DLManagedTensor * self)|;|;+} DLManagedTensor|;|;+#ifdef __cplusplus|;|+}  // DLPACK_EXTERN_C|;|+#endif|;|+#endif  // DLPACK_DLPACK_H_ || PR#19083 - numpy/core/src/common/npy_dlpack.h: @@ -0,0 +1,28 @@|;|+#include ""Python.h""|;|+#include ""dlpack/dlpack.h""|;|+|;|+#ifndef NPY_DLPACK_H|;|+#define NPY_DLPACK_H|;|+|;|+// Part of the Array API specification.|;|+#define NPY_DLPACK_CAPSULE_NAME ""dltensor""|;|+#define NPY_DLPACK_USED_CAPSULE_NAME ""used_dltensor""|;|+|;|+// Used internally by NumPy to store a base object|;|+// as it has to release a reference to the original|;|+// capsule.|;|+#define NPY_DLPACK_INTERNAL_CAPSULE_NAME ""numpy_dltensor""|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self, PyObject *const *args, Py_ssize_t len_args,|;|+             PyObject *kwnames)|;|;+|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|;+|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj)|;|;+|;|+#endif || PR#19083 - numpy/core/src/multiarray/dlpack.c: @@ -0,0 +1,408 @@|;|+#define NPY_NO_DEPRECATED_API NPY_API_VERSION|;|+#define _MULTIARRAYMODULE|;|+|;|+#define PY_SSIZE_T_CLEAN|;|+#include <Python.h>|;|+#include <dlpack/dlpack.h>|;|+|;|+#include ""numpy/arrayobject.h""|;|+#include ""common/npy_argparse.h""|;|+|;|+#include ""common/dlpack/dlpack.h""|;|+#include ""common/npy_dlpack.h""|;|+|;|+static void|;|+array_dlpack_deleter(DLManagedTensor *self)|;|+{|;|+    PyArrayObject *array = (PyArrayObject *)self->manager_ctx|;|;+    // This will also free the strides as it's one allocation.|;|+    PyMem_Free(self->dl_tensor.shape)|;|;+    PyMem_Free(self)|;|;+    Py_XDECREF(array)|;|;+}|;|+|;|+/* This is exactly as mandated by dlpack */|;|+static void dlpack_capsule_deleter(PyObject *self) {|;|+    if (PyCapsule_IsValid(self, NPY_DLPACK_USED_CAPSULE_NAME)) {|;|+        return|;|;+    }|;|+|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+/* used internally, almost identical to dlpack_capsule_deleter() */|;|+static void array_dlpack_internal_capsule_deleter(PyObject *self)|;|+{|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+|;|+// This function cannot return NULL, but it can fail,|;|+// So call PyErr_Occurred to check if it failed after|;|+// calling it.|;|+static DLDevice|;|+array_get_dl_device(PyArrayObject *self) {|;|+    DLDevice ret|;|;+    ret.device_type = kDLCPU|;|;+    ret.device_id = 0|;|;+    PyObject *base = PyArray_BASE(self)|;|;+    // The outer if is due to the fact that NumPy arrays are on the CPU|;|+    // by default (if not created from DLPack).|;|+    if (PyCapsule_IsValid(base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)) {|;|+        DLManagedTensor *managed = PyCapsule_GetPointer(|;|+                base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+        if (managed == NULL) {|;|+            return ret|;|;+        }|;|+        return managed->dl_tensor.device|;|;+    }|;|+    return ret|;|;+}|;|+|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self,|;|+        PyObject *const *args, Py_ssize_t len_args, PyObject *kwnames)|;|+{|;|+    PyObject *stream = Py_None|;|;+    NPY_PREPARE_ARGPARSER|;|;+    if (npy_parse_arguments(""__dlpack__"", args, len_args, kwnames,|;|+            ""$stream"", NULL, &stream, NULL, NULL, NULL)) {|;|+        return NULL|;|;+    }|;|+|;|+    if (stream != Py_None) {|;|+        PyErr_SetString(PyExc_RuntimeError, ""NumPy only supports ""|;|+                ""stream=None."")|;|;+        return NULL|;|;+    }|;|+|;|+    if ( !(PyArray_FLAGS(self) & NPY_ARRAY_WRITEABLE)) {|;|+        PyErr_SetString(PyExc_TypeError, ""NumPy currently only supports ""|;|+                ""dlpack for writeable arrays"")|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp itemsize = PyArray_ITEMSIZE(self)|;|;+    int ndim = PyArray_NDIM(self)|;|;+    npy_intp *strides = PyArray_STRIDES(self)|;|;+    npy_intp *shape = PyArray_SHAPE(self)|;|;+|;|+    if (!PyArray_IS_C_CONTIGUOUS(self) && PyArray_SIZE(self) != 1) {|;|+        for (int i = 0; i < ndim; ++i) {|;|+            if (strides[i] % itemsize != 0) {|;|+                PyErr_SetString(PyExc_RuntimeError,|;|+                        ""DLPack only supports strides which are a multiple of ""|;|+                        ""itemsize."")|;|;+                return NULL|;|;+            }|;|+        }|;|+    }|;|+|;|+    DLDataType managed_dtype|;|;+    PyArray_Descr *dtype = PyArray_DESCR(self)|;|;+|;|+    if (PyDataType_ISBYTESWAPPED(dtype)) {|;|+        PyErr_SetString(PyExc_TypeError, ""DLPack only supports native ""|;|+                    ""byte swapping."")|;|;+            return NULL|;|;+    }|;|+|;|+    managed_dtype.bits = 8 * itemsize|;|;+    managed_dtype.lanes = 1|;|;+|;|+    if (PyDataType_ISSIGNED(dtype)) {|;|+        managed_dtype.code = kDLInt|;|;+    }|;|+    else if (PyDataType_ISUNSIGNED(dtype)) {|;|+        managed_dtype.code = kDLUInt|;|;+    }|;|+    else if (PyDataType_ISFLOAT(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 8) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""floating point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLFloat|;|;+    }|;|+    else if (PyDataType_ISCOMPLEX(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 16) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""complex point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLComplex|;|;+    }|;|+    else {|;|+        PyErr_SetString(PyExc_TypeError,|;|+                        ""DLPack only supports signed/unsigned integers, float ""|;|+                        ""and complex dtypes."")|;|;+        return NULL|;|;+    }|;|+|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed = PyMem_Malloc(sizeof(DLManagedTensor))|;|;+    if (managed == NULL) {|;|+        PyErr_NoMemory()|;|;+        return NULL|;|;+    }|;|+|;|+    /*|;|+     * Note: the `dlpack.h` header suggests/standardizes that `data` must be|;|+     * 256-byte aligned.  We ignore this intentionally, because `__dlpack__`|;|+     * standardizes that `byte_offset` must be 0 (for now) to not break pytorch:|;|+     * https://github.com/data-apis/array-api/issues/293#issuecomment-964111413|;|+     *|;|+     * We further assume that exporting fully unaligned data is OK even without|;|+     * `byte_offset` since the standard does not reject it.|;|+     * Presumably, pytorch will support importing `byte_offset != 0` and NumPy|;|+     * can choose to use it starting about 2023.  At that point, it may be|;|+     * that NumPy MUST use `byte_offset` to adhere to the standard (as|;|+     * specified in the header)!|;|+     */|;|+    managed->dl_tensor.data = PyArray_DATA(self)|;|;+    managed->dl_tensor.byte_offset = 0|;|;+    managed->dl_tensor.device = device|;|;+    managed->dl_tensor.dtype = managed_dtype|;|;+|;|+    int64_t *managed_shape_strides = PyMem_Malloc(sizeof(int64_t) * ndim * 2)|;|;+    if (managed_shape_strides == NULL) {|;|+        PyErr_NoMemory()|;|;+        PyMem_Free(managed)|;|;+        return NULL|;|;+    }|;|+|;|+    int64_t *managed_shape = managed_shape_strides|;|;+    int64_t *managed_strides = managed_shape_strides + ndim|;|;+    for (int i = 0; i < ndim; ++i) {|;|+        managed_shape[i] = shape[i]|;|;+        // Strides in DLPack are items; in NumPy are bytes.|;|+        managed_strides[i] = strides[i] / itemsize|;|;+    }|;|+|;|+    managed->dl_tensor.ndim = ndim|;|;+    managed->dl_tensor.shape = managed_shape|;|;+    managed->dl_tensor.strides = NULL|;|;+    if (PyArray_SIZE(self) != 1 && !PyArray_IS_C_CONTIGUOUS(self)) {|;|+        managed->dl_tensor.strides = managed_strides|;|;+    }|;|+    managed->dl_tensor.byte_offset = 0|;|;+    managed->manager_ctx = self|;|;+    managed->deleter = array_dlpack_deleter|;|;+|;|+    PyObject *capsule = PyCapsule_New(managed, NPY_DLPACK_CAPSULE_NAME,|;|+            dlpack_capsule_deleter)|;|;+    if (capsule == NULL) {|;|+        PyMem_Free(managed)|;|;+        PyMem_Free(managed_shape_strides)|;|;+        return NULL|;|;+    }|;|+|;|+    // the capsule holds a reference|;|+    Py_INCREF(self)|;|;+    return capsule|;|;+}|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|+{|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+    return Py_BuildValue(""ii"", device.device_type, device.device_id)|;|;+}|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj) {|;|+    PyObject *capsule = PyObject_CallMethod((PyObject *)obj->ob_type,|;|+            ""__dlpack__"", ""O"", obj)|;|;+    if (capsule == NULL) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(capsule,|;|+        NPY_DLPACK_CAPSULE_NAME)|;|;+|;|+    if (managed == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    const int ndim = managed->dl_tensor.ndim|;|;+    if (ndim > NPY_MAXDIMS) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""maxdims of DLPack tensor is higher than the supported ""|;|+                ""maxdims."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    DLDeviceType device_type = managed->dl_tensor.device.device_type|;|;+    if (device_type != kDLCPU &&|;|+            device_type != kDLCUDAHost &&|;|+            device_type != kDLROCMHost &&|;|+            device_type != kDLCUDAManaged) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported device in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    if (managed->dl_tensor.dtype.lanes != 1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported lanes in DLTensor dtype."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    int typenum = -1|;|;+    const uint8_t bits = managed->dl_tensor.dtype.bits|;|;+    const npy_intp itemsize = bits / 8|;|;+    switch (managed->dl_tensor.dtype.code) {|;|+    case kDLInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_INT8; break|;|;+            case 16: typenum = NPY_INT16; break|;|;+            case 32: typenum = NPY_INT32; break|;|;+            case 64: typenum = NPY_INT64; break|;|;+        }|;|+        break|;|;+    case kDLUInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_UINT8; break|;|;+            case 16: typenum = NPY_UINT16; break|;|;+            case 32: typenum = NPY_UINT32; break|;|;+            case 64: typenum = NPY_UINT64; break|;|;+        }|;|+        break|;|;+    case kDLFloat:|;|+        switch (bits)|;|+        {|;|+            case 16: typenum = NPY_FLOAT16; break|;|;+            case 32: typenum = NPY_FLOAT32; break|;|;+            case 64: typenum = NPY_FLOAT64; break|;|;+        }|;|+        break|;|;+    case kDLComplex:|;|+        switch (bits)|;|+        {|;|+            case 64: typenum = NPY_COMPLEX64; break|;|;+            case 128: typenum = NPY_COMPLEX128; break|;|;+        }|;|+        break|;|;+    }|;|+|;|+    if (typenum == -1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported dtype in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp shape[NPY_MAXDIMS]|;|;+    npy_intp strides[NPY_MAXDIMS]|;|;+|;|+    for (int i = 0; i < ndim; ++i) {|;|+        shape[i] = managed->dl_tensor.shape[i]|;|;+        // DLPack has elements as stride units, NumPy has bytes.|;|+        if (managed->dl_tensor.strides != NULL) {|;|+            strides[i] = managed->dl_tensor.strides[i] * itemsize|;|;+        }|;|+    }|;|+|;|+    char *data = (char *)managed->dl_tensor.data +|;|+            managed->dl_tensor.byte_offset|;|;+|;|+    PyArray_Descr *descr = PyArray_DescrFromType(typenum)|;|;+    if (descr == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *ret = PyArray_NewFromDescr(&PyArray_Type, descr, ndim, shape,|;|+            managed->dl_tensor.strides != NULL ? strides : NULL, data, 0, NULL)|;|;+    if (ret == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *new_capsule = PyCapsule_New(managed,|;|+            NPY_DLPACK_INTERNAL_CAPSULE_NAME,|;|+            array_dlpack_internal_capsule_deleter)|;|;+    if (new_capsule == NULL) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyArray_SetBaseObject((PyArrayObject *)ret, new_capsule) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyCapsule_SetName(capsule, NPY_DLPACK_USED_CAPSULE_NAME) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    Py_DECREF(capsule)|;|;+    return ret|;|;+}|;|+|;|+ || PR#19083 - numpy/core/src/multiarray/methods.c: @@ -26,6 +26,7 @@|;| #include ""shape.h""|;| #include ""strfuncs.h""|;| #include ""array_assign.h""|;|+#include ""npy_dlpack.h""|;| |;| #include ""methods.h""|;| #include ""alloc.h""|;|@@ -2989,5 +2990,13 @@ NPY_NO_EXPORT PyMethodDef array_methods[] = {|;|     {""view"",|;|         (PyCFunction)array_view,|;|         METH_FASTCALL | METH_KEYWORDS, NULL},|;|+    // For data interchange between libraries|;|+    {""__dlpack__"",|;|+        (PyCFunction)array_dlpack,|;|+        METH_FASTCALL | METH_KEYWORDS, NULL},|;|+|;|+    {""__dlpack_device__"",|;|+        (PyCFunction)array_dlpack_device,|;|+        METH_NOARGS, NULL},|;|     {NULL, NULL, 0, NULL}           /* sentinel */|;| }; || PR#19083 - numpy/core/src/multiarray/multiarraymodule.c: @@ -70,6 +70,8 @@ NPY_NO_EXPORT int NPY_NUMUSERTYPES = 0|;|; #include ""get_attr_string.h""|;| #include ""experimental_public_dtype_api.h""  /* _get_experimental_dtype_api */|;| |;|+#include ""npy_dlpack.h""|;|+|;| /*|;|  *****************************************************************************|;|  **                    INCLUDE GENERATED CODE                               **|;|@@ -4231,7 +4233,6 @@ _reload_guard(PyObject *NPY_UNUSED(self)) {|;|     Py_RETURN_NONE|;|; }|;| |;|-|;| static struct PyMethodDef array_module_methods[] = {|;|     {""_get_implementing_args"",|;|         (PyCFunction)array__get_implementing_args,|;|@@ -4445,6 +4446,8 @@ static struct PyMethodDef array_module_methods[] = {|;|     {""_reload_guard"", (PyCFunction)_reload_guard,|;|         METH_NOARGS,|;|         ""Give a warning on reload and big warning in sub-interpreters.""},|;|+    {""_from_dlpack"", (PyCFunction)_from_dlpack,|;|+        METH_O, NULL},|;|     {NULL, NULL, 0, NULL}                /* sentinel */|;| }|;|;  || PR#19083 - numpy/core/tests/test_dlpack.py: @@ -0,0 +1,109 @@|;|+import sys|;|+import pytest|;|+|;|+import numpy as np|;|+from numpy.testing import assert_array_equal, IS_PYPY|;|+|;|+|;|+class TestDLPack:|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_dunder_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = x.__dlpack__()|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    def test_dunder_dlpack_stream(self):|;|+        x = np.arange(5)|;|+        x.__dlpack__(stream=None)|;|+|;|+        with pytest.raises(RuntimeError):|;|+            x.__dlpack__(stream=1)|;|+|;|+    def test_strides_not_multiple_of_itemsize(self):|;|+        dt = np.dtype([('int', np.int32), ('char', np.int8)])|;|+        y = np.zeros((5,), dtype=dt)|;|+        z = y['int']|;|+|;|+        with pytest.raises(RuntimeError):|;|+            np._from_dlpack(z)|;|+|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_from_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = np._from_dlpack(x)|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    @pytest.mark.parametrize(""dtype"", [|;|+        np.int8, np.int16, np.int32, np.int64,|;|+        np.uint8, np.uint16, np.uint32, np.uint64,|;|+        np.float16, np.float32, np.float64,|;|+        np.complex64, np.complex128|;|+    ])|;|+    def test_dtype_passthrough(self, dtype):|;|+        x = np.arange(5, dtype=dtype)|;|+        y = np._from_dlpack(x)|;|+|;|+        assert y.dtype == x.dtype|;|+        assert_array_equal(x, y)|;|+|;|+    def test_invalid_dtype(self):|;|+        x = np.asarray(np.datetime64('2021-05-27'))|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_invalid_byte_swapping(self):|;|+        dt = np.dtype('=i8').newbyteorder()|;|+        x = np.arange(5, dtype=dt)|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_non_contiguous(self):|;|+        x = np.arange(25).reshape((5, 5))|;|+|;|+        y1 = x[0]|;|+        assert_array_equal(y1, np._from_dlpack(y1))|;|+|;|+        y2 = x[:, 0]|;|+        assert_array_equal(y2, np._from_dlpack(y2))|;|+|;|+        y3 = x[1, :]|;|+        assert_array_equal(y3, np._from_dlpack(y3))|;|+|;|+        y4 = x[1]|;|+        assert_array_equal(y4, np._from_dlpack(y4))|;|+|;|+        y5 = np.diagonal(x).copy()|;|+        assert_array_equal(y5, np._from_dlpack(y5))|;|+|;|+    @pytest.mark.parametrize(""ndim"", range(33))|;|+    def test_higher_dims(self, ndim):|;|+        shape = (1,) * ndim|;|+        x = np.zeros(shape, dtype=np.float64)|;|+|;|+        assert shape == np._from_dlpack(x).shape|;|+|;|+    def test_dlpack_device(self):|;|+        x = np.arange(5)|;|+        assert x.__dlpack_device__() == (1, 0)|;|+        assert np._from_dlpack(x).__dlpack_device__() == (1, 0)|;|+|;|+    def dlpack_deleter_exception(self):|;|+        x = np.arange(5)|;|+        _ = x.__dlpack__()|;|+        raise RuntimeError|;|+    |;|+    def test_dlpack_destructor_exception(self):|;|+        with pytest.raises(RuntimeError):|;|+            self.dlpack_deleter_exception()|;|+|;|+    def test_readonly(self):|;|+        x = np.arange(5)|;|+        x.flags.writeable = False|;|+        with pytest.raises(TypeError):|;|+            x.__dlpack__()","ENH: Add the __dlpack__ and __dlpack_device__ methods to ndarray. || ENH, TST: Add the from_dlpack method and test DLPack. || MAINT, BUG: Documentation for DLPack protocol and refcounting bug fixes. || MAINT: Add URL to DLPack GitHub. || MAINT: Split up capsule deleter. || MAINT: Move around code so that there are no more unused warnings. || TST: Improve testing coverage for DLPack. || BUG: Fix handling of C-contiguous and 1-element arrays. || BUG, TST: Device bugfix and test __dl_device__. || MAINT: Robustify dlpack_capsule_deleter and add comments. || BUG: Offset not properly stored/computed. || move dlpack functions to a new file || BUG: fixes from review || Updates

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net>
Co-authored-by: Bas van Beek <43369155+BvB93@users.noreply.github.com> || change from_dlpack to _dlpack, remove unused header || make a.__dlpack__() fail if a is readonly || add release note, error out if offset is used || MAINT: Simplify `byte_offset` handling in dlpack.h and add comment

If `byte_offset = 0` is forced anyway, there is no point in trying
to preserve a previous `data` information from the capsule.
(And probably it should have used a base array also, and not just
a base DLPack capsule, anyway.)"
numpy/numpy,hameerabbasi,19013,DLPack support for NumPy,"## Feature
### Motivation
Currently, any library which needs to exchange data with NumPy needs to have it as a dependency. This issue will allow moving away from that approach to a more Pythonic standards-based approach leveraging the [DLPack Library](https://github.com/dmlc/dlpack), as described in the [Array API standard](https://data-apis.org). This is also mentioned in and a prerequisite for [NEP 47](https://numpy.org/neps/nep-0047-array-api-standard.html#dlpack-support-for-zero-copy-data-interchange), although it can be discussed and integrated independently of it as well, the only caveat being that if the NEP is accepted; adopting DLPack is a given.

DLPack is a small C header-only library with a stable ABI.

### Changes needed to NumPy
The `numpy.ndarray` type will need to gain two new methods:

* [`__dlpack__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-self-stream-none): This will return a `PyCapsule` with a [DLPack struct](https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L126-L162).
* [`__dlpack_device__`](https://data-apis.org/array-api/latest/API_specification/array_object.html#dlpack-device-self): This one will always return the CPU device for NumPy.

And the NumPy namespace will gain one extra function:

* [`from_dlpack`](https://data-apis.org/array-api/latest/API_specification/creation_functions.html#from-dlpack-x): This will consume a `PyCapsule` containing a DLPack struct and create a `numpy.ndarray` based on that. It will raise a `RuntimeError` on all unsupported configurations of the object.

Relevant issues/discussion: 

* data-apis/consortium-feedback#1
* [Array API docs](https://data-apis.org/array-api/latest/design_topics/data_interchange.html)
* Links to existing implementations: https://github.com/data-apis/consortium-feedback/issues/1#issuecomment-726066249
* PyTorch in-progress PR: pytorch/pytorch#57110
* Discussion on the DLPack issue tracker: dmlc/dlpack#55

Edit: Previously this issue said `from_dlpack` was a method, that has been corrected.

cc @rgommers @mattip ","For other commenters: the discussion at data-apis/consortium-feedback#1 is quite lengthy but does include answers to many questions like object lifetime management. It is helpful to understand the context. Many of my concerns were addressed there.

A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

I think this can be done separately from #18585. || I have tried to look through the discussion.  I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? – although maybe that is tricky without reference counts).  But maybe there is something about streams or so that I just don't see right now.

Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

For the API, I think, I am still a bit confused about view vs. copy.  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so?  Either as an input `copy={None, True, False}` or as an additional return flag (or even both).
Most of the current protocols don't have this problem, the one that does is `__array__` and it would be nice to have it there!

Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view, that seems like it must at least be easy to check (I guess `np.may_share_memory` might work).  Since there is no good way to ""predict"" what is going to happen.



But, in general I think it just needs a good PR.  Inn the end I don't really want to worry about it too much, if other projects already implemented basically the same thing (and it seems like they did).  So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping. || > I have tried to look through the discussion. I still don't understand why the ""consumed exactly once"" is important (the PyCapsule is reference counted and can clean up on delete, so the memory management seems fine? 

Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:
```python
# `x` is some array/tensor object
capsule = to_dlpack(x)
x2 = from_dlpack(capsule)
```
At that point you had a (non-useful) PyCapsule object floating around in the users code, and then doing `x3 = from_dlpack(capsule)` somewhere else in the code would of course lead to problems. Using `__dlpack__` avoids this by design. || > Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

I think we can make this a keyword-only argument without breaking compat with the existing protocol, and default it to `None`. Perhaps it can be in a future version, but that may need to be discussed separately.

> Would NumPy be able to just use the `offset` to ""make it fit"" even if that means `data` points to some random (earlier) place?

I believe not, in that case the allocation still isn't ""aligned"" unfortunately.

> Especially, if the alignment of the memory allocation in NumPy can lead to a copy return instead of a view,

For other commenters, this is due to the by-element strides of DLPack instead of the by-bytes. || > A side issue is the struct itself: the header mentions ""[The data] pointer is always aligned to 256 bytes as in CUDA"". If this is a hard requirement, NEP 49 may help achieve this in a zero-copy manner.

This is, indeed, a sticking point. I do not know how to resolve this. Perhaps this restriction could be clarified or removed if the rationale didn't apply to CPU data pointers.

cc @tqchen would you happen to know the answer? || >  If `__dlpack__` can return either a view or a copy, it would be nice if it could indicate so? Either as an input `copy={None, True, False}` or as an additional return flag (or even both).

Why would we want this? Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops). The protocol tries to return a view for performance reasons, but it may not always be possible for all libraries - and then it will return a view. Having an explicit `copy=` keyword seems like a mistake to me.

 || > Why would we want this?

Usually, performance. Maybe one may want the flexibility of a different path when a view isn't possible, e.g., perform operation in the existing library rather than moving it to a new one using DLPack.

Or, conversely, one may want to specify a copy because in-place ops are needed for an algorithm/function (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Of course, the default would be `None`, i.e., we don't guarantee either and then everything you said applies. || > Usually, performance.

Performance is already optimal, it default to zero copy.

> (I guess one can always do `x = x.copy()` or similar, but that's an extra LOC).

Exactly. That's about zero characters extra, so if you want to do something numpy-specific, use that. There are libraries that don't even have the concept of a view, and the buffer protocol and `__array_interface__` don't have a copy keyword either. Adding a copy keyword doesn't make sense to me.
 || > Performance is already optimal, it defaults to zero copy.

But that is not a stated requirement anywhere, I found yet?  And apparently NumPy cannot always export zero copy (which is fine, but then we need an additional `np.export_dlpack(...)` or `np.ensure_dlpack_exportable` function to do the copy if necessary)?

If the user wants to copy the data, they may have to do so *twice*, because they don't know whether the original array-like was copied already.  Either because the exporter does so always, or because it does so ""if necessary"" like NumPy would apparently.
Further, the buffer protocol also supports signaling read only export.  JAX could use that to allow a no-copy export when given?

> Semantics of a program using DLPack should not rely on view vs. copy (avoid in-place ops).

Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently?  What about copy on write semantics, or just plain old numpy style usage?

> [The consume only once behavior...] Exactly, it's not that important. It came from before we improved the Python API; the old way of doing it in other libraries was:

Fair enough, it might help with memory management.  It also might help a bit to ensure that only a single consumers will end up writing to the data. (I guess this doesn't relaly matter if we assume all exports are zero-copy, though.) || > But that is not a stated requirement anywhere, I found yet? 

Hmm, I'll have a look at where the most obvious place is to mention this. DLPack works just like the buffer protocol, except:
- it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well
- it has device support

> And apparently NumPy cannot always export zero copy

I don't think that is true. And I reviewed the implementations in other libraries like CuPy, MXNet, PyTorch and JAX a while back, and can't remember anything regarding the 256 byte alignment thing.

There may be more exotic libraries that perhaps could be forced to make a copy, e.g. Vaex has a concept of ""virtual columns"" where data is basically a string expression rather than it living in memory. In that case, zero-copy access isn't possible.

Another thing that can happen is that NumPy has, say, an array with odd strides. And then JAX and TensorFlow can't represent that, they only have contiguous arrays internally - hence they make a copy on the consumer side.

But for our purposes, I think there isn't too much magic - just think of it as an enhanced buffer protocol.
 || I hadn't noticed the comment (https://github.com/dmlc/dlpack/blob/main/include/dlpack/dlpack.h#L130) before. It talks about CUDA and OpenCL, and the only mention in the issue tracker is https://github.com/dmlc/dlpack/issues/1#issuecomment-282878582, which talks about vector types like `float4` for accelerators. It's not clear that the comment was meant to apply to CPU.

PEP 3118 also briefly mentions alignment: _"" The default endian is `@` which means native data-types and alignment. If un-aligned, native data-types are requested, then the endian specification is '^'.""_. Requiring alignment maybe makes sense, but why would one need 256-byte alignment on CPU? || Oh wait, this explains it (from issue description of https://github.com/data-apis/consortium-feedback/issues/1):

> Data field mandatory aligns to 256 bytes(for aligned load), allow byte_offset to offset the array if necessary

```C
  /*! \brief The offset in bytes to the beginning pointer to data */
  uint64_t byte_offset;
```
That should solve the issue? || > Further, the buffer protocol also supports signaling read only export. JAX could use that to allow a no-copy export when given?

I think that's more of a problem than a feature in the buffer protocol actually, and it reflects that it was written mostly from a ""NumPy needs/design"" point of view. Most libraries simply do not have a read-only array/tensor data structure, so if you create an array in such a library with `from_dlpack`, what are you supposed to do with a `readonly = 1` flag? || > So long NumPy isn't the odd one out, due to being the only one that has to copy for reasons like alignment or byte-swapping.

The last point is good - I think `__dlpack__` should just raise an exception for non-native endianness. That byte-swapping is still a prominent chapter in the [NumPy fundamentals section of the user guide](https://numpy.org/devdocs/user/basics.html) makes very little sense, we should just hide that in some obscure corner. || > Could you explain why this such a strong preference that it doesn't matter to think about how you could allow both exports transparently? 

DLPack is, by design, zero-copy. It's highly unusual for it to _have_ to make a copy on the producer side, the Vaex virtual column is the only example I could think of. And if we add `copy=False` for such corner cases, then that seems like design for the <1% case which makes the whole thing more complex for little benefit. Next will be the `do_a_device_transfer=False`, `readonly=False`, etc. Other protocols also don't do this, and where we do do it (`np.array`) we end up making the super-thin wrapper (`np.asarray`) that removes the keyword again.

> What about copy on write semantics, or just plain old numpy style usage?

Copy-on-write is nice, it's like the one thing I give Matlab a bit of credit for:) That's safe though, and stays within a library that would implement it - no keyword needed.

Plain-old numpy style usage: could be done if you know you are working with 2 libraries that have the same semantics (we don't have any 100% the same, but PyTorch and MXNet are fairly close), and you have full control over the code you write. Then you already have all the tools you need though, again no keyword needed. You can go write ahead and mutate memory that's shared between two libraries.

What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations. || > [NumPy cannot always export zero copy?] I don't think that is true.

> [`byte_offset`] should solve the issue?

Well, those were my main initial questions!   What is the definite answer?

> it has a deleter mechanism rather than refcounting, because a design goal was to make it work with pure C libraries as well

This seems just wrong. The buffer protocol has a deleter mechanism, and doesn't even use reference counting itself.  Python puts the result into `memoryview` and a lower level helper objects to *add* custom reference counting on top of that.

It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.
At that point the buffer-protocol may be a bit of a feature creap, but is probably a strict superset of the `__dlpack__` capabilities.

One thing where the two really differ (aside form device support and feature creap in the buffer protcol, and some standardized flags).  From a protocol point of view, I think the only real difference is that the buffer protocol allows the requester to pass simple flags to the exporter.

> [About no readonly flag]  I think that's more of a problem than a feature in the buffer protocol actually

Honestly, now I am just confused and a bit annoyed. How can such a simple flag be a problem, the consumer can easily check it after all and the exporter can always set readonly trivially?  My points do not feel addressed at all unless you make the two requirements: 

1. Any export must be no copy.  (You seem to be fine to make this a soft requirement, but that probably limits some use-cases slightly, or burdens the user with knowing about it.  Which I am fine with, as long as it is very predictable.)
2. Any import must assume that chunk of memory is (consumer) read-only (But the exporter is still allowed to modify it!).

Those are some clear limitations.  If that is the intention: OK, I don't care!  But I do feel it strange to claim that the buffer protocol is bad because it _doesn't_ have this limittion.

Why are view semantics, in-place algorithms accepting a `dlpack` manged object so out of question that you just dismiss them?  What about a visualization library that would like to visualize an array that is being updated in-place?  We had a _long_ discussion about that a while ago with respect to `__array__` and napari!

> And if we add copy=False for such corner cases [...] makes the whole thing more complex

Why?  We do not have to support a `copy=True` specifically (and even if, the exporter could just raise that it doesn't support it).  I was never suggesting a better API. I am only asking the question whether use-cases that would be covered by `copy=...` really not worthwhile supporting.  (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As I _also_ said, it would be completely sufficient to have a two new flags on the *exported* `DLManagedTensor` (or additionally if you shy away from modifying DLpack):

* `shared`: The buffer shares the original exporters data.
* `readonly` the buffer is readonly and may not be modified by the importer

It might be nice for the `napari` use-case to be able to signal the `shared` as well, since it avoids VEAX potentially copying everything, just to throw it away again.

I don't argue for `copy=` itself, I am not trying to create a new API, but there are use-cases that you are dimssing and not allowing. And I think those should be stated clearly and to be honest, I am not yet convinced DLPack gave those use-cases proper thought.

> What I had in mind was library authors: if you don't know whether you're talking to JAX, PyTorch or library X, you simply cannot reliably mix views and in-place operations.  {... and the paragraph above it ...}

Yes, but you are not addressing the questions/use case!  ~If I use numpy but import a JAX array (unknowingly where it came from), I should have to know about NUMPY only.  And that means that numpy has to know about JAX's expectations!  That is the whole point of an exchange protocol to smoothen out such differences!~

If Matlab is copy-on-write, Matlab has to know that the provider (NumPy) may not be, and maybe just copy right away becuase it sees the exported buffer is ""shared"" and ""writeable"".  The other way around, NumPy might want to know that it must not write to the Matlab data.

It seems to me you are dissmissing use-cases because you have an ideal single ~package~ homogeneous world in mind. When we have the chance right here to make the different worlds *not* collide, but rather work together harmoniously.  And all we seem to have to do is to add a few simple flags to the protocol! (maybe only for the exporter, maybe also for the request, I don't care/know).

---

Look, I do not care enough to fight over this:  `__dlpack__` is just another lightweight attribute, we already have like 4 of those. The only churn is the `from_dlpack` classmethod and that probably can deal just fine if a `__dlpack_v2__` happens... || Another argument that is completely fine for me, is if we say: Well, DLPack may grow those features/use-cases in the future, and we will be able to even add a ""requests"" API in the future without problem.
(It might be nice to map out map out how that could grow in the future, but I expect it isn't terribly hard, if we don't mind a `try:/except:` a specially).

At that point, the only thing would need to be to clarify expectations. E.g. copy should not happen, but may.  And whether or not its OK to write to a dlpack array, or we should e.g. default to a `ndarray.from_dlpack(object, writeable=None)` and force the user to pass `writeable=True` if they want to write into the view.  (And we live with potential additional copies, probably.) || > Well, those were my main initial questions! What is the definite answer?

That was 5 comments up, as one line, followed by lots of discussion about adding a `copy=` keyword. I missed that one line. Answer is yes, it solves it. 

> This seems just wrong. The buffer protocol has a deleter mechanism

I dunno, this is what PEP 3118 says as a ""rejected idea"": _Having a ""releaser"" object whose release-buffer was called. This was deemed unacceptable because it caused the protocol to be asymmetric (you called release on something different than you ""got"" the buffer from). It also complicated the protocol without providing a real benefit._. If it does have a deleter mechanism now, maybe that's wrong - or I misunderstood, I haven't looked at the code for ages.

> It is likely possible to extend the buffer protocol with a new ""device"" field (although maybe a bit clunky). It might even be possible to ""backport"" it to older Pythons.

This was extensively discussed for about a decade I believe. No one has done it, it's a lot of work to write a new PEP, and I don't see how you would backport it. Putting things in Python itself just means you have to wait years after making any change before you can use it.

It's also kind of a ""proof is in the pudding"": despite the buffer protocol being supported in the language itself, adoption is quite low. Unlike for DLPack, which is much newer.

> I am only asking the question whether use-cases that would be covered by copy=... really not worthwhile supporting. (And the uncertainty about NumPy being able to export no-copy just increases that issue.)

As Hameer already pointed out, `x = x.copy()` is equivalent. Hence I don't think that there are unsupported use cases. I do not see any case where NumPy must copy.

> Honestly, now I am just confused and a bit annoyed. ....
> My points do not feel addressed at all unless you make the two requirements: ...
> so out of question that you just dismiss them? 
> Yes, but you are not addressing the questions/use case! 
> there are use-cases that you are dimssing and not allowing. 
>  you have an ideal single ~package~ homogeneous world in mind.

Sebastian, seriously, you are slinging a ton of accusations as well as more API proposals. We have been working on this for months in the DLPack and array-api repos (it's a very much nontrivial topic), with review/contributions by quite a few people with extensive experience using all of DLPack, buffer protocol, and `__array_interface__`/`__cuda_array_interface__`. It seems you're upset about something.  I suggest to take a break from adding more, and use a higher bandwidth call to discuss afterwards if needed.

I'll just repeat for now: I don't think there are unsupported use cases, and hence I'm also not ""dismissing"" them. I just tried to answer questions as best I could. || I believe there are some (admittedly rare) cases I see where NumPy must copy: The strides inside DLPack assume a unit of array elements, and those inside NumPy assume a unit of bytes, which is more flexible. One can find cases where zero-copy isn't possible, and one can see these if all elements of `arr.strides` aren't a multiple of `arr.dtype.itemsize`. Concrete examples I can find are:

1. Slicing weirdly and then viewing (I was unable to make this work, even if it was theoretically possible within NumPy's framework):
    ```python
    >>> np.ones((4, 5), dtype=np.int8)[:, 1:].view(np.int32).strides  # Would otherwise be (20, 5)
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
    ValueError: To change to a dtype of a different size, the array must be C-contiguous
    ```
2. Selecting a field from a structured array (which is already rare):
    ```python
    >>> dt = np.dtype([('int', np.int32), ('byte', np.int8)])
    >>> np.zeros((4,), dtype=dt)['int'].strides
    (5,)
    ```

So, yes, it's possible, rare IMO, and can be easily predicted by checking for `all(s % arr.itemsize == 0 for s in arr.strides)`.

But what I see as the more pressing matter I should clarify is the alignment: Should one just round down the pointer to the next 256 bytes and also add the ""round down"" amount to the offset? || On my cell, so please forgive me for leaving only a drive-by comment: please ignore the alignment stuff. If we are talking about host-device copies, it's an implementation detail (of CUDA, HIP, or any sane memory pool implementation sitting on top). CUDA/HIP's copy APIs do not care about alignments. DLPack does not. CUDA Array Interface does not. No one does.

Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later. || > please ignore the alignment stuff

Thanks for clearing that up Ralf and @leofang, sorry for missing the link to the comment where it was more clearly defined.   I am not concerned about NumPy providing `__dlpack__` then.  Forcing the user to copy on weird strides or dtypes seems totally fine.

> Another thing is I seem to recall we agreed in an Array API meeting is that if a copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

@leofang: If a copy is *never* done, that is good.  My concern is mainly that it should be predictable. Although, *never* might even be nicer.  (The array api says it can return a view or copy, ~but it doesn't specify who would be making that copy, the exporter, importer, or either/both~, I guess the copy is expected to be made by the exporter only currently).

---

@rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself.  Maybe I am late to the party, but maybe can I have a bit of time to think out loud?  I am happy be pointed to a different place/issue, if you think this is a terrible place...

To be clear, I am still just *exploring* limitations, and how those limitations could be removed.  The `copy=` argument is a thing we had discussed for `__array__()` because of napari, so it didn't come out of nowhere, it always addressed at least the napari use-case below.

And yes, I may have had the wrong impression that this API still *could* be modified more easily if new use-cases/problems come up, easier than the buffer-protocol at least.  And just because I am discussing possible new API, doesn't mean I am trying to shut down adding the current as is.

---

The limitations as use-cases, instead of ""missing API"" are:

* ~Napari wants to show a numpy or cupy array that is will be updated in-place by the user.  It would be nice if it can inform the user when a function is not compatible with the input (i.e. the plot will never update if a copy was exported, confusing the user).~  EDIT: I misremembered the napari story.  Pytorch refused to do the copy, napari wanted to force a copy (signal that it is OK if a copy is made).  So, ""napari"" is not right, but we still decide that in-place modification (or viewing of mutable data) via DLPack import is discouraged (the user has to deal with the fact that it will not always work, a library that might want to do it can only document that fact).
* Vaex must copy the data, some algorithm would normally do a copy and work on that in-place.  But if it knows that the data was copied by Vaex during the export, it can skip the _additional_ copy of the data (for performance and not to blow up memory).
* JAX has immutable tensors, but if I do `np.ndarray.from_dlpack(jax_tensor)` what shouldl NumPy do?  If it came from Vaex, or anther library with writeable-view semantics, we can create a normal array view.  But if it is a JAX one, Numpy should either copy the data, or set the array to readonly.  Otherwise, the user might accidentally mutate the input array.
* The opposite: If JAX consumes a writeable-view semantics tensor from NumPy, it _must_ copy to ensure its content is actually immutable? Or does NumPy have to export a copy always (if the array is writeable)?
* Library B wraps a huge read-only memory mapped area and exports it with DLPack to NumPy.  Again, NumPy has to set the read-only flag or allow users to *crash the process* by accidentally writing to the array.

Now you did dismiss a few of these as user-problems, or just not relevant enough (i.e. don't use DLPack if you write in-place algorithms or like writeable-view semantics).  And the unnecessary copy is mitigated by Veax exposing a copy being uncommon, I guess?

But at least some still seem like (small?) user traps to me.  And ~it seems~ we have to at least always set the new array to read-only in NumPy or risk interpreter crashes if a truly readonly buffer is passed (EDIT: but yes the array-standard does mention that non-writing is preferred). So the ""no writeable-view"" actually becomes a hard requirement, rather than a soft preference).

Is adding one or two *bits* of information to DLPack on the table or are all of these small issues that we just want to live with?

---

And with that, sorry for a way too long post... || About the buffer protocol: You are right, I guess.  The buffer protocol has only the ""release function"". And that could be enough to allow deleting the original object, but it is not specified to be a valid. (By passing a new, different ""owner"" object out during buffer creation.  CPython's memoryviews would work with that happily, but NumPy doesn't.)

So yes, unlike DLPack, the buffer protocol doesn't _quite_ allow deleting the original exporting object. So maybe the ""release"" function is not a proper ""delete"" function in that sense. || > @rgommers, sorry if you feel I am just blocking your producitivity by making up moot issues and proposing changes to something that you have settled for yourself. Maybe I am late to the party, but maybe can I have a bit of time to think out loud? 

This is the thing - if you propose changes on this issue tracker, you're talking to others who then have to spend time responding to your proposals. It's different from ""thinking out loud"" (which I interpret as ""to clarify things for yourself""). For me the appropriate places to take notes or clarify things for myself are a piece of paper, a HackMD doc, my own fork, etc. - and then ask clarifying questions first rather than make new proposals immediately. The bandwidth differential we have (you're full-time on NumPy, I'm struggling to find enough time) makes the impact of that worse.

I think this is an important communication issue that comes up more often that I'd like. It'd be great if we could chat about it a little , maybe a call in the next few days - I'll ping you on Slack.

> And yes, I may have had the wrong impression that this API still could be modified more easily

The DLPack maintainers are quite responsive, and significant changes have already been made to DLPack itself (complex dtypes support, stream support, Python API, renaming struct fields for clarity, etc.). More changes, provided they fit in the DLPack design and have good rationales, are very welcome I'm sure. That said, it'd be great to get some experience with at least a prototype of the current design first - proposing changes not based on any experience with the protocol seems a little odd. || As annoying as it is to be on the receiving end of that, I have found that it has always been the case that the fault was mine, as the proposer. It's not your audience's fault that they weren't following all of your deliberations in real-time that would have shown how you worked out their problem cases. If it's not clearly laid out in the final proposal, it's a fair question. A ton of the PRNG design work went on in the [default `BitGenerator` mega-thread](https://github.com/numpy/numpy/issues/13635), but I'd never refer people back to it except to prove _that_ we did talk about something, not _what_ the answer is. If their question isn't explained on [`numpy.org`](https://numpy.org/doc/stable/reference/random/), then it's a fair one to ask and be answered.

Every new audience is a new discussion. You can short-circuit that discussion by drafting the proposal expansively and clearly. For whatever benefits the DLPack maintainers have gotten by keeping their RFCs strictly in Github issues, it does mean that there's no such document for you to use to forestall questions. || Thanks @rkern, that's all very fair. NEP 47, the array API docs and docs in the DLPack can all certainly be improved. 

> If it's not clearly laid out in the final proposal, it's a fair question.

Definitely, please ask those questions. Ask to see a PR first so you can play with it. And point out which are the important doc gaps to fill. It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal. || > It's simply kind of hard if that's mostly skipped over and we jump straight to an API extension proposal.

Agreed. There can be multiple reasons for the disconnect (the proposal isn't what you think it is, there's a disagreement about what the consequences of the proposal actually are, or there's a disagreement about whether the consequences are desirable). A counter-proposal is only appropriate once the disconnect is revealed, if not resolved.

AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.

```python
x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
y = numpy_dlpack.from_dlpack(some_other_array)
```

Such a prototype package would be useful in production in order to support older versions of numpy, regardless. It's not going to solve all use cases (you won't be able to write ""NEP 47-generic"" functions with it), but a number of use cases involving explicit conversions can be handled. A small third-party prototype will make the discussions concrete and even premature counter-proposals more tolerable to discuss. || First, replying to myself:

> Another thing is I seem to recall we agreed in a Array API meeting that if copy is needed, it's best for the user to handle it explicitly. I can try to look up a note on this later.

- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#design-topics-data-interchange--page-root) we said ""Zero-copy semantics where possible, making a copy only if needed (e.g. when data is not contiguous in memory). Rationale: performance.""
- [Here](https://data-apis.org/array-api/latest/design_topics/data_interchange.html#semantics) we said ""If an array that is accessed via the interchange protocol lives on a device that the requesting library does not support, it is recommended to raise a TypeError""
- [Here](https://github.com/data-apis/array-api/pull/106#issuecomment-759735186) we said the host-device copy is disfavored.

I think it's clear that host-device transfer should raise in NumPy's case. Now, let me move to Robert's above reply:

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Can we please not do this outside NumPy? Two reasons:
1. It is a very small pair of functions (`to_dlpack`/`from_dlpack`) that have been implemented in virtually all other major libraries as far as NEP 47 / Array API is concerned, including CuPy / PyTorch / TensorFlow and JAX. Apart from the deleter behavior which no one got it right in the first shot AFAIK, it actually works ok with little user complaints. I think PyTorch supports CPU tensors so I would recommend to peek at their implementation to see how they handle the CPU-GPU case. Otherwise, it is fairly straightforward to support.
2. @rkern you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result... || No, I saw that. But it's not essential for a prototype that can help work out some of the other details. I'm not saying you should maintain it forever (though it could be useful for working with current versions of numpy). It's noticeably easier to build and evaluate a small prototype package than it is to build and evaluate a branch of numpy, especially if what I want to test is how it relates to other packages, which have their own dependencies on versions of numpy. || I've only skimmed the conversation here, so apologies in advance if I'm repeating things

https://github.com/numpy/numpy/issues/19013#issuecomment-841881506 says

> AFAICT, there's nothing that prevents a prototype from being made outside of numpy first. There might just be a little wrapper object in the way until support lands in a release of numpy.
> 
> ```python
> x = other_array.from_dlpack(numpy_dlpack.to_dlpack(some_ndarray))
> y = numpy_dlpack.from_dlpack(some_other_array)
> ```

Are there technical reasons that we can't go through a PEP3118 `memoryview` as an intermediary?

```python
some_buffer = memoryview(some_ndarray)
x = other_array.from_dlpack(pep3118_dlpack.to_dlpack(some_buffer))
y_buffer = pep3118_dlpack.from_dlpack(some_other_array)
y = np.array(y_buffer)
```

That is, could a `pep3118_dlpack` library be written that provides _all_ object supporting PEP3118 with dlpack support, not just `np.ndarray`? Or is it impossible to write `pep3118_dlpack.to_dlpack` and `pep3118_dlpack.from_dlpack` correctly? || @eric-wieser I believe the answer is in https://github.com/numpy/numpy/issues/19013#issuecomment-843735344, 

> you missed that NEP 47 / Array API actually does not suggest to implement `to_dlpack()`, only `__dlpack__` + `__dlpack_device__` + `from_dlpack()`. The dunder methods must live in NumPy as a result...

 || My questions is more along the lines of ""is it possible to 'smuggle' simple `memoryview`s through the dlpack interface and vice versa"", and less about exactly what the conventions around the python API might look like - so I don't think that answers my question. || > Or is it impossible to write pep3118_dlpack.to_dlpack and pep3118_dlpack.from_dlpack correctly?

The feature set is a bit disjunct: the buffer-protocol supports much more, but doesn't support devices, but I don't think that is what you mean?

If there was a `dlpack.DLPackManagedTensor` library, then yeah... NumPy could effectively import that and use `DLPackManagedTensor.from_buffer()` and `memoryview(DLPAckManagedTensor)`  (I am assuming `DLPackManagedTensor` would implement the buffer protocol).

I am not sure the indirection is useful enough?  Hopefully DLPack is just so simple that it doesn't matter too much?   Effectively, NumPy would/could be exactly that library (although not the most elegant implementation)!  As far as I can tell NumPy supports the full set of features that is supported by _both_ DLPack and Memoryview.",closed,2021-05-14T07:43:15+00:00,2021-11-09T19:18:57+00:00,hameerabbasi,"01 - Enhancement, component: numpy._core",1,"PR#19083 - doc/neps/nep-0047-array-api-standard.rst: @@ -338,9 +338,10 @@ the options already present in NumPy are:|;| |;| Adding support for DLPack to NumPy entails:|;| |;|-- Adding a ``ndarray.__dlpack__`` method.|;|-- Adding a ``from_dlpack`` function, which takes as input an object|;|-  supporting ``__dlpack__``, and returns an ``ndarray``.|;|+- Adding a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C|;|+  structure wrapped in a ``PyCapsule``.|;|+- Adding a ``np._from_dlpack(obj)`` function, where ``obj`` supports|;|+  ``__dlpack__()``, and returns an ``ndarray``.|;| |;| DLPack is currently a ~200 LoC header, and is meant to be included directly, so|;| no external dependency is needed. Implementation should be straightforward. || PR#19083 - doc/release/upcoming_changes/19083.new_feature.rst: @@ -0,0 +1,6 @@|;|+Add NEP 47-compatible dlpack support|;|+------------------------------------|;|+|;|+Add a ``ndarray.__dlpack__()`` method which returns a ``dlpack`` C structure|;|+wrapped in a ``PyCapsule``. Also add a ``np._from_dlpack(obj)`` function, where|;|+``obj`` supports ``__dlpack__()``, and returns an ``ndarray``. || PR#19083 - numpy/__init__.pyi: @@ -1413,6 +1413,7 @@ _SupportsBuffer = Union[|;| |;| _T = TypeVar(""_T"")|;| _T_co = TypeVar(""_T_co"", covariant=True)|;|+_T_contra = TypeVar(""_T_contra"", contravariant=True)|;| _2Tuple = Tuple[_T, _T]|;| _CastingKind = L[""no"", ""equiv"", ""safe"", ""same_kind"", ""unsafe""]|;| |;|@@ -1432,6 +1433,10 @@ _ArrayTD64_co = NDArray[Union[bool_, integer[Any], timedelta64]]|;| # Introduce an alias for `dtype` to avoid naming conflicts.|;| _dtype = dtype|;| |;|+# `builtins.PyCapsule` unfortunately lacks annotations as of the moment|;|;+# use `Any` as a stopgap measure|;|+_PyCapsule = Any|;|+|;| class _SupportsItem(Protocol[_T_co]):|;|     def item(self, args: Any, /) -> _T_co: ...|;| |;|@@ -2439,6 +2444,12 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeType, _DType_co]):|;|     def __ior__(self: NDArray[signedinteger[_NBit1]], other: _ArrayLikeInt_co) -> NDArray[signedinteger[_NBit1]]: ...|;|     @overload|;|     def __ior__(self: NDArray[object_], other: Any) -> NDArray[object_]: ...|;|+    @overload|;|+    def __ior__(self: NDArray[_ScalarType], other: _RecursiveSequence) -> NDArray[_ScalarType]: ...|;|+    @overload|;|+    def __dlpack__(self: NDArray[number[Any]], *, stream: None = ...) -> _PyCapsule: ...|;|+    @overload|;|+    def __dlpack_device__(self) -> Tuple[int, L[0]]: ...|;| |;|     # Keep `dtype` at the bottom to avoid name conflicts with `np.dtype`|;|     @property|;|@@ -4320,3 +4331,9 @@ class chararray(ndarray[_ShapeType, _CharDType]):|;| |;| # NOTE: Deprecated|;| # class MachAr: ...|;|+|;|+class _SupportsDLPack(Protocol[_T_contra]):|;|+    def __dlpack__(self, *, stream: None | _T_contra = ...) -> _PyCapsule: ...|;|+|;|+def _from_dlpack(__obj: _SupportsDLPack[None]) -> NDArray[Any]: ...|;|+ || PR#19083 - numpy/array_api/__init__.py: @@ -136,7 +136,7 @@|;|     empty,|;|     empty_like,|;|     eye,|;|-    from_dlpack,|;|+    _from_dlpack,|;|     full,|;|     full_like,|;|     linspace,|;|@@ -155,7 +155,7 @@|;|     ""empty"",|;|     ""empty_like"",|;|     ""eye"",|;|-    ""from_dlpack"",|;|+    ""_from_dlpack"",|;|     ""full"",|;|     ""full_like"",|;|     ""linspace"", || PR#19083 - numpy/array_api/_creation_functions.py: @@ -151,7 +151,7 @@ def eye(|;|     return Array._new(np.eye(n_rows, M=n_cols, k=k, dtype=dtype))|;| |;| |;|-def from_dlpack(x: object, /) -> Array:|;|+def _from_dlpack(x: object, /) -> Array:|;|     # Note: dlpack support is not yet implemented on Array|;|     raise NotImplementedError(""DLPack support is not yet implemented"")|;|  || PR#19083 - numpy/core/_add_newdocs.py: @@ -1573,6 +1573,19 @@|;|         array_function_like_doc,|;|     ))|;| |;|+add_newdoc('numpy.core.multiarray', '_from_dlpack',|;|+    """"""|;|+    _from_dlpack(x, /)|;|+|;|+    Create a NumPy array from an object implementing the ``__dlpack__``|;|+    protocol.|;|+|;|+    See Also|;|+    --------|;|+    `Array API documentation|;|+    <https://data-apis.org/array-api/latest/design_topics/data_interchange.html#syntax-for-data-interchange-with-dlpack>`_|;|+    """""")|;|+|;| add_newdoc('numpy.core', 'fastCopyAndTranspose',|;|     """"""_fastCopyAndTranspose(a)"""""")|;| |;|@@ -2263,6 +2276,15 @@|;| add_newdoc('numpy.core.multiarray', 'ndarray', ('__array_struct__',|;|     """"""Array protocol: C-struct side.""""""))|;| |;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack__',|;|+    """"""a.__dlpack__(*, stream=None)|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;|+|;|+add_newdoc('numpy.core.multiarray', 'ndarray', ('__dlpack_device__',|;|+    """"""a.__dlpack_device__()|;|+    |;|+    DLPack Protocol: Part of the Array API.""""""))|;| |;| add_newdoc('numpy.core.multiarray', 'ndarray', ('base',|;|     """""" || PR#19083 - numpy/core/code_generators/genapi.py: @@ -41,6 +41,7 @@|;|              join('multiarray', 'datetime_busdaycal.c'),|;|              join('multiarray', 'datetime_strings.c'),|;|              join('multiarray', 'descriptor.c'),|;|+             join('multiarray', 'dlpack.c'),|;|              join('multiarray', 'dtypemeta.c'),|;|              join('multiarray', 'einsum.c.src'),|;|              join('multiarray', 'flagsobject.c'), || PR#19083 - numpy/core/multiarray.py: @@ -14,27 +14,28 @@|;| # do not change them. issue gh-15518|;| # _get_ndarray_c_version is semi-public, on purpose not added to __all__|;| from ._multiarray_umath import (|;|-    _fastCopyAndTranspose, _flagdict, _insert, _reconstruct, _vec_string,|;|-    _ARRAY_API, _monotonicity, _get_ndarray_c_version, _set_madvise_hugepage,|;|+    _fastCopyAndTranspose, _flagdict, _from_dlpack, _insert, _reconstruct,|;|+    _vec_string, _ARRAY_API, _monotonicity, _get_ndarray_c_version,|;|+    _set_madvise_hugepage,|;|     )|;| |;| __all__ = [|;|     '_ARRAY_API', 'ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'DATETIMEUNITS',|;|     'ITEM_HASOBJECT', 'ITEM_IS_POINTER', 'LIST_PICKLE', 'MAXDIMS',|;|     'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'NEEDS_INIT', 'NEEDS_PYAPI',|;|     'RAISE', 'USE_GETITEM', 'USE_SETITEM', 'WRAP', '_fastCopyAndTranspose',|;|-    '_flagdict', '_insert', '_reconstruct', '_vec_string', '_monotonicity',|;|-    'add_docstring', 'arange', 'array', 'asarray', 'asanyarray',|;|-    'ascontiguousarray', 'asfortranarray', 'bincount', 'broadcast',|;|-    'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|+    '_flagdict', '_from_dlpack', '_insert', '_reconstruct', '_vec_string',|;|+    '_monotonicity', 'add_docstring', 'arange', 'array', 'asarray',|;|+    'asanyarray', 'ascontiguousarray', 'asfortranarray', 'bincount',|;|+    'broadcast', 'busday_count', 'busday_offset', 'busdaycalendar', 'can_cast',|;|     'compare_chararrays', 'concatenate', 'copyto', 'correlate', 'correlate2',|;|     'count_nonzero', 'c_einsum', 'datetime_as_string', 'datetime_data',|;|     'dot', 'dragon4_positional', 'dragon4_scientific', 'dtype',|;|     'empty', 'empty_like', 'error', 'flagsobj', 'flatiter', 'format_longfloat',|;|-    'frombuffer', 'fromfile', 'fromiter', 'fromstring', 'get_handler_name',|;|-    'inner', 'interp', 'interp_complex', 'is_busday', 'lexsort',|;|-    'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray', 'nditer',|;|-    'nested_iters', 'normalize_axis_index', 'packbits',|;|+    'frombuffer', 'fromfile', 'fromiter', 'fromstring',|;|+    'get_handler_name', 'inner', 'interp', 'interp_complex', 'is_busday',|;|+    'lexsort', 'matmul', 'may_share_memory', 'min_scalar_type', 'ndarray',|;|+    'nditer', 'nested_iters', 'normalize_axis_index', 'packbits',|;|     'promote_types', 'putmask', 'ravel_multi_index', 'result_type', 'scalar',|;|     'set_datetimeparse_function', 'set_legacy_print_mode', 'set_numeric_ops',|;|     'set_string_function', 'set_typeDict', 'shares_memory',|;|@@ -46,6 +47,7 @@|;| scalar.__module__ = 'numpy.core.multiarray'|;| |;| |;|+_from_dlpack.__module__ = 'numpy'|;| arange.__module__ = 'numpy'|;| array.__module__ = 'numpy'|;| asarray.__module__ = 'numpy' || PR#19083 - numpy/core/numeric.py: @@ -13,8 +13,8 @@|;|     WRAP, arange, array, asarray, asanyarray, ascontiguousarray,|;|     asfortranarray, broadcast, can_cast, compare_chararrays,|;|     concatenate, copyto, dot, dtype, empty,|;|-    empty_like, flatiter, frombuffer, fromfile, fromiter, fromstring,|;|-    inner, lexsort, matmul, may_share_memory,|;|+    empty_like, flatiter, frombuffer, _from_dlpack, fromfile, fromiter,|;|+    fromstring, inner, lexsort, matmul, may_share_memory,|;|     min_scalar_type, ndarray, nditer, nested_iters, promote_types,|;|     putmask, result_type, set_numeric_ops, shares_memory, vdot, where,|;|     zeros, normalize_axis_index)|;|@@ -41,7 +41,7 @@|;|     'newaxis', 'ndarray', 'flatiter', 'nditer', 'nested_iters', 'ufunc',|;|     'arange', 'array', 'asarray', 'asanyarray', 'ascontiguousarray',|;|     'asfortranarray', 'zeros', 'count_nonzero', 'empty', 'broadcast', 'dtype',|;|-    'fromstring', 'fromfile', 'frombuffer', 'where',|;|+    'fromstring', 'fromfile', 'frombuffer', '_from_dlpack', 'where',|;|     'argwhere', 'copyto', 'concatenate', 'fastCopyAndTranspose', 'lexsort',|;|     'set_numeric_ops', 'can_cast', 'promote_types', 'min_scalar_type',|;|     'result_type', 'isfortran', 'empty_like', 'zeros_like', 'ones_like', || PR#19083 - numpy/core/setup.py: @@ -740,6 +740,7 @@ def gl_if_msvc(build_cmd):|;|     #######################################################################|;| |;|     common_deps = [|;|+            join('src', 'common', 'dlpack', 'dlpack.h'),|;|             join('src', 'common', 'array_assign.h'),|;|             join('src', 'common', 'binop_override.h'),|;|             join('src', 'common', 'cblasfuncs.h'),|;|@@ -749,6 +750,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'common', 'npy_cblas.h'),|;|             join('src', 'common', 'npy_config.h'),|;|             join('src', 'common', 'npy_ctypes.h'),|;|+            join('src', 'common', 'npy_dlpack.h'),|;|             join('src', 'common', 'npy_extint128.h'),|;|             join('src', 'common', 'npy_import.h'),|;|             join('src', 'common', 'npy_hashtable.h'),|;|@@ -881,6 +883,7 @@ def gl_if_msvc(build_cmd):|;|             join('src', 'multiarray', 'datetime_busday.c'),|;|             join('src', 'multiarray', 'datetime_busdaycal.c'),|;|             join('src', 'multiarray', 'descriptor.c'),|;|+            join('src', 'multiarray', 'dlpack.c'),|;|             join('src', 'multiarray', 'dtypemeta.c'),|;|             join('src', 'multiarray', 'dragon4.c'),|;|             join('src', 'multiarray', 'dtype_transfer.c'), || PR#19083 - numpy/core/src/common/dlpack/dlpack.h: @@ -0,0 +1,201 @@|;|+// Taken from:|;|+// https://github.com/dmlc/dlpack/blob/9b6176fdecb55e9bf39b16f08b96913ed3f275b4/include/dlpack/dlpack.h|;|+/*!|;|+ *  Copyright (c) 2017 by Contributors|;|+ * \file dlpack.h|;|+ * \brief The common header of DLPack.|;|+ */|;|+#ifndef DLPACK_DLPACK_H_|;|+#define DLPACK_DLPACK_H_|;|+|;|+#ifdef __cplusplus|;|+#define DLPACK_EXTERN_C extern ""C""|;|+#else|;|+#define DLPACK_EXTERN_C|;|+#endif|;|+|;|+/*! \brief The current version of dlpack */|;|+#define DLPACK_VERSION 050|;|+|;|+/*! \brief DLPACK_DLL prefix for windows */|;|+#ifdef _WIN32|;|+#ifdef DLPACK_EXPORTS|;|+#define DLPACK_DLL __declspec(dllexport)|;|+#else|;|+#define DLPACK_DLL __declspec(dllimport)|;|+#endif|;|+#else|;|+#define DLPACK_DLL|;|+#endif|;|+|;|+#include <stdint.h>|;|+#include <stddef.h>|;|+|;|+#ifdef __cplusplus|;|+extern ""C"" {|;|+#endif|;|+/*!|;|+ * \brief The device type in DLDevice.|;|+ */|;|+typedef enum {|;|+  /*! \brief CPU device */|;|+  kDLCPU = 1,|;|+  /*! \brief CUDA GPU device */|;|+  kDLCUDA = 2,|;|+  /*!|;|+   * \brief Pinned CUDA CPU memory by cudaMallocHost|;|+   */|;|+  kDLCUDAHost = 3,|;|+  /*! \brief OpenCL devices. */|;|+  kDLOpenCL = 4,|;|+  /*! \brief Vulkan buffer for next generation graphics. */|;|+  kDLVulkan = 7,|;|+  /*! \brief Metal for Apple GPU. */|;|+  kDLMetal = 8,|;|+  /*! \brief Verilog simulator buffer */|;|+  kDLVPI = 9,|;|+  /*! \brief ROCm GPUs for AMD GPUs */|;|+  kDLROCM = 10,|;|+  /*!|;|+   * \brief Pinned ROCm CPU memory allocated by hipMallocHost|;|+   */|;|+  kDLROCMHost = 11,|;|+  /*!|;|+   * \brief Reserved extension device type,|;|+   * used for quickly test extension device|;|+   * The semantics can differ depending on the implementation.|;|+   */|;|+  kDLExtDev = 12,|;|+  /*!|;|+   * \brief CUDA managed/unified memory allocated by cudaMallocManaged|;|+   */|;|+  kDLCUDAManaged = 13,|;|+} DLDeviceType|;|;+|;|+/*!|;|+ * \brief A Device for Tensor and operator.|;|+ */|;|+typedef struct {|;|+  /*! \brief The device type used in the device. */|;|+  DLDeviceType device_type|;|;+  /*!|;|+   * \brief The device index.|;|+   * For vanilla CPU memory, pinned memory, or managed memory, this is set to 0.|;|+   */|;|+  int device_id|;|;+} DLDevice|;|;+|;|+/*!|;|+ * \brief The type code options DLDataType.|;|+ */|;|+typedef enum {|;|+  /*! \brief signed integer */|;|+  kDLInt = 0U,|;|+  /*! \brief unsigned integer */|;|+  kDLUInt = 1U,|;|+  /*! \brief IEEE floating point */|;|+  kDLFloat = 2U,|;|+  /*!|;|+   * \brief Opaque handle type, reserved for testing purposes.|;|+   * Frameworks need to agree on the handle data type for the exchange to be well-defined.|;|+   */|;|+  kDLOpaqueHandle = 3U,|;|+  /*! \brief bfloat16 */|;|+  kDLBfloat = 4U,|;|+  /*!|;|+   * \brief complex number|;|+   * (C/C++/Python layout: compact struct per complex number)|;|+   */|;|+  kDLComplex = 5U,|;|+} DLDataTypeCode|;|;+|;|+/*!|;|+ * \brief The data type the tensor can hold.|;|+ *|;|+ *  Examples|;|+ *   - float: type_code = 2, bits = 32, lanes=1|;|+ *   - float4(vectorized 4 float): type_code = 2, bits = 32, lanes=4|;|+ *   - int8: type_code = 0, bits = 8, lanes=1|;|+ *   - std::complex<float>: type_code = 5, bits = 64, lanes = 1|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief Type code of base types.|;|+   * We keep it uint8_t instead of DLDataTypeCode for minimal memory|;|+   * footprint, but the value should be one of DLDataTypeCode enum values.|;|+   * */|;|+  uint8_t code|;|;+  /*!|;|+   * \brief Number of bits, common choices are 8, 16, 32.|;|+   */|;|+  uint8_t bits|;|;+  /*! \brief Number of lanes in the type, used for vector types. */|;|+  uint16_t lanes|;|;+} DLDataType|;|;+|;|+/*!|;|+ * \brief Plain C Tensor object, does not manage memory.|;|+ */|;|+typedef struct {|;|+  /*!|;|+   * \brief The opaque data pointer points to the allocated data. This will be|;|+   * CUDA device pointer or cl_mem handle in OpenCL. This pointer is always|;|+   * aligned to 256 bytes as in CUDA.|;|+   *|;|+   * For given DLTensor, the size of memory required to store the contents of|;|+   * data is calculated as follows:|;|+   *|;|+   * \code{.c}|;|+   * static inline size_t GetDataSize(const DLTensor* t) {|;|+   *   size_t size = 1|;|;+   *   for (tvm_index_t i = 0; i < t->ndim; ++i) {|;|+   *     size *= t->shape[i]|;|;+   *   }|;|+   *   size *= (t->dtype.bits * t->dtype.lanes + 7) / 8|;|;+   *   return size|;|;+   * }|;|+   * \endcode|;|+   */|;|+  void* data|;|;+  /*! \brief The device of the tensor */|;|+  DLDevice device|;|;+  /*! \brief Number of dimensions */|;|+  int ndim|;|;+  /*! \brief The data type of the pointer*/|;|+  DLDataType dtype|;|;+  /*! \brief The shape of the tensor */|;|+  int64_t* shape|;|;+  /*!|;|+   * \brief strides of the tensor (in number of elements, not bytes)|;|+   *  can be NULL, indicating tensor is compact and row-majored.|;|+   */|;|+  int64_t* strides|;|;+  /*! \brief The offset in bytes to the beginning pointer to data */|;|+  uint64_t byte_offset|;|;+} DLTensor|;|;+|;|+/*!|;|+ * \brief C Tensor object, manage memory of DLTensor. This data structure is|;|+ *  intended to facilitate the borrowing of DLTensor by another framework. It is|;|+ *  not meant to transfer the tensor. When the borrowing framework doesn't need|;|+ *  the tensor, it should call the deleter to notify the host that the resource|;|+ *  is no longer needed.|;|+ */|;|+typedef struct DLManagedTensor {|;|+  /*! \brief DLTensor which is being memory managed */|;|+  DLTensor dl_tensor|;|;+  /*! \brief the context of the original host framework of DLManagedTensor in|;|+   *   which DLManagedTensor is used in the framework. It can also be NULL.|;|+   */|;|+  void * manager_ctx|;|;+  /*! \brief Destructor signature void (*)(void*) - this should be called|;|+   *   to destruct manager_ctx which holds the DLManagedTensor. It can be NULL|;|+   *   if there is no way for the caller to provide a reasonable destructor.|;|+   *   The destructors deletes the argument self as well.|;|+   */|;|+  void (*deleter)(struct DLManagedTensor * self)|;|;+} DLManagedTensor|;|;+#ifdef __cplusplus|;|+}  // DLPACK_EXTERN_C|;|+#endif|;|+#endif  // DLPACK_DLPACK_H_ || PR#19083 - numpy/core/src/common/npy_dlpack.h: @@ -0,0 +1,28 @@|;|+#include ""Python.h""|;|+#include ""dlpack/dlpack.h""|;|+|;|+#ifndef NPY_DLPACK_H|;|+#define NPY_DLPACK_H|;|+|;|+// Part of the Array API specification.|;|+#define NPY_DLPACK_CAPSULE_NAME ""dltensor""|;|+#define NPY_DLPACK_USED_CAPSULE_NAME ""used_dltensor""|;|+|;|+// Used internally by NumPy to store a base object|;|+// as it has to release a reference to the original|;|+// capsule.|;|+#define NPY_DLPACK_INTERNAL_CAPSULE_NAME ""numpy_dltensor""|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self, PyObject *const *args, Py_ssize_t len_args,|;|+             PyObject *kwnames)|;|;+|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|;+|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj)|;|;+|;|+#endif || PR#19083 - numpy/core/src/multiarray/dlpack.c: @@ -0,0 +1,408 @@|;|+#define NPY_NO_DEPRECATED_API NPY_API_VERSION|;|+#define _MULTIARRAYMODULE|;|+|;|+#define PY_SSIZE_T_CLEAN|;|+#include <Python.h>|;|+#include <dlpack/dlpack.h>|;|+|;|+#include ""numpy/arrayobject.h""|;|+#include ""common/npy_argparse.h""|;|+|;|+#include ""common/dlpack/dlpack.h""|;|+#include ""common/npy_dlpack.h""|;|+|;|+static void|;|+array_dlpack_deleter(DLManagedTensor *self)|;|+{|;|+    PyArrayObject *array = (PyArrayObject *)self->manager_ctx|;|;+    // This will also free the strides as it's one allocation.|;|+    PyMem_Free(self->dl_tensor.shape)|;|;+    PyMem_Free(self)|;|;+    Py_XDECREF(array)|;|;+}|;|+|;|+/* This is exactly as mandated by dlpack */|;|+static void dlpack_capsule_deleter(PyObject *self) {|;|+    if (PyCapsule_IsValid(self, NPY_DLPACK_USED_CAPSULE_NAME)) {|;|+        return|;|;+    }|;|+|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+/* used internally, almost identical to dlpack_capsule_deleter() */|;|+static void array_dlpack_internal_capsule_deleter(PyObject *self)|;|+{|;|+    /* an exception may be in-flight, we must save it in case we create another one */|;|+    PyObject *type, *value, *traceback|;|;+    PyErr_Fetch(&type, &value, &traceback)|;|;+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(self, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+    if (managed == NULL) {|;|+        PyErr_WriteUnraisable(self)|;|;+        goto done|;|;+    }|;|+    /*|;|+     *  the spec says the deleter can be NULL if there is no way for the caller|;|+     * to provide a reasonable destructor.|;|+     */|;|+    if (managed->deleter) {|;|+        managed->deleter(managed)|;|;+        /* TODO: is the deleter allowed to set a python exception? */|;|+        assert(!PyErr_Occurred())|;|;+    }|;|+|;|+done:|;|+    PyErr_Restore(type, value, traceback)|;|;+}|;|+|;|+|;|+// This function cannot return NULL, but it can fail,|;|+// So call PyErr_Occurred to check if it failed after|;|+// calling it.|;|+static DLDevice|;|+array_get_dl_device(PyArrayObject *self) {|;|+    DLDevice ret|;|;+    ret.device_type = kDLCPU|;|;+    ret.device_id = 0|;|;+    PyObject *base = PyArray_BASE(self)|;|;+    // The outer if is due to the fact that NumPy arrays are on the CPU|;|+    // by default (if not created from DLPack).|;|+    if (PyCapsule_IsValid(base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)) {|;|+        DLManagedTensor *managed = PyCapsule_GetPointer(|;|+                base, NPY_DLPACK_INTERNAL_CAPSULE_NAME)|;|;+        if (managed == NULL) {|;|+            return ret|;|;+        }|;|+        return managed->dl_tensor.device|;|;+    }|;|+    return ret|;|;+}|;|+|;|+|;|+PyObject *|;|+array_dlpack(PyArrayObject *self,|;|+        PyObject *const *args, Py_ssize_t len_args, PyObject *kwnames)|;|+{|;|+    PyObject *stream = Py_None|;|;+    NPY_PREPARE_ARGPARSER|;|;+    if (npy_parse_arguments(""__dlpack__"", args, len_args, kwnames,|;|+            ""$stream"", NULL, &stream, NULL, NULL, NULL)) {|;|+        return NULL|;|;+    }|;|+|;|+    if (stream != Py_None) {|;|+        PyErr_SetString(PyExc_RuntimeError, ""NumPy only supports ""|;|+                ""stream=None."")|;|;+        return NULL|;|;+    }|;|+|;|+    if ( !(PyArray_FLAGS(self) & NPY_ARRAY_WRITEABLE)) {|;|+        PyErr_SetString(PyExc_TypeError, ""NumPy currently only supports ""|;|+                ""dlpack for writeable arrays"")|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp itemsize = PyArray_ITEMSIZE(self)|;|;+    int ndim = PyArray_NDIM(self)|;|;+    npy_intp *strides = PyArray_STRIDES(self)|;|;+    npy_intp *shape = PyArray_SHAPE(self)|;|;+|;|+    if (!PyArray_IS_C_CONTIGUOUS(self) && PyArray_SIZE(self) != 1) {|;|+        for (int i = 0; i < ndim; ++i) {|;|+            if (strides[i] % itemsize != 0) {|;|+                PyErr_SetString(PyExc_RuntimeError,|;|+                        ""DLPack only supports strides which are a multiple of ""|;|+                        ""itemsize."")|;|;+                return NULL|;|;+            }|;|+        }|;|+    }|;|+|;|+    DLDataType managed_dtype|;|;+    PyArray_Descr *dtype = PyArray_DESCR(self)|;|;+|;|+    if (PyDataType_ISBYTESWAPPED(dtype)) {|;|+        PyErr_SetString(PyExc_TypeError, ""DLPack only supports native ""|;|+                    ""byte swapping."")|;|;+            return NULL|;|;+    }|;|+|;|+    managed_dtype.bits = 8 * itemsize|;|;+    managed_dtype.lanes = 1|;|;+|;|+    if (PyDataType_ISSIGNED(dtype)) {|;|+        managed_dtype.code = kDLInt|;|;+    }|;|+    else if (PyDataType_ISUNSIGNED(dtype)) {|;|+        managed_dtype.code = kDLUInt|;|;+    }|;|+    else if (PyDataType_ISFLOAT(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 8) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""floating point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLFloat|;|;+    }|;|+    else if (PyDataType_ISCOMPLEX(dtype)) {|;|+        // We can't be sure that the dtype is|;|+        // IEEE or padded.|;|+        if (itemsize > 16) {|;|+            PyErr_SetString(PyExc_TypeError, ""DLPack only supports IEEE ""|;|+                    ""complex point types without padding."")|;|;+            return NULL|;|;+        }|;|+        managed_dtype.code = kDLComplex|;|;+    }|;|+    else {|;|+        PyErr_SetString(PyExc_TypeError,|;|+                        ""DLPack only supports signed/unsigned integers, float ""|;|+                        ""and complex dtypes."")|;|;+        return NULL|;|;+    }|;|+|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed = PyMem_Malloc(sizeof(DLManagedTensor))|;|;+    if (managed == NULL) {|;|+        PyErr_NoMemory()|;|;+        return NULL|;|;+    }|;|+|;|+    /*|;|+     * Note: the `dlpack.h` header suggests/standardizes that `data` must be|;|+     * 256-byte aligned.  We ignore this intentionally, because `__dlpack__`|;|+     * standardizes that `byte_offset` must be 0 (for now) to not break pytorch:|;|+     * https://github.com/data-apis/array-api/issues/293#issuecomment-964111413|;|+     *|;|+     * We further assume that exporting fully unaligned data is OK even without|;|+     * `byte_offset` since the standard does not reject it.|;|+     * Presumably, pytorch will support importing `byte_offset != 0` and NumPy|;|+     * can choose to use it starting about 2023.  At that point, it may be|;|+     * that NumPy MUST use `byte_offset` to adhere to the standard (as|;|+     * specified in the header)!|;|+     */|;|+    managed->dl_tensor.data = PyArray_DATA(self)|;|;+    managed->dl_tensor.byte_offset = 0|;|;+    managed->dl_tensor.device = device|;|;+    managed->dl_tensor.dtype = managed_dtype|;|;+|;|+    int64_t *managed_shape_strides = PyMem_Malloc(sizeof(int64_t) * ndim * 2)|;|;+    if (managed_shape_strides == NULL) {|;|+        PyErr_NoMemory()|;|;+        PyMem_Free(managed)|;|;+        return NULL|;|;+    }|;|+|;|+    int64_t *managed_shape = managed_shape_strides|;|;+    int64_t *managed_strides = managed_shape_strides + ndim|;|;+    for (int i = 0; i < ndim; ++i) {|;|+        managed_shape[i] = shape[i]|;|;+        // Strides in DLPack are items; in NumPy are bytes.|;|+        managed_strides[i] = strides[i] / itemsize|;|;+    }|;|+|;|+    managed->dl_tensor.ndim = ndim|;|;+    managed->dl_tensor.shape = managed_shape|;|;+    managed->dl_tensor.strides = NULL|;|;+    if (PyArray_SIZE(self) != 1 && !PyArray_IS_C_CONTIGUOUS(self)) {|;|+        managed->dl_tensor.strides = managed_strides|;|;+    }|;|+    managed->dl_tensor.byte_offset = 0|;|;+    managed->manager_ctx = self|;|;+    managed->deleter = array_dlpack_deleter|;|;+|;|+    PyObject *capsule = PyCapsule_New(managed, NPY_DLPACK_CAPSULE_NAME,|;|+            dlpack_capsule_deleter)|;|;+    if (capsule == NULL) {|;|+        PyMem_Free(managed)|;|;+        PyMem_Free(managed_shape_strides)|;|;+        return NULL|;|;+    }|;|+|;|+    // the capsule holds a reference|;|+    Py_INCREF(self)|;|;+    return capsule|;|;+}|;|+|;|+PyObject *|;|+array_dlpack_device(PyArrayObject *self, PyObject *NPY_UNUSED(args))|;|+{|;|+    DLDevice device = array_get_dl_device(self)|;|;+    if (PyErr_Occurred()) {|;|+        return NULL|;|;+    }|;|+    return Py_BuildValue(""ii"", device.device_type, device.device_id)|;|;+}|;|+|;|+NPY_NO_EXPORT PyObject *|;|+_from_dlpack(PyObject *NPY_UNUSED(self), PyObject *obj) {|;|+    PyObject *capsule = PyObject_CallMethod((PyObject *)obj->ob_type,|;|+            ""__dlpack__"", ""O"", obj)|;|;+    if (capsule == NULL) {|;|+        return NULL|;|;+    }|;|+|;|+    DLManagedTensor *managed =|;|+        (DLManagedTensor *)PyCapsule_GetPointer(capsule,|;|+        NPY_DLPACK_CAPSULE_NAME)|;|;+|;|+    if (managed == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    const int ndim = managed->dl_tensor.ndim|;|;+    if (ndim > NPY_MAXDIMS) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""maxdims of DLPack tensor is higher than the supported ""|;|+                ""maxdims."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    DLDeviceType device_type = managed->dl_tensor.device.device_type|;|;+    if (device_type != kDLCPU &&|;|+            device_type != kDLCUDAHost &&|;|+            device_type != kDLROCMHost &&|;|+            device_type != kDLCUDAManaged) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported device in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    if (managed->dl_tensor.dtype.lanes != 1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported lanes in DLTensor dtype."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    int typenum = -1|;|;+    const uint8_t bits = managed->dl_tensor.dtype.bits|;|;+    const npy_intp itemsize = bits / 8|;|;+    switch (managed->dl_tensor.dtype.code) {|;|+    case kDLInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_INT8; break|;|;+            case 16: typenum = NPY_INT16; break|;|;+            case 32: typenum = NPY_INT32; break|;|;+            case 64: typenum = NPY_INT64; break|;|;+        }|;|+        break|;|;+    case kDLUInt:|;|+        switch (bits)|;|+        {|;|+            case 8: typenum = NPY_UINT8; break|;|;+            case 16: typenum = NPY_UINT16; break|;|;+            case 32: typenum = NPY_UINT32; break|;|;+            case 64: typenum = NPY_UINT64; break|;|;+        }|;|+        break|;|;+    case kDLFloat:|;|+        switch (bits)|;|+        {|;|+            case 16: typenum = NPY_FLOAT16; break|;|;+            case 32: typenum = NPY_FLOAT32; break|;|;+            case 64: typenum = NPY_FLOAT64; break|;|;+        }|;|+        break|;|;+    case kDLComplex:|;|+        switch (bits)|;|+        {|;|+            case 64: typenum = NPY_COMPLEX64; break|;|;+            case 128: typenum = NPY_COMPLEX128; break|;|;+        }|;|+        break|;|;+    }|;|+|;|+    if (typenum == -1) {|;|+        PyErr_SetString(PyExc_RuntimeError,|;|+                ""Unsupported dtype in DLTensor."")|;|;+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    npy_intp shape[NPY_MAXDIMS]|;|;+    npy_intp strides[NPY_MAXDIMS]|;|;+|;|+    for (int i = 0; i < ndim; ++i) {|;|+        shape[i] = managed->dl_tensor.shape[i]|;|;+        // DLPack has elements as stride units, NumPy has bytes.|;|+        if (managed->dl_tensor.strides != NULL) {|;|+            strides[i] = managed->dl_tensor.strides[i] * itemsize|;|;+        }|;|+    }|;|+|;|+    char *data = (char *)managed->dl_tensor.data +|;|+            managed->dl_tensor.byte_offset|;|;+|;|+    PyArray_Descr *descr = PyArray_DescrFromType(typenum)|;|;+    if (descr == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *ret = PyArray_NewFromDescr(&PyArray_Type, descr, ndim, shape,|;|+            managed->dl_tensor.strides != NULL ? strides : NULL, data, 0, NULL)|;|;+    if (ret == NULL) {|;|+        Py_DECREF(capsule)|;|;+        return NULL|;|;+    }|;|+|;|+    PyObject *new_capsule = PyCapsule_New(managed,|;|+            NPY_DLPACK_INTERNAL_CAPSULE_NAME,|;|+            array_dlpack_internal_capsule_deleter)|;|;+    if (new_capsule == NULL) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyArray_SetBaseObject((PyArrayObject *)ret, new_capsule) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    if (PyCapsule_SetName(capsule, NPY_DLPACK_USED_CAPSULE_NAME) < 0) {|;|+        Py_DECREF(capsule)|;|;+        Py_DECREF(ret)|;|;+        return NULL|;|;+    }|;|+|;|+    Py_DECREF(capsule)|;|;+    return ret|;|;+}|;|+|;|+ || PR#19083 - numpy/core/src/multiarray/methods.c: @@ -26,6 +26,7 @@|;| #include ""shape.h""|;| #include ""strfuncs.h""|;| #include ""array_assign.h""|;|+#include ""npy_dlpack.h""|;| |;| #include ""methods.h""|;| #include ""alloc.h""|;|@@ -2989,5 +2990,13 @@ NPY_NO_EXPORT PyMethodDef array_methods[] = {|;|     {""view"",|;|         (PyCFunction)array_view,|;|         METH_FASTCALL | METH_KEYWORDS, NULL},|;|+    // For data interchange between libraries|;|+    {""__dlpack__"",|;|+        (PyCFunction)array_dlpack,|;|+        METH_FASTCALL | METH_KEYWORDS, NULL},|;|+|;|+    {""__dlpack_device__"",|;|+        (PyCFunction)array_dlpack_device,|;|+        METH_NOARGS, NULL},|;|     {NULL, NULL, 0, NULL}           /* sentinel */|;| }; || PR#19083 - numpy/core/src/multiarray/multiarraymodule.c: @@ -70,6 +70,8 @@ NPY_NO_EXPORT int NPY_NUMUSERTYPES = 0|;|; #include ""get_attr_string.h""|;| #include ""experimental_public_dtype_api.h""  /* _get_experimental_dtype_api */|;| |;|+#include ""npy_dlpack.h""|;|+|;| /*|;|  *****************************************************************************|;|  **                    INCLUDE GENERATED CODE                               **|;|@@ -4231,7 +4233,6 @@ _reload_guard(PyObject *NPY_UNUSED(self)) {|;|     Py_RETURN_NONE|;|; }|;| |;|-|;| static struct PyMethodDef array_module_methods[] = {|;|     {""_get_implementing_args"",|;|         (PyCFunction)array__get_implementing_args,|;|@@ -4445,6 +4446,8 @@ static struct PyMethodDef array_module_methods[] = {|;|     {""_reload_guard"", (PyCFunction)_reload_guard,|;|         METH_NOARGS,|;|         ""Give a warning on reload and big warning in sub-interpreters.""},|;|+    {""_from_dlpack"", (PyCFunction)_from_dlpack,|;|+        METH_O, NULL},|;|     {NULL, NULL, 0, NULL}                /* sentinel */|;| }|;|;  || PR#19083 - numpy/core/tests/test_dlpack.py: @@ -0,0 +1,109 @@|;|+import sys|;|+import pytest|;|+|;|+import numpy as np|;|+from numpy.testing import assert_array_equal, IS_PYPY|;|+|;|+|;|+class TestDLPack:|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_dunder_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = x.__dlpack__()|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    def test_dunder_dlpack_stream(self):|;|+        x = np.arange(5)|;|+        x.__dlpack__(stream=None)|;|+|;|+        with pytest.raises(RuntimeError):|;|+            x.__dlpack__(stream=1)|;|+|;|+    def test_strides_not_multiple_of_itemsize(self):|;|+        dt = np.dtype([('int', np.int32), ('char', np.int8)])|;|+        y = np.zeros((5,), dtype=dt)|;|+        z = y['int']|;|+|;|+        with pytest.raises(RuntimeError):|;|+            np._from_dlpack(z)|;|+|;|+    @pytest.mark.skipif(IS_PYPY, reason=""PyPy can't get refcounts."")|;|+    def test_from_dlpack_refcount(self):|;|+        x = np.arange(5)|;|+        y = np._from_dlpack(x)|;|+        assert sys.getrefcount(x) == 3|;|+        del y|;|+        assert sys.getrefcount(x) == 2|;|+|;|+    @pytest.mark.parametrize(""dtype"", [|;|+        np.int8, np.int16, np.int32, np.int64,|;|+        np.uint8, np.uint16, np.uint32, np.uint64,|;|+        np.float16, np.float32, np.float64,|;|+        np.complex64, np.complex128|;|+    ])|;|+    def test_dtype_passthrough(self, dtype):|;|+        x = np.arange(5, dtype=dtype)|;|+        y = np._from_dlpack(x)|;|+|;|+        assert y.dtype == x.dtype|;|+        assert_array_equal(x, y)|;|+|;|+    def test_invalid_dtype(self):|;|+        x = np.asarray(np.datetime64('2021-05-27'))|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_invalid_byte_swapping(self):|;|+        dt = np.dtype('=i8').newbyteorder()|;|+        x = np.arange(5, dtype=dt)|;|+|;|+        with pytest.raises(TypeError):|;|+            np._from_dlpack(x)|;|+|;|+    def test_non_contiguous(self):|;|+        x = np.arange(25).reshape((5, 5))|;|+|;|+        y1 = x[0]|;|+        assert_array_equal(y1, np._from_dlpack(y1))|;|+|;|+        y2 = x[:, 0]|;|+        assert_array_equal(y2, np._from_dlpack(y2))|;|+|;|+        y3 = x[1, :]|;|+        assert_array_equal(y3, np._from_dlpack(y3))|;|+|;|+        y4 = x[1]|;|+        assert_array_equal(y4, np._from_dlpack(y4))|;|+|;|+        y5 = np.diagonal(x).copy()|;|+        assert_array_equal(y5, np._from_dlpack(y5))|;|+|;|+    @pytest.mark.parametrize(""ndim"", range(33))|;|+    def test_higher_dims(self, ndim):|;|+        shape = (1,) * ndim|;|+        x = np.zeros(shape, dtype=np.float64)|;|+|;|+        assert shape == np._from_dlpack(x).shape|;|+|;|+    def test_dlpack_device(self):|;|+        x = np.arange(5)|;|+        assert x.__dlpack_device__() == (1, 0)|;|+        assert np._from_dlpack(x).__dlpack_device__() == (1, 0)|;|+|;|+    def dlpack_deleter_exception(self):|;|+        x = np.arange(5)|;|+        _ = x.__dlpack__()|;|+        raise RuntimeError|;|+    |;|+    def test_dlpack_destructor_exception(self):|;|+        with pytest.raises(RuntimeError):|;|+            self.dlpack_deleter_exception()|;|+|;|+    def test_readonly(self):|;|+        x = np.arange(5)|;|+        x.flags.writeable = False|;|+        with pytest.raises(TypeError):|;|+            x.__dlpack__()","ENH: Add the __dlpack__ and __dlpack_device__ methods to ndarray. || ENH, TST: Add the from_dlpack method and test DLPack. || MAINT, BUG: Documentation for DLPack protocol and refcounting bug fixes. || MAINT: Add URL to DLPack GitHub. || MAINT: Split up capsule deleter. || MAINT: Move around code so that there are no more unused warnings. || TST: Improve testing coverage for DLPack. || BUG: Fix handling of C-contiguous and 1-element arrays. || BUG, TST: Device bugfix and test __dl_device__. || MAINT: Robustify dlpack_capsule_deleter and add comments. || BUG: Offset not properly stored/computed. || move dlpack functions to a new file || BUG: fixes from review || Updates

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net>
Co-authored-by: Bas van Beek <43369155+BvB93@users.noreply.github.com> || change from_dlpack to _dlpack, remove unused header || make a.__dlpack__() fail if a is readonly || add release note, error out if offset is used || MAINT: Simplify `byte_offset` handling in dlpack.h and add comment

If `byte_offset = 0` is forced anyway, there is no point in trying
to preserve a previous `data` information from the capsule.
(And probably it should have used a base array also, and not just
a base DLPack capsule, anyway.)"
numpy/numpy,eendebakpt,28400,"BUG: numpy.histogram tries to allocate 98TB of memory with bins=""auto""","### Describe the issue:

For some data arrays, `np.histogram` tries to allocate absurd amount of memory and crashes. This happens with `bins = ""auto""` and supposedly is a result of miscalculation of required number of bins. 

### Reproduce the code example:

```python
import numpy as np

Z = np.array(
    [
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        0.00000000000000000000e00,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
    ]
)

np.histogram(Z, bins=""auto"")
```

### Error message:

```shell
Traceback (most recent call last):
  File ""/home/censored/bug.py"", line 137, in <module>
    np.histogram(Z, bins=""auto"")
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/lib/histograms.py"", line 780, in histogram
    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/lib/histograms.py"", line 446, in _get_bin_edges
    bin_edges = np.linspace(
                ^^^^^^^^^^^^
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/core/function_base.py"", line 140, in linspace
    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 98.2 TiB for an array with shape (13493864060128,) and data type float64
```

### Python and NumPy Versions:

1.26.4
3.12.7 (main, Feb  4 2025, 14:46:03) [GCC 14.2.0]


### Runtime Environment:

[{'numpy_version': '1.26.4',
  'python': '3.12.7 (main, Feb  4 2025, 14:46:03) [GCC 14.2.0]',
  'uname': uname_result(system='Linux', node='censored', release='6.11.0-14-generic', version='#15-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 10 23:48:25 UTC 2025', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Zen',
  'filepath': '/home/censored/.venv/lib/python3.12/site-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so',
  'internal_api': 'openblas',
  'num_threads': 16,
  'prefix': 'libopenblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.23.dev'}]

### Context for the issue:

_No response_","The issue is also present in numpy 2.x. Here is a bit smaller reproducer: 
```
import numpy as np
e = 1 + 1e-12
Z = [0,1,1,1,1,1,e,e,e,e,e,e, 2]
np.histogram(Z, bins=""auto"")
```
The problem is here:

https://github.com/numpy/numpy/blob/9e557eb0b621bbb92c4453b9674bb818c587845e/numpy/lib/_histograms_impl.py#L262-L269

The `_hist_bin_fd` takes the 25th and 75th percentile of the data (extremely small in the cases here) and uses that the calculate a bin width. If the 25th and 75th are equal, then `fd_bw` is zero so the output of `sturges_bw` is taken.

We could replace the condition `if fd_bw:` with 
```
if fd_bw < 1e-6 * (range[-1] - range[0]):
```
This would mean taking `sturges_bw` if the number of bins would up higher than 1 million. The `1e-6` is a bit arbitrary. || I'm no expert, but there is a decent amount of literature on this topic.

One example (cited on the wikipedia page for the Freedman-Diaconis rule): http://www.numdam.org/item/10.1051/ps:2006001.pdf

I don't know if inserting another rule of thumb in this logic is necessarily going to avoid making other cases worse. The above paper notes that Freedman-Diaconis assumes the data are being sampled from a smooth distribution. Given the large dynamic range in the test data I don't think that's a good assumption. Maybe there's a more principled algorithm to determine if Freedman-Diaconis doesn't make sense? || Also totally separately the `del range` stuff can probably go away - these are internal APIs, we should feel free to change them. || For context this is not limited to Freedman-Diaconis bins but is an issue with all the ""auto""-binning schemes. See also #15332. || @ngoldbaum I decided to add a rule of thumb which seems relaxed enough to keep the old behavior the normal cases, but which does avoid the out-of-memory issues. The rule is based on a maximum `n/log(n)` found in your reference ""How many bins should be put in a regular histogram"", ESAIM: Probability and Statistics, Volume 10 (2006), pp. 24-45, http://www.numdam.org/item/10.1051/ps:2006001.pdf

There is quite some literature available, but I suspect that what is a ""normal case""  and what is a good number for auto binning is subjective at the end of the day, so maybe we can just use a simple rule for the auto binning.",closed,2025-02-27T16:26:34+00:00,2025-03-17T07:39:33+00:00,ilyapopov,00 - Bug,1,"PR#28426 - doc/release/upcoming_changes/28426.change.rst: @@ -0,0 +1,6 @@|;|+Changes to automatic bin selection in numpy.histogram|;|+-----------------------------------------------------|;|+The automatic bin selection algorithm in ``numpy.histogram`` has been modified|;|+to avoid out-of-memory errors for samples with low variation.|;|+For full control over the selected bins the user can use set|;|+the ``bin`` or ``range`` parameters of ``numpy.histogram``. || PR#28426 - numpy/lib/_histograms_impl.py: @@ -228,28 +228,24 @@ def _hist_bin_fd(x, range):|;| |;| def _hist_bin_auto(x, range):|;|     """"""|;|-    Histogram bin estimator that uses the minimum width of the|;|-    Freedman-Diaconis and Sturges estimators if the FD bin width is non-zero.|;|-    If the bin width from the FD estimator is 0, the Sturges estimator is used.|;|+    Histogram bin estimator that uses the minimum width of a relaxed|;|+    Freedman-Diaconis and Sturges estimators if the FD bin width does|;|+    not result in a large number of bins. The relaxed Freedman-Diaconis estimator|;|+    limits the bin width to half the sqrt estimated to avoid small bins.|;| |;|     The FD estimator is usually the most robust method, but its width|;|     estimate tends to be too large for small `x` and bad for data with limited|;|     variance. The Sturges estimator is quite good for small (<1000) datasets|;|     and is the default in the R language. This method gives good off-the-shelf|;|     behaviour.|;| |;|-    If there is limited variance the IQR can be 0, which results in the|;|-    FD bin width being 0 too. This is not a valid bin width, so|;|-    ``np.histogram_bin_edges`` chooses 1 bin instead, which may not be optimal.|;|-    If the IQR is 0, it's unlikely any variance-based estimators will be of|;|-    use, so we revert to the Sturges estimator, which only uses the size of the|;|-    dataset in its calculation.|;| |;|     Parameters|;|     ----------|;|     x : array_like|;|         Input data that is to be histogrammed, trimmed to range. May not|;|         be empty.|;|+    range : Tuple with range for the histogram|;| |;|     Returns|;|     -------|;|@@ -261,12 +257,10 @@ def _hist_bin_auto(x, range):|;|     """"""|;|     fd_bw = _hist_bin_fd(x, range)|;|     sturges_bw = _hist_bin_sturges(x, range)|;|-    del range  # unused|;|-    if fd_bw:|;|-        return min(fd_bw, sturges_bw)|;|-    else:|;|-        # limited variance, so we return a len dependent bw estimator|;|-        return sturges_bw|;|+    sqrt_bw = _hist_bin_sqrt(x, range)|;|+    # heuristic to limit the maximal number of bins|;|+    fd_bw_corrected = max(fd_bw, sqrt_bw / 2)|;|+    return min(fd_bw_corrected, sturges_bw)|;| |;| |;| # Private dict initialized at module load time || PR#28426 - numpy/lib/tests/test_histograms.py: @@ -416,6 +416,13 @@ def test_gh_23110(self):|;|         expected_hist = np.array([1, 0])|;|         assert_array_equal(hist, expected_hist)|;| |;|+    def test_gh_28400(self):|;|+        e = 1 + 1e-12|;|+        Z = [0, 1, 1, 1, 1, 1, e, e, e, e, e, e, 2]|;|+        counts, edges = np.histogram(Z, bins=""auto"")|;|+        assert len(counts) < 10|;|+        assert edges[0] == Z[0]|;|+        assert edges[-1] == Z[-1]|;| |;| class TestHistogramOptimBinNums:|;|     """"""|;|@@ -502,15 +509,16 @@ def test_novariance(self):|;| |;|     def test_limited_variance(self):|;|         """"""|;|-        Check when IQR is 0, but variance exists, we return the sturges value|;|-        and not the fd value.|;|+        Check when IQR is 0, but variance exists, we return a reasonable value.|;|         """"""|;|         lim_var_data = np.ones(1000)|;|         lim_var_data[:3] = 0|;|         lim_var_data[-4:] = 100|;| |;|         edges_auto = histogram_bin_edges(lim_var_data, 'auto')|;|-        assert_equal(edges_auto, np.linspace(0, 100, 12))|;|+        assert_equal(edges_auto[0], 0)|;|+        assert_equal(edges_auto[-1], 100.)|;|+        assert len(edges_auto) < 100|;| |;|         edges_fd = histogram_bin_edges(lim_var_data, 'fd')|;|         assert_equal(edges_fd, np.array([0, 100]))","Limit the maximal number of bins for automatic histogram binning || BUG: Limit the maximal number of bins for automatic histogram binning || fix test || Merge branch 'auto_bins' of github.com:eendebakpt/numpy into auto_bins || fix test import || Update numpy/lib/_histograms_impl.py

Co-authored-by: Joren Hammudoglu <jhammudoglu@gmail.com> || lint || lint || Merge branch 'auto_bins' of github.com:eendebakpt/numpy into auto_bins || add release note || fix issues with overflow || review comments || remove unused import || remove unused import || typo || use continuous bin approximation || update test || Apply suggestions from code review

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || Apply suggestions from code review || Update numpy/lib/tests/test_histograms.py || fix test || Update numpy/lib/_histograms_impl.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net>"
numpy/numpy,seberg,28400,"BUG: numpy.histogram tries to allocate 98TB of memory with bins=""auto""","### Describe the issue:

For some data arrays, `np.histogram` tries to allocate absurd amount of memory and crashes. This happens with `bins = ""auto""` and supposedly is a result of miscalculation of required number of bins. 

### Reproduce the code example:

```python
import numpy as np

Z = np.array(
    [
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        2.00000000000028260674e-11,
        0.00000000000000000000e00,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        9.99999999999810431126e-12,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        1.99999999999995173450e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        0.00000000000000000000e00,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
        1.00000000000014130337e-11,
        9.99999999999810431126e-12,
    ]
)

np.histogram(Z, bins=""auto"")
```

### Error message:

```shell
Traceback (most recent call last):
  File ""/home/censored/bug.py"", line 137, in <module>
    np.histogram(Z, bins=""auto"")
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/lib/histograms.py"", line 780, in histogram
    bin_edges, uniform_bins = _get_bin_edges(a, bins, range, weights)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/lib/histograms.py"", line 446, in _get_bin_edges
    bin_edges = np.linspace(
                ^^^^^^^^^^^^
  File ""/home/censored/.venv/lib/python3.12/site-packages/numpy/core/function_base.py"", line 140, in linspace
    y = _nx.arange(0, num, dtype=dt).reshape((-1,) + (1,) * ndim(delta))
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 98.2 TiB for an array with shape (13493864060128,) and data type float64
```

### Python and NumPy Versions:

1.26.4
3.12.7 (main, Feb  4 2025, 14:46:03) [GCC 14.2.0]


### Runtime Environment:

[{'numpy_version': '1.26.4',
  'python': '3.12.7 (main, Feb  4 2025, 14:46:03) [GCC 14.2.0]',
  'uname': uname_result(system='Linux', node='censored', release='6.11.0-14-generic', version='#15-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 10 23:48:25 UTC 2025', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Zen',
  'filepath': '/home/censored/.venv/lib/python3.12/site-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so',
  'internal_api': 'openblas',
  'num_threads': 16,
  'prefix': 'libopenblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.23.dev'}]

### Context for the issue:

_No response_","The issue is also present in numpy 2.x. Here is a bit smaller reproducer: 
```
import numpy as np
e = 1 + 1e-12
Z = [0,1,1,1,1,1,e,e,e,e,e,e, 2]
np.histogram(Z, bins=""auto"")
```
The problem is here:

https://github.com/numpy/numpy/blob/9e557eb0b621bbb92c4453b9674bb818c587845e/numpy/lib/_histograms_impl.py#L262-L269

The `_hist_bin_fd` takes the 25th and 75th percentile of the data (extremely small in the cases here) and uses that the calculate a bin width. If the 25th and 75th are equal, then `fd_bw` is zero so the output of `sturges_bw` is taken.

We could replace the condition `if fd_bw:` with 
```
if fd_bw < 1e-6 * (range[-1] - range[0]):
```
This would mean taking `sturges_bw` if the number of bins would up higher than 1 million. The `1e-6` is a bit arbitrary. || I'm no expert, but there is a decent amount of literature on this topic.

One example (cited on the wikipedia page for the Freedman-Diaconis rule): http://www.numdam.org/item/10.1051/ps:2006001.pdf

I don't know if inserting another rule of thumb in this logic is necessarily going to avoid making other cases worse. The above paper notes that Freedman-Diaconis assumes the data are being sampled from a smooth distribution. Given the large dynamic range in the test data I don't think that's a good assumption. Maybe there's a more principled algorithm to determine if Freedman-Diaconis doesn't make sense? || Also totally separately the `del range` stuff can probably go away - these are internal APIs, we should feel free to change them. || For context this is not limited to Freedman-Diaconis bins but is an issue with all the ""auto""-binning schemes. See also #15332. || @ngoldbaum I decided to add a rule of thumb which seems relaxed enough to keep the old behavior the normal cases, but which does avoid the out-of-memory issues. The rule is based on a maximum `n/log(n)` found in your reference ""How many bins should be put in a regular histogram"", ESAIM: Probability and Statistics, Volume 10 (2006), pp. 24-45, http://www.numdam.org/item/10.1051/ps:2006001.pdf

There is quite some literature available, but I suspect that what is a ""normal case""  and what is a good number for auto binning is subjective at the end of the day, so maybe we can just use a simple rule for the auto binning.",closed,2025-02-27T16:26:34+00:00,2025-03-17T07:39:33+00:00,ilyapopov,00 - Bug,1,"PR#28426 - doc/release/upcoming_changes/28426.change.rst: @@ -0,0 +1,6 @@|;|+Changes to automatic bin selection in numpy.histogram|;|+-----------------------------------------------------|;|+The automatic bin selection algorithm in ``numpy.histogram`` has been modified|;|+to avoid out-of-memory errors for samples with low variation.|;|+For full control over the selected bins the user can use set|;|+the ``bin`` or ``range`` parameters of ``numpy.histogram``. || PR#28426 - numpy/lib/_histograms_impl.py: @@ -228,28 +228,24 @@ def _hist_bin_fd(x, range):|;| |;| def _hist_bin_auto(x, range):|;|     """"""|;|-    Histogram bin estimator that uses the minimum width of the|;|-    Freedman-Diaconis and Sturges estimators if the FD bin width is non-zero.|;|-    If the bin width from the FD estimator is 0, the Sturges estimator is used.|;|+    Histogram bin estimator that uses the minimum width of a relaxed|;|+    Freedman-Diaconis and Sturges estimators if the FD bin width does|;|+    not result in a large number of bins. The relaxed Freedman-Diaconis estimator|;|+    limits the bin width to half the sqrt estimated to avoid small bins.|;| |;|     The FD estimator is usually the most robust method, but its width|;|     estimate tends to be too large for small `x` and bad for data with limited|;|     variance. The Sturges estimator is quite good for small (<1000) datasets|;|     and is the default in the R language. This method gives good off-the-shelf|;|     behaviour.|;| |;|-    If there is limited variance the IQR can be 0, which results in the|;|-    FD bin width being 0 too. This is not a valid bin width, so|;|-    ``np.histogram_bin_edges`` chooses 1 bin instead, which may not be optimal.|;|-    If the IQR is 0, it's unlikely any variance-based estimators will be of|;|-    use, so we revert to the Sturges estimator, which only uses the size of the|;|-    dataset in its calculation.|;| |;|     Parameters|;|     ----------|;|     x : array_like|;|         Input data that is to be histogrammed, trimmed to range. May not|;|         be empty.|;|+    range : Tuple with range for the histogram|;| |;|     Returns|;|     -------|;|@@ -261,12 +257,10 @@ def _hist_bin_auto(x, range):|;|     """"""|;|     fd_bw = _hist_bin_fd(x, range)|;|     sturges_bw = _hist_bin_sturges(x, range)|;|-    del range  # unused|;|-    if fd_bw:|;|-        return min(fd_bw, sturges_bw)|;|-    else:|;|-        # limited variance, so we return a len dependent bw estimator|;|-        return sturges_bw|;|+    sqrt_bw = _hist_bin_sqrt(x, range)|;|+    # heuristic to limit the maximal number of bins|;|+    fd_bw_corrected = max(fd_bw, sqrt_bw / 2)|;|+    return min(fd_bw_corrected, sturges_bw)|;| |;| |;| # Private dict initialized at module load time || PR#28426 - numpy/lib/tests/test_histograms.py: @@ -416,6 +416,13 @@ def test_gh_23110(self):|;|         expected_hist = np.array([1, 0])|;|         assert_array_equal(hist, expected_hist)|;| |;|+    def test_gh_28400(self):|;|+        e = 1 + 1e-12|;|+        Z = [0, 1, 1, 1, 1, 1, e, e, e, e, e, e, 2]|;|+        counts, edges = np.histogram(Z, bins=""auto"")|;|+        assert len(counts) < 10|;|+        assert edges[0] == Z[0]|;|+        assert edges[-1] == Z[-1]|;| |;| class TestHistogramOptimBinNums:|;|     """"""|;|@@ -502,15 +509,16 @@ def test_novariance(self):|;| |;|     def test_limited_variance(self):|;|         """"""|;|-        Check when IQR is 0, but variance exists, we return the sturges value|;|-        and not the fd value.|;|+        Check when IQR is 0, but variance exists, we return a reasonable value.|;|         """"""|;|         lim_var_data = np.ones(1000)|;|         lim_var_data[:3] = 0|;|         lim_var_data[-4:] = 100|;| |;|         edges_auto = histogram_bin_edges(lim_var_data, 'auto')|;|-        assert_equal(edges_auto, np.linspace(0, 100, 12))|;|+        assert_equal(edges_auto[0], 0)|;|+        assert_equal(edges_auto[-1], 100.)|;|+        assert len(edges_auto) < 100|;| |;|         edges_fd = histogram_bin_edges(lim_var_data, 'fd')|;|         assert_equal(edges_fd, np.array([0, 100]))","Limit the maximal number of bins for automatic histogram binning || BUG: Limit the maximal number of bins for automatic histogram binning || fix test || Merge branch 'auto_bins' of github.com:eendebakpt/numpy into auto_bins || fix test import || Update numpy/lib/_histograms_impl.py

Co-authored-by: Joren Hammudoglu <jhammudoglu@gmail.com> || lint || lint || Merge branch 'auto_bins' of github.com:eendebakpt/numpy into auto_bins || add release note || fix issues with overflow || review comments || remove unused import || remove unused import || typo || use continuous bin approximation || update test || Apply suggestions from code review

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || Apply suggestions from code review || Update numpy/lib/tests/test_histograms.py || fix test || Update numpy/lib/_histograms_impl.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net>"
numpy/numpy,guan404ming,28504,MAINT: Clean up `numpy.ma.timer_comparison`,As discussed in https://github.com/numpy/numpy/pull/28501,,closed,2025-03-14T12:58:21+00:00,2025-03-14T17:11:56+00:00,jorenham,03 - Maintenance,1,"PR#28507 - numpy/ma/timer_comparison.py: @@ -1,450 +0,0 @@|;|-import functools|;|-import timeit|;|-|;|-import numpy as np|;|-import numpy._core.fromnumeric as fromnumeric|;|-|;|-from numpy.testing import build_err_msg|;|-|;|-|;|-pi = np.pi|;|-|;|-class ModuleTester:|;|-    def __init__(self, module):|;|-        self.module = module|;|-        self.allequal = module.allequal|;|-        self.arange = module.arange|;|-        self.array = module.array|;|-        self.concatenate = module.concatenate|;|-        self.count = module.count|;|-        self.equal = module.equal|;|-        self.filled = module.filled|;|-        self.getmask = module.getmask|;|-        self.getmaskarray = module.getmaskarray|;|-        self.id = id|;|-        self.inner = module.inner|;|-        self.make_mask = module.make_mask|;|-        self.masked = module.masked|;|-        self.masked_array = module.masked_array|;|-        self.masked_values = module.masked_values|;|-        self.mask_or = module.mask_or|;|-        self.nomask = module.nomask|;|-        self.ones = module.ones|;|-        self.outer = module.outer|;|-        self.repeat = module.repeat|;|-        self.resize = module.resize|;|-        self.sort = module.sort|;|-        self.take = module.take|;|-        self.transpose = module.transpose|;|-        self.zeros = module.zeros|;|-        self.MaskType = module.MaskType|;|-        try:|;|-            self.umath = module.umath|;|-        except AttributeError:|;|-            self.umath = module.core.umath|;|-        self.testnames = []|;|-|;|-    def assert_array_compare(self, comparison, x, y, err_msg='', header='',|;|-                         fill_value=True):|;|-        """"""|;|-        Assert that a comparison of two masked arrays is satisfied elementwise.|;|-|;|-        """"""|;|-        xf = self.filled(x)|;|-        yf = self.filled(y)|;|-        m = self.mask_or(self.getmask(x), self.getmask(y))|;|-|;|-        x = self.filled(self.masked_array(xf, mask=m), fill_value)|;|-        y = self.filled(self.masked_array(yf, mask=m), fill_value)|;|-        if (x.dtype.char != ""O""):|;|-            x = x.astype(np.float64)|;|-            if isinstance(x, np.ndarray) and x.size > 1:|;|-                x[np.isnan(x)] = 0|;|-            elif np.isnan(x):|;|-                x = 0|;|-        if (y.dtype.char != ""O""):|;|-            y = y.astype(np.float64)|;|-            if isinstance(y, np.ndarray) and y.size > 1:|;|-                y[np.isnan(y)] = 0|;|-            elif np.isnan(y):|;|-                y = 0|;|-        try:|;|-            cond = (x.shape == () or y.shape == ()) or x.shape == y.shape|;|-            if not cond:|;|-                msg = build_err_msg([x, y],|;|-                                    err_msg|;|-                                    + f'\n(shapes {x.shape}, {y.shape} mismatch)',|;|-                                    header=header,|;|-                                    names=('x', 'y'))|;|-                assert cond, msg|;|-            val = comparison(x, y)|;|-            if m is not self.nomask and fill_value:|;|-                val = self.masked_array(val, mask=m)|;|-            if isinstance(val, bool):|;|-                cond = val|;|-                reduced = [0]|;|-            else:|;|-                reduced = val.ravel()|;|-                cond = reduced.all()|;|-                reduced = reduced.tolist()|;|-            if not cond:|;|-                match = 100 - 100.0 * reduced.count(1) / len(reduced)|;|-                msg = build_err_msg([x, y],|;|-                                    err_msg|;|-                                    + '\n(mismatch %s%%)' % (match,),|;|-                                    header=header,|;|-                                    names=('x', 'y'))|;|-                assert cond, msg|;|-        except ValueError as e:|;|-            msg = build_err_msg([x, y], err_msg, header=header, names=('x', 'y'))|;|-            raise ValueError(msg) from e|;|-|;|-    def assert_array_equal(self, x, y, err_msg=''):|;|-        """"""|;|-        Checks the elementwise equality of two masked arrays.|;|-|;|-        """"""|;|-        self.assert_array_compare(self.equal, x, y, err_msg=err_msg,|;|-                                  header='Arrays are not equal')|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_0(self):|;|-        """"""|;|-        Tests creation|;|-|;|-        """"""|;|-        x = np.array([1., 1., 1., -2., pi / 2.0, 4., 5., -10., 10., 1., 2., 3.])|;|-        m = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]|;|-        xm = self.masked_array(x, mask=m)|;|-        xm[0]|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_1(self):|;|-        """"""|;|-        Tests creation|;|-|;|-        """"""|;|-        x = np.array([1., 1., 1., -2., pi / 2.0, 4., 5., -10., 10., 1., 2., 3.])|;|-        y = np.array([5., 0., 3., 2., -1., -4., 0., -10., 10., 1., 0., 3.])|;|-        m1 = [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]|;|-        m2 = [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]|;|-        xm = self.masked_array(x, mask=m1)|;|-        ym = self.masked_array(y, mask=m2)|;|-        xf = np.where(m1, 1.e+20, x)|;|-        xm.set_fill_value(1.e+20)|;|-|;|-        assert (xm - ym).filled(0).any()|;|-        s = x.shape|;|-        assert xm.size == functools.reduce(lambda x, y: x * y, s)|;|-        assert self.count(xm) == len(m1) - functools.reduce(lambda x, y: x + y, m1)|;|-|;|-        for s in [(4, 3), (6, 2)]:|;|-            x.shape = s|;|-            y.shape = s|;|-            xm.shape = s|;|-            ym.shape = s|;|-            xf.shape = s|;|-            assert self.count(xm) == len(m1) - functools.reduce(lambda x, y: x + y, m1)|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_2(self):|;|-        """"""|;|-        Tests conversions and indexing.|;|-|;|-        """"""|;|-        x1 = np.array([1, 2, 4, 3])|;|-        x2 = self.array(x1, mask=[1, 0, 0, 0])|;|-        x3 = self.array(x1, mask=[0, 1, 0, 1])|;|-        x4 = self.array(x1)|;|-        # test conversion to strings, no errors|;|-        str(x2)|;|-        repr(x2)|;|-        # tests of indexing|;|-        assert type(x2[1]) is type(x1[1])|;|-        assert x1[1] == x2[1]|;|-        x1[2] = 9|;|-        x2[2] = 9|;|-        self.assert_array_equal(x1, x2)|;|-        x1[1:3] = 99|;|-        x2[1:3] = 99|;|-        x2[1] = self.masked|;|-        x2[1:3] = self.masked|;|-        x2[:] = x1|;|-        x2[1] = self.masked|;|-        x3[:] = self.masked_array([1, 2, 3, 4], [0, 1, 1, 0])|;|-        x4[:] = self.masked_array([1, 2, 3, 4], [0, 1, 1, 0])|;|-        x1 = np.arange(5) * 1.0|;|-        x2 = self.masked_values(x1, 3.0)|;|-        x1 = self.array([1, 'hello', 2, 3], object)|;|-        x2 = np.array([1, 'hello', 2, 3], object)|;|-        # check that no error occurs.|;|-        x1[1]|;|-        x2[1]|;|-        assert x1[1:1].shape == (0,)|;|-        # Tests copy-size|;|-        n = [0, 0, 1, 0, 0]|;|-        m = self.make_mask(n)|;|-        m2 = self.make_mask(m)|;|-        assert m is m2|;|-        m3 = self.make_mask(m, copy=1)|;|-        assert m is not m3|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_3(self):|;|-        """"""|;|-        Tests resize/repeat|;|-|;|-        """"""|;|-        x4 = self.arange(4)|;|-        x4[2] = self.masked|;|-        y4 = self.resize(x4, (8,))|;|-        assert self.allequal(self.concatenate([x4, x4]), y4)|;|-        assert self.allequal(self.getmask(y4), [0, 0, 1, 0, 0, 0, 1, 0])|;|-        y5 = self.repeat(x4, (2, 2, 2, 2), axis=0)|;|-        self.assert_array_equal(y5, [0, 0, 1, 1, 2, 2, 3, 3])|;|-        y6 = self.repeat(x4, 2, axis=0)|;|-        assert self.allequal(y5, y6)|;|-        y7 = x4.repeat((2, 2, 2, 2), axis=0)|;|-        assert self.allequal(y5, y7)|;|-        y8 = x4.repeat(2, 0)|;|-        assert self.allequal(y5, y8)|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_4(self):|;|-        """"""|;|-        Test of take, transpose, inner, outer products.|;|-|;|-        """"""|;|-        x = self.arange(24)|;|-        y = np.arange(24)|;|-        x[5:6] = self.masked|;|-        x = x.reshape(2, 3, 4)|;|-        y = y.reshape(2, 3, 4)|;|-        assert self.allequal(np.transpose(y, (2, 0, 1)), self.transpose(x, (2, 0, 1)))|;|-        assert self.allequal(np.take(y, (2, 0, 1), 1), self.take(x, (2, 0, 1), 1))|;|-        assert self.allequal(np.inner(self.filled(x, 0), self.filled(y, 0)),|;|-                            self.inner(x, y))|;|-        assert self.allequal(np.outer(self.filled(x, 0), self.filled(y, 0)),|;|-                            self.outer(x, y))|;|-        y = self.array(['abc', 1, 'def', 2, 3], object)|;|-        y[2] = self.masked|;|-        t = self.take(y, [0, 3, 4])|;|-        assert t[0] == 'abc'|;|-        assert t[1] == 2|;|-        assert t[2] == 3|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_5(self):|;|-        """"""|;|-        Tests inplace w/ scalar|;|-|;|-        """"""|;|-        x = self.arange(10)|;|-        y = self.arange(10)|;|-        xm = self.arange(10)|;|-        xm[2] = self.masked|;|-        x += 1|;|-        assert self.allequal(x, y + 1)|;|-        xm += 1|;|-        assert self.allequal(xm, y + 1)|;|-|;|-        x = self.arange(10)|;|-        xm = self.arange(10)|;|-        xm[2] = self.masked|;|-        x -= 1|;|-        assert self.allequal(x, y - 1)|;|-        xm -= 1|;|-        assert self.allequal(xm, y - 1)|;|-|;|-        x = self.arange(10) * 1.0|;|-        xm = self.arange(10) * 1.0|;|-        xm[2] = self.masked|;|-        x *= 2.0|;|-        assert self.allequal(x, y * 2)|;|-        xm *= 2.0|;|-        assert self.allequal(xm, y * 2)|;|-|;|-        x = self.arange(10) * 2|;|-        xm = self.arange(10) * 2|;|-        xm[2] = self.masked|;|-        x /= 2|;|-        assert self.allequal(x, y)|;|-        xm /= 2|;|-        assert self.allequal(xm, y)|;|-|;|-        x = self.arange(10) * 1.0|;|-        xm = self.arange(10) * 1.0|;|-        xm[2] = self.masked|;|-        x /= 2.0|;|-        assert self.allequal(x, y / 2.0)|;|-        xm /= self.arange(10)|;|-        self.assert_array_equal(xm, self.ones((10,)))|;|-|;|-        x = self.arange(10).astype(np.float64)|;|-        xm = self.arange(10)|;|-        xm[2] = self.masked|;|-        x += 1.|;|-        assert self.allequal(x, y + 1.)|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_6(self):|;|-        """"""|;|-        Tests inplace w/ array|;|-|;|-        """"""|;|-        x = self.arange(10, dtype=np.float64)|;|-        y = self.arange(10)|;|-        xm = self.arange(10, dtype=np.float64)|;|-        xm[2] = self.masked|;|-        m = xm.mask|;|-        a = self.arange(10, dtype=np.float64)|;|-        a[-1] = self.masked|;|-        x += a|;|-        xm += a|;|-        assert self.allequal(x, y + a)|;|-        assert self.allequal(xm, y + a)|;|-        assert self.allequal(xm.mask, self.mask_or(m, a.mask))|;|-|;|-        x = self.arange(10, dtype=np.float64)|;|-        xm = self.arange(10, dtype=np.float64)|;|-        xm[2] = self.masked|;|-        m = xm.mask|;|-        a = self.arange(10, dtype=np.float64)|;|-        a[-1] = self.masked|;|-        x -= a|;|-        xm -= a|;|-        assert self.allequal(x, y - a)|;|-        assert self.allequal(xm, y - a)|;|-        assert self.allequal(xm.mask, self.mask_or(m, a.mask))|;|-|;|-        x = self.arange(10, dtype=np.float64)|;|-        xm = self.arange(10, dtype=np.float64)|;|-        xm[2] = self.masked|;|-        m = xm.mask|;|-        a = self.arange(10, dtype=np.float64)|;|-        a[-1] = self.masked|;|-        x *= a|;|-        xm *= a|;|-        assert self.allequal(x, y * a)|;|-        assert self.allequal(xm, y * a)|;|-        assert self.allequal(xm.mask, self.mask_or(m, a.mask))|;|-|;|-        x = self.arange(10, dtype=np.float64)|;|-        xm = self.arange(10, dtype=np.float64)|;|-        xm[2] = self.masked|;|-        m = xm.mask|;|-        a = self.arange(10, dtype=np.float64)|;|-        a[-1] = self.masked|;|-        x /= a|;|-        xm /= a|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_7(self):|;|-        ""Tests ufunc""|;|-        d = (self.array([1.0, 0, -1, pi / 2] * 2, mask=[0, 1] + [0] * 6),|;|-             self.array([1.0, 0, -1, pi / 2] * 2, mask=[1, 0] + [0] * 6),)|;|-        for f in ['sqrt', 'log', 'log10', 'exp', 'conjugate',|;|-#                  'sin', 'cos', 'tan',|;|-#                  'arcsin', 'arccos', 'arctan',|;|-#                  'sinh', 'cosh', 'tanh',|;|-#                  'arcsinh',|;|-#                  'arccosh',|;|-#                  'arctanh',|;|-#                  'absolute', 'fabs', 'negative',|;|-#                  # 'nonzero', 'around',|;|-#                  'floor', 'ceil',|;|-#                  # 'sometrue', 'alltrue',|;|-#                  'logical_not',|;|-#                  'add', 'subtract', 'multiply',|;|-#                  'divide', 'true_divide', 'floor_divide',|;|-#                  'remainder', 'fmod', 'hypot', 'arctan2',|;|-#                  'equal', 'not_equal', 'less_equal', 'greater_equal',|;|-#                  'less', 'greater',|;|-#                  'logical_and', 'logical_or', 'logical_xor',|;|-                  ]:|;|-            try:|;|-                uf = getattr(self.umath, f)|;|-            except AttributeError:|;|-                uf = getattr(fromnumeric, f)|;|-            mf = getattr(self.module, f)|;|-            args = d[:uf.nin]|;|-            ur = uf(*args)|;|-            mr = mf(*args)|;|-            self.assert_array_equal(ur.filled(0), mr.filled(0), f)|;|-            self.assert_array_equal(ur._mask, mr._mask)|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_99(self):|;|-        # test average|;|-        ott = self.array([0., 1., 2., 3.], mask=[1, 0, 0, 0])|;|-        self.assert_array_equal(2.0, self.average(ott, axis=0))|;|-        self.assert_array_equal(2.0, self.average(ott, weights=[1., 1., 2., 1.]))|;|-        result, wts = self.average(ott, weights=[1., 1., 2., 1.], returned=1)|;|-        self.assert_array_equal(2.0, result)|;|-        assert wts == 4.0|;|-        ott[:] = self.masked|;|-        assert self.average(ott, axis=0) is self.masked|;|-        ott = self.array([0., 1., 2., 3.], mask=[1, 0, 0, 0])|;|-        ott = ott.reshape(2, 2)|;|-        ott[:, 1] = self.masked|;|-        self.assert_array_equal(self.average(ott, axis=0), [2.0, 0.0])|;|-        assert self.average(ott, axis=1)[0] is self.masked|;|-        self.assert_array_equal([2., 0.], self.average(ott, axis=0))|;|-        result, wts = self.average(ott, axis=0, returned=1)|;|-        self.assert_array_equal(wts, [1., 0.])|;|-        w1 = [0, 1, 1, 1, 1, 0]|;|-        w2 = [[0, 1, 1, 1, 1, 0], [1, 0, 0, 0, 0, 1]]|;|-        x = self.arange(6)|;|-        self.assert_array_equal(self.average(x, axis=0), 2.5)|;|-        self.assert_array_equal(self.average(x, axis=0, weights=w1), 2.5)|;|-        y = self.array([self.arange(6), 2.0 * self.arange(6)])|;|-        self.assert_array_equal(self.average(y, None),|;|-                                np.add.reduce(np.arange(6)) * 3. / 12.)|;|-        self.assert_array_equal(self.average(y, axis=0), np.arange(6) * 3. / 2.)|;|-        self.assert_array_equal(self.average(y, axis=1),|;|-                                [self.average(x, axis=0),|;|-                                 self.average(x, axis=0) * 2.0])|;|-        self.assert_array_equal(self.average(y, None, weights=w2), 20. / 6.)|;|-        self.assert_array_equal(self.average(y, axis=0, weights=w2),|;|-                                [0., 1., 2., 3., 4., 10.])|;|-        self.assert_array_equal(self.average(y, axis=1),|;|-                                [self.average(x, axis=0),|;|-                                 self.average(x, axis=0) * 2.0])|;|-        m1 = self.zeros(6)|;|-        m2 = [0, 0, 1, 1, 0, 0]|;|-        m3 = [[0, 0, 1, 1, 0, 0], [0, 1, 1, 1, 1, 0]]|;|-        m4 = self.ones(6)|;|-        m5 = [0, 1, 1, 1, 1, 1]|;|-        self.assert_array_equal(self.average(self.masked_array(x, m1), axis=0), 2.5)|;|-        self.assert_array_equal(self.average(self.masked_array(x, m2), axis=0), 2.5)|;|-        self.assert_array_equal(self.average(self.masked_array(x, m5), axis=0), 0.0)|;|-        self.assert_array_equal(self.count(self.average(self.masked_array(x, m4),|;|-                                                        axis=0)), 0)|;|-        z = self.masked_array(y, m3)|;|-        self.assert_array_equal(self.average(z, None), 20. / 6.)|;|-        self.assert_array_equal(self.average(z, axis=0), [0., 1., 99., 99., 4.0, 7.5])|;|-        self.assert_array_equal(self.average(z, axis=1), [2.5, 5.0])|;|-        self.assert_array_equal(self.average(z, axis=0, weights=w2),|;|-                                [0., 1., 99., 99., 4.0, 10.0])|;|-|;|-    @np.errstate(all='ignore')|;|-    def test_A(self):|;|-        x = self.arange(24)|;|-        x[5:6] = self.masked|;|-        x = x.reshape(2, 3, 4)|;|-|;|-|;|-if __name__ == '__main__':|;|-    setup_base = (""from __main__ import ModuleTester \n""|;|-                  ""import numpy\n""|;|-                  ""tester = ModuleTester(module)\n"")|;|-    setup_cur = ""import numpy.ma.core as module\n"" + setup_base|;|-    (nrepeat, nloop) = (10, 10)|;|-|;|-    for i in range(1, 8):|;|-        func = 'tester.test_%i()' % i|;|-        cur = timeit.Timer(func, setup_cur).repeat(nrepeat, nloop * 10)|;|-        cur = np.sort(cur)|;|-        print(""#%i"" % i + 50 * '.')|;|-        print(eval(""ModuleTester.test_%i.__doc__"" % i))|;|-        print(f'core_current : {cur[0]:.3f} - {cur[1]:.3f}') || PR#28507 - numpy/tests/test_public_api.py: @@ -198,7 +198,6 @@ def test_NPY_NO_EXPORT():|;|     ""linalg.linalg"",|;|     ""ma.core"",|;|     ""ma.testutils"",|;|-    ""ma.timer_comparison"",|;|     ""matlib"",|;|     ""matrixlib"",|;|     ""matrixlib.defmatrix"",",Remove `ma.timer_comparison`
numpy/numpy,SaraInCode,28440,DOC: Place bitwise_count under bit-wise operations,"### Issue with current documentation:

Currently, the documentation lists [bitwise_count](https://numpy.org/doc/stable/reference/generated/numpy.bitwise_count.html) under [miscellaneous mathematical functions](https://numpy.org/doc/stable/reference/routines.math.html#miscellaneous), whereas it should be under [bit-wise operations](https://numpy.org/doc/stable/reference/routines.bitwise.html).

If desired, I can submit a PR to fix this.",@carlosgmartin are you working on it or can I take this up? || @SaraInCode Go ahead.,closed,2025-03-06T17:59:42+00:00,2025-03-14T09:48:26+00:00,carlosgmartin,04 - Documentation,1,"PR#28447 - doc/source/reference/routines.bitwise.rst: @@ -17,6 +17,7 @@ Elementwise bit operations|;|    bitwise_left_shift|;|    right_shift|;|    bitwise_right_shift|;|+   bitwise_count   |;| |;| Bit packing|;| ----------- || PR#28447 - doc/source/reference/routines.math.rst: @@ -193,4 +193,3 @@ Miscellaneous|;| |;|    interp|;| |;|-   bitwise_count",DOC: repositioned bitwise_count under bit-wise operations
numpy/numpy,mhvk,28493,"BUG: `np.unique_values(...)` isn't equivalent to `np.unique(..., equal_nan=False)` on `main`","### Describe the issue:

`unique_values` [is documented](https://numpy.org/doc/stable/reference/generated/numpy.unique_values.html#numpy-unique-values) as an alternative to `unique` with `equal_nan=False`.
A test in `unyt`, for `np.unique_values`, was written within the assumption that the outputs are expected to be strictly equal, but lately, [it hasn't been the case](https://github.com/yt-project/unyt/issues/564). Was this assumption incorrect, or is this a regression in numpy ?

I can reproduce the error without unyt, so I know it's not a bug on our side.
Further more, it could bisect the change to https://github.com/numpy/numpy/commit/9e557eb0b621bbb92c4453b9674bb818c587845e (gh-26018)

### Reproduce the code example:

```python
# t.py
import numpy as np
from numpy.testing import assert_array_equal


def test_unique_value():
    arr = np.arange(9).reshape(3, 3)
    expected = np.unique(arr, equal_nan=False)
    out = np.unique_values(arr)
    assert_array_equal(out, expected)
```

### Error message:

```shell
❯ pytest t.py                    
============================ test session starts =============================
platform darwin -- Python 3.13.2, pytest-8.3.5, pluggy-1.5.0
rootdir: /Users/clm/dev/yt-project/unyt
configfile: pyproject.toml
plugins: cov-6.0.0, doctestplus-1.4.0
collected 1 item                                                             

t.py F                                                          [100%]

================================== FAILURES ==================================
_____________________________ test_unique_value ______________________________

    def test_unique_value():
        arr = np.arange(9).reshape(3,3)
        expected = np.unique(arr, equal_nan=False)
        out = np.unique_values(arr)
>       assert_array_equal(out, expected)
E       AssertionError: 
E       Arrays are not equal
E       
E       Mismatched elements: 8 / 9 (88.9%)
E       Max absolute difference among violations: 8
E       Max relative difference among violations: 6.
E        ACTUAL: array([8, 7, 6, 5, 4, 3, 2, 1, 0])
E        DESIRED: array([0, 1, 2, 3, 4, 5, 6, 7, 8])

t.py:8: AssertionError
========================== short test summary info ===========================
FAILED t.py::test_unique_value - AssertionError: 
============================= 1 failed in 0.03s ==============================
```

### Python and NumPy Versions:

```
2.3.0.dev0+git20250227.9e557eb
3.13.2 (main, Mar 11 2025, 17:30:09) [Clang 20.1.0 ]
```

### Runtime Environment:

```
[{'numpy_version': '2.3.0.dev0+git20250227.9e557eb',
  'python': '3.13.2 (main, Mar 11 2025, 17:30:09) [Clang 20.1.0 ]',
  'uname': uname_result(system='Darwin', node='wifibridge.home', release='24.3.0', version='Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:23 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6020', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}}]
```
### Context for the issue:

_No response_","Intentional change:  IMO it was an oversight that the docs for these never mention that these functions don't guarantee a sorted result, *even if the result was/is sorted*.
And since the function is pretty new, I feel we can fix this.

But yes, the docs should make a note about it. || Awesome. Thanks for clarifying this ! || @seberg - It still confused me until I actually read the original PR. I think the docstring of `unique_values` should indeed be updated, most simply to note it is the same as `np.unique(x, equal_nan=False, sorted=False)` - that would make things clear immediately. ... see #28495

p.s. I'm actually a bit confused why the other `np.unique_*` functions default to `sorted=True`, but maybe that is simply because for those indices need to be kept or so... || > p.s. I'm actually a bit confused why the other np.unique_* functions default to sorted=True

The reason is, that right now it says `sorted=False` fails and I didn't change it in the original PR.
But right while not allowing `sorted=False` when it is currently not supported, seems like a reasonable choice, I actually agree that just allowing (but ignoring) it may be better.",closed,2025-03-13T13:15:13+00:00,2025-03-13T18:47:57+00:00,neutrinoceros,04 - Documentation,1,"PR#28495 - numpy/lib/_arraysetops_impl.py: @@ -612,7 +612,11 @@ def unique_values(x):|;| |;|     This function is an Array API compatible alternative to::|;| |;|-        np.unique(x, equal_nan=False)|;|+        np.unique(x, equal_nan=False, sorted=False)|;|+|;|+    .. versionchanged:: 2.3|;|+       The algorithm was changed to a faster one that does not rely on|;|+       sorting, and hence the results are no longer implicitly sorted.|;| |;|     Parameters|;|     ----------",DOC: let docstring mention that unique_values is now unsorted
numpy/numpy,mattip,28479,DOC: the hack in conf.py to rename scalars crashes PyPy,"There is a hack to change the `tp_name` attribute on scalar types to the canonical name. This assumes a layout of a `PyObject` that does not match the one on PyPy. PyPy segfaults when using it to build docs. We should figure out a better way to do this.


The code came from #17331, which I merged.",,closed,2025-03-11T21:08:35+00:00,2025-03-12T18:36:10+00:00,mattip,,1,"PR#28483 - doc/source/conf.py: @@ -52,8 +52,12 @@ class PyTypeObject(ctypes.Structure):|;|     ]:|;|         typ = getattr(numpy, name)|;|         c_typ = PyTypeObject.from_address(id(typ))|;|-        c_typ.tp_name = _name_cache[typ] = b""numpy."" + name.encode('utf8')|;|-|;|+        if sys.implementation.name == 'cpython':|;|+            c_typ.tp_name = _name_cache[typ] = b""numpy."" + name.encode('utf8')|;|+        else:|;|+            # It is not guarenteed that the c_typ has this model on other|;|+            # implementations|;|+            _name_cache[typ] = b""numpy."" + name.encode('utf8')|;| |;| replace_scalar_type_names()|;| ",DOC: only change tp_name on CPython [skip azp][skip actions][skip cirrus]
numpy/numpy,wheeleha,27183,DOC: turning off AVX512,"### Issue with current documentation:

On https://numpy.org/devdocs/reference/simd/build-options.html there are recommendations for turning off AVX512 support.
```
python -m build --wheel -Csetup-args=-Dcpu-dispatch=""max -avx512f -avx512cd \
-avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl""
```
I saw the same list in the ""CPU Optimization Options"" output as 'requested' for dispatch, but all of them were still listed as ""Enabled"" in the next line.

### Idea or request for content:

I had to add -avx512_spr to the list so that AVX512 was really disabled, i.e.
```
-Csetup-args=-Dcpu-dispatch=""max -avx512f -avx512cd -avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl -avx512_spr""
```
Then no AVX512 option was listed in ""Enabled"".
(I guess if any AVX512 is still allowed, it will turn on all of them?)",Working on this!,open,2024-08-11T13:05:24+00:00,,0-wiz-0,"04 - Documentation, component: SIMD",1,"PR#28451 - doc/source/reference/simd/build-options.rst: @@ -98,7 +98,7 @@ You may have some reservations about including of ``AVX512`` or|;| any other CPU feature and you want to exclude from the dispatched features::|;| |;|     python -m build --wheel -Csetup-args=-Dcpu-dispatch=""max -avx512f -avx512cd \|;|-    -avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl""|;|+    -avx512_knl -avx512_knm -avx512_skx -avx512_clx -avx512_cnl -avx512_icl -avx512_spr""|;| |;| .. _opt-supported-features:|;| ",Documentation Edit: Add -avx512_spr to disable AVX512 in build options
numpy/numpy,seberg,28434,DOC: PyArray_CHKFLAGS protorype is wrong in the documentation,"### Issue with current documentation:

PyArray_CHKFLAGS is shown to receive a `PyObject *` argument in the documentation, but the actual function prototype is `PyArray_CHKFLAGS(const PyArrayObject *arr, int flags)`

![Image](https://github.com/user-attachments/assets/c0328370-bdfb-4a08-9e64-e80cae7f5299)

This results in failed compilation (please see this example https://github.com/danielhrisca/asammdf/actions/runs/13681474652/job/38254696040)

As a result I think all the macros that are built using PyArray_CHKFLAGS have wrong prototypes in the documentation

### Idea or request for content:

_No response_","Would you like to open a PR to correct the docs?

https://github.com/numpy/numpy/blob/01e98f1098a8a40df80bda98a3e8ea714b979010/doc/source/reference/c-api/array.rst?plain=1#L1549 || I've made a PR to fix this, I hope it's ok",closed,2025-03-05T17:25:53+00:00,2025-03-07T15:28:38+00:00,danielhrisca,04 - Documentation,1,"PR#28437 - doc/source/reference/c-api/array.rst: @@ -1546,7 +1546,7 @@ Flag checking|;| For all of these macros *arr* must be an instance of a (subclass of)|;| :c:data:`PyArray_Type`.|;| |;|-.. c:function:: int PyArray_CHKFLAGS(PyObject *arr, int flags)|;|+.. c:function:: int PyArray_CHKFLAGS(const PyArrayObject *arr, int flags)|;| |;|     The first parameter, arr, must be an ndarray or subclass. The|;|     parameter, *flags*, should be an integer consisting of bitwise|;|@@ -1555,60 +1555,60 @@ For all of these macros *arr* must be an instance of a (subclass of)|;|     :c:data:`NPY_ARRAY_OWNDATA`, :c:data:`NPY_ARRAY_ALIGNED`,|;|     :c:data:`NPY_ARRAY_WRITEABLE`, :c:data:`NPY_ARRAY_WRITEBACKIFCOPY`.|;| |;|-.. c:function:: int PyArray_IS_C_CONTIGUOUS(PyObject *arr)|;|+.. c:function:: int PyArray_IS_C_CONTIGUOUS(const PyArrayObject *arr)|;| |;|     Evaluates true if *arr* is C-style contiguous.|;| |;|-.. c:function:: int PyArray_IS_F_CONTIGUOUS(PyObject *arr)|;|+.. c:function:: int PyArray_IS_F_CONTIGUOUS(const PyArrayObject *arr)|;| |;|     Evaluates true if *arr* is Fortran-style contiguous.|;| |;|-.. c:function:: int PyArray_ISFORTRAN(PyObject *arr)|;|+.. c:function:: int PyArray_ISFORTRAN(const PyArrayObject *arr)|;| |;|     Evaluates true if *arr* is Fortran-style contiguous and *not*|;|     C-style contiguous. :c:func:`PyArray_IS_F_CONTIGUOUS`|;|     is the correct way to test for Fortran-style contiguity.|;| |;|-.. c:function:: int PyArray_ISWRITEABLE(PyObject *arr)|;|+.. c:function:: int PyArray_ISWRITEABLE(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* can be written to|;| |;|-.. c:function:: int PyArray_ISALIGNED(PyObject *arr)|;|+.. c:function:: int PyArray_ISALIGNED(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is properly aligned on|;|     the machine.|;| |;|-.. c:function:: int PyArray_ISBEHAVED(PyObject *arr)|;|+.. c:function:: int PyArray_ISBEHAVED(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is aligned and writeable|;|     and in machine byte-order according to its descriptor.|;| |;|-.. c:function:: int PyArray_ISBEHAVED_RO(PyObject *arr)|;|+.. c:function:: int PyArray_ISBEHAVED_RO(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is aligned and in machine|;|     byte-order.|;| |;|-.. c:function:: int PyArray_ISCARRAY(PyObject *arr)|;|+.. c:function:: int PyArray_ISCARRAY(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is C-style contiguous,|;|     and :c:func:`PyArray_ISBEHAVED` (*arr*) is true.|;| |;|-.. c:function:: int PyArray_ISFARRAY(PyObject *arr)|;|+.. c:function:: int PyArray_ISFARRAY(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is Fortran-style|;|     contiguous and :c:func:`PyArray_ISBEHAVED` (*arr*) is true.|;| |;|-.. c:function:: int PyArray_ISCARRAY_RO(PyObject *arr)|;|+.. c:function:: int PyArray_ISCARRAY_RO(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is C-style contiguous,|;|     aligned, and in machine byte-order.|;| |;|-.. c:function:: int PyArray_ISFARRAY_RO(PyObject *arr)|;|+.. c:function:: int PyArray_ISFARRAY_RO(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* is Fortran-style|;|     contiguous, aligned, and in machine byte-order **.**|;| |;|-.. c:function:: int PyArray_ISONESEGMENT(PyObject *arr)|;|+.. c:function:: int PyArray_ISONESEGMENT(const PyArrayObject *arr)|;| |;|     Evaluates true if the data area of *arr* consists of a single|;|     (C-style or Fortran-style) contiguous segment.","DOC: fix documentation for Flag checking functions and macros

the array argument type should be PyArrayObject instead of PyObject

See #28434 || use ""const PyArrayObject *"" for all the flag checking functions as requested in the PR review || Update doc/source/reference/c-api/array.rst"
numpy/numpy,ngoldbaum,28412,BUG: cp313t-win32 wheel tests are failing on main,"cp313t-win32 wheel tests are failing on main as can be seen in https://github.com/numpy/numpy/actions/runs/13611418851
","Thanks for pointing that out @mayeut!

The single failure is:
```
worker 'gw0' crashed while running '_core/tests/test_multithreading.py::test_legacy_usertype_cast_init_thread_safety'
...
  =========================== short test summary info ===========================
  FAILED _core/tests/test_multithreading.py::test_legacy_usertype_cast_init_thread_safety
  1 failed, 48659 passed, 1938 skipped, 30 xfailed, 5 xpassed in 1942.64s (0:32:22)
```

The test was already tweaked once for 32-bit Linux with a ""couldn't spawn enough threads"" code comment. So it may just need to be disabled or made less aggressive on all 32-bit systems. @ngoldbaum could you have a look?",closed,2025-03-02T07:57:53+00:00,2025-03-03T20:42:57+00:00,mayeut,"00 - Bug, 39 - free-threading",2,"PR#28421 - numpy/_core/tests/test_array_coercion.py: @@ -14,7 +14,8 @@|;| from numpy._core._rational_tests import rational|;| |;| from numpy.testing import (|;|-    assert_array_equal, assert_warns, IS_PYPY)|;|+    assert_array_equal, assert_warns, IS_PYPY, IS_64BIT|;|+)|;| |;| |;| def arraylikes():|;|@@ -718,8 +719,7 @@ def __array__(self, dtype=None, copy=None):|;|         arr = np.array([ArrayLike])|;|         assert arr[0] is ArrayLike|;| |;|-    @pytest.mark.skipif(|;|-            np.dtype(np.intp).itemsize < 8, reason=""Needs 64bit platform"")|;|+    @pytest.mark.skipif(not IS_64BIT, reason=""Needs 64bit platform"")|;|     def test_too_large_array_error_paths(self):|;|         """"""Test the error paths, including for memory leaks""""""|;|         arr = np.array(0, dtype=""uint8"") || PR#28421 - numpy/_core/tests/test_multiarray.py: @@ -30,7 +30,7 @@|;|     assert_array_equal, assert_raises_regex, assert_array_almost_equal,|;|     assert_allclose, IS_PYPY, IS_WASM, IS_PYSTON, HAS_REFCOUNT,|;|     assert_array_less, runstring, temppath, suppress_warnings, break_cycles,|;|-    check_support_sve, assert_array_compare,|;|+    check_support_sve, assert_array_compare, IS_64BIT|;|     )|;| from numpy.testing._private.utils import requires_memory, _no_tracing|;| from numpy._core.tests._locales import CommaDecimalPointLocale|;|@@ -978,7 +978,7 @@ def test_too_big_error(self):|;|         assert_raises(ValueError, np.zeros, shape, dtype=np.int8)|;|         assert_raises(ValueError, np.ones, shape, dtype=np.int8)|;| |;|-    @pytest.mark.skipif(np.dtype(np.intp).itemsize != 8,|;|+    @pytest.mark.skipif(not IS_64BIT,|;|                         reason=""malloc may not fail on 32 bit systems"")|;|     def test_malloc_fails(self):|;|         # This test is guaranteed to fail due to a too large allocation || PR#28421 - numpy/_core/tests/test_multithreading.py: @@ -5,7 +5,7 @@|;| import numpy as np|;| import pytest|;| |;|-from numpy.testing import IS_WASM|;|+from numpy.testing import IS_WASM, IS_64BIT|;| from numpy.testing._private.utils import run_threaded|;| from numpy._core import _rational_tests|;| |;|@@ -257,20 +257,16 @@ def func(arr):|;|             f.result()|;| |;| |;|+@pytest.mark.skipif(|;|+    not IS_64BIT,|;|+    reason=""Sometimes causes failures or crashes due to OOM on 32 bit runners""|;|+)|;| def test_legacy_usertype_cast_init_thread_safety():|;|     def closure(b):|;|         b.wait()|;|         np.full((10, 10), 1, _rational_tests.rational)|;| |;|-    try:|;|-        run_threaded(closure, 250, pass_barrier=True)|;|-    except RuntimeError:|;|-        # The 32 bit linux runner will trigger this with 250 threads. I can|;|-        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|-        # more resource-constrained.|;|-        # Reducing the number of threads means the test doesn't trigger the|;|-        # bug. Better to skip on some platforms than add a useless test.|;|-        pytest.skip(""Couldn't spawn enough threads to run the test"")|;|+    run_threaded(closure, 250, pass_barrier=True)|;| |;| @pytest.mark.parametrize(""dtype"", [bool, int, float])|;| def test_nonzero(dtype): || PR#28421 - numpy/_core/tests/test_regression.py: @@ -14,7 +14,8 @@|;|         assert_, assert_equal, IS_PYPY, assert_almost_equal,|;|         assert_array_equal, assert_array_almost_equal, assert_raises,|;|         assert_raises_regex, assert_warns, suppress_warnings,|;|-        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON, IS_WASM|;|+        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON, IS_WASM,|;|+        IS_64BIT,|;|         )|;| from numpy.testing._private.utils import _no_tracing, requires_memory|;| from numpy._utils import asbytes, asunicode|;|@@ -2264,7 +2265,7 @@ def test_void_compare_segfault(self):|;|     def test_reshape_size_overflow(self):|;|         # gh-7455|;|         a = np.ones(20)[::2]|;|-        if np.dtype(np.intp).itemsize == 8:|;|+        if IS_64BIT:|;|             # 64 bit. The following are the prime factors of 2**63 + 5,|;|             # plus a leading 2, so when multiplied together as int64,|;|             # the result overflows to a total size of 10. || PR#28421 - numpy/f2py/tests/test_return_real.py: @@ -1,8 +1,8 @@|;| import platform|;| import pytest|;|-import numpy as np|;| |;| from numpy import array|;|+from numpy.testing import IS_64BIT|;| from . import util|;| |;| |;|@@ -53,8 +53,7 @@ def check_function(self, t, tname):|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| class TestCReturnReal(TestReturnReal):|;|     suffix = "".pyf"" || PR#28421 - numpy/f2py/tests/test_semicolon_split.py: @@ -1,6 +1,7 @@|;| import platform|;| import pytest|;|-import numpy as np|;|+|;|+from numpy.testing import IS_64BIT|;| |;| from . import util|;| |;|@@ -11,8 +12,7 @@|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| class TestMultiline(util.F2PyTest):|;|     suffix = "".pyf""|;|@@ -44,8 +44,7 @@ def test_multiline(self):|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| @pytest.mark.slow|;| class TestCallstatement(util.F2PyTest): || PR#28421 - numpy/lib/tests/test_format.py: @@ -283,7 +283,7 @@|;| import numpy as np|;| from numpy.testing import (|;|     assert_, assert_array_equal, assert_raises, assert_raises_regex,|;|-    assert_warns, IS_PYPY, IS_WASM|;|+    assert_warns, IS_PYPY, IS_WASM, IS_64BIT|;|     )|;| from numpy.testing._private.utils import requires_memory|;| from numpy.lib import format|;|@@ -926,8 +926,7 @@ def test_large_file_support(tmpdir):|;| |;| |;| @pytest.mark.skipif(IS_PYPY, reason=""flaky on PyPy"")|;|-@pytest.mark.skipif(np.dtype(np.intp).itemsize < 8,|;|-                    reason=""test requires 64-bit system"")|;|+@pytest.mark.skipif(not IS_64BIT, reason=""test requires 64-bit system"")|;| @pytest.mark.slow|;| @requires_memory(free_bytes=2 * 2**30)|;| def test_large_archive(tmpdir): || PR#28421 - numpy/testing/_private/utils.py: @@ -45,7 +45,7 @@|;|         'HAS_REFCOUNT', ""IS_WASM"", 'suppress_warnings', 'assert_array_compare',|;|         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',|;|         'IS_MUSL', 'check_support_sve', 'NOGIL_BUILD',|;|-        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded',|;|+        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded', 'IS_64BIT',|;|         ]|;| |;| |;|@@ -104,6 +104,7 @@ class KnownFailureException(Exception):|;|     IS_MUSL = True|;| |;| NOGIL_BUILD = bool(sysconfig.get_config_var(""Py_GIL_DISABLED""))|;|+IS_64BIT = np.dtype(np.intp).itemsize == 8|;| |;| def assert_(val, msg=''):|;|     """""" || PR#28424 - numpy/_core/tests/test_array_coercion.py: @@ -14,7 +14,8 @@|;| from numpy._core._rational_tests import rational|;| |;| from numpy.testing import (|;|-    assert_array_equal, assert_warns, IS_PYPY)|;|+    assert_array_equal, assert_warns, IS_PYPY, IS_64BIT|;|+)|;| |;| |;| def arraylikes():|;|@@ -716,8 +717,7 @@ def __array__(self, dtype=None, copy=None):|;|         arr = np.array([ArrayLike])|;|         assert arr[0] is ArrayLike|;| |;|-    @pytest.mark.skipif(|;|-            np.dtype(np.intp).itemsize < 8, reason=""Needs 64bit platform"")|;|+    @pytest.mark.skipif(not IS_64BIT, reason=""Needs 64bit platform"")|;|     def test_too_large_array_error_paths(self):|;|         """"""Test the error paths, including for memory leaks""""""|;|         arr = np.array(0, dtype=""uint8"") || PR#28424 - numpy/_core/tests/test_multiarray.py: @@ -30,7 +30,7 @@|;|     assert_array_equal, assert_raises_regex, assert_array_almost_equal,|;|     assert_allclose, IS_PYPY, IS_WASM, IS_PYSTON, HAS_REFCOUNT,|;|     assert_array_less, runstring, temppath, suppress_warnings, break_cycles,|;|-    check_support_sve, assert_array_compare,|;|+    check_support_sve, assert_array_compare, IS_64BIT|;|     )|;| from numpy.testing._private.utils import requires_memory, _no_tracing|;| from numpy._core.tests._locales import CommaDecimalPointLocale|;|@@ -983,7 +983,7 @@ def test_too_big_error(self):|;|         assert_raises(ValueError, np.zeros, shape, dtype=np.int8)|;|         assert_raises(ValueError, np.ones, shape, dtype=np.int8)|;| |;|-    @pytest.mark.skipif(np.dtype(np.intp).itemsize != 8,|;|+    @pytest.mark.skipif(not IS_64BIT,|;|                         reason=""malloc may not fail on 32 bit systems"")|;|     def test_malloc_fails(self):|;|         # This test is guaranteed to fail due to a too large allocation || PR#28424 - numpy/_core/tests/test_multithreading.py: @@ -5,7 +5,7 @@|;| import numpy as np|;| import pytest|;| |;|-from numpy.testing import IS_WASM|;|+from numpy.testing import IS_WASM, IS_64BIT|;| from numpy.testing._private.utils import run_threaded|;| from numpy._core import _rational_tests|;| |;|@@ -257,20 +257,16 @@ def func(arr):|;|             f.result()|;| |;| |;|+@pytest.mark.skipif(|;|+    not IS_64BIT,|;|+    reason=""Sometimes causes failures or crashes due to OOM on 32 bit runners""|;|+)|;| def test_legacy_usertype_cast_init_thread_safety():|;|     def closure(b):|;|         b.wait()|;|         np.full((10, 10), 1, _rational_tests.rational)|;| |;|-    try:|;|-        run_threaded(closure, 250, pass_barrier=True)|;|-    except RuntimeError:|;|-        # The 32 bit linux runner will trigger this with 250 threads. I can|;|-        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|-        # more resource-constrained.|;|-        # Reducing the number of threads means the test doesn't trigger the|;|-        # bug. Better to skip on some platforms than add a useless test.|;|-        pytest.skip(""Couldn't spawn enough threads to run the test"")|;|+    run_threaded(closure, 250, pass_barrier=True)|;| |;| @pytest.mark.parametrize(""dtype"", [bool, int, float])|;| def test_nonzero(dtype): || PR#28424 - numpy/_core/tests/test_regression.py: @@ -14,7 +14,8 @@|;|         assert_, assert_equal, IS_PYPY, assert_almost_equal,|;|         assert_array_equal, assert_array_almost_equal, assert_raises,|;|         assert_raises_regex, assert_warns, suppress_warnings,|;|-        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON, IS_WASM|;|+        _assert_valid_refcount, HAS_REFCOUNT, IS_PYSTON, IS_WASM,|;|+        IS_64BIT,|;|         )|;| from numpy.testing._private.utils import _no_tracing, requires_memory|;| from numpy._utils import asbytes, asunicode|;|@@ -2265,7 +2266,7 @@ def test_void_compare_segfault(self):|;|     def test_reshape_size_overflow(self):|;|         # gh-7455|;|         a = np.ones(20)[::2]|;|-        if np.dtype(np.intp).itemsize == 8:|;|+        if IS_64BIT:|;|             # 64 bit. The following are the prime factors of 2**63 + 5,|;|             # plus a leading 2, so when multiplied together as int64,|;|             # the result overflows to a total size of 10. || PR#28424 - numpy/f2py/tests/test_return_real.py: @@ -1,8 +1,8 @@|;| import platform|;| import pytest|;|-import numpy as np|;| |;| from numpy import array|;|+from numpy.testing import IS_64BIT|;| from . import util|;| |;| |;|@@ -53,8 +53,7 @@ def check_function(self, t, tname):|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| class TestCReturnReal(TestReturnReal):|;|     suffix = "".pyf"" || PR#28424 - numpy/f2py/tests/test_semicolon_split.py: @@ -1,6 +1,7 @@|;| import platform|;| import pytest|;|-import numpy as np|;|+|;|+from numpy.testing import IS_64BIT|;| |;| from . import util|;| |;|@@ -11,8 +12,7 @@|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| class TestMultiline(util.F2PyTest):|;|     suffix = "".pyf""|;|@@ -44,8 +44,7 @@ def test_multiline(self):|;|     ""but not when run in isolation"",|;| )|;| @pytest.mark.skipif(|;|-    np.dtype(np.intp).itemsize < 8,|;|-    reason=""32-bit builds are buggy""|;|+    not IS_64BIT, reason=""32-bit builds are buggy""|;| )|;| @pytest.mark.slow|;| class TestCallstatement(util.F2PyTest): || PR#28424 - numpy/lib/tests/test_format.py: @@ -283,7 +283,7 @@|;| import numpy as np|;| from numpy.testing import (|;|     assert_, assert_array_equal, assert_raises, assert_raises_regex,|;|-    assert_warns, IS_PYPY, IS_WASM|;|+    assert_warns, IS_PYPY, IS_WASM, IS_64BIT|;|     )|;| from numpy.testing._private.utils import requires_memory|;| from numpy.lib import format|;|@@ -927,8 +927,7 @@ def test_large_file_support(tmpdir):|;| |;| |;| @pytest.mark.skipif(IS_PYPY, reason=""flaky on PyPy"")|;|-@pytest.mark.skipif(np.dtype(np.intp).itemsize < 8,|;|-                    reason=""test requires 64-bit system"")|;|+@pytest.mark.skipif(not IS_64BIT, reason=""test requires 64-bit system"")|;| @pytest.mark.slow|;| @requires_memory(free_bytes=2 * 2**30)|;| def test_large_archive(tmpdir): || PR#28424 - numpy/testing/_private/utils.py: @@ -46,7 +46,7 @@|;|         'HAS_REFCOUNT', ""IS_WASM"", 'suppress_warnings', 'assert_array_compare',|;|         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',|;|         'IS_MUSL', 'check_support_sve', 'NOGIL_BUILD',|;|-        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded',|;|+        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded', 'IS_64BIT',|;|         ]|;| |;| |;|@@ -105,6 +105,7 @@ class KnownFailureException(Exception):|;|     IS_MUSL = True|;| |;| NOGIL_BUILD = bool(sysconfig.get_config_var(""Py_GIL_DISABLED""))|;|+IS_64BIT = np.dtype(np.intp).itemsize == 8|;| |;| def assert_(val, msg=''):|;|     """"""","TST: add new IS_64BIT constant for testing || BUG: skip legacy dtype multithreaded test on 32 bit runners

[wheel build] || TST: add new IS_64BIT constant for testing || BUG: skip legacy dtype multithreaded test on 32 bit runners

[wheel build]"
numpy/numpy,mayeut,28405,NumPy build segfaults on PPC64LE CI,"See e.g. [this CI run](https://github.com/numpy/numpy/actions/runs/13594514623/job/38008217836). This started happening in the last day or two.

```
44/384] Compiling C object numpy/_core/_struct_ufunc_tests.cpython-310-powerpc64le-linux-gnu.so.p/src_umath__struct_ufunc_tests.c.o
[45/384] Linking static target numpy/_core/lib_umath_tests_mtargets.a
FAILED: numpy/_core/lib_umath_tests_mtargets.a 
rm -f numpy/_core/lib_umath_tests_mtargets.a && gcc-ar csrDT numpy/_core/lib_umath_tests_mtargets.a numpy/_core/lib_umath_tests.dispatch.h_baseline.a.p/src_umath__umath_tests.dispatch.c.o numpy/_core/lib_umath_tests.dispatch.h_VSX3.a.p/src_umath__umath_tests.dispatch.c.o
Segmentation fault (core dumped)
```

It looks like the linker segfaults? Maybe a QEMU emulation bug?","s390x is also failing: https://github.com/numpy/numpy/actions/runs/13612579137
",closed,2025-02-28T19:01:54+00:00,2025-03-02T10:22:32+00:00,ngoldbaum,,2,"PR#28423 - .github/workflows/linux_qemu.yml: @@ -14,6 +14,7 @@ on:|;|     branches:|;|       - main|;|       - maintenance/**|;|+  workflow_dispatch:|;| |;| defaults:|;|   run:|;|@@ -28,8 +29,9 @@ permissions:|;| |;| jobs:|;|   linux_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-22.04|;|     continue-on-error: true|;|     strategy:|;|@@ -107,7 +109,8 @@ jobs:|;| |;|     - name: Initialize binfmt_misc for qemu-user-static|;|       run: ||;|-        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes|;|+        # see https://hub.docker.com/r/tonistiigi/binfmt for available versions|;|+        docker run --rm --privileged tonistiigi/binfmt:qemu-v9.2.2-52 --install all|;| |;|     - name: Install GCC cross-compilers|;|       run: ||;|@@ -176,4 +179,3 @@ jobs:|;|             cd /numpy && spin test -- -k \""${RUNTIME_TEST_FILTER}\""|;|           '""|;| |;|- || PR#28411 - .github/workflows/linux_qemu.yml: @@ -14,6 +14,7 @@ on:|;|     branches:|;|       - main|;|       - maintenance/**|;|+  workflow_dispatch:|;| |;| defaults:|;|   run:|;|@@ -28,8 +29,9 @@ permissions:|;| |;| jobs:|;|   linux_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-22.04|;|     continue-on-error: true|;|     strategy:|;|@@ -108,7 +110,8 @@ jobs:|;| |;|     - name: Initialize binfmt_misc for qemu-user-static|;|       run: ||;|-        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes|;|+        # see https://hub.docker.com/r/tonistiigi/binfmt for available versions|;|+        docker run --rm --privileged tonistiigi/binfmt:qemu-v9.2.2-52 --install all|;| |;|     - name: Install GCC cross-compilers|;|       run: ||;|@@ -179,8 +182,9 @@ jobs:|;| |;| |;|   linux_loongarch64_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-24.04|;|     continue-on-error: true|;|     strategy:","CI: use QEMU 9.2.2 for Linux Qemu tests

Following a kernel update on GHA runners, QEMU tests are failing randomly.
Update the version of QEMU used in order to fix the random segfauls. || Update .github/workflows/linux_qemu.yml || Update linux_qemu.yml || CI: use QEMU 9.2.2 for Linux Qemu tests

Following a kernel update on GHA runners, QEMU tests are failing randomly.
Update the version of QEMU used in order to fix the random segfauls. || Update .github/workflows/linux_qemu.yml || Update linux_qemu.yml"
numpy/numpy,andyfaff,28405,NumPy build segfaults on PPC64LE CI,"See e.g. [this CI run](https://github.com/numpy/numpy/actions/runs/13594514623/job/38008217836). This started happening in the last day or two.

```
44/384] Compiling C object numpy/_core/_struct_ufunc_tests.cpython-310-powerpc64le-linux-gnu.so.p/src_umath__struct_ufunc_tests.c.o
[45/384] Linking static target numpy/_core/lib_umath_tests_mtargets.a
FAILED: numpy/_core/lib_umath_tests_mtargets.a 
rm -f numpy/_core/lib_umath_tests_mtargets.a && gcc-ar csrDT numpy/_core/lib_umath_tests_mtargets.a numpy/_core/lib_umath_tests.dispatch.h_baseline.a.p/src_umath__umath_tests.dispatch.c.o numpy/_core/lib_umath_tests.dispatch.h_VSX3.a.p/src_umath__umath_tests.dispatch.c.o
Segmentation fault (core dumped)
```

It looks like the linker segfaults? Maybe a QEMU emulation bug?","s390x is also failing: https://github.com/numpy/numpy/actions/runs/13612579137
",closed,2025-02-28T19:01:54+00:00,2025-03-02T10:22:32+00:00,ngoldbaum,,2,"PR#28423 - .github/workflows/linux_qemu.yml: @@ -14,6 +14,7 @@ on:|;|     branches:|;|       - main|;|       - maintenance/**|;|+  workflow_dispatch:|;| |;| defaults:|;|   run:|;|@@ -28,8 +29,9 @@ permissions:|;| |;| jobs:|;|   linux_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-22.04|;|     continue-on-error: true|;|     strategy:|;|@@ -107,7 +109,8 @@ jobs:|;| |;|     - name: Initialize binfmt_misc for qemu-user-static|;|       run: ||;|-        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes|;|+        # see https://hub.docker.com/r/tonistiigi/binfmt for available versions|;|+        docker run --rm --privileged tonistiigi/binfmt:qemu-v9.2.2-52 --install all|;| |;|     - name: Install GCC cross-compilers|;|       run: ||;|@@ -176,4 +179,3 @@ jobs:|;|             cd /numpy && spin test -- -k \""${RUNTIME_TEST_FILTER}\""|;|           '""|;| |;|- || PR#28411 - .github/workflows/linux_qemu.yml: @@ -14,6 +14,7 @@ on:|;|     branches:|;|       - main|;|       - maintenance/**|;|+  workflow_dispatch:|;| |;| defaults:|;|   run:|;|@@ -28,8 +29,9 @@ permissions:|;| |;| jobs:|;|   linux_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-22.04|;|     continue-on-error: true|;|     strategy:|;|@@ -108,7 +110,8 @@ jobs:|;| |;|     - name: Initialize binfmt_misc for qemu-user-static|;|       run: ||;|-        docker run --rm --privileged multiarch/qemu-user-static --reset -p yes|;|+        # see https://hub.docker.com/r/tonistiigi/binfmt for available versions|;|+        docker run --rm --privileged tonistiigi/binfmt:qemu-v9.2.2-52 --install all|;| |;|     - name: Install GCC cross-compilers|;|       run: ||;|@@ -179,8 +182,9 @@ jobs:|;| |;| |;|   linux_loongarch64_qemu:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|+    # Only workflow_dispatch is enabled on forks.|;|+    # To enable this job and subsequent jobs on a fork for other events, comment out:|;|+    if: github.repository == 'numpy/numpy' || github.event_name == 'workflow_dispatch'|;|     runs-on: ubuntu-24.04|;|     continue-on-error: true|;|     strategy:","CI: use QEMU 9.2.2 for Linux Qemu tests

Following a kernel update on GHA runners, QEMU tests are failing randomly.
Update the version of QEMU used in order to fix the random segfauls. || Update .github/workflows/linux_qemu.yml || Update linux_qemu.yml || CI: use QEMU 9.2.2 for Linux Qemu tests

Following a kernel update on GHA runners, QEMU tests are failing randomly.
Update the version of QEMU used in order to fix the random segfauls. || Update .github/workflows/linux_qemu.yml || Update linux_qemu.yml"
numpy/numpy,tylerjereddy,28354,BUG: `np.bincount` casting `uint64` to `int64`,"### Describe the issue:

When passing a `uint64` array to `np.bincount`, it appears to try to cast the input (or some internally created array) to `int64`. This in turn raises an exception.

### Reproduce the code example:

```python
import numpy as np

a = np.arange(64, dtype=np.uint64)
np.bincount(a)
```

### Error message:

```python
Traceback (most recent call last):
  File ""..."", line 4, in <module>
    np.bincount(a)
TypeError: Cannot cast array data from dtype('uint64') to dtype('int64') according to the rule 'safe'
```

### Python and NumPy Versions:

```
2.2.2
3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:32:50) [Clang 16.0.6 ]
```

### Runtime Environment:

```python
[{'numpy_version': '2.2.2',
  'python': '3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:32:50) '
            '[Clang 16.0.6 ]',
  'uname': uname_result(system='Darwin', node='jkirkham-mlt', release='23.6.0', version='Darwin Kernel Version 23.6.0: Thu Sep 12 23:35:29 PDT 2024; root:xnu-10063.141.1.701.1~1/RELEASE_ARM64_T6000', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}},
 {'architecture': 'VORTEX',
  'filepath': '/Users/jkirkham/miniforge/lib/libopenblas.0.dylib',
  'internal_api': 'openblas',
  'num_threads': 10,
  'prefix': 'libopenblas',
  'threading_layer': 'openmp',
  'user_api': 'blas',
  'version': '0.3.28'},
 {'filepath': '/Users/jkirkham/miniforge/lib/libomp.dylib',
  'internal_api': 'openmp',
  'num_threads': 10,
  'prefix': 'libomp',
  'user_api': 'openmp',
  'version': None}]
```

### Context for the issue:

_No response_","Just to check - is this a regression? || >  is this a regression?

It  is also true for NumPy 1.26.4, so I suspect it has been around for a while.",closed,2025-02-18T22:03:25+00:00,2025-03-03T14:31:31+00:00,jakirkham,"00 - Bug, sprintable - C",1,"PR#28355 - numpy/_core/src/multiarray/compiled_base.c: @@ -150,8 +150,12 @@ arr_bincount(PyObject *NPY_UNUSED(self), PyObject *const *args,|;|         }|;|         if (PyArray_SIZE(tmp1) > 0) {|;|             /* The input is not empty, so convert it to NPY_INTP. */|;|-            lst = (PyArrayObject *)PyArray_ContiguousFromAny((PyObject *)tmp1,|;|-                                                             NPY_INTP, 1, 1)|;|;+            int flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_C_CONTIGUOUS|;|;+            if (PyArray_ISINTEGER(tmp1)) {|;|+                flags = flags | NPY_ARRAY_FORCECAST|;|;+            }|;|+            PyArray_Descr* local_dtype = PyArray_DescrFromType(NPY_INTP)|;|;+            lst = (PyArrayObject *)PyArray_FromAny((PyObject *)tmp1, local_dtype, 1, 1, flags, NULL)|;|;             Py_DECREF(tmp1)|;|;             if (lst == NULL) {|;|                 /* Failed converting to NPY_INTP. */|;|@@ -177,7 +181,13 @@ arr_bincount(PyObject *NPY_UNUSED(self), PyObject *const *args,|;|     }|;| |;|     if (lst == NULL) {|;|-        lst = (PyArrayObject *)PyArray_ContiguousFromAny(list, NPY_INTP, 1, 1)|;|;+        int flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_C_CONTIGUOUS|;|;+        if (PyArray_Check((PyObject *)list) &&|;|+            PyArray_ISINTEGER((PyArrayObject *)list)) {|;|+            flags = flags | NPY_ARRAY_FORCECAST|;|;+        }|;|+        PyArray_Descr* local_dtype = PyArray_DescrFromType(NPY_INTP)|;|;+        lst = (PyArrayObject *)PyArray_FromAny(list, local_dtype, 1, 1, flags, NULL)|;|;         if (lst == NULL) {|;|             goto fail|;|;         } || PR#28355 - numpy/lib/tests/test_function_base.py: @@ -2959,6 +2959,27 @@ def test_error_not_1d(self, vals):|;|         with assert_raises(ValueError):|;|             np.bincount(vals)|;| |;|+    @pytest.mark.parametrize(""dt"", np.typecodes[""AllInteger""])|;|+    def test_gh_28354(self, dt):|;|+        a = np.array([0, 1, 1, 3, 2, 1, 7], dtype=dt)|;|+        actual = np.bincount(a)|;|+        expected = [1, 3, 1, 1, 0, 0, 0, 1]|;|+        assert_array_equal(actual, expected)|;|+|;|+    def test_contiguous_handling(self):|;|+        # check for absence of hard crash|;|+        np.bincount(np.arange(10000)[::2])|;|+|;|+    def test_gh_28354_array_like(self):|;|+        class A:|;|+            def __array__(self):|;|+                return np.array([0, 1, 1, 3, 2, 1, 7], dtype=np.uint64)|;|+|;|+        a = A()|;|+        actual = np.bincount(a)|;|+        expected = [1, 3, 1, 1, 0, 0, 0, 1]|;|+        assert_array_equal(actual, expected)|;|+|;| |;| class TestInterp:|;| ","BUG: safer bincount casting

* Fixes #28354

* Force usage of `npy_intp` type in `np.bincount()` and avoid
unsafe casting errors with i.e., `npy_uint64`. This is similar
to our behavior with indexing. || MAINT, BUG: PR 28355 revisions

* `arr_bincount()` now only uses unsafe casting for integer
input types, and the number of casting operations has
been reduced for the code path used in above PR.

* a test for non-crashing behavior with non-contiguous
`bincount()` input has been added. || MAINT, BUG: PR 28355 revisions

* Based on reviewer feedback, narrow the scope of the `flags`
variable in `arr_bincount()`.

* Based on reviewer feedback, add an array-like test for the `uint64`
casting issue, which indeed fails before and passes after adding
a similar shim to the array-like code path in `arr_bincount()`.

* Based on reviewer feedback, switch the patching from `PyArray_Size`
to `PyArray_Check` in a few places. || Update numpy/_core/src/multiarray/compiled_base.c"
numpy/numpy,seberg,28354,BUG: `np.bincount` casting `uint64` to `int64`,"### Describe the issue:

When passing a `uint64` array to `np.bincount`, it appears to try to cast the input (or some internally created array) to `int64`. This in turn raises an exception.

### Reproduce the code example:

```python
import numpy as np

a = np.arange(64, dtype=np.uint64)
np.bincount(a)
```

### Error message:

```python
Traceback (most recent call last):
  File ""..."", line 4, in <module>
    np.bincount(a)
TypeError: Cannot cast array data from dtype('uint64') to dtype('int64') according to the rule 'safe'
```

### Python and NumPy Versions:

```
2.2.2
3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:32:50) [Clang 16.0.6 ]
```

### Runtime Environment:

```python
[{'numpy_version': '2.2.2',
  'python': '3.12.5 | packaged by conda-forge | (main, Aug  8 2024, 18:32:50) '
            '[Clang 16.0.6 ]',
  'uname': uname_result(system='Darwin', node='jkirkham-mlt', release='23.6.0', version='Darwin Kernel Version 23.6.0: Thu Sep 12 23:35:29 PDT 2024; root:xnu-10063.141.1.701.1~1/RELEASE_ARM64_T6000', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}},
 {'architecture': 'VORTEX',
  'filepath': '/Users/jkirkham/miniforge/lib/libopenblas.0.dylib',
  'internal_api': 'openblas',
  'num_threads': 10,
  'prefix': 'libopenblas',
  'threading_layer': 'openmp',
  'user_api': 'blas',
  'version': '0.3.28'},
 {'filepath': '/Users/jkirkham/miniforge/lib/libomp.dylib',
  'internal_api': 'openmp',
  'num_threads': 10,
  'prefix': 'libomp',
  'user_api': 'openmp',
  'version': None}]
```

### Context for the issue:

_No response_","Just to check - is this a regression? || >  is this a regression?

It  is also true for NumPy 1.26.4, so I suspect it has been around for a while.",closed,2025-02-18T22:03:25+00:00,2025-03-03T14:31:31+00:00,jakirkham,"00 - Bug, sprintable - C",1,"PR#28355 - numpy/_core/src/multiarray/compiled_base.c: @@ -150,8 +150,12 @@ arr_bincount(PyObject *NPY_UNUSED(self), PyObject *const *args,|;|         }|;|         if (PyArray_SIZE(tmp1) > 0) {|;|             /* The input is not empty, so convert it to NPY_INTP. */|;|-            lst = (PyArrayObject *)PyArray_ContiguousFromAny((PyObject *)tmp1,|;|-                                                             NPY_INTP, 1, 1)|;|;+            int flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_C_CONTIGUOUS|;|;+            if (PyArray_ISINTEGER(tmp1)) {|;|+                flags = flags | NPY_ARRAY_FORCECAST|;|;+            }|;|+            PyArray_Descr* local_dtype = PyArray_DescrFromType(NPY_INTP)|;|;+            lst = (PyArrayObject *)PyArray_FromAny((PyObject *)tmp1, local_dtype, 1, 1, flags, NULL)|;|;             Py_DECREF(tmp1)|;|;             if (lst == NULL) {|;|                 /* Failed converting to NPY_INTP. */|;|@@ -177,7 +181,13 @@ arr_bincount(PyObject *NPY_UNUSED(self), PyObject *const *args,|;|     }|;| |;|     if (lst == NULL) {|;|-        lst = (PyArrayObject *)PyArray_ContiguousFromAny(list, NPY_INTP, 1, 1)|;|;+        int flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_ALIGNED | NPY_ARRAY_C_CONTIGUOUS|;|;+        if (PyArray_Check((PyObject *)list) &&|;|+            PyArray_ISINTEGER((PyArrayObject *)list)) {|;|+            flags = flags | NPY_ARRAY_FORCECAST|;|;+        }|;|+        PyArray_Descr* local_dtype = PyArray_DescrFromType(NPY_INTP)|;|;+        lst = (PyArrayObject *)PyArray_FromAny(list, local_dtype, 1, 1, flags, NULL)|;|;         if (lst == NULL) {|;|             goto fail|;|;         } || PR#28355 - numpy/lib/tests/test_function_base.py: @@ -2959,6 +2959,27 @@ def test_error_not_1d(self, vals):|;|         with assert_raises(ValueError):|;|             np.bincount(vals)|;| |;|+    @pytest.mark.parametrize(""dt"", np.typecodes[""AllInteger""])|;|+    def test_gh_28354(self, dt):|;|+        a = np.array([0, 1, 1, 3, 2, 1, 7], dtype=dt)|;|+        actual = np.bincount(a)|;|+        expected = [1, 3, 1, 1, 0, 0, 0, 1]|;|+        assert_array_equal(actual, expected)|;|+|;|+    def test_contiguous_handling(self):|;|+        # check for absence of hard crash|;|+        np.bincount(np.arange(10000)[::2])|;|+|;|+    def test_gh_28354_array_like(self):|;|+        class A:|;|+            def __array__(self):|;|+                return np.array([0, 1, 1, 3, 2, 1, 7], dtype=np.uint64)|;|+|;|+        a = A()|;|+        actual = np.bincount(a)|;|+        expected = [1, 3, 1, 1, 0, 0, 0, 1]|;|+        assert_array_equal(actual, expected)|;|+|;| |;| class TestInterp:|;| ","BUG: safer bincount casting

* Fixes #28354

* Force usage of `npy_intp` type in `np.bincount()` and avoid
unsafe casting errors with i.e., `npy_uint64`. This is similar
to our behavior with indexing. || MAINT, BUG: PR 28355 revisions

* `arr_bincount()` now only uses unsafe casting for integer
input types, and the number of casting operations has
been reduced for the code path used in above PR.

* a test for non-crashing behavior with non-contiguous
`bincount()` input has been added. || MAINT, BUG: PR 28355 revisions

* Based on reviewer feedback, narrow the scope of the `flags`
variable in `arr_bincount()`.

* Based on reviewer feedback, add an array-like test for the `uint64`
casting issue, which indeed fails before and passes after adding
a similar shim to the array-like code path in `arr_bincount()`.

* Based on reviewer feedback, switch the patching from `PyArray_Size`
to `PyArray_Check` in a few places. || Update numpy/_core/src/multiarray/compiled_base.c"
numpy/numpy,f380cedric,28402,DOC: no mention of scimath submodule in the np.lib namescape changes under 2.0 migration guide,"### Issue with current documentation:

In the current 2.0 migration guide, under the changes around `np.lib`, there is a list of submodules kept under it.
https://github.com/numpy/numpy/blob/da268d45aab791023c8d953db6f4597019f770cb/doc/source/numpy_2_0_migration_guide.rst?plain=1#L362-L363
From my understanding, the list is exhaustive, but `scimath` is not mentioned (nor in the NEP).

### Idea or request for content:

Either mention the list is not exhaustive and provide a reference to the exhaustive list, or ensure the list is complete.","This appears to just be an oversight, a PR to add `scimath` to that listing is welcome.",closed,2025-02-28T10:07:51+00:00,2025-03-02T16:04:34+00:00,f380cedric,04 - Documentation,1,"PR#28413 - doc/source/numpy_2_0_migration_guide.rst: @@ -359,7 +359,7 @@ namespace, which is their primary location. To make it unambiguous how to access|;| public function, ``np.lib`` is now empty and contains only a handful of specialized submodules,|;| classes and functions:|;| |;|-- ``array_utils``, ``format``, ``introspect``, ``mixins``, ``npyio``|;|+- ``array_utils``, ``format``, ``introspect``, ``mixins``, ``npyio``, ``scimath``|;|   and ``stride_tricks`` submodules,|;| |;| - ``Arrayterator`` and ``NumpyVersion`` classes,","DOC: add scimath in np.lib submodules listing

Closes #28402."
numpy/numpy,seberg,22237,BUG: `choose` does an unnecessary cast of the initial `out` values,"### Describe the issue:

Choose (I think) always overwrites all values in the output.  It is thus unnecessary to cast a given `out` to the resulting dtype (if a cast is necesssary).

This can lead to spurious warnings as given in the below example

### Reproduce the code example:

```python
import numpy as np

a = np.arange(3)
b = np.ones((3, 3), dtype=np.int64)

out = np.array([np.nan, np.nan, np.nan])

np.choose(a, b, out=out)
```


### Error message:

```shell
/home/sebastian/forks/numpy/build/testenv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57: RuntimeWarning: invalid value encountered in cast
  return bound(*args, **kwds)
```


### NumPy/Python version information:

All versions up to 1.24-dev will do the unnecessary cast, but only the current dev gives the spurious warning.
(We have a typing test that could run into this randomly, although I am changing it in a different PR)

### Context for the issue:

_No response_","Hmm, I looked at this one for a bit, it definitely wasn't as simple as naively preserving the `dtype` of `out` in `obj` that gets assigned to. Such a strategy did allow me to pass the example above without a warning, but some other tests were really sensitive to a variety of issues related to memory overlap and some nasty tests where `byteorder` was different between some of the arrays involved. I tried detecting that and using `PyArray_Byteswap` but it didn't seem to help much.

I started messing around with `PyArray_Descr` tailored to specific purposes and it went about as well as you might expect. Maybe I'll circle back to this in the sprint tomorrow, but I definitely ended up in a situation where patching the immediate issue made other parts of the testsuite pretty unhappy. || I think the problem here isn't the new array/dtype.  We need the new array with writebackifcopy for casting.  But `PyArray_FromArray` copies the old array when necessary, while what we actually somewhat need is a new empty one (which we copy when we are done).

Not sure whats the best way to achieve this, maybe it needs a manual check or a new helper, unless some `out` values need to be preserved, that seems always better in principle.  If they do need to be preserved, things are a bit funny anyway, because allowing casts that are not safe is awkward.",closed,2022-09-09T11:24:16+00:00,2025-02-26T10:24:43+00:00,seberg,00 - Bug,1,"PR#28206 - numpy/_core/src/multiarray/item_selection.c: @@ -1028,6 +1028,7 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     }|;|     dtype = PyArray_DESCR(mps[0])|;|; |;|+    int copy_existing_out = 0|;|;     /* Set-up return array */|;|     if (out == NULL) {|;|         Py_INCREF(dtype)|;|;@@ -1039,10 +1040,6 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|                                                     (PyObject *)ap)|;|;     }|;|     else {|;|-        int flags = NPY_ARRAY_CARRAY ||;|-                    NPY_ARRAY_WRITEBACKIFCOPY ||;|-                    NPY_ARRAY_FORCECAST|;|;-|;|         if ((PyArray_NDIM(out) != multi->nd)|;|                     || !PyArray_CompareLists(PyArray_DIMS(out),|;|                                              multi->dimensions,|;|@@ -1052,9 +1049,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|             goto fail|;|;         }|;| |;|+        if (PyArray_FailUnlessWriteable(out, ""output array"") < 0) {|;|+            goto fail|;|;+        }|;|+|;|         for (i = 0; i < n; i++) {|;|             if (arrays_overlap(out, mps[i])) {|;|-                flags |= NPY_ARRAY_ENSURECOPY|;|;+                copy_existing_out = 1|;|;             }|;|         }|;| |;|@@ -1064,10 +1065,25 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|              * so the input array is not changed|;|              * before the error is called|;|              */|;|-            flags |= NPY_ARRAY_ENSURECOPY|;|;+            copy_existing_out = 1|;|;+        }|;|+|;|+        if (!PyArray_EquivTypes(dtype, PyArray_DESCR(out))) {|;|+            copy_existing_out = 1|;|;+        }|;|+|;|+        if (copy_existing_out) {|;|+            Py_INCREF(dtype)|;|;+            obj = (PyArrayObject *)PyArray_NewFromDescr(&PyArray_Type,|;|+                                                        dtype,|;|+                                                        multi->nd,|;|+                                                        multi->dimensions,|;|+                                                        NULL, NULL, 0,|;|+                                                        (PyObject *)out)|;|;+        }|;|+        else {|;|+            obj = (PyArrayObject *)Py_NewRef(out)|;|;         }|;|-        Py_INCREF(dtype)|;|;-        obj = (PyArrayObject *)PyArray_FromArray(out, dtype, flags)|;|;     }|;| |;|     if (obj == NULL) {|;|@@ -1080,12 +1096,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     NPY_ARRAYMETHOD_FLAGS transfer_flags = 0|;|;     if (PyDataType_REFCHK(dtype)) {|;|         int is_aligned = IsUintAligned(obj)|;|;+        PyArray_Descr *obj_dtype = PyArray_DESCR(obj)|;|;         PyArray_GetDTypeTransferFunction(|;|                     is_aligned,|;|                     dtype->elsize,|;|-                    dtype->elsize,|;|+                    obj_dtype->elsize,|;|                     dtype,|;|-                    dtype, 0, &cast_info,|;|+                    obj_dtype, 0, &cast_info,|;|                     &transfer_flags)|;|;     }|;| |;|@@ -1142,11 +1159,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     }|;|     Py_DECREF(ap)|;|;     PyDataMem_FREE(mps)|;|;-    if (out != NULL && out != obj) {|;|-        Py_INCREF(out)|;|;-        PyArray_ResolveWritebackIfCopy(obj)|;|;+    if (copy_existing_out) {|;|+        int res = PyArray_CopyInto(out, obj)|;|;         Py_DECREF(obj)|;|;-        obj = out|;|;+        if (res < 0) {|;|+            return NULL|;|;+        }|;|+        return Py_NewRef(out)|;|;     }|;|     return (PyObject *)obj|;|;  || PR#28206 - numpy/_core/tests/test_multiarray.py: @@ -1984,6 +1984,12 @@ def test_choose(self):|;|         y = np.choose([0, 0, 0], [x[:3], x[:3], x[:3]], out=x[1:4], mode='wrap')|;|         assert_equal(y, np.array([0, 1, 2]))|;| |;|+        # gh_28206 check fail when out not writeable|;|+        x = np.arange(3)|;|+        out = np.zeros(3)|;|+        out.setflags(write=False)|;|+        assert_raises(ValueError, np.choose, [0, 1, 2], [x, x, x], out=out)|;|+|;|     def test_prod(self):|;|         ba = [1, 2, 10, 11, 6, 5, 4]|;|         ba2 = [[1, 2, 3, 4], [5, 6, 7, 9], [10, 3, 4, 5]]|;|@@ -10223,6 +10229,16 @@ def test_gh_24459():|;|         np.choose(a, [3, -1])|;| |;| |;|+def test_gh_28206():|;|+    a = np.arange(3)|;|+    b = np.ones((3, 3), dtype=np.int64)|;|+    out = np.array([np.nan, np.nan, np.nan])|;|+|;|+    with warnings.catch_warnings():|;|+        warnings.simplefilter(""error"", RuntimeWarning)|;|+        np.choose(a, b, out=out)|;|+|;|+|;| @pytest.mark.parametrize(""N"", np.arange(2, 512))|;| @pytest.mark.parametrize(""dtype"", [np.int16, np.uint16,|;|                         np.int32, np.uint32, np.int64, np.uint64])",BUG: Remove unnecessary copying and casting from out array in PyArray_Choose || BUG: Add missing output dimension check in PyArray_Choose || Add test checking for spurious warning in np.choose || BUG: Add failure check to copying operation in np.choose || BUG: Add defensive comparison instead of equals for failure check || BUG: Revert changes || BUG: Add check in np.choose for different dtypes to create new array || BUG: Revert accidental changes || BUG: Revert accidental changes || Merge branch 'main' of https://github.com/numpy/numpy into bug/choose-unnecessary-cast || BUG: Revert accidental changes || BUG: Revert unnecessary changes || ENH: Add test for large array fast powers || BUG: Revert accidental changes || BUG: Adjust transfer function for cast in PyArray_Choose || TST: Add test for string casting in np.choose || TST: Add long string to np.choose for StringDType || BUG: Fix duplicate code cleanup in failure in np.choose || TST: Remove np.choose string test to be addressed in future || MAINT: Simplify array copying logic in np.choose || MAINT: Simplify output array handling in np.choose || MAINT: Change confusing variable name || MAINT: Remove unnecessary type in new array from descr || MAINT: Rename confusing variable || BUG: Fix incorrect error handling || BUG: Remove unnecessary variable assignment and clarify name || BUG: Remove reference increment not needed in conditional branch || TST: Check fail when out in np.choose not writeable || Apply suggestions from code review
numpy/numpy,MaanasArora,22237,BUG: `choose` does an unnecessary cast of the initial `out` values,"### Describe the issue:

Choose (I think) always overwrites all values in the output.  It is thus unnecessary to cast a given `out` to the resulting dtype (if a cast is necesssary).

This can lead to spurious warnings as given in the below example

### Reproduce the code example:

```python
import numpy as np

a = np.arange(3)
b = np.ones((3, 3), dtype=np.int64)

out = np.array([np.nan, np.nan, np.nan])

np.choose(a, b, out=out)
```


### Error message:

```shell
/home/sebastian/forks/numpy/build/testenv/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57: RuntimeWarning: invalid value encountered in cast
  return bound(*args, **kwds)
```


### NumPy/Python version information:

All versions up to 1.24-dev will do the unnecessary cast, but only the current dev gives the spurious warning.
(We have a typing test that could run into this randomly, although I am changing it in a different PR)

### Context for the issue:

_No response_","Hmm, I looked at this one for a bit, it definitely wasn't as simple as naively preserving the `dtype` of `out` in `obj` that gets assigned to. Such a strategy did allow me to pass the example above without a warning, but some other tests were really sensitive to a variety of issues related to memory overlap and some nasty tests where `byteorder` was different between some of the arrays involved. I tried detecting that and using `PyArray_Byteswap` but it didn't seem to help much.

I started messing around with `PyArray_Descr` tailored to specific purposes and it went about as well as you might expect. Maybe I'll circle back to this in the sprint tomorrow, but I definitely ended up in a situation where patching the immediate issue made other parts of the testsuite pretty unhappy. || I think the problem here isn't the new array/dtype.  We need the new array with writebackifcopy for casting.  But `PyArray_FromArray` copies the old array when necessary, while what we actually somewhat need is a new empty one (which we copy when we are done).

Not sure whats the best way to achieve this, maybe it needs a manual check or a new helper, unless some `out` values need to be preserved, that seems always better in principle.  If they do need to be preserved, things are a bit funny anyway, because allowing casts that are not safe is awkward.",closed,2022-09-09T11:24:16+00:00,2025-02-26T10:24:43+00:00,seberg,00 - Bug,1,"PR#28206 - numpy/_core/src/multiarray/item_selection.c: @@ -1028,6 +1028,7 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     }|;|     dtype = PyArray_DESCR(mps[0])|;|; |;|+    int copy_existing_out = 0|;|;     /* Set-up return array */|;|     if (out == NULL) {|;|         Py_INCREF(dtype)|;|;@@ -1039,10 +1040,6 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|                                                     (PyObject *)ap)|;|;     }|;|     else {|;|-        int flags = NPY_ARRAY_CARRAY ||;|-                    NPY_ARRAY_WRITEBACKIFCOPY ||;|-                    NPY_ARRAY_FORCECAST|;|;-|;|         if ((PyArray_NDIM(out) != multi->nd)|;|                     || !PyArray_CompareLists(PyArray_DIMS(out),|;|                                              multi->dimensions,|;|@@ -1052,9 +1049,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|             goto fail|;|;         }|;| |;|+        if (PyArray_FailUnlessWriteable(out, ""output array"") < 0) {|;|+            goto fail|;|;+        }|;|+|;|         for (i = 0; i < n; i++) {|;|             if (arrays_overlap(out, mps[i])) {|;|-                flags |= NPY_ARRAY_ENSURECOPY|;|;+                copy_existing_out = 1|;|;             }|;|         }|;| |;|@@ -1064,10 +1065,25 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|              * so the input array is not changed|;|              * before the error is called|;|              */|;|-            flags |= NPY_ARRAY_ENSURECOPY|;|;+            copy_existing_out = 1|;|;+        }|;|+|;|+        if (!PyArray_EquivTypes(dtype, PyArray_DESCR(out))) {|;|+            copy_existing_out = 1|;|;+        }|;|+|;|+        if (copy_existing_out) {|;|+            Py_INCREF(dtype)|;|;+            obj = (PyArrayObject *)PyArray_NewFromDescr(&PyArray_Type,|;|+                                                        dtype,|;|+                                                        multi->nd,|;|+                                                        multi->dimensions,|;|+                                                        NULL, NULL, 0,|;|+                                                        (PyObject *)out)|;|;+        }|;|+        else {|;|+            obj = (PyArrayObject *)Py_NewRef(out)|;|;         }|;|-        Py_INCREF(dtype)|;|;-        obj = (PyArrayObject *)PyArray_FromArray(out, dtype, flags)|;|;     }|;| |;|     if (obj == NULL) {|;|@@ -1080,12 +1096,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     NPY_ARRAYMETHOD_FLAGS transfer_flags = 0|;|;     if (PyDataType_REFCHK(dtype)) {|;|         int is_aligned = IsUintAligned(obj)|;|;+        PyArray_Descr *obj_dtype = PyArray_DESCR(obj)|;|;         PyArray_GetDTypeTransferFunction(|;|                     is_aligned,|;|                     dtype->elsize,|;|-                    dtype->elsize,|;|+                    obj_dtype->elsize,|;|                     dtype,|;|-                    dtype, 0, &cast_info,|;|+                    obj_dtype, 0, &cast_info,|;|                     &transfer_flags)|;|;     }|;| |;|@@ -1142,11 +1159,13 @@ PyArray_Choose(PyArrayObject *ip, PyObject *op, PyArrayObject *out,|;|     }|;|     Py_DECREF(ap)|;|;     PyDataMem_FREE(mps)|;|;-    if (out != NULL && out != obj) {|;|-        Py_INCREF(out)|;|;-        PyArray_ResolveWritebackIfCopy(obj)|;|;+    if (copy_existing_out) {|;|+        int res = PyArray_CopyInto(out, obj)|;|;         Py_DECREF(obj)|;|;-        obj = out|;|;+        if (res < 0) {|;|+            return NULL|;|;+        }|;|+        return Py_NewRef(out)|;|;     }|;|     return (PyObject *)obj|;|;  || PR#28206 - numpy/_core/tests/test_multiarray.py: @@ -1984,6 +1984,12 @@ def test_choose(self):|;|         y = np.choose([0, 0, 0], [x[:3], x[:3], x[:3]], out=x[1:4], mode='wrap')|;|         assert_equal(y, np.array([0, 1, 2]))|;| |;|+        # gh_28206 check fail when out not writeable|;|+        x = np.arange(3)|;|+        out = np.zeros(3)|;|+        out.setflags(write=False)|;|+        assert_raises(ValueError, np.choose, [0, 1, 2], [x, x, x], out=out)|;|+|;|     def test_prod(self):|;|         ba = [1, 2, 10, 11, 6, 5, 4]|;|         ba2 = [[1, 2, 3, 4], [5, 6, 7, 9], [10, 3, 4, 5]]|;|@@ -10223,6 +10229,16 @@ def test_gh_24459():|;|         np.choose(a, [3, -1])|;| |;| |;|+def test_gh_28206():|;|+    a = np.arange(3)|;|+    b = np.ones((3, 3), dtype=np.int64)|;|+    out = np.array([np.nan, np.nan, np.nan])|;|+|;|+    with warnings.catch_warnings():|;|+        warnings.simplefilter(""error"", RuntimeWarning)|;|+        np.choose(a, b, out=out)|;|+|;|+|;| @pytest.mark.parametrize(""N"", np.arange(2, 512))|;| @pytest.mark.parametrize(""dtype"", [np.int16, np.uint16,|;|                         np.int32, np.uint32, np.int64, np.uint64])",BUG: Remove unnecessary copying and casting from out array in PyArray_Choose || BUG: Add missing output dimension check in PyArray_Choose || Add test checking for spurious warning in np.choose || BUG: Add failure check to copying operation in np.choose || BUG: Add defensive comparison instead of equals for failure check || BUG: Revert changes || BUG: Add check in np.choose for different dtypes to create new array || BUG: Revert accidental changes || BUG: Revert accidental changes || Merge branch 'main' of https://github.com/numpy/numpy into bug/choose-unnecessary-cast || BUG: Revert accidental changes || BUG: Revert unnecessary changes || ENH: Add test for large array fast powers || BUG: Revert accidental changes || BUG: Adjust transfer function for cast in PyArray_Choose || TST: Add test for string casting in np.choose || TST: Add long string to np.choose for StringDType || BUG: Fix duplicate code cleanup in failure in np.choose || TST: Remove np.choose string test to be addressed in future || MAINT: Simplify array copying logic in np.choose || MAINT: Simplify output array handling in np.choose || MAINT: Change confusing variable name || MAINT: Remove unnecessary type in new array from descr || MAINT: Rename confusing variable || BUG: Fix incorrect error handling || BUG: Remove unnecessary variable assignment and clarify name || BUG: Remove reference increment not needed in conditional branch || TST: Check fail when out in np.choose not writeable || Apply suggestions from code review
numpy/numpy,mayeut,27932,BUG: NumPy build failure on Alpine Linux s390x,"### Describe the issue:

Failure to build on Alpine Linux s390x where `HWCAP_S390_VX` is not defined.
There's a patch downstream which won't work on glibc<2.33: https://gitlab.alpinelinux.org/alpine/aports/-/blob/v3.21.0/community/py3-numpy/s390x-hwcap.patch?ref_type=tags

### Reproduce the code example:

```python
in a musllinux_1_2_s390x container:
apk add openblas-dev
pip wheel -w $(pwd) --no-binary=numpy numpy==2.1.1
```


### Error message:

```shell
cc -Inumpy/core/_umath_tests.cpython-312-s390x-linux-musl.so.p -Inumpy/core -I../../numpy/core -I../../numpy/core/src/multiarray -I../../numpy/core/src/npymath -Inumpy/core/include -I../../numpy/core/include -I../../numpy/core/src/common -I/opt/_internal/cpython-3.12.8/include/python3.12 -I/tmp/pip-wheel-6fwvkqrl/numpy_c87a1d8e27ec475bbcf6ad8f75a59ba4/.mesonpy-91dpnx77/build/meson_cpu -fvisibility=hidden -fdiagnostics-color=always -DNDEBUG -Wall -Winvalid-pch -std=c99 -O3 -fno-strict-aliasing -fPIC -DNPY_INTERNAL_BUILD -DHAVE_NPY_CONFIG_H -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -MD -MQ numpy/core/_umath_tests.cpython-312-s390x-linux-musl.so.p/src_common_npy_cpu_features.c.o -MF numpy/core/_umath_tests.cpython-312-s390x-linux-musl.so.p/src_common_npy_cpu_features.c.o.d -o numpy/core/_umath_tests.cpython-312-s390x-linux-musl.so.p/src_common_npy_cpu_features.c.o -c ../../numpy/core/src/common/npy_cpu_features.c
      ../../numpy/core/src/common/npy_cpu_features.c: In function 'npy__cpu_init_features':
      ../../numpy/core/src/common/npy_cpu_features.c:640:18: error: 'HWCAP_S390_VX' undeclared (first use in this function); did you mean 'HWCAP_S390_VXE'?
        640 |     if ((hwcap & HWCAP_S390_VX) == 0) {
            |                  ^~~~~~~~~~~~~
            |                  HWCAP_S390_VXE

```
```


### Python and NumPy Versions:

Python 3.12
NumPy 2.1.1

### Runtime Environment:

_No response_

### Context for the issue:

_No response_",,closed,2024-12-08T10:07:43+00:00,2024-12-08T11:46:59+00:00,mayeut,00 - Bug,1,"PR#27933 - numpy/_core/src/common/npy_cpu_features.c: @@ -631,10 +631,14 @@ npy__cpu_init_features(void)|;| #elif defined(__s390x__)|;| |;| #include <sys/auxv.h>|;|-#ifndef HWCAP_S390_VXE|;|-    #define HWCAP_S390_VXE 8192|;|-#endif|;| |;|+/* kernel HWCAP names, available in musl, not available in glibc<2.33: https://sourceware.org/bugzilla/show_bug.cgi?id=25971 */|;|+#ifndef HWCAP_S390_VXRS|;|+    #define HWCAP_S390_VXRS 2048|;|+#endif|;|+#ifndef HWCAP_S390_VXRS_EXT|;|+    #define HWCAP_S390_VXRS_EXT 8192|;|+#endif|;| #ifndef HWCAP_S390_VXRS_EXT2|;|     #define HWCAP_S390_VXRS_EXT2 32768|;| #endif|;|@@ -645,7 +649,7 @@ npy__cpu_init_features(void)|;|     memset(npy__cpu_have, 0, sizeof(npy__cpu_have[0]) * NPY_CPU_FEATURE_MAX)|;|; |;|     unsigned int hwcap = getauxval(AT_HWCAP)|;|;-    if ((hwcap & HWCAP_S390_VX) == 0) {|;|+    if ((hwcap & HWCAP_S390_VXRS) == 0) {|;|         return|;|;     }|;| |;|@@ -656,7 +660,7 @@ npy__cpu_init_features(void)|;|        return|;|;     }|;| |;|-    npy__cpu_have[NPY_CPU_FEATURE_VXE] = (hwcap & HWCAP_S390_VXE) != 0|;|;+    npy__cpu_have[NPY_CPU_FEATURE_VXE] = (hwcap & HWCAP_S390_VXRS_EXT) != 0|;|; |;|     npy__cpu_have[NPY_CPU_FEATURE_VX]  = 1|;|; }","BUG: fix building numpy on musl s390x

`HWCAP_S390_VX` is not defined on musl libc. Define the macro when not already defined.
xref https://gitlab.alpinelinux.org/alpine/aports/-/blob/v3.21.0/community/py3-numpy/s390x-hwcap.patch?ref_type=tags || MAINT: use kernel HWCAP names for s390"
numpy/numpy,bartosz-grabowski,15986,Chain exceptions where appropriate,"Picking up from #15731, there are many places in numpy where we do something like:
```python
try:
    something_which_throws_typeError
except TypeError:
    raise ValueError(""a clearer explanation of what went wrong"")
```

It would produce a marginally clearer error if we could change these to use traceback chaining. Our two options are either:

1. The inner error provides valuable information that is not present in the outer error. We should use `from e`.
    ```python
    try:
        something_which_throws_typeError
    except TypeError as e:
        raise ValueError(""a clearer explanation of what went wrong"") from e
    ```
2. The inner error provides  no valuable information that is not present in the outer error. We should use `from None`:
   ```python
   try:
       some_dict[name]
   except KeyError:
       raise ValueError(""The name %s is not supported"" % name) from None
   ```
   In that example all the information from the `KeyError` is already in the message of the new error, so there is no point chaining



An example of such a change would be [this line](https://github.com/numpy/numpy/pull/15731/files#diff-e55dc29434893b7f529192a2e77e9b07R7070) of this otherwise-discarded patch.

For now, I would recommend we only apply this to cases where the exception is thrown unconditionally, as other cases can be more nuanced.

---

### Please see [this list](https://github.com/numpy/numpy/issues/15986#issuecomment-660762674) for potential places to contribute. Special thanks to @nkleinbaer for compiling the list!","Sure @JanukanS, thanks. We don't usually assign issues. So you can search for these type of calls and simply open a PR with suggested changes linking this issue. || Hi @seberg 
I determined the part to be changed, can i work on this issue too? || Can I work on this issue? It is my first issue and I want to give it a try! || @ayao451 please feel free. A good place to start might be by checking the PRs linked in this issue: exception chaining has been added in quite a few places, and a few other instances have been identified as better off unchanged (e.g. nested exceptions in the test suite).  || A lot of these instances have been fixed (thanks to all the contributors for this!) It would be nice to have a ""definition of done"" for this issue if anyone wants to do a little forensics to see what's already been tackled, what's been reviewed and determined better left as-is, and what still remains to be done. || @rossbar I think I can help the 'forensics' you describe above. My thought was to create a regex expression to search for instances of nested exceptions in the codebase (excluding tests).  Something like  `(\s*)except .*\n(\1\s+.*\n)*\1\s+raise` to capture the indentation level of the original `except` statement, then searching for `raise` within that indent block. 

Then I could cross-reference that list with those instances that have already been addressed in the PRs above, and make a table of what's been addressed and what still needs to be reviewed.

 Does that seem like a reasonable approach? I'm a complete beginner, found this issue through the 'good first issue' tag, so just want to ensure I'm not going down a rabbit hole or creating additional confusion. || @nkleinbaer that approach sounds reasonable, and I think tabulating the results in this issue would be very useful. Even if the cross-referencing proves to be difficult to automate, having a list of all of the potential instances for exception chaining would help finish off this issue. If you are interested in taking this on I think that'd be great! Feel free ping with any questions/comments. || OK, to start off here is a table of the files that have been touched in reference to this issue, the number of instances reviewed, the action taken, and associated PRs. I've used the nomenclature **""Implemented exception chaining""** to indicate something of the form `except SomeError as e: raise SomeOtherError from e` and **""Explicitly silenced exception chaining""** to indicate the form `except SomeError as e: raise SomeOtherError from None`. Please correct if the this can be phrased better.

In some cases my regex found additional instances of 'nested' exceptions in these files that I do not see included in the PRs. It may be the case that they were intentionally left as is, but because I cannot find any documented 'review' of them I have included them for completeness.

| File                                         | Action Taken                                                                      | Associated PR(s) | Comments                                                                                            |
|----------------------------------------------|-----------------------------------------------------------------------------------|------------------|-----------------------------------------------------------------------------------------------------|
| ctypeslib.py                           | 1 instance each: explicitly silenced exception chaining and implemented exception chaining | #16418           |            1  additional instances may need review https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ctypeslib.py#L151  |                                                                              |
| core/_dtype.py                         | 1 instance(s): explicitly silenced exception chaining                                            | #16418           |                                                                                                     |
| core/_internal.py                      | 2 instance(s): explicitly silenced exception chaining                                            | #16747           |                                                                                                     |
| core/fromnumeric.py                    | 1 instance(s): implemented exception chaining                                                    | #16418           |                                                                                                     |
| core/memap.py                          | 1 instance(s): explicitly silenced exception chaining                                            | #16067           |                                                                                                     |
| core/records.py                        | 2 instance(s): implemented exception chaining                                                    | #16418           |                                1 additional instance may need review   https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/core/records.py#L495                                                                  |
| core/code_generators/generate_umath.py | 1 instance(s): implemented exception chaining                                                    | #16254           |                                                                                                     |
| distutils/command/build_clib.py        | 1 instance(s): implemented exception chaining                                                    | #16032           |                                                                                                     |
| distutils/command/build_ext.py         | 1 instance(s): implemented exception chaining                                                    | #16042           |                                                                                                     |
| lib/_datasource.py                     | 1 instance(s): Completely removed nested exception ->  left inner exception by itself            | #16761           |                                                                                                     |
| lib/hisograms.py                       | 1 instance(s): implemented exception chaining                                                    | #16064           | 1 additional instance added in #16129 - seems to implement exception chaining correctly but may need review                          |
| lib/index_tricks.py                    | 1 instance(s): implemented exception chaining                                                    | #16064           | 1 additional instance needs review   https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/index_tricks.py#L378                        |
| lib/npyio.py                           | 2 instance(s): implemented exception chaining                                                    | #16121           | A bit confused on what happened here. My regex finds 8 instances total - I think all have been reviewed and some were determined to be better left as is in #16218, may be worth a second look |
| lib/shape_base.py                      | 1 instance(s): explicitly silenced exception chaining                                            | #16064           |                                    2 additional instances may need review https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/shape_base.py#L774 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/shape_base.py#L868                                                               |
| lib/ufunclike.py                       | 2 instance(s): implemented exception chaining                                                    | #16064           |                                                                                                     |
| linalg/linalg.py                       | 2 instance(s): implemented exception chaining                                                    | #16061           |                                                                                                     |
| ma/core.py                             | 1 instance(s): explicitly silenced exception chaining                                            | #16067           |     3 additional instances may need review https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/core.py#L446 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/core.py#L463 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/core.py#L3794                                                                                        |
| matrixlib/defmatrix.py                 | 1 instance(s): explicitly silenced exception chaining                                            | #16215           |                                                                                                |
| polynomial/polyutils.py                | 2 instance(s): implemented exception chaining                                                    | #16061           |                                                                                                     | || And here is a table of additional files/instances found by my regex that have NOT yet been reviewed in a PR related to this issue. Some of these look like they are already handling exception chaining properly (example einsumfunc.py), but again included here for completeness because I see no documentation of an explicit review. 

| File                               | Instances found by  Regex | Instances                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|------------------------------------|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| __init__.py                        | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/__init__.py#L127 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/__init__.py#L292                                                                                                                                                                                                                                                                     |
| compat/py3k.py                     | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/compat/py3k.py#L173                                                                                                                                                                                                                                                                                                                                                                      |
| core/_type_aliases.py              | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/core/_type_aliases.py#L47                                                                                                                                                                                                                                                                                                                                                                |
| core/einsumfunc.py                 | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/core/einsumfunc.py#L583 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/core/einsumfunc.py#L598                                                                                                                                                                                                                                                                                                                                                                  |
| core/code_generators/genapi.py     | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/core/code_generators/genapi.py#L283                                                                                                                                                                                                                                                                                                                                                      |
| distutils/conv_template.py         | 4                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/conv_template.py#L219 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/conv_template.py#L239 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/conv_template.py#L287 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/conv_template.py#L324 |
| distutils/mingw32ccompiler.py      | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/mingw32ccompiler.py#L563                                                                                                                                                                                                                                                                                                                                                       |
| distutils/unixccompiler.py          | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/unixccompiler.py#L52 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/unixccompiler.py#L124                                                                                                                                                                                                                                          |
| distutils/command/config.py        | 3                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/command/config.py#L53 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/command/config.py#L96 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/command/config.py#L456                                                                                                                   |
| distutils/fcompiler/__init__.py    | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/__init__.py#L613 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/__init__.py#L681                                                                                                                                                                                                                             |
| distutils/fcompiler/compaq.py      | 3                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/compaq.py#L82 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/compaq.py#L87 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/compaq.py#L91                                                                                                              |
| distutils/fcompiler/environment.py | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/distutils/fcompiler/environment.py#L35                                                                                                                                                                                                                                                                                                                                                   |
| fft/_pocketfft.py                  | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/fft/_pocketfft.py#L113                                                                                                                                                                                                                                                                                                                                                                   |
| lib/arraypad.py                    | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/arraypad.py#L785                                                                                                                                                                                                                                                                                                                                                                     |
| lib/arraysetops.py                 | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/arraysetops.py#L279 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/arraysetops.py#L303                                                                                                                                                                                                                                                       |
| lib/format.py                      | 4                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/format.py#L379 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/format.py#L596 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/format.py#L617 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/lib/format.py#L745                                                     |
| linalg/lapack_lite/make_lite.py    | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/linalg/lapack_lite/make_lite.py#L264                                                                                                                                                                                                                                                                                                                                                     |
| ma/mrecords.py                     | 3                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/mrecords.py#L201 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/mrecords.py#L254 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/mrecords.py#L276                                                                                                                                                        |
| ma/timer_comparison.py             | 1                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ma/timer_comparison.py#L103                                                                                                                                                                                                                                                                                                                                                              |
| polynomial/_polybase.py            | 2                         | https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/polynomial/_polybase.py#L550 https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/polynomial/_polybase.py#L608                                                                                                                                                                                                                                             |
|                                    |                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|                                    |                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | || Thanks for taking the time to put this report together @nkleinbaer , this is a really nice review of the current state of things!

I think the most effective way to present the information to help close this issue would be if we could take all of the instances that you found in your regex search, and list them using a list of checkboxes, e.g.

```
 - [x] https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ctypeslib.py#L151
 - [ ] https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/__init__.py#L127
 ...
```
where instances that have been *changed or reviewed* get a check, and instances that haven't been addressed yet are left un-checked. That way, we have a running list of the instances where a decision has been made (whether to chain exceptions, use `from None`, or leave as-is) so that contributors can focus on the remaining ones.

This should give us a list like:
 - [x] https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/ctypeslib.py#L151
 - [ ] https://github.com/numpy/numpy/blob/6ef5ec39cdfaf77aa4600ec2e3bf9f679a4fd527/numpy/__init__.py#L127

which I believe GitHub will summarize in a progress bar for the issue.

If it is easy for you to re-organize your results in this way and you don't mind the extra effort, it'd be great if you could add a list formatted as described in a comment below, then I will take the list and move it up to the top comment so it is more visible. You've already done plenty though, so if you don't have the bandwidth that's totally fine - just let me know and I'll organize the list using your results. Thanks for all you've done so far! || Sure, I can do that! I actually wanted to have check boxes in the tables above, but couldn't figure out how to do the formatting (not sure if possible at all). Mega-checklist to follow.  || - [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/__init__.py#L127
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/__init__.py#L292
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ctypeslib.py#L151
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ctypeslib.py#L300
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ctypeslib.py#L380
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/compat/py3k.py#L173
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/_dtype.py#L27
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/_internal.py#L164
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/_internal.py#L375
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/_type_aliases.py#L47
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/einsumfunc.py#L583
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/einsumfunc.py#L598
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/fromnumeric.py#L540
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/memmap.py#L212
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/records.py#L464
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/records.py#L495
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/records.py#L512
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/code_generators/genapi.py#L283
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/core/code_generators/generate_umath.py#L1032
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/conv_template.py#L219
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/conv_template.py#L239
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/conv_template.py#L287
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/conv_template.py#L324
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/mingw32ccompiler.py#L563
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/unixccompiler.py#L52
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/unixccompiler.py#L124
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/command/build_clib.py#L64
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/command/build_ext.py#L64
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/command/config.py#L53
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/command/config.py#L96
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/command/config.py#L456
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/__init__.py#L613
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/__init__.py#L681
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/compaq.py#L82
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/compaq.py#L87
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/compaq.py#L91
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/distutils/fcompiler/environment.py#L35
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/fft/_pocketfft.py#L113
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/arraypad.py#L785
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/arraysetops.py#L279
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/arraysetops.py#L303
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/format.py#L379
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/format.py#L596
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/format.py#L617
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/format.py#L745
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/histograms.py#L420
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/histograms.py#L1053
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L88
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L448
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L745
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L1058
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L1086
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L1443
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L1773
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/npyio.py#L2064
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/shape_base.py#L375
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/shape_base.py#L774
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/shape_base.py#L868
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/ufunclike.py#L191
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/lib/ufunclike.py#L262
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/linalg/linalg.py#L624
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/linalg/linalg.py#L2542
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/linalg/lapack_lite/make_lite.py#L264
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/core.py#L285
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/core.py#L446
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/core.py#L463
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/core.py#L3794
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/mrecords.py#L201
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/mrecords.py#L254
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/mrecords.py#L276
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/ma/timer_comparison.py#L103
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/matrixlib/defmatrix.py#L1024
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/polynomial/_polybase.py#L550
- [ ] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/polynomial/_polybase.py#L608
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/polynomial/polyutils.py#L196
- [x] https://github.com/numpy/numpy/blob/a0028bca0117874606bce99261d978df8d3f6610/numpy/polynomial/polyutils.py#L780
 || @nkleinbaer I wasn't able to add the full list to the top comment (trying to do so gave github fits), so I've linked to it instead. Many thanks for compiling it! || Hi, picked this file numpy/numpy/lib/arraypad.py to update exceptions and created a pull request.  || I found more: #17108. || In the recent developer meeting we discussed this issue, which is pretty low on the benefit/cost ratio. We would like to suggest that contributors show the output from the error. This will require you think about the error: is the code path actually hit? Does it make sense to chain the exception? || I haven't really followed this, just happened to take a peek at gh-18400 now which adds only `from None` in a bunch of places. @eric-wieser is that actually useful to do? It seems quite non-idiomatic to me. || It's very marginally useful, as it removes unhelpful wording from tracebacks like ""another exception occurred"", and removes `KeyError`s internal to numpy that are just an implementation convenience. I regular see Python novices scared enough by a long traceback that they just read none of it.

This issue seems to be effective at drawing in new contributors, although I haven't kept track of whether any of them go on to contribute further. || > ... I regular see Python novices scared enough by a long traceback that they just read none of it.

Agreed. Okay makes sense, thanks @eric-wieser  || Hello everyone. I'm new to open-source and I want to start doing some work.
Can I jump in and contribute to the solution of this issue? As you see I already  tried to commit some code but it failed on few tests. Can somebody explain what went wrong? @eric-wieser perhaps? || > Hello everyone. I'm new to open-source and I want to start doing some work.
> Can I jump in and contribute to the solution of this issue? As you see I already tried to commit some code but it failed on few tests. Can somebody explain what went wrong? @eric-wieser perhaps?

Yes, Its you starting you can start with these issues mentioned top above  and follow the contributing guidelines. Then start code and test whether is it working or not with all related requirements. happy coding! || ... with that please realize that this is a low priority issue, so PRs may take a while to get reviewed and merged. And as I commented above:
> We would like to suggest that contributors show the output from the error. This will require you think about the error: is the code path actually hit? Does it make sense to chain the exception? || Hey @eric-wieser, I am new to open source and would like to contribute to this project. Can I work on this issue?  || I think we have gotten about as much mileage as possible from this issue and would like to close it. @eric-wieser what do you think? || I think I agree @mattip, feel free to close. We can still review any remaining open PRs.

I'm curious if any contributors who contributed for the first time to numpy thanks to this issue ended up making further contributions later, or if they've all just been drive-by one-off contributions. || Maybe they are now contributing elsewhere. ",closed,2020-04-15T14:29:35+00:00,2021-08-19T18:28:26+00:00,eric-wieser,,1,"PR#16215 - numpy/matrixlib/defmatrix.py: @@ -1024,8 +1024,8 @@ def _from_string(str, gdict, ldict):|;|             except KeyError:|;|                 try:|;|                     thismat = gdict[col]|;|-                except KeyError:|;|-                    raise KeyError(""%s not found"" % (col,))|;|+                except KeyError as e:|;|+                    raise NameError(f""name {col!r} is not defined"") from None|;| |;|             coltup.append(thismat)|;|         rowtup.append(concatenate(coltup, axis=-1))","MAINT: chain exceptions in defmatrix.py || MAINT: switch to newer string formatting || ENH: Make error message cleaner in defmatrix.py

Co-authored-by: Eric Wieser <wieser.eric@gmail.com> || MAINT: Switch to f-string formatting

Make a switch to f-string formatting to avoid 80-char line limit.

Co-authored-by: Ross Barnowski <rossbar@berkeley.edu>"
numpy/numpy,l09rin,28315,BUG: numpy.loadtxt reads only 50000 lines when skip_rows >= max_rows,"### Describe the issue:

As in the title, probably related to the closed issue #26754 .

### Reproduce the code example:

```python
import numpy as np
import os
from tempfile import NamedTemporaryFile, mkstemp

file_length = 400000
data = np.arange(1,file_length+1).astype(str) + "" a 0.5 1""
fd, fname = mkstemp()
os.close(fd)
with open(fname, ""w"") as fh:
    fh.write(""\n"".join(data))
res = np.loadtxt(fname, dtype = 'str', delimiter="" "", skiprows=200000, max_rows=100000)
print(len(res), len(res) == 100000)  # 50000 False
```

### Error message:

```shell

```

### Python and NumPy Versions:

2.2.2
3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]


### Runtime Environment:

_No response_

### Context for the issue:

_No response_","Maybe the misnamed [`skiprows`](https://github.com/l09rin/numpy/blob/06f987b7b77453aae7fa11de15f728567fccd407/numpy/lib/_npyio_impl.py#L1088) should be `skiplines`, or `skiplines` should be refactored to be `skiprows`? || I guess the problem is related to the fact that when it reads in chunks, at every call of load_from_filelike it gets skiplines non zero... I will try a fix to that and add a test || Indeed in function _read() there was a skiprows=0 meant to do that job, but the variable should be skiplines as pointed out by @mattip ",closed,2025-02-10T15:26:21+00:00,2025-02-18T14:48:49+00:00,l09rin,00 - Bug,1,"PR#28319 - numpy/lib/_npyio_impl.py: @@ -1085,7 +1085,7 @@ def _read(fname, *, delimiter=',', comment='#', quote='""',|;|                 # be adapted (in principle the concatenate could cast).|;|                 chunks.append(next_arr.astype(read_dtype_via_object_chunks))|;| |;|-                skiprows = 0  # Only have to skip for first chunk|;|+                skiplines = 0  # Only have to skip for first chunk|;|                 if max_rows >= 0:|;|                     max_rows -= chunk_size|;|                 if len(next_arr) < chunk_size: || PR#28319 - numpy/lib/tests/test_loadtxt.py: @@ -1073,3 +1073,28 @@ def test_maxrows_exceeding_chunksize(nmax):|;|     res = np.loadtxt(fname, dtype=str, delimiter="" "", max_rows=nmax)|;|     os.remove(fname)|;|     assert len(res) == nmax|;|+|;|+@pytest.mark.parametrize(""nskip"", (0, 10000, 12345, 50000, 67891, 100000))|;|+def test_skiprow_exceeding_maxrows_exceeding_chunksize(tmpdir, nskip):|;|+    # tries to read a file in chunks by skipping a variable amount of lines,|;|+    # less, equal, greater than max_rows|;|+    file_length = 110000|;|+    data = ""\n"".join(f""{i} a 0.5 1"" for i in range(1, file_length + 1))|;|+    expected_length = min(60000, file_length - nskip)|;|+    expected = np.arange(nskip + 1, nskip + 1 + expected_length).astype(str)|;|+|;|+    # file-like path|;|+    txt = StringIO(data)|;|+    res = np.loadtxt(txt, dtype='str', delimiter="" "", skiprows=nskip, max_rows=60000)|;|+    assert len(res) == expected_length|;|+    # are the right lines read in res?|;|+    assert_array_equal(expected, res[:, 0])|;|+|;|+    # file-obj path|;|+    tmp_file = tmpdir / ""test_data.txt""|;|+    tmp_file.write(data)|;|+    fname = str(tmp_file)|;|+    res = np.loadtxt(fname, dtype='str', delimiter="" "", skiprows=nskip, max_rows=60000)|;|+    assert len(res) == expected_length|;|+    # are the right lines read in res?|;|+    assert_array_equal(expected, res[:, 0])","fixed bug in function _read in numpy/lib/_npyio_impl.py, misnamed variable skiplines as skiprows; added test in numpy/lib/tests/test_loadtxt.py || fixed sintax in test_loadtxt.py || changed use of mkstemp with use of tmpdir provided by pytest || fixed bug in use of tmpdir in loadtxt test || Update numpy/lib/tests/test_loadtxt.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || Update file numpy/lib/tests/test_loadtxt.py || Update file numpy/lib/tests/test_loadtxt.py || Update numpy/lib/tests/test_loadtxt.py"
numpy/numpy,seberg,28315,BUG: numpy.loadtxt reads only 50000 lines when skip_rows >= max_rows,"### Describe the issue:

As in the title, probably related to the closed issue #26754 .

### Reproduce the code example:

```python
import numpy as np
import os
from tempfile import NamedTemporaryFile, mkstemp

file_length = 400000
data = np.arange(1,file_length+1).astype(str) + "" a 0.5 1""
fd, fname = mkstemp()
os.close(fd)
with open(fname, ""w"") as fh:
    fh.write(""\n"".join(data))
res = np.loadtxt(fname, dtype = 'str', delimiter="" "", skiprows=200000, max_rows=100000)
print(len(res), len(res) == 100000)  # 50000 False
```

### Error message:

```shell

```

### Python and NumPy Versions:

2.2.2
3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]


### Runtime Environment:

_No response_

### Context for the issue:

_No response_","Maybe the misnamed [`skiprows`](https://github.com/l09rin/numpy/blob/06f987b7b77453aae7fa11de15f728567fccd407/numpy/lib/_npyio_impl.py#L1088) should be `skiplines`, or `skiplines` should be refactored to be `skiprows`? || I guess the problem is related to the fact that when it reads in chunks, at every call of load_from_filelike it gets skiplines non zero... I will try a fix to that and add a test || Indeed in function _read() there was a skiprows=0 meant to do that job, but the variable should be skiplines as pointed out by @mattip ",closed,2025-02-10T15:26:21+00:00,2025-02-18T14:48:49+00:00,l09rin,00 - Bug,1,"PR#28319 - numpy/lib/_npyio_impl.py: @@ -1085,7 +1085,7 @@ def _read(fname, *, delimiter=',', comment='#', quote='""',|;|                 # be adapted (in principle the concatenate could cast).|;|                 chunks.append(next_arr.astype(read_dtype_via_object_chunks))|;| |;|-                skiprows = 0  # Only have to skip for first chunk|;|+                skiplines = 0  # Only have to skip for first chunk|;|                 if max_rows >= 0:|;|                     max_rows -= chunk_size|;|                 if len(next_arr) < chunk_size: || PR#28319 - numpy/lib/tests/test_loadtxt.py: @@ -1073,3 +1073,28 @@ def test_maxrows_exceeding_chunksize(nmax):|;|     res = np.loadtxt(fname, dtype=str, delimiter="" "", max_rows=nmax)|;|     os.remove(fname)|;|     assert len(res) == nmax|;|+|;|+@pytest.mark.parametrize(""nskip"", (0, 10000, 12345, 50000, 67891, 100000))|;|+def test_skiprow_exceeding_maxrows_exceeding_chunksize(tmpdir, nskip):|;|+    # tries to read a file in chunks by skipping a variable amount of lines,|;|+    # less, equal, greater than max_rows|;|+    file_length = 110000|;|+    data = ""\n"".join(f""{i} a 0.5 1"" for i in range(1, file_length + 1))|;|+    expected_length = min(60000, file_length - nskip)|;|+    expected = np.arange(nskip + 1, nskip + 1 + expected_length).astype(str)|;|+|;|+    # file-like path|;|+    txt = StringIO(data)|;|+    res = np.loadtxt(txt, dtype='str', delimiter="" "", skiprows=nskip, max_rows=60000)|;|+    assert len(res) == expected_length|;|+    # are the right lines read in res?|;|+    assert_array_equal(expected, res[:, 0])|;|+|;|+    # file-obj path|;|+    tmp_file = tmpdir / ""test_data.txt""|;|+    tmp_file.write(data)|;|+    fname = str(tmp_file)|;|+    res = np.loadtxt(fname, dtype='str', delimiter="" "", skiprows=nskip, max_rows=60000)|;|+    assert len(res) == expected_length|;|+    # are the right lines read in res?|;|+    assert_array_equal(expected, res[:, 0])","fixed bug in function _read in numpy/lib/_npyio_impl.py, misnamed variable skiplines as skiprows; added test in numpy/lib/tests/test_loadtxt.py || fixed sintax in test_loadtxt.py || changed use of mkstemp with use of tmpdir provided by pytest || fixed bug in use of tmpdir in loadtxt test || Update numpy/lib/tests/test_loadtxt.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || Update file numpy/lib/tests/test_loadtxt.py || Update file numpy/lib/tests/test_loadtxt.py || Update numpy/lib/tests/test_loadtxt.py"
numpy/numpy,SlobodanMiletic,25626,BUG: Complex printing tests fail on Windows ARM64,"### Describe the issue:

6 out of 16 tests fail in `test_print.py` when running on Windows on ARM. They appear to all be related to complex numbers. If I've read the results correctly, it only affects `np.cdouble` and `np.clongdouble` and not `np.complex64`.

### Reproduce the code example:

```python
pytest numpy/_core/tests/test_print.py
```


### Error message:

```shell
__________ test_complex_types[complex128] __________

tp = <class 'numpy.complex128'>

    @pytest.mark.parametrize('tp', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_types(tp):
        """"""Check formatting of complex types.

            This is only for the str function, and only for simple types.
            The precision of np.float32 and np.longdouble aren't the same as the
            python float precision.

        """"""
        for x in [0, 1, -1, 1e20]:
            assert_equal(str(tp(x)), str(complex(x)),
                         err_msg='Failed str formatting for type %s' % tp)
            assert_equal(str(tp(x*1j)), str(complex(x*1j)),
                         err_msg='Failed str formatting for type %s' % tp)
>           assert_equal(str(tp(x + x*1j)), str(complex(x + x*1j)),
                         err_msg='Failed str formatting for type %s' % tp)
E           AssertionError:
E           Items are not equal: Failed str formatting for type <class 'numpy.complex128'>
E            ACTUAL: '(1+0j)'
E            DESIRED: '(1+1j)'

tp         = <class 'numpy.complex128'>
x          = 1

numpy\_core\tests\test_print.py:65: AssertionError
__________ test_complex_types[clongdouble] __________

tp = <class 'numpy.clongdouble'>

    @pytest.mark.parametrize('tp', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_types(tp):
        """"""Check formatting of complex types.

            This is only for the str function, and only for simple types.
            The precision of np.float32 and np.longdouble aren't the same as the
            python float precision.

        """"""
        for x in [0, 1, -1, 1e20]:
            assert_equal(str(tp(x)), str(complex(x)),
                         err_msg='Failed str formatting for type %s' % tp)
            assert_equal(str(tp(x*1j)), str(complex(x*1j)),
                         err_msg='Failed str formatting for type %s' % tp)
>           assert_equal(str(tp(x + x*1j)), str(complex(x + x*1j)),
                         err_msg='Failed str formatting for type %s' % tp)
E           AssertionError:
E           Items are not equal: Failed str formatting for type <class 'numpy.clongdouble'>
E            ACTUAL: '(1+0j)'
E            DESIRED: '(1+1j)'

tp         = <class 'numpy.clongdouble'>
x          = 1

numpy\_core\tests\test_print.py:65: AssertionError
__________ test_complex_inf_nan[complex128] __________

dtype = <class 'numpy.complex128'>

    @pytest.mark.parametrize('dtype', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_inf_nan(dtype):
        """"""Check inf/nan formatting of complex types.""""""
        TESTS = {
            complex(np.inf, 0): ""(inf+0j)"",
            complex(0, np.inf): ""infj"",
            complex(-np.inf, 0): ""(-inf+0j)"",
            complex(0, -np.inf): ""-infj"",
            complex(np.inf, 1): ""(inf+1j)"",
            complex(1, np.inf): ""(1+infj)"",
            complex(-np.inf, 1): ""(-inf+1j)"",
            complex(1, -np.inf): ""(1-infj)"",
            complex(np.nan, 0): ""(nan+0j)"",
            complex(0, np.nan): ""nanj"",
            complex(-np.nan, 0): ""(nan+0j)"",
            complex(0, -np.nan): ""nanj"",
            complex(np.nan, 1): ""(nan+1j)"",
            complex(1, np.nan): ""(1+nanj)"",
            complex(-np.nan, 1): ""(nan+1j)"",
            complex(1, -np.nan): ""(1+nanj)"",
        }
        for c, s in TESTS.items():
>           assert_equal(str(dtype(c)), s)
E           AssertionError:
E           Items are not equal:
E            ACTUAL: '(inf+0j)'
E            DESIRED: '(inf+1j)'

TESTS      = {(inf+0j): '(inf+0j)', infj: 'infj', (-inf+0j): '(-inf+0j)', -infj: '-infj', ...}
c          = (inf+1j)
dtype      = <class 'numpy.complex128'>
s          = '(inf+1j)'

numpy\_core\tests\test_print.py:99: AssertionError
__________ test_complex_inf_nan[clongdouble] __________

dtype = <class 'numpy.clongdouble'>

    @pytest.mark.parametrize('dtype', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_inf_nan(dtype):
        """"""Check inf/nan formatting of complex types.""""""
        TESTS = {
            complex(np.inf, 0): ""(inf+0j)"",
            complex(0, np.inf): ""infj"",
            complex(-np.inf, 0): ""(-inf+0j)"",
            complex(0, -np.inf): ""-infj"",
            complex(np.inf, 1): ""(inf+1j)"",
            complex(1, np.inf): ""(1+infj)"",
            complex(-np.inf, 1): ""(-inf+1j)"",
            complex(1, -np.inf): ""(1-infj)"",
            complex(np.nan, 0): ""(nan+0j)"",
            complex(0, np.nan): ""nanj"",
            complex(-np.nan, 0): ""(nan+0j)"",
            complex(0, -np.nan): ""nanj"",
            complex(np.nan, 1): ""(nan+1j)"",
            complex(1, np.nan): ""(1+nanj)"",
            complex(-np.nan, 1): ""(nan+1j)"",
            complex(1, -np.nan): ""(1+nanj)"",
        }
        for c, s in TESTS.items():
>           assert_equal(str(dtype(c)), s)
E           AssertionError:
E           Items are not equal:
E            ACTUAL: '(inf+0j)'
E            DESIRED: '(inf+1j)'

TESTS      = {(inf+0j): '(inf+0j)', infj: 'infj', (-inf+0j): '(-inf+0j)', -infj: '-infj', ...}
c          = (inf+1j)
dtype      = <class 'numpy.clongdouble'>
s          = '(inf+1j)'

numpy\_core\tests\test_print.py:99: AssertionError
__________test_complex_type_print[complex128] __________

tp = <class 'numpy.complex128'>

    @pytest.mark.parametrize('tp', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_type_print(tp):
        """"""Check formatting when using print """"""
        # We do not create complex with inf/nan directly because the feature is
        # missing in python < 2.6
        for x in [0, 1, -1, 1e20]:
            _test_redirected_print(complex(x), tp)

        if tp(1e16).itemsize > 8:
            _test_redirected_print(complex(1e16), tp)
        else:
            ref = '(1e+16+0j)'
            _test_redirected_print(complex(1e16), tp, ref)

>       _test_redirected_print(complex(np.inf, 1), tp, '(inf+1j)')

tp         = <class 'numpy.complex128'>
x          = 1e+20

numpy\_core\tests\test_print.py:152:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = (inf+1j), tp = <class 'numpy.complex128'>, ref = '(inf+1j)'

    def _test_redirected_print(x, tp, ref=None):
        file = StringIO()
        file_tp = StringIO()
        stdout = sys.stdout
        try:
            sys.stdout = file_tp
            print(tp(x))
            sys.stdout = file
            if ref:
                print(ref)
            else:
                print(x)
        finally:
            sys.stdout = stdout

>       assert_equal(file.getvalue(), file_tp.getvalue(),
                     err_msg='print failed for type%s' % tp)
E       AssertionError:
E       Items are not equal: print failed for type<class 'numpy.complex128'>
E        ACTUAL: '(inf+1j)\n'
E        DESIRED: '(inf+0j)\n'

file       = <_io.StringIO object at 0x000001FEED9B0640>
file_tp    = <_io.StringIO object at 0x000001FEED9B0280>
ref        = '(inf+1j)'
stdout     = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000001FEEAA7FA40>' mode='r+' encoding='utf-8'>
tp         = <class 'numpy.complex128'>
x          = (inf+1j)

numpy\_core\tests\test_print.py:118: AssertionError
__________ test_complex_type_print[clongdouble] __________

tp = <class 'numpy.clongdouble'>

    @pytest.mark.parametrize('tp', [np.complex64, np.cdouble, np.clongdouble])
    def test_complex_type_print(tp):
        """"""Check formatting when using print """"""
        # We do not create complex with inf/nan directly because the feature is
        # missing in python < 2.6
        for x in [0, 1, -1, 1e20]:
            _test_redirected_print(complex(x), tp)

        if tp(1e16).itemsize > 8:
            _test_redirected_print(complex(1e16), tp)
        else:
            ref = '(1e+16+0j)'
            _test_redirected_print(complex(1e16), tp, ref)

>       _test_redirected_print(complex(np.inf, 1), tp, '(inf+1j)')

tp         = <class 'numpy.clongdouble'>
x          = 1e+20

numpy\_core\tests\test_print.py:152:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

x = (inf+1j), tp = <class 'numpy.clongdouble'>, ref = '(inf+1j)'

    def _test_redirected_print(x, tp, ref=None):
        file = StringIO()
        file_tp = StringIO()
        stdout = sys.stdout
        try:
            sys.stdout = file_tp
            print(tp(x))
            sys.stdout = file
            if ref:
                print(ref)
            else:
                print(x)
        finally:
            sys.stdout = stdout

>       assert_equal(file.getvalue(), file_tp.getvalue(),
                     err_msg='print failed for type%s' % tp)
E       AssertionError:
E       Items are not equal: print failed for type<class 'numpy.clongdouble'>
E        ACTUAL: '(inf+1j)\n'
E        DESIRED: '(inf+0j)\n'

file       = <_io.StringIO object at 0x000001FEED9B0C40>
file_tp    = <_io.StringIO object at 0x000001FEED9B0B80>
ref        = '(inf+1j)'
stdout     = <_io.TextIOWrapper name='<tempfile._TemporaryFileWrapper object at 0x000001FEEAA7FA40>' mode='r+' encoding='utf-8'>
tp         = <class 'numpy.clongdouble'>
x          = (inf+1j)

numpy\_core\tests\test_print.py:118: AssertionError
```


### Python and NumPy Versions:

2.0.0.dev0+git20240118.a7c6be5
3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:12:47) [MSC v.1937 64 bit (ARM64)]


### Runtime Environment:

```
[{'numpy_version': '2.0.0.dev0+git20240118.a7c6be5',
  'python': '3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:12:47) [MSC v.1937 '
            '64 bit (ARM64)]',
  'uname': uname_result(system='Windows', node='mars', release='11', version='10.0.22621', machine='ARM64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': [],
                      'not_found': []}}]
None
```
(PS, this function prints already, so you can remove `print` from the PR template.)

### Context for the issue:

I've started working on building Matplotlib on Windows on Arm.","Missed that `numpy/polynomial/tests/test_printing.py::test_complex_coefficients` also fails the same way:
```
__________ test_complex_coefficients __________

    def test_complex_coefficients():
        """"""Test both numpy and built-in complex.""""""
        coefs = [0+1j, 1+1j, -2+2j, 3+0j]
        # numpy complex
        p1 = poly.Polynomial(coefs)
        # Python complex
        p2 = poly.Polynomial(array(coefs, dtype=object))
        poly.set_default_printstyle('unicode')
>       assert_equal(str(p1), ""1j + (1+1j)·x - (2-2j)·x² + (3+0j)·x³"")
E       AssertionError:
E       Items are not equal:
E        ACTUAL: '1j + (1+0j)·x - (2+0j)·x² + (3+0j)·x³'
E        DESIRED: '1j + (1+1j)·x - (2-2j)·x² + (3+0j)·x³'

coefs      = [1j, (1+1j), (-2+2j), (3+0j)]
p1         = Polynomial([ 0.+1.j,  1.+1.j, -2.+2.j,  3.+0.j], domain=[-1,  1], window=[-1,  1], symbol='x')
p2         = Polynomial([1j, (1+1j), (-2+2j), (3+0j)], dtype=object, domain=[-1,  1], window=[-1,  1], symbol='x')

numpy\polynomial\tests\test_printing.py:251: AssertionError
``` || Oops, missed one more in `numpy/_core/tests/test_arrayprint.py::TestPrintOptions::test_legacy_mode_scalars`, but it's more of the same:
```
__________ TestPrintOptions.test_legacy_mode_scalars __________

self = <numpy._core.tests.test_arrayprint.TestPrintOptions object at 0x0000027CF6D3B1D0>

    def test_legacy_mode_scalars(self):
        # in legacy mode, str of floats get truncated, and complex scalars
        # use * for non-finite imaginary part
        np.set_printoptions(legacy='1.13')
        assert_equal(str(np.float64(1.123456789123456789)), '1.12345678912')
        assert_equal(str(np.complex128(complex(1, np.nan))), '(1+nan*j)')

        np.set_printoptions(legacy=False)
        assert_equal(str(np.float64(1.123456789123456789)),
                     '1.1234567891234568')
>       assert_equal(str(np.complex128(complex(1, np.nan))), '(1+nanj)')
E       AssertionError:
E       Items are not equal:
E        ACTUAL: '(1+0j)'
E        DESIRED: '(1+nanj)'

self       = <numpy._core.tests.test_arrayprint.TestPrintOptions object at 0x0000027CF6D3B1D0>

numpy\_core\tests\test_arrayprint.py:895: AssertionError

``` || Or even more simply:
```
$ python
Python 3.12.1 (tags/v3.12.1:2305ca5, Dec  7 2023, 22:12:47) [MSC v.1937 64 bit (ARM64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy as np
>>> np.complex64(1, 2)
np.complex64(1+2j)
>>> np.complex128(1, 2)
np.complex128(1+0j)
```
even though:
```
>>> val = np.complex64(1, 2)
>>> val.real
np.float32(1.0)
>>> val.imag
np.float32(2.0)
>>> val = np.complex128(1, 2)
>>> val.real
np.float64(1.0)
>>> val.imag
np.float64(2.0)
>>>
```
so this is specifically about printing. || I did some printf debugging on a arm64 windows VM and I don't think this is necessarily printing specific. In particular, if I put a `printf` inside `npy_cimag` like so:

```
diff --git a/numpy/_core/include/numpy/npy_math.h b/numpy/_core/include/numpy/npy_math.h
index 216b173fde..c532eb963b 100644
--- a/numpy/_core/include/numpy/npy_math.h
+++ b/numpy/_core/include/numpy/npy_math.h
@@ -372,6 +372,7 @@ static inline void npy_csetreal(npy_cdouble *z, const double r)

 static inline double npy_cimag(const npy_cdouble z)
 {
+    printf(""z: %f, %f"", ((double *) &z)[0], ((double *) &z)[1]);
     return ((double *) &z)[1];
 }
```

I see in my terminal output when I execute `np.complex128(1, 2)` that the imagingary part is zero in the `npy_cdouble` struct.

It looks like `val.imag` uses a different code path via `gentype_imag_get` that interprets the data in the imaginary part as a float and goes through the float scalar repr machinery and somehow that ends up with the correct value.

This is reaching the edge of my windows knowledge. || Ping @lysnikolaou, maybe this is related to the complex number refactoring? || This maybe related to issues with x64-translation.
I noticed that on WoA pip tries to compile numpy for me.
Perhaps the OP is running an x64 version.

I just opened https://github.com/numpy/numpy/issues/25858 which is somewhat related. || No, I am running entirely native only. || Issue can be reproduced only in MSVC build with optimizations (llvm and MINGW builds are working fine).
Problem is located in c@name@type_@kind@ function in scalartypes.c.src. Imaginary part is being nulled in this function after the line
```
if (npy_isfinite(npy_creal@n@(val))) 
```
When code is changed by removing some parts or adding specific printf commands everything starts behaving correctly. 
Going through the disassembly of this method step by step, and comparing with working cases problem is located to these two instructions:
```
    ldr d0, [sp, #0x10]
    str q0, [sp, #0x10]
```

It looks that for some reason MSVC arm64 compiler is making wrong optimizations for complex numbers in this context.
We opened the compiler bug for this issue: https://developercommunity.visualstudio.com/t/C-ARM64-compiler-optimization-bug-when-u/10714602

There is also fix that can be added from the NumPy side. In the methods for getting the imaginary and real parts in npy_math.h ( npy_cimagl, npy_creall ...) for non C++ code numpy should use appropriate c api calls (cimagl, creall ... ) . It would look something like: 
    static inline npy_longdouble npy_cimagl(const npy_clongdouble z)
    {
    #if defined(__cplusplus)
        return ((longdouble_t *) &z)[1];
    #else
        return cimagl(z);
    #endif
    }

With this change tests are passing. Most probably compiler is seeing these APIs differently and generates proper calls.
We will open a PR with this fix. ",open,2024-01-19T08:38:15+00:00,,QuLogic,00 - Bug,1,"PR#27096 - numpy/_core/include/numpy/npy_math.h: @@ -362,7 +362,11 @@ NPY_INPLACE npy_longdouble npy_heavisidel(npy_longdouble x, npy_longdouble h0)|;|; |;| static inline double npy_creal(const npy_cdouble z)|;| {|;|+#if defined(__cplusplus)|;|     return ((double *) &z)[0]|;|;+#else|;|+    return creal(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetreal(npy_cdouble *z, const double r)|;|@@ -372,7 +376,11 @@ static inline void npy_csetreal(npy_cdouble *z, const double r)|;| |;| static inline double npy_cimag(const npy_cdouble z)|;| {|;|+#if defined(__cplusplus)|;|     return ((double *) &z)[1]|;|;+#else|;|+    return cimag(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetimag(npy_cdouble *z, const double i)|;|@@ -382,7 +390,11 @@ static inline void npy_csetimag(npy_cdouble *z, const double i)|;| |;| static inline float npy_crealf(const npy_cfloat z)|;| {|;|+#if defined(__cplusplus)|;|     return ((float *) &z)[0]|;|;+#else|;|+    return crealf(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetrealf(npy_cfloat *z, const float r)|;|@@ -392,7 +404,11 @@ static inline void npy_csetrealf(npy_cfloat *z, const float r)|;| |;| static inline float npy_cimagf(const npy_cfloat z)|;| {|;|+#if defined(__cplusplus)|;|     return ((float *) &z)[1]|;|;+#else|;|+    return cimagf(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetimagf(npy_cfloat *z, const float i)|;|@@ -402,7 +418,11 @@ static inline void npy_csetimagf(npy_cfloat *z, const float i)|;| |;| static inline npy_longdouble npy_creall(const npy_clongdouble z)|;| {|;|+#if defined(__cplusplus)|;|     return ((longdouble_t *) &z)[0]|;|;+#else|;|+    return creall(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetreall(npy_clongdouble *z, const longdouble_t r)|;|@@ -412,7 +432,11 @@ static inline void npy_csetreall(npy_clongdouble *z, const longdouble_t r)|;| |;| static inline npy_longdouble npy_cimagl(const npy_clongdouble z)|;| {|;|+#if defined(__cplusplus)|;|     return ((longdouble_t *) &z)[1]|;|;+#else|;|+    return cimagl(z)|;|;+#endif|;| }|;| |;| static inline void npy_csetimagl(npy_clongdouble *z, const longdouble_t i)","BUG: Complex printing tests fail on Windows ARM64

Fixes issue #25626"
numpy/numpy,ngoldbaum,28316,BUG: calling `_core.multiarray.scalar` with only a `dtype[object_]` or `StringDType` segfaults,"I tried this with all dtypes, but only these two deliquents-types cause `scalar()` to segfault.
I don't see how this could be triggered during pickling or something, but .

## repro

### `StringDType`

Expectation: the same as `StringDType().type()`, i.e. `""""`.

```pycon
>>> import numpy as np
>>> np._core.multiarray.scalar(np.dtype(""T""))
[1]    384277 segmentation fault (core dumped)  python
```

### `dtype[object_]`

Expectation: the same as `np.object_()`, i.e. `None`.

```pycon
>>> import numpy as np
>>> np._core.multiarray.scalar(np.dtype(""O""))
<python-input-1>:1: DeprecationWarning: Unpickling a scalar with object dtype is deprecated. Object scalars should never be created. If this was a properly created pickle, please open a NumPy issue. In a best effort this returns the original object.
  np._core.multiarray.scalar(np.dtype(""O""))
[1]    381740 segmentation fault (core dumped)  python
```

## info

```pycon
>>> import sys; sys.version
'3.13.2 (main, Feb  7 2025, 04:13:54) [GCC 11.4.0]'
>>> import platform; platform.platform()
'Linux-6.9.3-76060903-generic-x86_64-with-glibc2.35'
>>> np.__version__
'2.2.2'
```","Sorry, just for some context - why do you care about this? It's a private API after all... || > Sorry, just for some context - why do you care about this?

I don't 🤷🏻. I just stumbled upon this when I was trying to figure out how to stub it. So it's fine me if you wanna close it as a ""wontfix"". || Eh it’s probably best for there not to be magic numpy incantations that segfault Python. Not to say that there aren’t plenty more ways to do that but we should try to fix them if people report them.

Thankfully this will likely be easy to fix. || On `main`, I see:

```
>>> np._core.multiarray.scalar(np.dtype(""O""))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: Cannot unpickle a scalar with object dtype.
>>> np._core.multiarray.scalar(np.dtype(""T""))
[1]    58412 segmentation fault  spin python
```

So I think the object cast has been fixed since NumPy 2.2.2. I'll go ahead and add a path that queries the `scalar_type` on the DTypeMeta for new-style DTypes, which should fix StringDType as well all new user DTypes or future new-style DTypes we add.",closed,2025-02-11T00:36:16+00:00,2025-02-14T19:54:50+00:00,jorenham,00 - Bug,1,"PR#28332 - numpy/_core/src/multiarray/multiarraymodule.c: @@ -2113,6 +2113,12 @@ array_scalar(PyObject *NPY_UNUSED(ignored), PyObject *args, PyObject *kwds)|;|                     ""Cannot unpickle a scalar with object dtype."")|;|;             return NULL|;|;         }|;|+        if (typecode->type_num == NPY_VSTRING) {|;|+            // TODO: if we ever add a StringDType scalar, this might need to change|;|+            PyErr_SetString(PyExc_TypeError,|;|+                            ""Cannot unpickle a StringDType scalar"")|;|;+            return NULL|;|;+        }|;|         /* We store the full array to unpack it here: */|;|         if (!PyArray_CheckExact(obj)) {|;|             /* We pickle structured voids as arrays currently */ || PR#28332 - numpy/_core/tests/test_dtype.py: @@ -1676,6 +1676,22 @@ def test_float_alias_names(self, name):|;|         with pytest.raises(AttributeError):|;|             getattr(numpy.dtypes, name + ""DType"") is numpy.dtypes.Float16DType|;| |;|+    def test_scalar_helper_all_dtypes(self):|;|+        for dtype in np.dtypes.__all__:|;|+            dt_class = getattr(np.dtypes, dtype)|;|+            dt = np.dtype(dt_class)|;|+            if dt.char not in 'OTVM':|;|+                assert np._core.multiarray.scalar(dt) == dt.type()|;|+            elif dt.char == 'V':|;|+                assert np._core.multiarray.scalar(dt) == dt.type(b'\x00')|;|+            elif dt.char == 'M':|;|+                # can't do anything with this without generating ValueError|;|+                # because 'M' has no units|;|+                _ = np._core.multiarray.scalar(dt)|;|+            else:|;|+                with pytest.raises(TypeError):|;|+                    np._core.multiarray.scalar(dt)|;|+|;| |;| class TestFromCTypes:|;| ",BUG: avoid segfault in np._core.multiarray.scalar
numpy/numpy,abhishek-iitmadras,26910,BUG: Failed to build from source,"## Describe the issue:

Hi. I tried to build NumPy from source with clang. While this journey I found few problems:
- failed tests
- linking problems
- crashed compiler

Enjoy the report

## Reproduce the code example:

- Clone repo:
```shell
$ git clone --recursive --branch=v2.0.0 git@github.com:numpy/numpy.git
$ cd numpy
```

- Add Dockerfile:
```Dockerfile
# https://stackoverflow.com/a/54386573
# GCC_ASAN_PRELOAD_PATH=$(gcc -print-file-name=libasan.so)
# CLANG_ASAN_PRELOAD_PATH=$(clang -print-file-name=libclang_rt.asan-x86_64.so)


ARG ENV=""ubuntu_gcc_env""

FROM ubuntu:24.04 as ubuntu_env
RUN apt-get update -y && \
    apt-get install -y \
        gfortran \
        liblapack-dev \
        libopenblas-dev \
        pkg-config \
        python3-dbg \
        python3-dev \
        python3-dev \
        python3-pip \
        python3-venv



FROM ubuntu_env as ubuntu_gcc_env
RUN apt-get install -y \
        gcc \
        g++



FROM ubuntu_gcc_env as ubuntu_gcc_asan_env
ENV CFLAGS=""-g -O0 -fsanitize=address"" \
    CCFLAGS=""-g -O0 -fsanitize=address"" \
    CXXFLAGS=""-g -O0 -fsanitize=address"" \
    CPPFLAGS=""-g -O0 -fsanitize=address"" \
    LDFLAGS=""-fsanitize=address"" \
    LD_PRELOAD=""/usr/lib/gcc/aarch64-linux-gnu/13/libasan.so"" \
    ASAN_OPTIONS=""detect_leaks=0"" 



FROM ubuntu_gcc_env as ubuntu_gcc_hwasan_env
ENV CFLAGS=""-g -O0 -fsanitize=hwaddress"" \
    CCFLAGS=""-g -O0 -fsanitize=hwaddress"" \
    CXXFLAGS=""-g -O0 -fsanitize=hwaddress"" \
    CPPFLAGS=""-g -O0 -fsanitize=hwaddress"" \
    LDFLAGS=""-fsanitize=hwaddress"" \
    # LD_PRELOAD=""/usr/lib/gcc/aarch64-linux-gnu/13/libhwasan.so"" \
    ASAN_OPTIONS=""detect_leaks=0"" \
    HWASAN_OPTIONS=""detect_leaks=0""



FROM ubuntu_env as ubuntu_clang18_env
RUN apt-get install -y \
        clang \
        clang-tools \
        lld
RUN rm /usr/bin/ld && \
    ln -s /usr/bin/ld.lld /usr/bin/ld
ENV CC=clang \
    CXX=clang++



FROM ubuntu_clang18_env as ubuntu_clang18_asan_env
ENV CFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CCFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CXXFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CPPFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    LDFLAGS=""-fsanitize=address -shared-libsan"" \
    LD_PRELOAD=""/usr/lib/llvm-18/lib/clang/18/lib/linux/libclang_rt.asan-aarch64.so"" \
    ASAN_OPTIONS=""detect_leaks=0""



FROM ubuntu_clang18_env as ubuntu_clang18_hwasan_env
ENV CFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CCFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CXXFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CPPFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    LDFLAGS=""-fsanitize=hwaddress -shared-libsan"" \
    LD_PRELOAD=""/usr/lib/llvm-18/lib/clang/18/lib/linux/libclang_rt.hwasan-aarch64.so"" \
    ASAN_OPTIONS=""detect_leaks=0"" \
    HWASAN_OPTIONS=""detect_leaks=0""



FROM ubuntu_env as ubuntu_clang19_env
RUN apt-get install -y \
    lsb-release \
    wget \
    software-properties-common \
    gnupg
RUN wget https://apt.llvm.org/llvm.sh && \
    chmod +x llvm.sh && \
    ./llvm.sh 19 && \
    ln -s /usr/bin/lld-19 /usr/local/bin/lld && \
    ln -s /usr/bin/clang-19 /usr/local/bin/clang && \
    ln -s /usr/bin/clang++-19 /usr/local/bin/clang++ && \
    rm /usr/bin/ld && \
    ln -s /usr/lib/llvm-19/bin/ld.lld /usr/bin/ld
ENV CC=clang \
    CXX=clang++




FROM ubuntu_clang19_env as ubuntu_clang19_asan_env
ENV CFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CCFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CXXFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    CPPFLAGS=""-g -O0 -fsanitize=address -shared-libsan"" \
    LDFLAGS=""-fsanitize=address -shared-libsan"" \
    LD_PRELOAD=""/usr/lib/llvm-19/lib/clang/19/lib/linux/libclang_rt.asan-aarch64.so"" \
    ASAN_OPTIONS=""detect_leaks=0""




FROM ubuntu_clang19_env as ubuntu_clang19_hwasan_env
ENV CFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CCFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CXXFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    CPPFLAGS=""-g -O0 -fsanitize=hwaddress -shared-libsan"" \
    LDFLAGS=""-fsanitize=hwaddress -shared-libsan"" \
    LD_PRELOAD=""/usr/lib/llvm-19/lib/clang/19/lib/linux/libclang_rt.hwasan-aarch64.so"" \
    ASAN_OPTIONS=""detect_leaks=0"" \
    HWASAN_OPTIONS=""detect_leaks=0""



FROM ${ENV} as build_env
COPY . /src
WORKDIR /src
RUN python3 -m venv /venv && \
    . /venv/bin/activate && \
    pip3 install -r requirements/all_requirements.txt
```

- Add docker-compose.yaml:
```yaml
version: '3.8'

services:
  ubuntu_gcc_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_gcc_env

  ubuntu_gcc_asan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_gcc_asan_env

  ubuntu_gcc_hwasan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_gcc_hwasan_env

  ubuntu_clang18_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang18_env

  ubuntu_clang18_asan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang18_asan_env

  ubuntu_clang18_hwasan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang18_hwasan_env

  ubuntu_clang19_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang19_env

  ubuntu_clang19_asan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang19_asan_env

  ubuntu_clang19_hwasan_env:
    build:
      target: build_env
      args:
        ENV: ubuntu_clang19_hwasan_env
```
- Build images
```
$ docker compose build
```
- Run commands in environment
```shell
$ source /venv/bin/activate
$ spin build
$ spin test
```

## Versions

```shell
$ gcc --version
gcc (Ubuntu 13.2.0-23ubuntu4) 13.2.0
Copyright (C) 2023 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
```

```shell
$ python3 --version
Python 3.12.3
```

```shell
$ clang --version
Ubuntu clang version 18.1.3 (1ubuntu1)
Target: aarch64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/bin
```

```shell
$ clang --version
Ubuntu clang version 19.0.0 (++20240709081800+2c42c2263dc6-1~exp1~20240709201923.273)
Target: aarch64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/lib/llvm-19/bin
```

```shell
$ cat /etc/os-release
PRETTY_NAME=""Ubuntu 24.04 LTS""
NAME=""Ubuntu""
VERSION_ID=""24.04""
VERSION=""24.04 LTS (Noble Numbat)""
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo
```

```shell
$ docker version
Client:
 Cloud integration: v1.0.35+desktop.13
 Version:           26.1.1
 API version:       1.45
 Go version:        go1.21.9
 Git commit:        4cf5afa
 Built:             Tue Apr 30 11:44:56 2024
 OS/Arch:           darwin/arm64
 Context:           desktop-linux

Server: Docker Desktop 4.30.0 (149282)
 Engine:
  Version:          26.1.1
  API version:      1.45 (minimum version 1.24)
  Go version:       go1.21.9
  Git commit:       ac2de55
  Built:            Tue Apr 30 11:48:04 2024
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          1.6.31
  GitCommit:        e377cd56a71523140ca6ae87e30244719194a521
 runc:
  Version:          1.1.12
  GitCommit:        v1.1.12-0-g51d5e94
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

## Runs
### ubuntu_gcc_env
OK
```shell
$ docker compose run ubuntu_gcc_env
$ source /venv/bin/activate
$ spin build 
OK
$ spin test
43233 passed, 890 skipped, 2785 deselected, 58 xfailed, 5 xpassed in 97.26s (0:01:37)
```

### ubuntu_gcc_asan_env
Stops with no reason
```shell
$ docker compose run ubuntu_gcc_asan_env
$ source /venv/bin/activate
$ spin build 
OK
$ spin test
Invoking `build` prior to running tests:
$ /venv/bin/python3 vendored-meson/meson/meson.py compile -C build
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /venv/bin/ninja -C /src/build
ninja: Entering directory `/src/build'
[1/1] Generating numpy/generate-version with a custom command
Saving version to numpy/version.py
$ /venv/bin/python3 vendored-meson/meson/meson.py install --only-changed -C build --destdir ../build-install
$ export PYTHONPATH=""/src/build-install/usr/lib/python3/dist-packages""
$ /venv/bin/python3 -P -c 'import numpy'
$ export PYTHONPATH=""/src/build-install/usr/lib/python3/dist-packages""
$ cd /src/build-install/usr/lib/python3/dist-packages
$ /venv/bin/python3 -m pytest --rootdir=/src/build-install/usr/lib/python3/dist-packages -m 'not slow' numpy
===================================================================================================== test session starts =====================================================================================================
platform linux -- Python 3.12.3, pytest-7.4.0, pluggy-1.5.0
rootdir: /src/build-install/usr/lib/python3/dist-packages
configfile: ../../../../../pytest.ini
plugins: cov-4.1.0, hypothesis-6.81.1, xdist-3.6.1
collected 46970 items / 2785 deselected / 1 skipped / 44185 selected

numpy/_core/tests/test__exceptions.py
numpy/_core/tests/test_abc.py
numpy/_core/tests/test_api.py
numpy/_core/tests/test_argparse.py
numpy/_core/tests/test_array_coercion.py .............................................................x................................................................................................................
```

### ubuntu_gcc_hwasan_env
Timeout (still waiting, ~12h)
```shell
$ docker compose run ubuntu_gcc_hwasan_env
$ source venv/bin/activate
$ spin build 
...
[319/323] Linking static target numpy/_core/libhighway_qsort_16bit.dispatch.h_ASIMDHP.a
```


### ubuntu_clang18_env
Tests failed:
```shell
$ docker compose run ubuntu_clang18_env
$ source venv/bin/activate
$ spin build 
OK
$ spin test
43233 passed, 890 skipped, 2785 deselected, 58 xfailed, 5 xpassed in 100.34s (0:01:40)

=============== FAILURES ===============
_______________ TestDivision.test_floor_division_errors[g] _______________

self = <numpy._core.tests.test_umath.TestDivision object at 0xffff74cf7800>, dtype = 'g'

    @pytest.mark.skipif(hasattr(np.__config__, ""blas_ssl2_info""),
            reason=""gh-22982"")
    @pytest.mark.skipif(IS_WASM, reason=""fp errors don't work in wasm"")
    @pytest.mark.parametrize('dtype', np.typecodes['Float'])
    def test_floor_division_errors(self, dtype):
        fnan = np.array(np.nan, dtype=dtype)
        fone = np.array(1.0, dtype=dtype)
        fzer = np.array(0.0, dtype=dtype)
        finf = np.array(np.inf, dtype=dtype)
        # divide by zero error check
        with np.errstate(divide='raise', invalid='ignore'):
            assert_raises(FloatingPointError, np.floor_divide, fone, fzer)
        with np.errstate(divide='ignore', invalid='raise'):
            np.floor_divide(fone, fzer)

        # The following already contain a NaN and should not warn
        with np.errstate(all='raise'):
>           np.floor_divide(fnan, fone)
E           FloatingPointError: invalid value encountered in floor_divide

dtype      = 'g'
finf       = array(inf, dtype=float128)
fnan       = array(nan, dtype=float128)
fone       = array(1., dtype=float128)
fzer       = array(0., dtype=float128)
self       = <numpy._core.tests.test_umath.TestDivision object at 0xffff74cf7800>

numpy/_core/tests/test_umath.py:680: FloatingPointError

_______________ TestRemainder.test_float_remainder_errors[remainder-g] _______________

self = <numpy._core.tests.test_umath.TestRemainder object at 0xffff746a5640>, dtype = 'g', fn = <ufunc 'remainder'>

    @pytest.mark.skipif(hasattr(np.__config__, ""blas_ssl2_info""),
            reason=""gh-22982"")
    @pytest.mark.skipif(IS_WASM, reason=""fp errors don't work in wasm"")
    @pytest.mark.xfail(sys.platform.startswith(""darwin""),
           reason=""MacOS seems to not give the correct 'invalid' warning for ""
                  ""`fmod`.  Hopefully, others always do."")
    @pytest.mark.parametrize('dtype', np.typecodes['Float'])
    @pytest.mark.parametrize('fn', [np.fmod, np.remainder])
    def test_float_remainder_errors(self, dtype, fn):
        fzero = np.array(0.0, dtype=dtype)
        fone = np.array(1.0, dtype=dtype)
        finf = np.array(np.inf, dtype=dtype)
        fnan = np.array(np.nan, dtype=dtype)

        # The following already contain a NaN and should not warn.
        with np.errstate(all='raise'):
            with pytest.raises(FloatingPointError,
                    match=""invalid value""):
                fn(fone, fzero)
            fn(fnan, fzero)
>           fn(fzero, fnan)
E           FloatingPointError: invalid value encountered in remainder

dtype      = 'g'
finf       = array(inf, dtype=float128)
fn         = <ufunc 'remainder'>
fnan       = array(nan, dtype=float128)
fone       = array(1., dtype=float128)
fzero      = array(0., dtype=float128)
self       = <numpy._core.tests.test_umath.TestRemainder object at 0xffff746a5640>

numpy/_core/tests/test_umath.py:827: FloatingPointError
=============== short test summary info ===============
FAILED numpy/_core/tests/test_umath.py::TestDivision::test_floor_division_errors[g] - FloatingPointError: invalid value encountered in floor_divide
FAILED numpy/_core/tests/test_umath.py::TestRemainder::test_float_remainder_errors[remainder-g] - FloatingPointError: invalid value encountered in remainder
=============== 2 failed, 43231 passed, 890 skipped, 2785 deselected, 58 xfailed, 5 xpassed in 193.05s (0:03:13) ===============
```

### ubuntu_clang18_hwasan_env
Compiler is going down:
```
$ docker compose run ubuntu_clang18_hwasan_env
$ source venv/bin/activate
$ spin build 
[208/323] Compiling C++ object numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o
FAILED: numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o
clang++ -Inumpy/_core/libhighway_qsort.dispatch.h_SVE.a.p -Inumpy/_core -I../numpy/_core -Inumpy/_core/include -I../numpy/_core/include -I../numpy/_core/src/common -I../numpy/_core/src/multiarray -I../numpy/_core/src/npymath -I../numpy/_core/src/umath -I../numpy/_core/src/highway -I/usr/include/python3.12 -I/usr/include/aarch64-linux-gnu/python3.12 -I/src/build/meson_cpu -fcolor-diagnostics -Wall -Winvalid-pch -std=c++17 -O2 -g -ftrapping-math -DNPY_HAVE_CLANG_FPSTRICT -g -O0 -fsanitize=hwaddress -shared-libsan -g -O0 -fsanitize=hwaddress -shared-libsan -fPIC -DNPY_INTERNAL_BUILD -DHAVE_NPY_CONFIG_H -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti -O3 -DNPY_HAVE_NEON_VFPV4 -DNPY_HAVE_NEON_FP16 -DNPY_HAVE_NEON -DNPY_HAVE_ASIMD -DNPY_HAVE_ASIMDHP -DNPY_HAVE_SVE -march=armv8.2-a+sve+fp16 -DNPY_MTARGETS_CURRENT=SVE -MD -MQ numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o -MF numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o.d -o numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o -c ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp
fatal error: error in backend: Invalid size request on a scalable vector.
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace, preprocessed source, and associated run script.
Stack dump:
0.	Program arguments: clang++ -Inumpy/_core/libhighway_qsort.dispatch.h_SVE.a.p -Inumpy/_core -I../numpy/_core -Inumpy/_core/include -I../numpy/_core/include -I../numpy/_core/src/common -I../numpy/_core/src/multiarray -I../numpy/_core/src/npymath -I../numpy/_core/src/umath -I../numpy/_core/src/highway -I/usr/include/python3.12 -I/usr/include/aarch64-linux-gnu/python3.12 -I/src/build/meson_cpu -fcolor-diagnostics -Wall -Winvalid-pch -std=c++17 -O2 -g -ftrapping-math -DNPY_HAVE_CLANG_FPSTRICT -g -O0 -fsanitize=hwaddress -shared-libsan -g -O0 -fsanitize=hwaddress -shared-libsan -fPIC -DNPY_INTERNAL_BUILD -DHAVE_NPY_CONFIG_H -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -D__STDC_VERSION__=0 -fno-exceptions -fno-rtti -O3 -DNPY_HAVE_NEON_VFPV4 -DNPY_HAVE_NEON_FP16 -DNPY_HAVE_NEON -DNPY_HAVE_ASIMD -DNPY_HAVE_ASIMDHP -DNPY_HAVE_SVE -march=armv8.2-a+sve+fp16 -DNPY_MTARGETS_CURRENT=SVE -MD -MQ numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o -MF numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o.d -o numpy/_core/libhighway_qsort.dispatch.h_SVE.a.p/src_npysort_highway_qsort.dispatch.cpp.o -c ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp
1.	<eof> parser at end of file
2.	Optimizer
Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):
0  libLLVM.so.18.1      0x0000ffff7eead398 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) + 84
1  libLLVM.so.18.1      0x0000ffff7eeab5a8 llvm::sys::RunSignalHandlers() + 116
2  libLLVM.so.18.1      0x0000ffff7edfb17c
3  libLLVM.so.18.1      0x0000ffff7edfb128
4  libLLVM.so.18.1      0x0000ffff7eea7fcc llvm::sys::Process::Exit(int, bool) + 52
5  clang++              0x0000aaaaaad32560
6  libLLVM.so.18.1      0x0000ffff7ee08a20 llvm::report_fatal_error(llvm::Twine const&, bool) + 248
7  libLLVM.so.18.1      0x0000ffff7ee08928 llvm::report_fatal_error(llvm::Twine const&, bool) + 0
8  libLLVM.so.18.1      0x0000ffff7ee62334 llvm::TypeSize::operator unsigned long() const + 0
9  libLLVM.so.18.1      0x0000ffff7ee6235c llvm::TypeSize::operator unsigned long() const + 40
10 libLLVM.so.18.1      0x0000ffff7fa12940 llvm::memtag::StackInfoBuilder::isInterestingAlloca(llvm::AllocaInst const&) + 276
11 libLLVM.so.18.1      0x0000ffff7fa124f0 llvm::memtag::StackInfoBuilder::visit(llvm::Instruction&) + 136
12 libLLVM.so.18.1      0x0000ffff7fb474e0
13 libLLVM.so.18.1      0x0000ffff7fb47210 llvm::HWAddressSanitizerPass::run(llvm::Module&, llvm::AnalysisManager<llvm::Module>&) + 6552
14 libLLVM.so.18.1      0x0000ffff7f03a09c llvm::PassManager<llvm::Module, llvm::AnalysisManager<llvm::Module>>::run(llvm::Module&, llvm::AnalysisManager<llvm::Module>&) + 332
15 libclang-cpp.so.18.1 0x0000ffff86f72fe0
16 libclang-cpp.so.18.1 0x0000ffff86f6b918 clang::EmitBackendOutput(clang::DiagnosticsEngine&, clang::HeaderSearchOptions const&, clang::CodeGenOptions const&, clang::TargetOptions const&, clang::LangOptions const&, llvm::StringRef, llvm::Module*, clang::BackendAction, llvm::IntrusiveRefCntPtr<llvm::vfs::FileSystem>, std::unique_ptr<llvm::raw_pwrite_stream, std::default_delete<llvm::raw_pwrite_stream>>, clang::BackendConsumer*) + 1844
17 libclang-cpp.so.18.1 0x0000ffff87285f58 clang::BackendConsumer::HandleTranslationUnit(clang::ASTContext&) + 1180
18 libclang-cpp.so.18.1 0x0000ffff85eea5b0 clang::ParseAST(clang::Sema&, bool, bool) + 572
19 libclang-cpp.so.18.1 0x0000ffff87c9fa34 clang::FrontendAction::Execute() + 112
20 libclang-cpp.so.18.1 0x0000ffff87c30590 clang::CompilerInstance::ExecuteAction(clang::FrontendAction&) + 744
21 libclang-cpp.so.18.1 0x0000ffff87d18e4c clang::ExecuteCompilerInvocation(clang::CompilerInstance*) + 616
22 clang++              0x0000aaaaaad321c4 cc1_main(llvm::ArrayRef<char const*>, char const*, void*) + 3360
23 clang++              0x0000aaaaaad2fbac
24 libclang-cpp.so.18.1 0x0000ffff8792a950
25 libLLVM.so.18.1      0x0000ffff7edfb0f8 llvm::CrashRecoveryContext::RunSafely(llvm::function_ref<void ()>) + 168
26 libclang-cpp.so.18.1 0x0000ffff8792a1bc clang::driver::CC1Command::Execute(llvm::ArrayRef<std::optional<llvm::StringRef>>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>*, bool*) const + 352
27 libclang-cpp.so.18.1 0x0000ffff878f8d3c clang::driver::Compilation::ExecuteCommand(clang::driver::Command const&, clang::driver::Command const*&, bool) const + 756
28 libclang-cpp.so.18.1 0x0000ffff878f8f4c clang::driver::Compilation::ExecuteJobs(clang::driver::JobList const&, llvm::SmallVectorImpl<std::pair<int, clang::driver::Command const*>>&, bool) const + 136
29 libclang-cpp.so.18.1 0x0000ffff879112f4 clang::driver::Driver::ExecuteCompilation(clang::driver::Compilation&, llvm::SmallVectorImpl<std::pair<int, clang::driver::Command const*>>&) + 324
30 clang++              0x0000aaaaaad2f344 clang_main(int, char**, llvm::ToolContext const&) + 9756
31 clang++              0x0000aaaaaad3ae40 main + 92
32 libc.so.6            0x0000ffff7dcf84c4
33 libc.so.6            0x0000ffff7dcf8598 __libc_start_main + 152
34 clang++              0x0000aaaaaad2c970 _start + 48
clang++: error: clang frontend command failed with exit code 70 (use -v to see invocation)
Ubuntu clang version 18.1.3 (1ubuntu1)
Target: aarch64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/bin
clang++: note: diagnostic msg:
********************

PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:
Preprocessed source(s) and associated run script(s) are located at:
clang++: note: diagnostic msg: /tmp/highway_qsort-02f1d0.cpp
clang++: note: diagnostic msg: /tmp/highway_qsort-02f1d0.sh
clang++: note: diagnostic msg:

********************
[223/323] Compiling C++ object numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so.p/src_npysort_timsort.cpp.o
ninja: build stopped: subcommand failed.
```

### ubuntu_clang19_env
Tests failed:
```shell
$ docker compose run ubuntu_clang19_env
$ spin build
OK
$ spin test
=============== FAILURES ===============
_______________ TestDivision.test_floor_division_errors[g] _______________

self = <numpy._core.tests.test_umath.TestDivision object at 0xffff6c7af5f0>, dtype = 'g'

    @pytest.mark.skipif(hasattr(np.__config__, ""blas_ssl2_info""),
            reason=""gh-22982"")
    @pytest.mark.skipif(IS_WASM, reason=""fp errors don't work in wasm"")
    @pytest.mark.parametrize('dtype', np.typecodes['Float'])
    def test_floor_division_errors(self, dtype):
        fnan = np.array(np.nan, dtype=dtype)
        fone = np.array(1.0, dtype=dtype)
        fzer = np.array(0.0, dtype=dtype)
        finf = np.array(np.inf, dtype=dtype)
        # divide by zero error check
        with np.errstate(divide='raise', invalid='ignore'):
            assert_raises(FloatingPointError, np.floor_divide, fone, fzer)
        with np.errstate(divide='ignore', invalid='raise'):
            np.floor_divide(fone, fzer)

        # The following already contain a NaN and should not warn
        with np.errstate(all='raise'):
>           np.floor_divide(fnan, fone)
E           FloatingPointError: invalid value encountered in floor_divide

dtype      = 'g'
finf       = array(inf, dtype=float128)
fnan       = array(nan, dtype=float128)
fone       = array(1., dtype=float128)
fzer       = array(0., dtype=float128)
self       = <numpy._core.tests.test_umath.TestDivision object at 0xffff6c7af5f0>

numpy/_core/tests/test_umath.py:680: FloatingPointError
_______________ TestRemainder.test_float_remainder_errors[remainder-g] _______________

self = <numpy._core.tests.test_umath.TestRemainder object at 0xffff6c165430>, dtype = 'g', fn = <ufunc 'remainder'>

    @pytest.mark.skipif(hasattr(np.__config__, ""blas_ssl2_info""),
            reason=""gh-22982"")
    @pytest.mark.skipif(IS_WASM, reason=""fp errors don't work in wasm"")
    @pytest.mark.xfail(sys.platform.startswith(""darwin""),
           reason=""MacOS seems to not give the correct 'invalid' warning for ""
                  ""`fmod`.  Hopefully, others always do."")
    @pytest.mark.parametrize('dtype', np.typecodes['Float'])
    @pytest.mark.parametrize('fn', [np.fmod, np.remainder])
    def test_float_remainder_errors(self, dtype, fn):
        fzero = np.array(0.0, dtype=dtype)
        fone = np.array(1.0, dtype=dtype)
        finf = np.array(np.inf, dtype=dtype)
        fnan = np.array(np.nan, dtype=dtype)

        # The following already contain a NaN and should not warn.
        with np.errstate(all='raise'):
            with pytest.raises(FloatingPointError,
                    match=""invalid value""):
                fn(fone, fzero)
            fn(fnan, fzero)
>           fn(fzero, fnan)
E           FloatingPointError: invalid value encountered in remainder

dtype      = 'g'
finf       = array(inf, dtype=float128)
fn         = <ufunc 'remainder'>
fnan       = array(nan, dtype=float128)
fone       = array(1., dtype=float128)
fzero      = array(0., dtype=float128)
self       = <numpy._core.tests.test_umath.TestRemainder object at 0xffff6c165430>

numpy/_core/tests/test_umath.py:827: FloatingPointError
=============== short test summary info ===============
FAILED numpy/_core/tests/test_umath.py::TestDivision::test_floor_division_errors[g] - FloatingPointError: invalid value encountered in floor_divide
FAILED numpy/_core/tests/test_umath.py::TestRemainder::test_float_remainder_errors[remainder-g] - FloatingPointError: invalid value encountered in remainder
=============== 2 failed, 43231 passed, 890 skipped, 2785 deselected, 58 xfailed, 5 xpassed in 98.56s (0:01:38) ===============
```

### ubuntu_clang19_asan_env
undefined symbol: _ZN3hwy11VectorBytesEv
```shell
$ docker compose run ubuntu_clang19_asan_env
$ spin build
OK
$ spin test
Invoking `build` prior to running tests:
$ /venv/bin/python3 vendored-meson/meson/meson.py compile -C build
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /venv/bin/ninja -C /src/build
ninja: Entering directory `/src/build'
[1/1] Generating numpy/generate-version with a custom command
Saving version to numpy/version.py
$ /venv/bin/python3 vendored-meson/meson/meson.py install --only-changed -C build --destdir ../build-install
$ export PYTHONPATH=""/src/build-install/usr/lib/python3/dist-packages""
$ /venv/bin/python3 -P -c 'import numpy'
Traceback (most recent call last):
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/_core/__init__.py"", line 23, in <module>
    from . import multiarray
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/_core/multiarray.py"", line 10, in <module>
    from . import overrides
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/_core/overrides.py"", line 8, in <module>
    from numpy._core._multiarray_umath import (
ImportError: /src/build-install/usr/lib/python3/dist-packages/numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so: undefined symbol: _ZN3hwy11VectorBytesEv

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/__init__.py"", line 114, in <module>
    from numpy.__config__ import show as show_config
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/__config__.py"", line 4, in <module>
    from numpy._core._multiarray_umath import (
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/_core/__init__.py"", line 49, in <module>
    raise ImportError(msg)
ImportError:

IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!

Importing the numpy C-extensions failed. This error can happen for
many reasons, often due to issues with your setup or how NumPy was
installed.

We have compiled some common reasons and troubleshooting tips at:

    https://numpy.org/devdocs/user/troubleshooting-importerror.html

Please note and check the following:

  * The Python version is: Python3.12 from ""/venv/bin/python3""
  * The NumPy version is: ""2.0.0""

and make sure that they are the versions you expect.
Please carefully study the documentation linked above for further help.

Original error was: /src/build-install/usr/lib/python3/dist-packages/numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so: undefined symbol: _ZN3hwy11VectorBytesEv


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/src/build-install/usr/lib/python3/dist-packages/numpy/__init__.py"", line 119, in <module>
    raise ImportError(msg) from e
ImportError: Error importing numpy: you should not try to import numpy from
        its source directory; please exit the numpy source tree, and relaunch
        your python interpreter from there.
As a sanity check, we tried to import numpy.
Stopping. Please investigate the build error.
```

### ubuntu_clang19_hwasan_env
Build failed: HWAddressSanitizer: tag-mismatch
```shell
$ docker compose run ubuntu_clang19_hwasan_env
$ spin build
Invoking `build` prior to running tests:
$ /venv/bin/python3 vendored-meson/meson/meson.py compile -C build
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /venv/bin/ninja -C /src/build
ninja: Entering directory `/src/build'
[1/1] Generating numpy/generate-version with a custom command
Saving version to numpy/version.py
$ /venv/bin/python3 vendored-meson/meson/meson.py install --only-changed -C build --destdir ../build-install
$ export PYTHONPATH=""/src/build-install/usr/lib/python3/dist-packages""
$ /venv/bin/python3 -P -c 'import numpy'
==3669==ERROR: HWAddressSanitizer: tag-mismatch on address 0xffff923937a0 at pc 0xffff94427ec4
WRITE of size 353 at 0xffff923937a0 tags: ab/00 (ptr/mem) in thread T0
    #0 0xffff94427ec4 in __hwasan_memset (/usr/lib/llvm-19/lib/clang/19/lib/linux/libclang_rt.hwasan-aarch64.so+0x27ec4) (BuildId: 2f010f5286219c795eacb8b5bf9bef0e613730c3)
    #1 0xffff91e86c14 in npy__cpu_init_features /src/build/../numpy/_core/src/common/npy_cpu_features.c:780:5
    #2 0xffff91e86510 in npy_cpu_init /src/build/../numpy/_core/src/common/npy_cpu_features.c:44:5
    #3 0xffff917e62fc in PyInit__multiarray_umath /src/build/../numpy/_core/src/multiarray/multiarraymodule.c:4971:9
    #4 0x66def0 in _PyImport_LoadDynamicModuleWithSpec /usr/src/python3.12-3.12.3-1/build-static/../Python/importdl.c:169:9
    #5 0x66d338 in _imp_create_dynamic_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:3775:11
    #6 0x66d338 in _imp_create_dynamic /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/import.c.h:506:20
    #7 0x502d4c in cfunction_vectorcall_FASTCALL /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:422:24
    #8 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #9 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #10 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #11 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #12 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #13 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #14 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #15 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #16 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #17 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #18 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #19 0x55d264 in builtin_exec_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:1096:17
    #20 0x55d264 in builtin_exec /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:586:20
    #21 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #22 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #23 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #24 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #25 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #26 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #27 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #28 0x55d754 in builtin___import___impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:275:12
    #29 0x55d754 in builtin___import__ /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:107:20
    #30 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #31 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #32 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #33 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #34 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #35 0x58c120 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2931:25
    #36 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #37 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #38 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #39 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #40 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #41 0x55d264 in builtin_exec_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:1096:17
    #42 0x55d264 in builtin_exec /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:586:20
    #43 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #44 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #45 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #46 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #47 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #48 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #49 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #50 0x55d754 in builtin___import___impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:275:12
    #51 0x55d754 in builtin___import__ /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:107:20
    #52 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #53 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #54 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #55 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #56 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #57 0x58c120 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2931:25
    #58 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #59 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #60 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #61 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #62 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #63 0x55d264 in builtin_exec_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:1096:17
    #64 0x55d264 in builtin_exec /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:586:20
    #65 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #66 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #67 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #68 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #69 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #70 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #71 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #72 0x55d754 in builtin___import___impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:275:12
    #73 0x55d754 in builtin___import__ /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:107:20
    #74 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #75 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #76 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #77 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #78 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #79 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #80 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #81 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #82 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #83 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #84 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #85 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #86 0x55d264 in builtin_exec_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:1096:17
    #87 0x55d264 in builtin_exec /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:586:20
    #88 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #89 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #90 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #91 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #92 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #93 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #94 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #95 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #96 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #97 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #98 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #99 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #100 0x55d264 in builtin_exec_impl /usr/src/python3.12-3.12.3-1/build-static/../Python/bltinmodule.c:1096:17
    #101 0x55d264 in builtin_exec /usr/src/python3.12-3.12.3-1/build-static/../Python/clinic/bltinmodule.c.h:586:20
    #102 0x502a38 in cfunction_vectorcall_FASTCALL_KEYWORDS /usr/src/python3.12-3.12.3-1/build-static/../Objects/methodobject.c:438:24
    #103 0x5652ac in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:3254:26
    #104 0x4c2f00 in _PyObject_VectorcallTstate /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_call.h:92:11
    #105 0x4c2f00 in object_vacall /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:850:14
    #106 0x4c4ae4 in PyObject_CallMethodObjArgs /usr/src/python3.12-3.12.3-1/build-static/../Objects/call.c:911:24
    #107 0x58bee8 in import_find_and_load /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2779:11
    #108 0x58bee8 in PyImport_ImportModuleLevelObject /usr/src/python3.12-3.12.3-1/build-static/../Python/import.c:2862:15
    #109 0x565f6c in import_name /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:2482:15
    #110 0x565f6c in _PyEval_EvalFrameDefault /usr/src/python3.12-3.12.3-1/build-static/Python/bytecodes.c:2135:19
    #111 0x560070 in _PyEval_EvalFrame /usr/src/python3.12-3.12.3-1/build-static/../Include/internal/pycore_ceval.h:89:16
    #112 0x560070 in _PyEval_Vector /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:1683:12
    #113 0x560070 in PyEval_EvalCode /usr/src/python3.12-3.12.3-1/build-static/../Python/ceval.c:578:21
    #114 0x598ddc in run_eval_code_obj /usr/src/python3.12-3.12.3-1/build-static/../Python/pythonrun.c:1722:9
    #115 0x598ddc in run_mod /usr/src/python3.12-3.12.3-1/build-static/../Python/pythonrun.c:1743:19
    #116 0x598ddc in PyRun_StringFlags /usr/src/python3.12-3.12.3-1/build-static/../Python/pythonrun.c:1618:15
    #117 0x67c990 in PyRun_SimpleStringFlags /usr/src/python3.12-3.12.3-1/build-static/../Python/pythonrun.c:480:9
    #118 0x68919c in pymain_run_command /usr/src/python3.12-3.12.3-1/build-static/../Modules/main.c:255:11
    #119 0x68919c in pymain_run_python /usr/src/python3.12-3.12.3-1/build-static/../Modules/main.c:620:21
    #120 0x68919c in Py_RunMain /usr/src/python3.12-3.12.3-1/build-static/../Modules/main.c:709:5
    #121 0x688ca4 in Py_BytesMain /usr/src/python3.12-3.12.3-1/build-static/../Modules/main.c:763:12
    #122 0xffff941284c0 in __libc_start_call_main csu/../sysdeps/nptl/libc_start_call_main.h:58:16
    #123 0xffff94128594 in __libc_start_main csu/../csu/libc-start.c:360:3
    #124 0x5f24ec in _start (/usr/bin/python3.12+0x5f24ec) (BuildId: 18160fe6beb052a7e6830ecc99e313a3498c377d)


Thread: T0 0xeffe00002000 stack: [0xfffffb0da000,0xfffffb8da000) sz: 8388608 tls: [0xffff94ed7460,0xffff94ed8320)
Thread: T1 0xeffe00012000 stack: [0xffff8eb00000,0xffff8f2ff140) sz: 8384832 tls: [0xffff8f2ff140,0xffff8f300000)
Thread: T2 0xeffe00022000 stack: [0xffff8e2f0000,0xffff8eaef140) sz: 8384832 tls: [0xffff8eaef140,0xffff8eaf0000)
Thread: T3 0xeffe00032000 stack: [0xffff8dae0000,0xffff8e2df140) sz: 8384832 tls: [0xffff8e2df140,0xffff8e2e0000)
Thread: T4 0xeffe00042000 stack: [0xffff8d2d0000,0xffff8dacf140) sz: 8384832 tls: [0xffff8dacf140,0xffff8dad0000)
Thread: T5 0xeffe00052000 stack: [0xffff8cac0000,0xffff8d2bf140) sz: 8384832 tls: [0xffff8d2bf140,0xffff8d2c0000)
Thread: T6 0xeffe00062000 stack: [0xffff8c2b0000,0xffff8caaf140) sz: 8384832 tls: [0xffff8caaf140,0xffff8cab0000)
Thread: T7 0xeffe00072000 stack: [0xffff8baa0000,0xffff8c29f140) sz: 8384832 tls: [0xffff8c29f140,0xffff8c2a0000)
Thread: T8 0xeffe00082000 stack: [0xffff8b290000,0xffff8ba8f140) sz: 8384832 tls: [0xffff8ba8f140,0xffff8ba90000)
Thread: T9 0xeffe00092000 stack: [0xffff8aa80000,0xffff8b27f140) sz: 8384832 tls: [0xffff8b27f140,0xffff8b280000)
Thread: T10 0xeffe000a2000 stack: [0xffff8a270000,0xffff8aa6f140) sz: 8384832 tls: [0xffff8aa6f140,0xffff8aa70000)
Thread: T11 0xeffe000b2000 stack: [0xffff89a60000,0xffff8a25f140) sz: 8384832 tls: [0xffff8a25f140,0xffff8a260000)
Thread: T12 0xeffe000c2000 stack: [0xffff89250000,0xffff89a4f140) sz: 8384832 tls: [0xffff89a4f140,0xffff89a50000)
Thread: T13 0xeffe000d2000 stack: [0xffff88a40000,0xffff8923f140) sz: 8384832 tls: [0xffff8923f140,0xffff89240000)

Memory tags around the buggy address (one tag corresponds to 16 bytes):
  0xffff92392f00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393000: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393100: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393200: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393300: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393400: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393500: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393600: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
=>0xffff92393700: 00  00  00  00  00  00  00  00  00  00 [00] 00  00  00  00  00
  0xffff92393800: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393900: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393a00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393b00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393c00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393d00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393e00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
  0xffff92393f00: 00  00  00  00  00  00  00  00  00  00  00  00  00  00  00  00
Tags for short granules around the buggy address (one tag corresponds to 16 bytes):
  0xffff92393600: ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..
=>0xffff92393700: ..  ..  ..  ..  ..  ..  ..  ..  ..  .. [..] ..  ..  ..  ..  ..
  0xffff92393800: ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..
See https://clang.llvm.org/docs/HardwareAssistedAddressSanitizerDesign.html#short-granules for a description of short granule tags
SUMMARY: HWAddressSanitizer: tag-mismatch /src/build/../numpy/_core/src/common/npy_cpu_features.c:780:5 in npy__cpu_init_features
As a sanity check, we tried to import numpy.
Stopping. Please investigate the build error.
```

### Notes
Compiler warnings:
```
[142/323] Compiling C object numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so.p/src_multiarray_alloc.c.o
../numpy/_core/src/multiarray/alloc.c: In function ‘PyDataMem_RENEW’:
../numpy/_core/src/multiarray/alloc.c:274:9: warning: pointer ‘ptr’ may be used after ‘realloc’ [-Wuse-after-free]
  274 |         PyTraceMalloc_Untrack(NPY_TRACE_DOMAIN, (npy_uintp)ptr);
      |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../numpy/_core/src/multiarray/alloc.c:272:14: note: call to ‘realloc’ here
  272 |     result = realloc(ptr, size);
      |              ^~~~~~~~~~~~~~~~~~
```
```
[8/323] Generating numpy/generate-version with a custom command
Saving version to numpy/version.py
[141/323] Compiling C object numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so.p/src_multiarray_alloc.c.o
../numpy/_core/src/multiarray/alloc.c: In function ‘PyDataMem_RENEW’:
../numpy/_core/src/multiarray/alloc.c:274:9: warning: pointer ‘ptr’ may be used after ‘realloc’ [-Wuse-after-free]
  274 |         PyTraceMalloc_Untrack(NPY_TRACE_DOMAIN, (npy_uintp)ptr);
      |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
../numpy/_core/src/multiarray/alloc.c:272:14: note: call to ‘realloc’ here
  272 |     result = realloc(ptr, size);
      |              ^~~~~~~~~~~~~~~~~~
[267/323] Compiling C++ object numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so.p/src_umath_stringdtype_ufuncs.cpp.o
In file included from ../numpy/_core/src/umath/stringdtype_ufuncs.cpp:21:
../numpy/_core/src/umath/string_buffer.h:265:23: warning: template-id not allowed for constructor in C++20 [-Wtemplate-id-cdtor]
  265 |     inline Buffer<enc>()
      |                       ^
../numpy/_core/src/umath/string_buffer.h:265:23: note: remove the ‘< >’
../numpy/_core/src/umath/string_buffer.h:270:23: warning: template-id not allowed for constructor in C++20 [-Wtemplate-id-cdtor]
  270 |     inline Buffer<enc>(char *buf_, npy_int64 elsize_)
      |                       ^
../numpy/_core/src/umath/string_buffer.h:270:23: note: remove the ‘< >’
[284/323] Compiling C++ object numpy/_core/_multiarray_umath.cpython-312-aarch64-linux-gnu.so.p/src_umath_string_ufuncs.cpp.o
In file included from ../numpy/_core/src/umath/string_ufuncs.cpp:21:
../numpy/_core/src/umath/string_buffer.h:265:23: warning: template-id not allowed for constructor in C++20 [-Wtemplate-id-cdtor]
  265 |     inline Buffer<enc>()
      |                       ^
../numpy/_core/src/umath/string_buffer.h:265:23: note: remove the ‘< >’
../numpy/_core/src/umath/string_buffer.h:270:23: warning: template-id not allowed for constructor in C++20 [-Wtemplate-id-cdtor]
  270 |     inline Buffer<enc>(char *buf_, npy_int64 elsize_)
      |                       ^
../numpy/_core/src/umath/string_buffer.h:270:23: note: remove the ‘< >’ 
```
","We switched from gcc ASAN to clang ASAN a while ago in our tests because of unexplained hangs. Probably related to some of these. || Thank you for the very detailed report @n-bes. It's a little hard to figure out what's actionable, since a good amount is about ASan. I think we can say that only Clang ASan is supported, and discard the GCC ASan issues reported here (of course if anyone understands them and wants to dig in, that is welcome). 

For the other issues, could you please open separate reports? I think:
- the test failures are a valid bug report
- for the `realloc(ptr, size)` compile warning there's already an open issue
- if there's a non-ASan build failure, a separate report would help || @n-bes did you get a chance to review the last comment here? || @mattip, @rgommers, Hi. @alex, provided me link to https://github.com/google/sanitizers/issues/1245

So, some my HWASan reports look like FP. Recently, I rebuild [cpython](https://github.com/python/cpython) (~500 configurations) and need time to process logs (I want to exclude FPs). 

After that, I'll handle numpy. || > I rebuild [cpython](https://github.com/python/cpython) (~500 configurations) and need time to process logs

https://github.com/n-bes/build-cpython/

Hope I find time to do something similar for numpy
",closed,2024-07-11T16:51:43+00:00,2025-01-31T23:45:20+00:00,n-bes,00 - Bug,1,"PR#28232 - numpy/_core/src/npymath/npy_math_internal.h.src: @@ -506,6 +506,14 @@ NPY_INPLACE @type@ npy_logaddexp2@c@(@type@ x, @type@ y)|;|     }|;| }|;| |;|+|;|+/* Define a macro for the ARM64 Clang specific condition */|;|+#if defined(__aarch64__) && defined(__clang__)|;|+    #define IS_ARM64_CLANG 1|;|+#else|;|+    #define IS_ARM64_CLANG 0|;|+#endif|;|+|;| /*|;|  * Wrapper function for remainder edge cases|;|  * Internally calls npy_divmod*|;|@@ -514,34 +522,48 @@ NPY_INPLACE @type@|;| npy_remainder@c@(@type@ a, @type@ b)|;| {|;|     @type@ mod|;|;-    if (NPY_UNLIKELY(!b)) {|;|+    |;|+    if (NPY_UNLIKELY(!b) || |;|+        NPY_UNLIKELY(IS_ARM64_CLANG && sizeof(@type@) == sizeof(long double) && (npy_isnan(a) || npy_isnan(b)))) {|;|         /*|;|-         * in2 == 0 (and not NaN): normal fmod will give the correct|;|-         * result (always NaN). `divmod` may set additional FPE for the|;|-         * division by zero creating an inf.|;|+         * Handle two cases:|;|+         * 1. in2 == 0 (and not NaN): normal fmod will give the correct|;|+         *    result (always NaN). `divmod` may set additional FPE for the|;|+         *    division by zero creating an inf.|;|+         * 2. ARM64 with Clang: Special handling to avoid FPE with float128|;|+         *    TODO: This is a workaround for a known Clang issue on ARM64 where |;|+         *    float128 operations trigger incorrect FPE behavior. This can be |;|+         *    removed once fixed:|;|+         *    https://github.com/llvm/llvm-project/issues/59924|;|          */|;|-        mod = npy_fmod@c@(a, b)|;|;-    }|;|-    else {|;|-        npy_divmod@c@(a, b, &mod)|;|;+        return npy_fmod@c@(a, b)|;|;     }|;|+    |;|+    npy_divmod@c@(a, b, &mod)|;|;     return mod|;|; }|;| |;| NPY_INPLACE @type@|;| npy_floor_divide@c@(@type@ a, @type@ b) {|;|     @type@ div, mod|;|;-    if (NPY_UNLIKELY(!b)) {|;|+    |;|+    if (NPY_UNLIKELY(!b) || |;|+        NPY_UNLIKELY(IS_ARM64_CLANG && sizeof(@type@) == sizeof(long double) && (npy_isnan(a) || npy_isnan(b)))) {|;|         /*|;|-         * in2 == 0 (and not NaN): normal division will give the correct|;|-         * result (Inf or NaN). `divmod` may set additional FPE for the modulo|;|-         * evaluating to NaN.|;|+         * Handle two cases:|;|+         * 1. in2 == 0 (and not NaN): normal division will give the correct|;|+         *    result (Inf or NaN). `divmod` may set additional FPE for the modulo|;|+         *    evaluating to NaN.|;|+         * 2. ARM64 with Clang: Special handling to avoid FPE with float128|;|+         *    TODO: This is a workaround for a known Clang issue on ARM64 where |;|+         *    float128 operations trigger incorrect FPE behavior. This can be |;|+         *    removed once fixed:|;|+         *    https://github.com/llvm/llvm-project/issues/59924|;|          */|;|-        div = a / b|;|;-    }|;|-    else {|;|-        div = npy_divmod@c@(a, b, &mod)|;|;+        return a / b|;|;     }|;|+    |;|+    div = npy_divmod@c@(a, b, &mod)|;|;     return div|;|; }|;| ",clang test failure on arm64 with float128 || Change logic || simplified return statement
numpy/numpy,charris,28048,BUG: Race adding legacy casts to custom dtype under free threading,"### Describe the issue:

If the following code is run under Python 3.13.1t, it fails nondeterministically with `A cast was already added for <class 'numpy.dtype[rational]'> -> <class 'numpy.dtypes.Int8DType'>. (method: legacy_cast)`.


### Reproduce the code example:

```python
import concurrent.futures
import functools
import threading
import numpy as np
import numpy._core._rational_tests as _rational_tests

num_threads = 1000

def closure(b):
    b.wait()
    for _ in range(100):
        np.full((10, 10), 1, _rational_tests.rational)


with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    b = threading.Barrier(num_threads)
    futures = [executor.submit(functools.partial(closure, b)) for _ in range(num_threads)]
    [f.result() for f in futures]
```


### Error message:

```shell
Traceback (most recent call last):
  File ""/Users/goldbaum/.pyenv/versions/3.13.1t/lib/python3.13t/site-packages/numpy/_core/numeric.py"", line 353, in full
    multiarray.copyto(a, fill_value, casting='unsafe')
RuntimeError: A cast was already added for <class 'numpy.dtype[rational]'> -> <class 'numpy.dtypes.Int8DType'>. (method: legacy_cast)
```


### Python and NumPy Versions:

2.3.0.dev0+git20241219.35b2c4a
3.13.1 experimental free-threading build (tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 (11)]


### Runtime Environment:

[{'numpy_version': '2.3.0.dev0+git20241219.35b2c4a',
'python': '3.13.1 experimental free-threading build '
'(tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 '
'(11)]',
'uname': uname_result(system='Linux', node='', release='', version='https://github.com/https://github.com/numpy/numpy/pull/1 SMP PREEMPT_DYNAMIC Debian 6.redacted (2024-10-16)', machine='x86_64')},
{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
'found': ['SSSE3',
'SSE41',
'POPCNT',
'SSE42',
'AVX',
'F16C',
'FMA3',
'AVX2'],
'not_found': ['AVX512F',
'AVX512CD',
'AVX512_KNL',
'AVX512_SKX',
'AVX512_CLX',
'AVX512_CNL',
'AVX512_ICL']}},
{'architecture': 'Zen',
'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.27.so',
'internal_api': 'openblas',
'num_threads': 128,
'prefix': 'libopenblas',
'threading_layer': 'pthreads',
'user_api': 'blas',
'version': '0.3.27'}]


### Context for the issue:

Found when working on free-threading support in JAX.","Hmmmm, I wonder if we can/should do this at registration time already to avoid having to add another locking point (registration should happen at import, I think.  And if not, it should be the callers problem to lock). || Here's the C traceback:

```
* thread #10, stop reason = breakpoint 2.1
  * frame #0: 0x0000000100d60340 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddCastingImplementation(meth=0x0000038d680100f0) at convert_datatype.c:2011:23 [opt]
    frame #1: 0x0000000100d60460 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddCastingImplementation_FromSpec(spec=0x0000000178e66248, private=1) at convert_datatype.c:2036:15 [opt]
    frame #2: 0x0000000100dd4230 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddLegacyWrapping_CastingImpl(from=0x0000038d564d6400, to=0x0000038d564d0800, casting=NPY_UNSAFE_CASTING) at usertypes.c:0 [opt]
    frame #3: 0x0000000100d5d15c _multiarray_umath.cpython-313t-darwin.so`PyArray_GetCastingImpl(from=0x0000038d564d6400, to=<unavailable>) at convert_datatype.c:144:13 [opt]
    frame #4: 0x0000000100d5de34 _multiarray_umath.cpython-313t-darwin.so`PyArray_CanCastSafely(fromtype=<unavailable>, totype=<unavailable>) at convert_datatype.c:540:29 [opt]
    frame #5: 0x0000000100dd3e3c _multiarray_umath.cpython-313t-darwin.so`legacy_userdtype_common_dtype_function(cls=0x0000038d564d6400, other=0x0000038d564d0800) at usertypes.c:522:9 [opt]
    frame #6: 0x0000000100d45f90 _multiarray_umath.cpython-313t-darwin.so`int_common_dtype(__NPY_UNUSED_TAGGEDcls=<unavailable>, other=0x0000038d564d6400) at abstractdtypes.c:179:34 [opt]
    frame #7: 0x0000000100d5b820 _multiarray_umath.cpython-313t-darwin.so`PyArray_CommonDType(dtype1=0x0000000100f8b5f0, dtype2=0x0000038d564d6400) at common_dtype.c:58:20 [opt]
    frame #8: 0x0000000100d465e4 _multiarray_umath.cpython-313t-darwin.so`npy_find_descr_for_scalar(scalar=0, original_descr=0x0000000100f81278, in_DT=<unavailable>, op_DT=<unavailable>) at abstractdtypes.c:460:33 [opt]
    frame #9: 0x0000000100dafd58 _multiarray_umath.cpython-313t-darwin.so`array_copyto(__NPY_UNUSED_TAGGEDignored=<unavailable>, args=<unavailable>, len_args=<unavailable>, kwnames=<unavailable>) at multiarraymodule.c:1966:32 [opt]
```

NumPy is lazily generating casts, but we can probably initialize casts between user dtypes and the built-in DTypes using this machinery at DType registration time.

Failing that, we can keep the current implementation and lock the DType when we need to fill the cache. Possibly behind a `shared_mutex` like the dispatch cache. || I edited the reproducer to use `_rational_tests.rational` instead of `ml_dtypes`. Thankfully it triggers with `rational`. This should make it much easier to add a test along with a fix. || @seberg I need your opinion about what the best way forward here is.

The reason this is set up this way is because user dtypes first create a DType instance and then after that register a bunch of casts. There's no function that says ""this DType is fully initialized, do finalization steps."" 

The current approach for wrapping the legacy user dtype casts avoids the need to monkey with the internals of the legacy dtype implementation (including all the `cancastto` pointers, besides reading them after they're already set up) because by the time a cast actually happens, the legacy dtype is already done setting up, including all the casts.

I see three ways to fix this and none are great.

1. Add a new public function to finalize legacy dtypes. This must be called after all casts are registered. The new function could then call `PyArray_AddLegacyWrapping_CastingImpl` for all built-in dtypes to initialize casts during DType registration time. `ml_dtypes` could adopt this but I doubt legacy user dtypes are well enough maintained to be able to adopt a new C API function to fix a bug you're only likely to hit under free-threading.
2. Initialize a basic set of casts in the `DTypeMeta` wrapping the legacy user DType right after calling `dtypemeta_wrap_legacy_descriptor` using `PyArray_AddLegacyWrapping_CastingImpl` but then inside `PyArray_RegisterCanCast` I'd need to update the casting safety of the wrapping `ArrayMethod`, which is an annoying inversion of abstractions, because `PyArray_RegisterCanCast` is deep in the guts of the legacy user dtype implementation.
3. As alluded to above, lock the `castingimpls` slot of `PyArray_DTypeMeta` instances, probably behind a `shared_mutex`. This will probably require converting a bunch of code to C++ and might also not scale well. That also means adding locking to handle an issue that only affects legacy user DTypes to *all* DTypes. || Ah, so I had a very good reason to put it exactly where it is :(.  My thoughts:

1. My first gut-feeling was to not do this.  But it doesn't seem so bad, I agree only `ml_types` would use this, but maybe that is OK?  Unmaintained extension dtypes may not be ""advertising"" free-threading support anyway.
   We could probably hack a `DeprecationWarning`or a straight error that enforces the API when free-threading is enabled.  (not back-portable, but...)
2. This seems too akward and hard to follow to me...
3. Converting to C++ shouldn't stop us, it is churn, but likely churn that is good if it happens in the long run anyway.
   But maybe there are even easier options?  `castingimpls` is just a dict, IIRC, so I think we can call `GetItem()` even while an other thread may be adding a new cast?  If that is the case, we should be able to get away with just a critical section (and another check if it showed up) in the function adding the casts?

Since I think being a `dict` should make locking easy, locking seems like a good approach to me now.  But if it is not, I think going the new API route isn't as bad as it may seem initially. || > castingimpls is just a dict, IIRC, so I think we can call GetItem() even while an other thread may be adding a new cast? If that is the case, we should be able to get away with just a critical section (and another check if it showed up) in the function adding the casts?

I'll have to look closer at this, but I think you'd need to apply a critical section when *reading* `castingimpls`, and you'd introduce contention in the common case. It would be safe but if someone tried to call the same cast operation simultaneously from many threads it would scale poorly, just like the ufunc scaling issue we saw with critical sections. || Another perhaps less satisfying option is to let the race happen and just ignore this error case. The cast created by both threads should be identical. || `castingimpls` isn't actually used in all that many places, so maybe requiring C++ to access it isn't so bad:

```
_core/src/umath/_scaled_float_dtype.c
881:    NPY_DT_SLOTS(&PyArray_SFloatDType)->castingimpls = PyDict_New();
882:    if (NPY_DT_SLOTS(&PyArray_SFloatDType)->castingimpls == NULL) {

_core/src/multiarray/usertypes.c
348:            NPY_DT_SLOTS(NPY_DTYPE(descr))->castingimpls, (PyObject *)to_DType);

_core/src/multiarray/dtypemeta.h
80:    PyObject *castingimpls;

_core/src/multiarray/_multiarray_tests.c.src
886:        while (PyDict_Next(NPY_DT_SLOTS(from_dtype)->castingimpls,

_core/src/multiarray/dtypemeta.c
43:    Py_XDECREF(NPY_DT_SLOTS(self)->castingimpls);
323:    NPY_DT_SLOTS(DType)->castingimpls = PyDict_New();
324:    if (NPY_DT_SLOTS(DType)->castingimpls == NULL) {
1153:    dt_slots->castingimpls = PyDict_New();
1154:    if (dt_slots->castingimpls == NULL) {

_core/src/multiarray/convert_datatype.c
83:        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to);
130:                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,
159:    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,
2007:    if (PyDict_Contains(NPY_DT_SLOTS(meth->dtypes[0])->castingimpls,
2014:    if (PyDict_SetItem(NPY_DT_SLOTS(meth->dtypes[0])->castingimpls,
```

I'll look at converting the bits of NumPy needed to put `castingimpls` behind a `shared_mutex`. || Yeah, in fact, I think the `convert_datatype.c` function is probably the _only_ place that really matters (not sure if dict iteration is safe, but if not it is just a little helper that doesn't matter).
All other occurrences are at dtype creation time or should be (i.e. a the `usertypes.c` one is a sanity check that tells users that a cast was registered after being used) and it just uses `GetItem`.

If that isn't possible (and not just not the nicest way to do it!), I would still like to understand why it isn't OK to call `GetItemWithError` and only lock (very unlikely) if the result is `NULL`. (Although then checking if it was added in the meantime is necessary of course.) || I managed to get the numpy tests passing after converting `convert_datatype.c` and `dtypemeta.c` to C++ along with adding some `extern ""C"" {` in several headers. See https://github.com/numpy/numpy/pull/28253

I think the most straightforward way to add the mutex is to extend the `NPY_DType_Slots` struct to have a pointer to a mutex at the end:

```diff
diff --git a/numpy/_core/src/multiarray/dtypemeta.h b/numpy/_core/src/multiarray/dtypemeta.h
index a8b78e3f75..888ec09fba 100644
--- a/numpy/_core/src/multiarray/dtypemeta.h
+++ b/numpy/_core/src/multiarray/dtypemeta.h
@@ -85,6 +85,12 @@ typedef struct {
      * dtype instance for backward compatibility.  (Keep this at end)
      */
     PyArray_ArrFuncs f;
+
+    /*
+     *  Mutex to protect against race conditions modifying castingimpls at
+     *  runtime
+     */
+    void *mutex;
 } NPY_DType_Slots;
```

I can then heap-allocate the mutex during DType creation to avoid polluting the internal C API with C++ constructs and follow the pattern of the other `shared_mutex` use inside the dispatch cache.

If anyone spots any issues with that let me know but I think I'm going to try to implement this next. || I mean, I still really don't understand why we shouldn't just try once (even _with_ this mutex!) and then a critical section on the castingimpl's itself seems just sa well (very very unlikely to be hit in practice).
But presumably converting to C++ is straight-forward and adding a mutex is fine. || Isn't that thread-unsafe? All accesses need to be done under the critical section otherwise you could be reading from the dict while another thread writes to it. That's why I want an RWlock. || > Built-in types like [dict](https://docs.python.org/3/library/stdtypes.html#dict), [list](https://docs.python.org/3/library/stdtypes.html#list), and [set](https://docs.python.org/3/library/stdtypes.html#set) use internal locks to protect against concurrent modifications in ways that behave similarly to the GIL

I mean, the whole point of the `GetRef()` API was to make it thread-safe no?

(Which doesn't mean we shouldn't just do the C++ conversion maybe, it is maybe time...) || (I somewhat remember things as: for ufuncs we said that using a dict rather than a custom hash-table would be a solution where we don't need a custom lock.) || What's happening right now is technically thread-safe in the sense that there are no data races, but there is a race condition. We *could* use `PyDict_GetItemRef` instead, but it doesn't matter that we're creating a borrowed reference because the casts live as long as the DType, and we have a strong reference to the DType inside of `PyArray_GetCastingImpl`. `PyDict_GetItemRef` only helps you if you don't know that a borrowed reference is safe.

What I want to do is make the race condition impossible, by blocking all threads from reading the `castingimpls` while any thread tries to write to it, which should only happen the first time someone tries to do a cast with a legacy user DType for some pair of DTypes.

Does that make more sense? || @ngoldbaum but the `GetItemRef` is thread-safe, in the sense that the return is either the correct cast impl or `NULL`, no?
If it is the correct cast impl, we are all good!

If the return is `NULL`, we need to lock down `castingimpls`!  Then there are two possibilities:
* Another thread was faster, by the time we get the `castingimpls` lock, the cast is already added.
* We were faster, and we should add the cast.

So, if the return was `NULL` (and only then, which happens only once for each cast!), we have to lock `castingimpls` and then check again before we create it to avoid adding it twice (if another thread was faster).

Since `castingimpls` will effectively always return non-null (we add a `None` to indicate ""undefined"") and we don't need any additional mutex for the first `GetItemRef`, it seems nice to just avoid the mutex for the first step in any case? || I opened https://github.com/numpy/numpy/pull/28290",closed,2024-12-20T21:17:25+00:00,2025-02-11T16:55:16+00:00,hawkinsp,"00 - Bug, 39 - free-threading",2,"PR#28290 - .github/workflows/compiler_sanitizers.yml: @@ -60,6 +60,8 @@ jobs:|;|         pip install -r requirements/build_requirements.txt|;|         pip install -r requirements/ci_requirements.txt|;|         pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the ASAN output|;|+        pip uninstall -y pytest-xdist|;|     - name: Build|;|       run:|;|         python -m spin build -j2 -- -Db_sanitize=address|;|@@ -111,6 +113,8 @@ jobs:|;|         pip install -r requirements/build_requirements.txt|;|         pip install -r requirements/ci_requirements.txt|;|         pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the TSAN output|;|+        pip uninstall -y pytest-xdist|;|     - name: Build|;|       run:|;|         python -m spin build -j2 -- -Db_sanitize=thread || PR#28290 - numpy/_core/src/multiarray/convert_datatype.c: @@ -63,46 +63,24 @@ static PyObject *|;| PyArray_GetObjectToGenericCastingImpl(void)|;|; |;| |;|-/**|;|- * Fetch the casting implementation from one DType to another.|;|- *|;|- * @param from The implementation to cast from|;|- * @param to The implementation to cast to|;|- *|;|- * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|- *          error set.|;|- */|;|-NPY_NO_EXPORT PyObject *|;|-PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+static PyObject *|;|+create_casting_impl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;| {|;|-    PyObject *res|;|;-    if (from == to) {|;|-        res = (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl|;|;-    }|;|-    else {|;|-        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to)|;|;-    }|;|-    if (res != NULL || PyErr_Occurred()) {|;|-        Py_XINCREF(res)|;|;-        return res|;|;-    }|;|     /*|;|-     * The following code looks up CastingImpl based on the fact that anything|;|+     * Look up CastingImpl based on the fact that anything|;|      * can be cast to and from objects or structured (void) dtypes.|;|-     *|;|-     * The last part adds casts dynamically based on legacy definition|;|      */|;|     if (from->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetObjectToGenericCastingImpl()|;|;+        return PyArray_GetObjectToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetGenericToObjectCastingImpl()|;|;+        return PyArray_GetGenericToObjectCastingImpl()|;|;     }|;|     else if (from->type_num == NPY_VOID) {|;|-        res = PyArray_GetVoidToGenericCastingImpl()|;|;+        return PyArray_GetVoidToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_VOID) {|;|-        res = PyArray_GetGenericToVoidCastingImpl()|;|;+        return PyArray_GetGenericToVoidCastingImpl()|;|;     }|;|     /*|;|      * Reject non-legacy dtypes. They need to use the new API to add casts and|;|@@ -126,42 +104,105 @@ PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|                     from->singleton, to->type_num)|;|;             if (castfunc == NULL) {|;|                 PyErr_Clear()|;|;-                /* Remember that this cast is not possible */|;|-                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                            (PyObject *) to, Py_None) < 0) {|;|-                    return NULL|;|;-                }|;|                 Py_RETURN_NONE|;|;             }|;|         }|;|-|;|-        /* PyArray_AddLegacyWrapping_CastingImpl find the correct casting level: */|;|-        /*|;|-         * TODO: Possibly move this to the cast registration time. But if we do|;|-         *       that, we have to also update the cast when the casting safety|;|-         *       is registered.|;|+        /* Create a cast using the state of the legacy casting setup defined|;|+         * during the setup of the DType.|;|+         *|;|+         * Ideally we would do this when we create the DType, but legacy user|;|+         * DTypes don't have a way to signal that a DType is done setting up|;|+         * casts. Without such a mechanism, the safest way to know that a|;|+         * DType is done setting up is to register the cast lazily the first|;|+         * time a user does the cast.|;|+         *|;|+         * We *could* register the casts when we create the wrapping|;|+         * DTypeMeta, but that means the internals of the legacy user DType|;|+         * system would need to update the state of the casting safety flags|;|+         * in the cast implementations stored on the DTypeMeta. That's an|;|+         * inversion of abstractions and would be tricky to do without|;|+         * creating circular dependencies inside NumPy.|;|          */|;|         if (PyArray_AddLegacyWrapping_CastingImpl(from, to, -1) < 0) {|;|             return NULL|;|;         }|;|+        /* castingimpls is unconditionally filled by|;|+         * AddLegacyWrapping_CastingImpl, so this won't create a recursive|;|+         * critical section|;|+         */|;|         return PyArray_GetCastingImpl(from, to)|;|;     }|;|+}|;| |;|-    if (res == NULL) {|;|+static PyObject *|;|+ensure_castingimpl_exists(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    int return_error = 0|;|;+    PyObject *res = NULL|;|;+|;|+    /* Need to create the cast. This might happen at runtime so we enter a|;|+       critical section to avoid races */|;|+|;|+    Py_BEGIN_CRITICAL_SECTION(NPY_DT_SLOTS(from)->castingimpls)|;|;+|;|+    /* check if another thread filled it while this thread was blocked on|;|+       acquiring the critical section */|;|+    if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to,|;|+                          &res) < 0) {|;|+        return_error = 1|;|;+    }|;|+    else if (res == NULL) {|;|+        res = create_casting_impl(from, to)|;|;+        if (res == NULL) {|;|+            return_error = 1|;|;+        }|;|+        else if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|+                                (PyObject *)to, res) < 0) {|;|+            return_error = 1|;|;+        }|;|+    }|;|+    Py_END_CRITICAL_SECTION()|;|;+    if (return_error) {|;|+        Py_XDECREF(res)|;|;         return NULL|;|;     }|;|-    if (from == to) {|;|+    if (from == to && res == Py_None) {|;|         PyErr_Format(PyExc_RuntimeError,|;|                 ""Internal NumPy error, within-DType cast missing for %S!"", from)|;|;         Py_DECREF(res)|;|;         return NULL|;|;     }|;|-    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                (PyObject *)to, res) < 0) {|;|-        Py_DECREF(res)|;|;+    return res|;|;+}|;|+|;|+/**|;|+ * Fetch the casting implementation from one DType to another.|;|+ *|;|+ * @param from The implementation to cast from|;|+ * @param to The implementation to cast to|;|+ *|;|+ * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|+ *          error set.|;|+ */|;|+NPY_NO_EXPORT PyObject *|;|+PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    PyObject *res = NULL|;|;+    if (from == to) {|;|+        if ((NPY_DT_SLOTS(from)->within_dtype_castingimpl) != NULL) {|;|+            res = Py_XNewRef(|;|+                    (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl)|;|;+        }|;|+    }|;|+    else if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls,|;|+                               (PyObject *)to, &res) < 0) {|;|         return NULL|;|;     }|;|-    return res|;|;+    if (res != NULL) {|;|+        return res|;|;+    }|;|+|;|+    return ensure_castingimpl_exists(from, to)|;|; }|;| |;| |;|@@ -410,7 +451,7 @@ _get_cast_safety_from_castingimpl(PyArrayMethodObject *castingimpl,|;|  * implementations fully to have them available for doing the actual cast|;|  * later.|;|  *|;|- * @param from The descriptor to cast from |;|+ * @param from The descriptor to cast from|;|  * @param to The descriptor to cast to (may be NULL)|;|  * @param to_dtype If `to` is NULL, must pass the to_dtype (otherwise this|;|  *        is ignored).|;|@@ -2021,6 +2062,11 @@ PyArray_AddCastingImplementation(PyBoundArrayMethodObject *meth)|;| /**|;|  * Add a new casting implementation using a PyArrayMethod_Spec.|;|  *|;|+ * Using this function outside of module initialization without holding a|;|+ * critical section on the castingimpls dict may lead to a race to fill the|;|+ * dict. Use PyArray_GetGastingImpl to lazily register casts at runtime|;|+ * safely.|;|+ *|;|  * @param spec The specification to use as a source|;|  * @param private If private, allow slots not publicly exposed.|;|  * @return 0 on success -1 on failure || PR#28290 - numpy/_core/src/multiarray/dtypemeta.c: @@ -1252,6 +1252,12 @@ dtypemeta_wrap_legacy_descriptor(|;|             return -1|;|;         }|;|     }|;|+    else {|;|+        // ensure the within dtype cast is populated for legacy user dtypes|;|+        if (PyArray_GetCastingImpl(dtype_class, dtype_class) == NULL) {|;|+            return -1|;|;+        }|;|+    }|;| |;|     return 0|;|; } || PR#28290 - numpy/_core/tests/test_multithreading.py: @@ -7,6 +7,7 @@|;| |;| from numpy.testing import IS_WASM|;| from numpy.testing._private.utils import run_threaded|;|+from numpy._core import _rational_tests|;| |;| if IS_WASM:|;|     pytest.skip(allow_module_level=True, reason=""no threading support in wasm"")|;|@@ -254,3 +255,19 @@ def func(arr):|;| |;|         for f in futures:|;|             f.result()|;|+|;|+|;|+def test_legacy_usertype_cast_init_thread_safety():|;|+    def closure(b):|;|+        b.wait()|;|+        np.full((10, 10), 1, _rational_tests.rational)|;|+|;|+    try:|;|+        run_threaded(closure, 250, pass_barrier=True)|;|+    except RuntimeError:|;|+        # The 32 bit linux runner will trigger this with 250 threads. I can|;|+        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|+        # more resource-constrained.|;|+        # Reducing the number of threads means the test doesn't trigger the|;|+        # bug. Better to skip on some platforms than add a useless test.|;|+        pytest.skip(""Couldn't spawn enough threads to run the test"") || PR#28290 - numpy/testing/_private/utils.py: @@ -2734,9 +2734,16 @@ def run_threaded(func, max_workers=8, pass_count=False,|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|+                all_args = [(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|+                all_args = [(func, *args) for i in range(max_workers)]|;|+            try:|;|+                futures = []|;|+                for arg in all_args:|;|+                    futures.append(tpe.submit(*arg))|;|+            finally:|;|+                if len(futures) < max_workers and pass_barrier:|;|+                    barrier.abort()|;|             for f in futures:|;|                 f.result()|;|  || PR#28321 - .github/workflows/compiler_sanitizers.yml: @@ -0,0 +1,127 @@|;|+name: Test with compiler sanitizers|;|+|;|+on:|;|+  push:|;|+    branches:|;|+      - main|;|+  pull_request:|;|+    branches:|;|+      - main|;|+      - maintenance/**|;|+|;|+defaults:|;|+  run:|;|+    shell: bash|;|+|;|+concurrency:|;|+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}|;|+  cancel-in-progress: true|;|+|;|+permissions:|;|+  contents: read # to fetch code (actions/checkout)|;|+|;|+jobs:|;|+  clang_ASAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with address sanitizer|;|+      run: ||;|+        CONFIGURE_OPTS=""--with-address-sanitizer"" pyenv install 3.13|;|+        pyenv global 3.13|;|+    - name: Install dependencies|;|+      run: ||;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the ASAN output|;|+        pip uninstall -y pytest-xdist|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=address|;|+    - name: Test|;|+      run: ||;|+        # pass -s to pytest to see ASAN errors and warnings, otherwise pytest captures them|;|+        ASAN_OPTIONS=detect_leaks=0:symbolize=1:strict_init_order=true:allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test -- -v -s --timeout=600 --durations=10|;|+|;|+  clang_TSAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with thread sanitizer support|;|+      run: ||;|+        # free-threaded Python is much more likely to trigger races|;|+        CONFIGURE_OPTS=""--with-thread-sanitizer"" pyenv install 3.13t|;|+        pyenv global 3.13t|;|+    - name: Install dependencies|;|+      run: ||;|+        # TODO: remove when a released cython supports free-threaded python|;|+        pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython|;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the TSAN output|;|+        pip uninstall -y pytest-xdist|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=thread|;|+    - name: Test|;|+      run: ||;|+        # These tests are slow, so only run tests in files that do ""import threading"" to make them count|;|+        TSAN_OPTIONS=allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test \|;|+        `find numpy -name ""test*.py"" | xargs grep -l ""import threading"" | tr '\n' ' '` \|;|+        -- -v -s --timeout=600 --durations=10 || PR#28321 - numpy/_core/src/multiarray/convert_datatype.c: @@ -62,46 +62,24 @@ static PyObject *|;| PyArray_GetObjectToGenericCastingImpl(void)|;|; |;| |;|-/**|;|- * Fetch the casting implementation from one DType to another.|;|- *|;|- * @param from The implementation to cast from|;|- * @param to The implementation to cast to|;|- *|;|- * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|- *          error set.|;|- */|;|-NPY_NO_EXPORT PyObject *|;|-PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+static PyObject *|;|+create_casting_impl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;| {|;|-    PyObject *res|;|;-    if (from == to) {|;|-        res = (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl|;|;-    }|;|-    else {|;|-        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to)|;|;-    }|;|-    if (res != NULL || PyErr_Occurred()) {|;|-        Py_XINCREF(res)|;|;-        return res|;|;-    }|;|     /*|;|-     * The following code looks up CastingImpl based on the fact that anything|;|+     * Look up CastingImpl based on the fact that anything|;|      * can be cast to and from objects or structured (void) dtypes.|;|-     *|;|-     * The last part adds casts dynamically based on legacy definition|;|      */|;|     if (from->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetObjectToGenericCastingImpl()|;|;+        return PyArray_GetObjectToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetGenericToObjectCastingImpl()|;|;+        return PyArray_GetGenericToObjectCastingImpl()|;|;     }|;|     else if (from->type_num == NPY_VOID) {|;|-        res = PyArray_GetVoidToGenericCastingImpl()|;|;+        return PyArray_GetVoidToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_VOID) {|;|-        res = PyArray_GetGenericToVoidCastingImpl()|;|;+        return PyArray_GetGenericToVoidCastingImpl()|;|;     }|;|     /*|;|      * Reject non-legacy dtypes. They need to use the new API to add casts and|;|@@ -125,42 +103,105 @@ PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|                     from->singleton, to->type_num)|;|;             if (castfunc == NULL) {|;|                 PyErr_Clear()|;|;-                /* Remember that this cast is not possible */|;|-                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                            (PyObject *) to, Py_None) < 0) {|;|-                    return NULL|;|;-                }|;|                 Py_RETURN_NONE|;|;             }|;|         }|;|-|;|-        /* PyArray_AddLegacyWrapping_CastingImpl find the correct casting level: */|;|-        /*|;|-         * TODO: Possibly move this to the cast registration time. But if we do|;|-         *       that, we have to also update the cast when the casting safety|;|-         *       is registered.|;|+        /* Create a cast using the state of the legacy casting setup defined|;|+         * during the setup of the DType.|;|+         *|;|+         * Ideally we would do this when we create the DType, but legacy user|;|+         * DTypes don't have a way to signal that a DType is done setting up|;|+         * casts. Without such a mechanism, the safest way to know that a|;|+         * DType is done setting up is to register the cast lazily the first|;|+         * time a user does the cast.|;|+         *|;|+         * We *could* register the casts when we create the wrapping|;|+         * DTypeMeta, but that means the internals of the legacy user DType|;|+         * system would need to update the state of the casting safety flags|;|+         * in the cast implementations stored on the DTypeMeta. That's an|;|+         * inversion of abstractions and would be tricky to do without|;|+         * creating circular dependencies inside NumPy.|;|          */|;|         if (PyArray_AddLegacyWrapping_CastingImpl(from, to, -1) < 0) {|;|             return NULL|;|;         }|;|+        /* castingimpls is unconditionally filled by|;|+         * AddLegacyWrapping_CastingImpl, so this won't create a recursive|;|+         * critical section|;|+         */|;|         return PyArray_GetCastingImpl(from, to)|;|;     }|;|+}|;| |;|-    if (res == NULL) {|;|+static PyObject *|;|+ensure_castingimpl_exists(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    int return_error = 0|;|;+    PyObject *res = NULL|;|;+|;|+    /* Need to create the cast. This might happen at runtime so we enter a|;|+       critical section to avoid races */|;|+|;|+    Py_BEGIN_CRITICAL_SECTION(NPY_DT_SLOTS(from)->castingimpls)|;|;+|;|+    /* check if another thread filled it while this thread was blocked on|;|+       acquiring the critical section */|;|+    if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to,|;|+                          &res) < 0) {|;|+        return_error = 1|;|;+    }|;|+    else if (res == NULL) {|;|+        res = create_casting_impl(from, to)|;|;+        if (res == NULL) {|;|+            return_error = 1|;|;+        }|;|+        else if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|+                                (PyObject *)to, res) < 0) {|;|+            return_error = 1|;|;+        }|;|+    }|;|+    Py_END_CRITICAL_SECTION()|;|;+    if (return_error) {|;|+        Py_XDECREF(res)|;|;         return NULL|;|;     }|;|-    if (from == to) {|;|+    if (from == to && res == Py_None) {|;|         PyErr_Format(PyExc_RuntimeError,|;|                 ""Internal NumPy error, within-DType cast missing for %S!"", from)|;|;         Py_DECREF(res)|;|;         return NULL|;|;     }|;|-    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                (PyObject *)to, res) < 0) {|;|-        Py_DECREF(res)|;|;+    return res|;|;+}|;|+|;|+/**|;|+ * Fetch the casting implementation from one DType to another.|;|+ *|;|+ * @param from The implementation to cast from|;|+ * @param to The implementation to cast to|;|+ *|;|+ * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|+ *          error set.|;|+ */|;|+NPY_NO_EXPORT PyObject *|;|+PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    PyObject *res = NULL|;|;+    if (from == to) {|;|+        if ((NPY_DT_SLOTS(from)->within_dtype_castingimpl) != NULL) {|;|+            res = Py_XNewRef(|;|+                    (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl)|;|;+        }|;|+    }|;|+    else if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls,|;|+                               (PyObject *)to, &res) < 0) {|;|         return NULL|;|;     }|;|-    return res|;|;+    if (res != NULL) {|;|+        return res|;|;+    }|;|+|;|+    return ensure_castingimpl_exists(from, to)|;|; }|;| |;| |;|@@ -409,7 +450,7 @@ _get_cast_safety_from_castingimpl(PyArrayMethodObject *castingimpl,|;|  * implementations fully to have them available for doing the actual cast|;|  * later.|;|  *|;|- * @param from The descriptor to cast from |;|+ * @param from The descriptor to cast from|;|  * @param to The descriptor to cast to (may be NULL)|;|  * @param to_dtype If `to` is NULL, must pass the to_dtype (otherwise this|;|  *        is ignored).|;|@@ -2031,6 +2072,11 @@ PyArray_AddCastingImplementation(PyBoundArrayMethodObject *meth)|;| /**|;|  * Add a new casting implementation using a PyArrayMethod_Spec.|;|  *|;|+ * Using this function outside of module initialization without holding a|;|+ * critical section on the castingimpls dict may lead to a race to fill the|;|+ * dict. Use PyArray_GetGastingImpl to lazily register casts at runtime|;|+ * safely.|;|+ *|;|  * @param spec The specification to use as a source|;|  * @param private If private, allow slots not publicly exposed.|;|  * @return 0 on success -1 on failure || PR#28321 - numpy/_core/src/multiarray/dtypemeta.c: @@ -1252,6 +1252,12 @@ dtypemeta_wrap_legacy_descriptor(|;|             return -1|;|;         }|;|     }|;|+    else {|;|+        // ensure the within dtype cast is populated for legacy user dtypes|;|+        if (PyArray_GetCastingImpl(dtype_class, dtype_class) == NULL) {|;|+            return -1|;|;+        }|;|+    }|;| |;|     return 0|;|; } || PR#28321 - numpy/_core/tests/test_multithreading.py: @@ -1,10 +1,13 @@|;|+import concurrent.futures|;| import threading|;|+import string|;| |;| import numpy as np|;| import pytest|;| |;| from numpy.testing import IS_WASM|;| from numpy.testing._private.utils import run_threaded|;|+from numpy._core import _rational_tests|;| |;| if IS_WASM:|;|     pytest.skip(allow_module_level=True, reason=""no threading support in wasm"")|;|@@ -165,3 +168,106 @@ def closure(b):|;|             x = np.repeat(x0, 2, axis=0)[::2]|;| |;|     run_threaded(closure, max_workers=10, pass_barrier=True)|;|+|;|+|;|+def test_structured_advanced_indexing():|;|+    # Test that copyswap(n) used by integer array indexing is threadsafe|;|+    # for structured datatypes, see gh-15387. This test can behave randomly.|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(6000, 8)).view(dt)[:, 0]|;|+|;|+    rng = np.random.default_rng()|;|+|;|+    def func(arr):|;|+        indx = rng.integers(0, len(arr), size=6000, dtype=np.intp)|;|+        arr[indx]|;|+|;|+    tpe = concurrent.futures.ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_structured_threadsafety2():|;|+    # Nonzero (and some other functions) should be threadsafe for|;|+    # structured datatypes, see gh-15387. This test can behave randomly.|;|+    from concurrent.futures import ThreadPoolExecutor|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(5000, 4)).view(dt)[:, 0]|;|+|;|+    def func(arr):|;|+        arr.nonzero()|;|+|;|+    tpe = ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_stringdtype_multithreaded_access_and_mutation(|;|+        dtype, random_string_list):|;|+    # this test uses an RNG and may crash or cause deadlocks if there is a|;|+    # threading bug|;|+    rng = np.random.default_rng(0x4D3D3D3)|;|+|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = rng.choice(chars, size=100 * 10, replace=True)|;|+    random_string_list = ret.view(""U100"")|;|+|;|+    def func(arr):|;|+        rnd = rng.random()|;|+        # either write to random locations in the array, compute a ufunc, or|;|+        # re-initialize the array|;|+        if rnd < 0.25:|;|+            num = np.random.randint(0, arr.size)|;|+            arr[num] = arr[num] + ""hello""|;|+        elif rnd < 0.5:|;|+            if rnd < 0.375:|;|+                np.add(arr, arr)|;|+            else:|;|+                np.add(arr, arr, out=arr)|;|+        elif rnd < 0.75:|;|+            if rnd < 0.875:|;|+                np.multiply(arr, np.int64(2))|;|+            else:|;|+                np.multiply(arr, np.int64(2), out=arr)|;|+        else:|;|+            arr[:] = random_string_list|;|+|;|+    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as tpe:|;|+        arr = np.array(random_string_list, dtype=dtype)|;|+        futures = [tpe.submit(func, arr) for _ in range(500)]|;|+|;|+        for f in futures:|;|+            f.result()|;|+|;|+|;|+def test_legacy_usertype_cast_init_thread_safety():|;|+    def closure(b):|;|+        b.wait()|;|+        np.full((10, 10), 1, _rational_tests.rational)|;|+|;|+    try:|;|+        run_threaded(closure, 250, pass_barrier=True)|;|+    except RuntimeError:|;|+        # The 32 bit linux runner will trigger this with 250 threads. I can|;|+        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|+        # more resource-constrained.|;|+        # Reducing the number of threads means the test doesn't trigger the|;|+        # bug. Better to skip on some platforms than add a useless test.|;|+        pytest.skip(""Couldn't spawn enough threads to run the test"") || PR#28321 - numpy/conftest.py: @@ -2,6 +2,7 @@|;| Pytest configuration and fixtures for the Numpy test suite.|;| """"""|;| import os|;|+import string|;| import sys|;| import tempfile|;| from contextlib import contextmanager|;|@@ -10,9 +11,11 @@|;| import hypothesis|;| import pytest|;| import numpy|;|+import numpy as np|;| |;| from numpy._core._multiarray_tests import get_fpu_mode|;|-from numpy.testing._private.utils import NOGIL_BUILD|;|+from numpy._core.tests._natype import pd_NA|;|+from numpy.testing._private.utils import NOGIL_BUILD, get_stringdtype_dtype|;| |;| try:|;|     from scipy_doctest.conftest import dt_config|;|@@ -204,12 +207,12 @@ def warnings_errors_and_rng(test=None):|;|     dt_config.check_namespace['StringDType'] = numpy.dtypes.StringDType|;| |;|     # temporary skips|;|-    dt_config.skiplist = set([|;|+    dt_config.skiplist = {|;|         'numpy.savez',    # unclosed file|;|         'numpy.matlib.savez',|;|         'numpy.__array_namespace_info__',|;|         'numpy.matlib.__array_namespace_info__',|;|-    ])|;|+    }|;| |;|     # xfail problematic tutorials|;|     dt_config.pytest_extra_xfail = {|;|@@ -231,3 +234,28 @@ def warnings_errors_and_rng(test=None):|;|         'numpy/f2py/_backends/_distutils.py',|;|     ]|;| |;|+|;|+@pytest.fixture|;|+def random_string_list():|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = np.random.choice(chars, size=100 * 10, replace=True)|;|+    return ret.view(""U100"")|;|+|;|+|;|+@pytest.fixture(params=[True, False])|;|+def coerce(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture(|;|+    params=[""unset"", None, pd_NA, np.nan, float(""nan""), ""__nan__""],|;|+    ids=[""unset"", ""None"", ""pandas.NA"", ""np.nan"", ""float('nan')"", ""string nan""],|;|+)|;|+def na_object(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture()|;|+def dtype(na_object, coerce):|;|+    return get_stringdtype_dtype(na_object, coerce) || PR#28321 - numpy/testing/_private/utils.py: @@ -4,6 +4,7 @@|;| """"""|;| import os|;| import sys|;|+import pathlib|;| import platform|;| import re|;| import gc|;|@@ -19,16 +20,19 @@|;| import sysconfig|;| import concurrent.futures|;| import threading|;|+import importlib.metadata|;| |;| import numpy as np|;| from numpy._core import (|;|      intp, float32, empty, arange, array_repr, ndarray, isnat, array)|;| from numpy import isfinite, isnan, isinf|;| import numpy.linalg._umath_linalg|;| from numpy._utils import _rename_parameter|;|+from numpy._core.tests._natype import pd_NA|;| |;| from io import StringIO|;| |;|+|;| __all__ = [|;|         'assert_equal', 'assert_almost_equal', 'assert_approx_equal',|;|         'assert_array_equal', 'assert_array_less', 'assert_string_equal',|;|@@ -42,7 +46,7 @@|;|         'HAS_REFCOUNT', ""IS_WASM"", 'suppress_warnings', 'assert_array_compare',|;|         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',|;|         'IS_MUSL', 'check_support_sve', 'NOGIL_BUILD',|;|-        'IS_EDITABLE', 'run_threaded',|;|+        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded',|;|         ]|;| |;| |;|@@ -54,10 +58,40 @@ class KnownFailureException(Exception):|;| KnownFailureTest = KnownFailureException  # backwards compat|;| verbose = 0|;| |;|+NUMPY_ROOT = pathlib.Path(np.__file__).parent|;|+|;|+try:|;|+    np_dist = importlib.metadata.distribution('numpy')|;|+except importlib.metadata.PackageNotFoundError:|;|+    IS_INSTALLED = IS_EDITABLE = False|;|+else:|;|+    IS_INSTALLED = True|;|+    try:|;|+        if sys.version_info >= (3, 13):|;|+            IS_EDITABLE = np_dist.origin.dir_info.editable|;|+        else:|;|+            # Backport importlib.metadata.Distribution.origin|;|+            import json, types  # noqa: E401|;|+            origin = json.loads(|;|+                np_dist.read_text('direct_url.json') or '{}',|;|+                object_hook=lambda data: types.SimpleNamespace(**data),|;|+            )|;|+            IS_EDITABLE = origin.dir_info.editable|;|+    except AttributeError:|;|+        IS_EDITABLE = False|;|+|;|+    # spin installs numpy directly via meson, instead of using meson-python, and|;|+    # runs the module by setting PYTHONPATH. This is problematic because the|;|+    # resulting installation lacks the Python metadata (.dist-info), and numpy|;|+    # might already be installed on the environment, causing us to find its|;|+    # metadata, even though we are not actually loading that package.|;|+    # Work around this issue by checking if the numpy root matches.|;|+    if not IS_EDITABLE and np_dist.locate_file('numpy') != NUMPY_ROOT:|;|+        IS_INSTALLED = False|;|+|;| IS_WASM = platform.machine() in [""wasm32"", ""wasm64""]|;| IS_PYPY = sys.implementation.name == 'pypy'|;| IS_PYSTON = hasattr(sys, ""pyston_version_info"")|;|-IS_EDITABLE = not bool(np.__path__) or 'editable' in np.__path__[0]|;| HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON|;| HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64|;| |;|@@ -101,14 +135,15 @@ def GetPerformanceAttributes(object, counter, instance=None,|;|         # thread's CPU usage is either 0 or 100).  To read counters like this,|;|         # you should copy this function, but keep the counter open, and call|;|         # CollectQueryData() each time you need to know.|;|-        # See http://msdn.microsoft.com/library/en-us/dnperfmo/html/perfmonpt2.asp (dead link)|;|+        # See http://msdn.microsoft.com/library/en-us/dnperfmo/html/perfmonpt2.asp|;|+        #(dead link)|;|         # My older explanation for this was that the ""AddCounter"" process|;|         # forced the CPU to 100%, but the above makes more sense :)|;|         import win32pdh|;|         if format is None:|;|             format = win32pdh.PDH_FMT_LONG|;|-        path = win32pdh.MakeCounterPath( (machine, object, instance, None,|;|-                                          inum, counter))|;|+        path = win32pdh.MakeCounterPath((machine, object, instance, None,|;|+                                         inum, counter))|;|         hq = win32pdh.OpenQuery()|;|         try:|;|             hc = win32pdh.AddCounter(hq, path)|;|@@ -166,7 +201,7 @@ def jiffies(_proc_pid_stat=f'/proc/{os.getpid()}/stat', _load_time=[]):|;|                 l = f.readline().split(' ')|;|             return int(l[13])|;|         except Exception:|;|-            return int(100*(time.time()-_load_time[0]))|;|+            return int(100 * (time.time() - _load_time[0]))|;| else:|;|     # os.getpid is not in all platforms available.|;|     # Using time is safe but inaccurate, especially when process|;|@@ -182,15 +217,15 @@ def jiffies(_load_time=[]):|;|         import time|;|         if not _load_time:|;|             _load_time.append(time.time())|;|-        return int(100*(time.time()-_load_time[0]))|;|+        return int(100 * (time.time() - _load_time[0]))|;| |;| |;| def build_err_msg(arrays, err_msg, header='Items are not equal:',|;|                   verbose=True, names=('ACTUAL', 'DESIRED'), precision=8):|;|     msg = ['\n' + header]|;|     err_msg = str(err_msg)|;|     if err_msg:|;|-        if err_msg.find('\n') == -1 and len(err_msg) < 79-len(header):|;|+        if err_msg.find('\n') == -1 and len(err_msg) < 79 - len(header):|;|             msg = [msg[0] + ' ' + err_msg]|;|         else:|;|             msg.append(err_msg)|;|@@ -659,14 +694,14 @@ def assert_approx_equal(actual, desired, significant=7, err_msg='',|;|     # Normalized the numbers to be in range (-10.0,10.0)|;|     # scale = float(pow(10,math.floor(math.log10(0.5*(abs(desired)+abs(actual))))))|;|     with np.errstate(invalid='ignore'):|;|-        scale = 0.5*(np.abs(desired) + np.abs(actual))|;|+        scale = 0.5 * (np.abs(desired) + np.abs(actual))|;|         scale = np.power(10, np.floor(np.log10(scale)))|;|     try:|;|-        sc_desired = desired/scale|;|+        sc_desired = desired / scale|;|     except ZeroDivisionError:|;|         sc_desired = 0.0|;|     try:|;|-        sc_actual = actual/scale|;|+        sc_actual = actual / scale|;|     except ZeroDivisionError:|;|         sc_actual = 0.0|;|     msg = build_err_msg(|;|@@ -687,7 +722,7 @@ def assert_approx_equal(actual, desired, significant=7, err_msg='',|;|             return|;|     except (TypeError, NotImplementedError):|;|         pass|;|-    if np.abs(sc_desired - sc_actual) >= np.power(10., -(significant-1)):|;|+    if np.abs(sc_desired - sc_actual) >= np.power(10., -(significant - 1)):|;|         raise AssertionError(msg)|;| |;| |;|@@ -1379,10 +1414,10 @@ def check_support_sve(__cache=[]):|;|     """"""|;|     gh-22982|;|     """"""|;|-    |;|+|;|     if __cache:|;|         return __cache[0]|;|-    |;|+|;|     import subprocess|;|     cmd = 'lscpu'|;|     try:|;|@@ -1543,7 +1578,7 @@ def measure(code_str, times=1, label=None):|;|         i += 1|;|         exec(code, globs, locs)|;|     elapsed = jiffies() - elapsed|;|-    return 0.01*elapsed|;|+    return 0.01 * elapsed|;| |;| |;| def _assert_valid_refcount(op):|;|@@ -1557,7 +1592,7 @@ def _assert_valid_refcount(op):|;|     import gc|;|     import numpy as np|;| |;|-    b = np.arange(100*100).reshape(100, 100)|;|+    b = np.arange(100 * 100).reshape(100, 100)|;|     c = b|;|     i = 1|;| |;|@@ -1735,7 +1770,7 @@ def assert_array_almost_equal_nulp(x, y, nulp=1):|;|     ax = np.abs(x)|;|     ay = np.abs(y)|;|     ref = nulp * np.spacing(np.where(ax > ay, ax, ay))|;|-    if not np.all(np.abs(x-y) <= ref):|;|+    if not np.all(np.abs(x - y) <= ref):|;|         if np.iscomplexobj(x) or np.iscomplexobj(y):|;|             msg = f""Arrays are not equal to {nulp} ULP""|;|         else:|;|@@ -1851,7 +1886,7 @@ def nulp_diff(x, y, dtype=None):|;|                          (x.shape, y.shape))|;| |;|     def _diff(rx, ry, vdt):|;|-        diff = np.asarray(rx-ry, dtype=vdt)|;|+        diff = np.asarray(rx - ry, dtype=vdt)|;|         return np.abs(diff)|;| |;|     rx = integer_repr(x)|;|@@ -2596,7 +2631,7 @@ def check_free_memory(free_bytes):|;|         except ValueError as exc:|;|             raise ValueError(f'Invalid environment variable {env_var}: {exc}')|;| |;|-        msg = (f'{free_bytes/1e9} GB memory required, but environment variable '|;|+        msg = (f'{free_bytes / 1e9} GB memory required, but environment variable '|;|                f'NPY_AVAILABLE_MEM={env_value} set')|;|     else:|;|         mem_free = _get_mem_available()|;|@@ -2607,7 +2642,9 @@ def check_free_memory(free_bytes):|;|                    ""the test."")|;|             mem_free = -1|;|         else:|;|-            msg = f'{free_bytes/1e9} GB memory required, but {mem_free/1e9} GB available'|;|+            free_bytes_gb = free_bytes / 1e9|;|+            mem_free_gb = mem_free / 1e9|;|+            msg = f'{free_bytes_gb} GB memory required, but {mem_free_gb} GB available'|;| |;|     return msg if mem_free < free_bytes else None|;| |;|@@ -2700,8 +2737,23 @@ def run_threaded(func, max_workers=8, pass_count=False,|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|+                all_args = [(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|+                all_args = [(func, *args) for i in range(max_workers)]|;|+            try:|;|+                futures = []|;|+                for arg in all_args:|;|+                    futures.append(tpe.submit(*arg))|;|+            finally:|;|+                if len(futures) < max_workers and pass_barrier:|;|+                    barrier.abort()|;|             for f in futures:|;|                 f.result()|;|+|;|+|;|+def get_stringdtype_dtype(na_object, coerce=True):|;|+    # explicit is check for pd_NA because != with pd_NA returns pd_NA|;|+    if na_object is pd_NA or na_object != ""unset"":|;|+        return np.dtypes.StringDType(na_object=na_object, coerce=coerce)|;|+    else:|;|+        return np.dtypes.StringDType(coerce=coerce) || PR#28321 - requirements/test_requirements.txt: @@ -9,6 +9,7 @@ pytest-cov==4.1.0|;| meson|;| ninja; sys_platform != ""emscripten""|;| pytest-xdist|;|+pytest-timeout|;| # for numpy.random.test.test_extending|;| cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:","BUG: fix race initializing legacy dtype casts || CI: remove pytest-xdist from TSAN and ASAN CI python env || BUG: fix logic error in ensure_castingimpl_exists || BUG: fix data race setting up within dtype cats for legacy user dtypes || MAINT: spawn fewer threads to hopefully fix 32 bit runners || BUG: fix reference counting error || BUG: fix resource cleanup when thread spawning errors || MAINT: refactor run_threaded to use a try/finally block || MAINT: clean up slightly || MAINT: fix linter || MAINT: go back to try/except || MAINT: fix indentation and clarify comment || MAINT: use a try/finally to make the deadlock protection more robust || MAINT: respond to code review || BUG: fix race initializing legacy dtype casts || CI: remove pytest-xdist from TSAN and ASAN CI python env || BUG: fix logic error in ensure_castingimpl_exists || BUG: fix data race setting up within dtype cats for legacy user dtypes || MAINT: spawn fewer threads to hopefully fix 32 bit runners || BUG: fix reference counting error || BUG: fix resource cleanup when thread spawning errors || MAINT: refactor run_threaded to use a try/finally block || MAINT: clean up slightly || MAINT: fix linter || MAINT: go back to try/except || MAINT: fix indentation and clarify comment || MAINT: use a try/finally to make the deadlock protection more robust || MAINT: respond to code review || MAINT: Update some testing files from main

- Checkout numpy/testing/_private/utils.py
- Checkout numpy/_core/tests/test_multithreading.py
- Checkout conftest.py
- Update test_requirements.txt"
numpy/numpy,ngoldbaum,28048,BUG: Race adding legacy casts to custom dtype under free threading,"### Describe the issue:

If the following code is run under Python 3.13.1t, it fails nondeterministically with `A cast was already added for <class 'numpy.dtype[rational]'> -> <class 'numpy.dtypes.Int8DType'>. (method: legacy_cast)`.


### Reproduce the code example:

```python
import concurrent.futures
import functools
import threading
import numpy as np
import numpy._core._rational_tests as _rational_tests

num_threads = 1000

def closure(b):
    b.wait()
    for _ in range(100):
        np.full((10, 10), 1, _rational_tests.rational)


with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
    b = threading.Barrier(num_threads)
    futures = [executor.submit(functools.partial(closure, b)) for _ in range(num_threads)]
    [f.result() for f in futures]
```


### Error message:

```shell
Traceback (most recent call last):
  File ""/Users/goldbaum/.pyenv/versions/3.13.1t/lib/python3.13t/site-packages/numpy/_core/numeric.py"", line 353, in full
    multiarray.copyto(a, fill_value, casting='unsafe')
RuntimeError: A cast was already added for <class 'numpy.dtype[rational]'> -> <class 'numpy.dtypes.Int8DType'>. (method: legacy_cast)
```


### Python and NumPy Versions:

2.3.0.dev0+git20241219.35b2c4a
3.13.1 experimental free-threading build (tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 (11)]


### Runtime Environment:

[{'numpy_version': '2.3.0.dev0+git20241219.35b2c4a',
'python': '3.13.1 experimental free-threading build '
'(tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 '
'(11)]',
'uname': uname_result(system='Linux', node='', release='', version='https://github.com/https://github.com/numpy/numpy/pull/1 SMP PREEMPT_DYNAMIC Debian 6.redacted (2024-10-16)', machine='x86_64')},
{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
'found': ['SSSE3',
'SSE41',
'POPCNT',
'SSE42',
'AVX',
'F16C',
'FMA3',
'AVX2'],
'not_found': ['AVX512F',
'AVX512CD',
'AVX512_KNL',
'AVX512_SKX',
'AVX512_CLX',
'AVX512_CNL',
'AVX512_ICL']}},
{'architecture': 'Zen',
'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.27.so',
'internal_api': 'openblas',
'num_threads': 128,
'prefix': 'libopenblas',
'threading_layer': 'pthreads',
'user_api': 'blas',
'version': '0.3.27'}]


### Context for the issue:

Found when working on free-threading support in JAX.","Hmmmm, I wonder if we can/should do this at registration time already to avoid having to add another locking point (registration should happen at import, I think.  And if not, it should be the callers problem to lock). || Here's the C traceback:

```
* thread #10, stop reason = breakpoint 2.1
  * frame #0: 0x0000000100d60340 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddCastingImplementation(meth=0x0000038d680100f0) at convert_datatype.c:2011:23 [opt]
    frame #1: 0x0000000100d60460 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddCastingImplementation_FromSpec(spec=0x0000000178e66248, private=1) at convert_datatype.c:2036:15 [opt]
    frame #2: 0x0000000100dd4230 _multiarray_umath.cpython-313t-darwin.so`PyArray_AddLegacyWrapping_CastingImpl(from=0x0000038d564d6400, to=0x0000038d564d0800, casting=NPY_UNSAFE_CASTING) at usertypes.c:0 [opt]
    frame #3: 0x0000000100d5d15c _multiarray_umath.cpython-313t-darwin.so`PyArray_GetCastingImpl(from=0x0000038d564d6400, to=<unavailable>) at convert_datatype.c:144:13 [opt]
    frame #4: 0x0000000100d5de34 _multiarray_umath.cpython-313t-darwin.so`PyArray_CanCastSafely(fromtype=<unavailable>, totype=<unavailable>) at convert_datatype.c:540:29 [opt]
    frame #5: 0x0000000100dd3e3c _multiarray_umath.cpython-313t-darwin.so`legacy_userdtype_common_dtype_function(cls=0x0000038d564d6400, other=0x0000038d564d0800) at usertypes.c:522:9 [opt]
    frame #6: 0x0000000100d45f90 _multiarray_umath.cpython-313t-darwin.so`int_common_dtype(__NPY_UNUSED_TAGGEDcls=<unavailable>, other=0x0000038d564d6400) at abstractdtypes.c:179:34 [opt]
    frame #7: 0x0000000100d5b820 _multiarray_umath.cpython-313t-darwin.so`PyArray_CommonDType(dtype1=0x0000000100f8b5f0, dtype2=0x0000038d564d6400) at common_dtype.c:58:20 [opt]
    frame #8: 0x0000000100d465e4 _multiarray_umath.cpython-313t-darwin.so`npy_find_descr_for_scalar(scalar=0, original_descr=0x0000000100f81278, in_DT=<unavailable>, op_DT=<unavailable>) at abstractdtypes.c:460:33 [opt]
    frame #9: 0x0000000100dafd58 _multiarray_umath.cpython-313t-darwin.so`array_copyto(__NPY_UNUSED_TAGGEDignored=<unavailable>, args=<unavailable>, len_args=<unavailable>, kwnames=<unavailable>) at multiarraymodule.c:1966:32 [opt]
```

NumPy is lazily generating casts, but we can probably initialize casts between user dtypes and the built-in DTypes using this machinery at DType registration time.

Failing that, we can keep the current implementation and lock the DType when we need to fill the cache. Possibly behind a `shared_mutex` like the dispatch cache. || I edited the reproducer to use `_rational_tests.rational` instead of `ml_dtypes`. Thankfully it triggers with `rational`. This should make it much easier to add a test along with a fix. || @seberg I need your opinion about what the best way forward here is.

The reason this is set up this way is because user dtypes first create a DType instance and then after that register a bunch of casts. There's no function that says ""this DType is fully initialized, do finalization steps."" 

The current approach for wrapping the legacy user dtype casts avoids the need to monkey with the internals of the legacy dtype implementation (including all the `cancastto` pointers, besides reading them after they're already set up) because by the time a cast actually happens, the legacy dtype is already done setting up, including all the casts.

I see three ways to fix this and none are great.

1. Add a new public function to finalize legacy dtypes. This must be called after all casts are registered. The new function could then call `PyArray_AddLegacyWrapping_CastingImpl` for all built-in dtypes to initialize casts during DType registration time. `ml_dtypes` could adopt this but I doubt legacy user dtypes are well enough maintained to be able to adopt a new C API function to fix a bug you're only likely to hit under free-threading.
2. Initialize a basic set of casts in the `DTypeMeta` wrapping the legacy user DType right after calling `dtypemeta_wrap_legacy_descriptor` using `PyArray_AddLegacyWrapping_CastingImpl` but then inside `PyArray_RegisterCanCast` I'd need to update the casting safety of the wrapping `ArrayMethod`, which is an annoying inversion of abstractions, because `PyArray_RegisterCanCast` is deep in the guts of the legacy user dtype implementation.
3. As alluded to above, lock the `castingimpls` slot of `PyArray_DTypeMeta` instances, probably behind a `shared_mutex`. This will probably require converting a bunch of code to C++ and might also not scale well. That also means adding locking to handle an issue that only affects legacy user DTypes to *all* DTypes. || Ah, so I had a very good reason to put it exactly where it is :(.  My thoughts:

1. My first gut-feeling was to not do this.  But it doesn't seem so bad, I agree only `ml_types` would use this, but maybe that is OK?  Unmaintained extension dtypes may not be ""advertising"" free-threading support anyway.
   We could probably hack a `DeprecationWarning`or a straight error that enforces the API when free-threading is enabled.  (not back-portable, but...)
2. This seems too akward and hard to follow to me...
3. Converting to C++ shouldn't stop us, it is churn, but likely churn that is good if it happens in the long run anyway.
   But maybe there are even easier options?  `castingimpls` is just a dict, IIRC, so I think we can call `GetItem()` even while an other thread may be adding a new cast?  If that is the case, we should be able to get away with just a critical section (and another check if it showed up) in the function adding the casts?

Since I think being a `dict` should make locking easy, locking seems like a good approach to me now.  But if it is not, I think going the new API route isn't as bad as it may seem initially. || > castingimpls is just a dict, IIRC, so I think we can call GetItem() even while an other thread may be adding a new cast? If that is the case, we should be able to get away with just a critical section (and another check if it showed up) in the function adding the casts?

I'll have to look closer at this, but I think you'd need to apply a critical section when *reading* `castingimpls`, and you'd introduce contention in the common case. It would be safe but if someone tried to call the same cast operation simultaneously from many threads it would scale poorly, just like the ufunc scaling issue we saw with critical sections. || Another perhaps less satisfying option is to let the race happen and just ignore this error case. The cast created by both threads should be identical. || `castingimpls` isn't actually used in all that many places, so maybe requiring C++ to access it isn't so bad:

```
_core/src/umath/_scaled_float_dtype.c
881:    NPY_DT_SLOTS(&PyArray_SFloatDType)->castingimpls = PyDict_New();
882:    if (NPY_DT_SLOTS(&PyArray_SFloatDType)->castingimpls == NULL) {

_core/src/multiarray/usertypes.c
348:            NPY_DT_SLOTS(NPY_DTYPE(descr))->castingimpls, (PyObject *)to_DType);

_core/src/multiarray/dtypemeta.h
80:    PyObject *castingimpls;

_core/src/multiarray/_multiarray_tests.c.src
886:        while (PyDict_Next(NPY_DT_SLOTS(from_dtype)->castingimpls,

_core/src/multiarray/dtypemeta.c
43:    Py_XDECREF(NPY_DT_SLOTS(self)->castingimpls);
323:    NPY_DT_SLOTS(DType)->castingimpls = PyDict_New();
324:    if (NPY_DT_SLOTS(DType)->castingimpls == NULL) {
1153:    dt_slots->castingimpls = PyDict_New();
1154:    if (dt_slots->castingimpls == NULL) {

_core/src/multiarray/convert_datatype.c
83:        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to);
130:                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,
159:    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,
2007:    if (PyDict_Contains(NPY_DT_SLOTS(meth->dtypes[0])->castingimpls,
2014:    if (PyDict_SetItem(NPY_DT_SLOTS(meth->dtypes[0])->castingimpls,
```

I'll look at converting the bits of NumPy needed to put `castingimpls` behind a `shared_mutex`. || Yeah, in fact, I think the `convert_datatype.c` function is probably the _only_ place that really matters (not sure if dict iteration is safe, but if not it is just a little helper that doesn't matter).
All other occurrences are at dtype creation time or should be (i.e. a the `usertypes.c` one is a sanity check that tells users that a cast was registered after being used) and it just uses `GetItem`.

If that isn't possible (and not just not the nicest way to do it!), I would still like to understand why it isn't OK to call `GetItemWithError` and only lock (very unlikely) if the result is `NULL`. (Although then checking if it was added in the meantime is necessary of course.) || I managed to get the numpy tests passing after converting `convert_datatype.c` and `dtypemeta.c` to C++ along with adding some `extern ""C"" {` in several headers. See https://github.com/numpy/numpy/pull/28253

I think the most straightforward way to add the mutex is to extend the `NPY_DType_Slots` struct to have a pointer to a mutex at the end:

```diff
diff --git a/numpy/_core/src/multiarray/dtypemeta.h b/numpy/_core/src/multiarray/dtypemeta.h
index a8b78e3f75..888ec09fba 100644
--- a/numpy/_core/src/multiarray/dtypemeta.h
+++ b/numpy/_core/src/multiarray/dtypemeta.h
@@ -85,6 +85,12 @@ typedef struct {
      * dtype instance for backward compatibility.  (Keep this at end)
      */
     PyArray_ArrFuncs f;
+
+    /*
+     *  Mutex to protect against race conditions modifying castingimpls at
+     *  runtime
+     */
+    void *mutex;
 } NPY_DType_Slots;
```

I can then heap-allocate the mutex during DType creation to avoid polluting the internal C API with C++ constructs and follow the pattern of the other `shared_mutex` use inside the dispatch cache.

If anyone spots any issues with that let me know but I think I'm going to try to implement this next. || I mean, I still really don't understand why we shouldn't just try once (even _with_ this mutex!) and then a critical section on the castingimpl's itself seems just sa well (very very unlikely to be hit in practice).
But presumably converting to C++ is straight-forward and adding a mutex is fine. || Isn't that thread-unsafe? All accesses need to be done under the critical section otherwise you could be reading from the dict while another thread writes to it. That's why I want an RWlock. || > Built-in types like [dict](https://docs.python.org/3/library/stdtypes.html#dict), [list](https://docs.python.org/3/library/stdtypes.html#list), and [set](https://docs.python.org/3/library/stdtypes.html#set) use internal locks to protect against concurrent modifications in ways that behave similarly to the GIL

I mean, the whole point of the `GetRef()` API was to make it thread-safe no?

(Which doesn't mean we shouldn't just do the C++ conversion maybe, it is maybe time...) || (I somewhat remember things as: for ufuncs we said that using a dict rather than a custom hash-table would be a solution where we don't need a custom lock.) || What's happening right now is technically thread-safe in the sense that there are no data races, but there is a race condition. We *could* use `PyDict_GetItemRef` instead, but it doesn't matter that we're creating a borrowed reference because the casts live as long as the DType, and we have a strong reference to the DType inside of `PyArray_GetCastingImpl`. `PyDict_GetItemRef` only helps you if you don't know that a borrowed reference is safe.

What I want to do is make the race condition impossible, by blocking all threads from reading the `castingimpls` while any thread tries to write to it, which should only happen the first time someone tries to do a cast with a legacy user DType for some pair of DTypes.

Does that make more sense? || @ngoldbaum but the `GetItemRef` is thread-safe, in the sense that the return is either the correct cast impl or `NULL`, no?
If it is the correct cast impl, we are all good!

If the return is `NULL`, we need to lock down `castingimpls`!  Then there are two possibilities:
* Another thread was faster, by the time we get the `castingimpls` lock, the cast is already added.
* We were faster, and we should add the cast.

So, if the return was `NULL` (and only then, which happens only once for each cast!), we have to lock `castingimpls` and then check again before we create it to avoid adding it twice (if another thread was faster).

Since `castingimpls` will effectively always return non-null (we add a `None` to indicate ""undefined"") and we don't need any additional mutex for the first `GetItemRef`, it seems nice to just avoid the mutex for the first step in any case? || I opened https://github.com/numpy/numpy/pull/28290",closed,2024-12-20T21:17:25+00:00,2025-02-11T16:55:16+00:00,hawkinsp,"00 - Bug, 39 - free-threading",2,"PR#28290 - .github/workflows/compiler_sanitizers.yml: @@ -60,6 +60,8 @@ jobs:|;|         pip install -r requirements/build_requirements.txt|;|         pip install -r requirements/ci_requirements.txt|;|         pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the ASAN output|;|+        pip uninstall -y pytest-xdist|;|     - name: Build|;|       run:|;|         python -m spin build -j2 -- -Db_sanitize=address|;|@@ -111,6 +113,8 @@ jobs:|;|         pip install -r requirements/build_requirements.txt|;|         pip install -r requirements/ci_requirements.txt|;|         pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the TSAN output|;|+        pip uninstall -y pytest-xdist|;|     - name: Build|;|       run:|;|         python -m spin build -j2 -- -Db_sanitize=thread || PR#28290 - numpy/_core/src/multiarray/convert_datatype.c: @@ -63,46 +63,24 @@ static PyObject *|;| PyArray_GetObjectToGenericCastingImpl(void)|;|; |;| |;|-/**|;|- * Fetch the casting implementation from one DType to another.|;|- *|;|- * @param from The implementation to cast from|;|- * @param to The implementation to cast to|;|- *|;|- * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|- *          error set.|;|- */|;|-NPY_NO_EXPORT PyObject *|;|-PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+static PyObject *|;|+create_casting_impl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;| {|;|-    PyObject *res|;|;-    if (from == to) {|;|-        res = (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl|;|;-    }|;|-    else {|;|-        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to)|;|;-    }|;|-    if (res != NULL || PyErr_Occurred()) {|;|-        Py_XINCREF(res)|;|;-        return res|;|;-    }|;|     /*|;|-     * The following code looks up CastingImpl based on the fact that anything|;|+     * Look up CastingImpl based on the fact that anything|;|      * can be cast to and from objects or structured (void) dtypes.|;|-     *|;|-     * The last part adds casts dynamically based on legacy definition|;|      */|;|     if (from->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetObjectToGenericCastingImpl()|;|;+        return PyArray_GetObjectToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetGenericToObjectCastingImpl()|;|;+        return PyArray_GetGenericToObjectCastingImpl()|;|;     }|;|     else if (from->type_num == NPY_VOID) {|;|-        res = PyArray_GetVoidToGenericCastingImpl()|;|;+        return PyArray_GetVoidToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_VOID) {|;|-        res = PyArray_GetGenericToVoidCastingImpl()|;|;+        return PyArray_GetGenericToVoidCastingImpl()|;|;     }|;|     /*|;|      * Reject non-legacy dtypes. They need to use the new API to add casts and|;|@@ -126,42 +104,105 @@ PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|                     from->singleton, to->type_num)|;|;             if (castfunc == NULL) {|;|                 PyErr_Clear()|;|;-                /* Remember that this cast is not possible */|;|-                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                            (PyObject *) to, Py_None) < 0) {|;|-                    return NULL|;|;-                }|;|                 Py_RETURN_NONE|;|;             }|;|         }|;|-|;|-        /* PyArray_AddLegacyWrapping_CastingImpl find the correct casting level: */|;|-        /*|;|-         * TODO: Possibly move this to the cast registration time. But if we do|;|-         *       that, we have to also update the cast when the casting safety|;|-         *       is registered.|;|+        /* Create a cast using the state of the legacy casting setup defined|;|+         * during the setup of the DType.|;|+         *|;|+         * Ideally we would do this when we create the DType, but legacy user|;|+         * DTypes don't have a way to signal that a DType is done setting up|;|+         * casts. Without such a mechanism, the safest way to know that a|;|+         * DType is done setting up is to register the cast lazily the first|;|+         * time a user does the cast.|;|+         *|;|+         * We *could* register the casts when we create the wrapping|;|+         * DTypeMeta, but that means the internals of the legacy user DType|;|+         * system would need to update the state of the casting safety flags|;|+         * in the cast implementations stored on the DTypeMeta. That's an|;|+         * inversion of abstractions and would be tricky to do without|;|+         * creating circular dependencies inside NumPy.|;|          */|;|         if (PyArray_AddLegacyWrapping_CastingImpl(from, to, -1) < 0) {|;|             return NULL|;|;         }|;|+        /* castingimpls is unconditionally filled by|;|+         * AddLegacyWrapping_CastingImpl, so this won't create a recursive|;|+         * critical section|;|+         */|;|         return PyArray_GetCastingImpl(from, to)|;|;     }|;|+}|;| |;|-    if (res == NULL) {|;|+static PyObject *|;|+ensure_castingimpl_exists(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    int return_error = 0|;|;+    PyObject *res = NULL|;|;+|;|+    /* Need to create the cast. This might happen at runtime so we enter a|;|+       critical section to avoid races */|;|+|;|+    Py_BEGIN_CRITICAL_SECTION(NPY_DT_SLOTS(from)->castingimpls)|;|;+|;|+    /* check if another thread filled it while this thread was blocked on|;|+       acquiring the critical section */|;|+    if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to,|;|+                          &res) < 0) {|;|+        return_error = 1|;|;+    }|;|+    else if (res == NULL) {|;|+        res = create_casting_impl(from, to)|;|;+        if (res == NULL) {|;|+            return_error = 1|;|;+        }|;|+        else if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|+                                (PyObject *)to, res) < 0) {|;|+            return_error = 1|;|;+        }|;|+    }|;|+    Py_END_CRITICAL_SECTION()|;|;+    if (return_error) {|;|+        Py_XDECREF(res)|;|;         return NULL|;|;     }|;|-    if (from == to) {|;|+    if (from == to && res == Py_None) {|;|         PyErr_Format(PyExc_RuntimeError,|;|                 ""Internal NumPy error, within-DType cast missing for %S!"", from)|;|;         Py_DECREF(res)|;|;         return NULL|;|;     }|;|-    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                (PyObject *)to, res) < 0) {|;|-        Py_DECREF(res)|;|;+    return res|;|;+}|;|+|;|+/**|;|+ * Fetch the casting implementation from one DType to another.|;|+ *|;|+ * @param from The implementation to cast from|;|+ * @param to The implementation to cast to|;|+ *|;|+ * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|+ *          error set.|;|+ */|;|+NPY_NO_EXPORT PyObject *|;|+PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    PyObject *res = NULL|;|;+    if (from == to) {|;|+        if ((NPY_DT_SLOTS(from)->within_dtype_castingimpl) != NULL) {|;|+            res = Py_XNewRef(|;|+                    (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl)|;|;+        }|;|+    }|;|+    else if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls,|;|+                               (PyObject *)to, &res) < 0) {|;|         return NULL|;|;     }|;|-    return res|;|;+    if (res != NULL) {|;|+        return res|;|;+    }|;|+|;|+    return ensure_castingimpl_exists(from, to)|;|; }|;| |;| |;|@@ -410,7 +451,7 @@ _get_cast_safety_from_castingimpl(PyArrayMethodObject *castingimpl,|;|  * implementations fully to have them available for doing the actual cast|;|  * later.|;|  *|;|- * @param from The descriptor to cast from |;|+ * @param from The descriptor to cast from|;|  * @param to The descriptor to cast to (may be NULL)|;|  * @param to_dtype If `to` is NULL, must pass the to_dtype (otherwise this|;|  *        is ignored).|;|@@ -2021,6 +2062,11 @@ PyArray_AddCastingImplementation(PyBoundArrayMethodObject *meth)|;| /**|;|  * Add a new casting implementation using a PyArrayMethod_Spec.|;|  *|;|+ * Using this function outside of module initialization without holding a|;|+ * critical section on the castingimpls dict may lead to a race to fill the|;|+ * dict. Use PyArray_GetGastingImpl to lazily register casts at runtime|;|+ * safely.|;|+ *|;|  * @param spec The specification to use as a source|;|  * @param private If private, allow slots not publicly exposed.|;|  * @return 0 on success -1 on failure || PR#28290 - numpy/_core/src/multiarray/dtypemeta.c: @@ -1252,6 +1252,12 @@ dtypemeta_wrap_legacy_descriptor(|;|             return -1|;|;         }|;|     }|;|+    else {|;|+        // ensure the within dtype cast is populated for legacy user dtypes|;|+        if (PyArray_GetCastingImpl(dtype_class, dtype_class) == NULL) {|;|+            return -1|;|;+        }|;|+    }|;| |;|     return 0|;|; } || PR#28290 - numpy/_core/tests/test_multithreading.py: @@ -7,6 +7,7 @@|;| |;| from numpy.testing import IS_WASM|;| from numpy.testing._private.utils import run_threaded|;|+from numpy._core import _rational_tests|;| |;| if IS_WASM:|;|     pytest.skip(allow_module_level=True, reason=""no threading support in wasm"")|;|@@ -254,3 +255,19 @@ def func(arr):|;| |;|         for f in futures:|;|             f.result()|;|+|;|+|;|+def test_legacy_usertype_cast_init_thread_safety():|;|+    def closure(b):|;|+        b.wait()|;|+        np.full((10, 10), 1, _rational_tests.rational)|;|+|;|+    try:|;|+        run_threaded(closure, 250, pass_barrier=True)|;|+    except RuntimeError:|;|+        # The 32 bit linux runner will trigger this with 250 threads. I can|;|+        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|+        # more resource-constrained.|;|+        # Reducing the number of threads means the test doesn't trigger the|;|+        # bug. Better to skip on some platforms than add a useless test.|;|+        pytest.skip(""Couldn't spawn enough threads to run the test"") || PR#28290 - numpy/testing/_private/utils.py: @@ -2734,9 +2734,16 @@ def run_threaded(func, max_workers=8, pass_count=False,|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|+                all_args = [(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|+                all_args = [(func, *args) for i in range(max_workers)]|;|+            try:|;|+                futures = []|;|+                for arg in all_args:|;|+                    futures.append(tpe.submit(*arg))|;|+            finally:|;|+                if len(futures) < max_workers and pass_barrier:|;|+                    barrier.abort()|;|             for f in futures:|;|                 f.result()|;|  || PR#28321 - .github/workflows/compiler_sanitizers.yml: @@ -0,0 +1,127 @@|;|+name: Test with compiler sanitizers|;|+|;|+on:|;|+  push:|;|+    branches:|;|+      - main|;|+  pull_request:|;|+    branches:|;|+      - main|;|+      - maintenance/**|;|+|;|+defaults:|;|+  run:|;|+    shell: bash|;|+|;|+concurrency:|;|+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}|;|+  cancel-in-progress: true|;|+|;|+permissions:|;|+  contents: read # to fetch code (actions/checkout)|;|+|;|+jobs:|;|+  clang_ASAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with address sanitizer|;|+      run: ||;|+        CONFIGURE_OPTS=""--with-address-sanitizer"" pyenv install 3.13|;|+        pyenv global 3.13|;|+    - name: Install dependencies|;|+      run: ||;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the ASAN output|;|+        pip uninstall -y pytest-xdist|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=address|;|+    - name: Test|;|+      run: ||;|+        # pass -s to pytest to see ASAN errors and warnings, otherwise pytest captures them|;|+        ASAN_OPTIONS=detect_leaks=0:symbolize=1:strict_init_order=true:allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test -- -v -s --timeout=600 --durations=10|;|+|;|+  clang_TSAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with thread sanitizer support|;|+      run: ||;|+        # free-threaded Python is much more likely to trigger races|;|+        CONFIGURE_OPTS=""--with-thread-sanitizer"" pyenv install 3.13t|;|+        pyenv global 3.13t|;|+    - name: Install dependencies|;|+      run: ||;|+        # TODO: remove when a released cython supports free-threaded python|;|+        pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython|;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+        # xdist captures stdout/stderr, but we want the TSAN output|;|+        pip uninstall -y pytest-xdist|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=thread|;|+    - name: Test|;|+      run: ||;|+        # These tests are slow, so only run tests in files that do ""import threading"" to make them count|;|+        TSAN_OPTIONS=allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test \|;|+        `find numpy -name ""test*.py"" | xargs grep -l ""import threading"" | tr '\n' ' '` \|;|+        -- -v -s --timeout=600 --durations=10 || PR#28321 - numpy/_core/src/multiarray/convert_datatype.c: @@ -62,46 +62,24 @@ static PyObject *|;| PyArray_GetObjectToGenericCastingImpl(void)|;|; |;| |;|-/**|;|- * Fetch the casting implementation from one DType to another.|;|- *|;|- * @param from The implementation to cast from|;|- * @param to The implementation to cast to|;|- *|;|- * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|- *          error set.|;|- */|;|-NPY_NO_EXPORT PyObject *|;|-PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+static PyObject *|;|+create_casting_impl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;| {|;|-    PyObject *res|;|;-    if (from == to) {|;|-        res = (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl|;|;-    }|;|-    else {|;|-        res = PyDict_GetItemWithError(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to)|;|;-    }|;|-    if (res != NULL || PyErr_Occurred()) {|;|-        Py_XINCREF(res)|;|;-        return res|;|;-    }|;|     /*|;|-     * The following code looks up CastingImpl based on the fact that anything|;|+     * Look up CastingImpl based on the fact that anything|;|      * can be cast to and from objects or structured (void) dtypes.|;|-     *|;|-     * The last part adds casts dynamically based on legacy definition|;|      */|;|     if (from->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetObjectToGenericCastingImpl()|;|;+        return PyArray_GetObjectToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_OBJECT) {|;|-        res = PyArray_GetGenericToObjectCastingImpl()|;|;+        return PyArray_GetGenericToObjectCastingImpl()|;|;     }|;|     else if (from->type_num == NPY_VOID) {|;|-        res = PyArray_GetVoidToGenericCastingImpl()|;|;+        return PyArray_GetVoidToGenericCastingImpl()|;|;     }|;|     else if (to->type_num == NPY_VOID) {|;|-        res = PyArray_GetGenericToVoidCastingImpl()|;|;+        return PyArray_GetGenericToVoidCastingImpl()|;|;     }|;|     /*|;|      * Reject non-legacy dtypes. They need to use the new API to add casts and|;|@@ -125,42 +103,105 @@ PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|                     from->singleton, to->type_num)|;|;             if (castfunc == NULL) {|;|                 PyErr_Clear()|;|;-                /* Remember that this cast is not possible */|;|-                if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                            (PyObject *) to, Py_None) < 0) {|;|-                    return NULL|;|;-                }|;|                 Py_RETURN_NONE|;|;             }|;|         }|;|-|;|-        /* PyArray_AddLegacyWrapping_CastingImpl find the correct casting level: */|;|-        /*|;|-         * TODO: Possibly move this to the cast registration time. But if we do|;|-         *       that, we have to also update the cast when the casting safety|;|-         *       is registered.|;|+        /* Create a cast using the state of the legacy casting setup defined|;|+         * during the setup of the DType.|;|+         *|;|+         * Ideally we would do this when we create the DType, but legacy user|;|+         * DTypes don't have a way to signal that a DType is done setting up|;|+         * casts. Without such a mechanism, the safest way to know that a|;|+         * DType is done setting up is to register the cast lazily the first|;|+         * time a user does the cast.|;|+         *|;|+         * We *could* register the casts when we create the wrapping|;|+         * DTypeMeta, but that means the internals of the legacy user DType|;|+         * system would need to update the state of the casting safety flags|;|+         * in the cast implementations stored on the DTypeMeta. That's an|;|+         * inversion of abstractions and would be tricky to do without|;|+         * creating circular dependencies inside NumPy.|;|          */|;|         if (PyArray_AddLegacyWrapping_CastingImpl(from, to, -1) < 0) {|;|             return NULL|;|;         }|;|+        /* castingimpls is unconditionally filled by|;|+         * AddLegacyWrapping_CastingImpl, so this won't create a recursive|;|+         * critical section|;|+         */|;|         return PyArray_GetCastingImpl(from, to)|;|;     }|;|+}|;| |;|-    if (res == NULL) {|;|+static PyObject *|;|+ensure_castingimpl_exists(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    int return_error = 0|;|;+    PyObject *res = NULL|;|;+|;|+    /* Need to create the cast. This might happen at runtime so we enter a|;|+       critical section to avoid races */|;|+|;|+    Py_BEGIN_CRITICAL_SECTION(NPY_DT_SLOTS(from)->castingimpls)|;|;+|;|+    /* check if another thread filled it while this thread was blocked on|;|+       acquiring the critical section */|;|+    if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls, (PyObject *)to,|;|+                          &res) < 0) {|;|+        return_error = 1|;|;+    }|;|+    else if (res == NULL) {|;|+        res = create_casting_impl(from, to)|;|;+        if (res == NULL) {|;|+            return_error = 1|;|;+        }|;|+        else if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|+                                (PyObject *)to, res) < 0) {|;|+            return_error = 1|;|;+        }|;|+    }|;|+    Py_END_CRITICAL_SECTION()|;|;+    if (return_error) {|;|+        Py_XDECREF(res)|;|;         return NULL|;|;     }|;|-    if (from == to) {|;|+    if (from == to && res == Py_None) {|;|         PyErr_Format(PyExc_RuntimeError,|;|                 ""Internal NumPy error, within-DType cast missing for %S!"", from)|;|;         Py_DECREF(res)|;|;         return NULL|;|;     }|;|-    if (PyDict_SetItem(NPY_DT_SLOTS(from)->castingimpls,|;|-                (PyObject *)to, res) < 0) {|;|-        Py_DECREF(res)|;|;+    return res|;|;+}|;|+|;|+/**|;|+ * Fetch the casting implementation from one DType to another.|;|+ *|;|+ * @param from The implementation to cast from|;|+ * @param to The implementation to cast to|;|+ *|;|+ * @returns A castingimpl (PyArrayDTypeMethod *), None or NULL with an|;|+ *          error set.|;|+ */|;|+NPY_NO_EXPORT PyObject *|;|+PyArray_GetCastingImpl(PyArray_DTypeMeta *from, PyArray_DTypeMeta *to)|;|+{|;|+    PyObject *res = NULL|;|;+    if (from == to) {|;|+        if ((NPY_DT_SLOTS(from)->within_dtype_castingimpl) != NULL) {|;|+            res = Py_XNewRef(|;|+                    (PyObject *)NPY_DT_SLOTS(from)->within_dtype_castingimpl)|;|;+        }|;|+    }|;|+    else if (PyDict_GetItemRef(NPY_DT_SLOTS(from)->castingimpls,|;|+                               (PyObject *)to, &res) < 0) {|;|         return NULL|;|;     }|;|-    return res|;|;+    if (res != NULL) {|;|+        return res|;|;+    }|;|+|;|+    return ensure_castingimpl_exists(from, to)|;|; }|;| |;| |;|@@ -409,7 +450,7 @@ _get_cast_safety_from_castingimpl(PyArrayMethodObject *castingimpl,|;|  * implementations fully to have them available for doing the actual cast|;|  * later.|;|  *|;|- * @param from The descriptor to cast from |;|+ * @param from The descriptor to cast from|;|  * @param to The descriptor to cast to (may be NULL)|;|  * @param to_dtype If `to` is NULL, must pass the to_dtype (otherwise this|;|  *        is ignored).|;|@@ -2031,6 +2072,11 @@ PyArray_AddCastingImplementation(PyBoundArrayMethodObject *meth)|;| /**|;|  * Add a new casting implementation using a PyArrayMethod_Spec.|;|  *|;|+ * Using this function outside of module initialization without holding a|;|+ * critical section on the castingimpls dict may lead to a race to fill the|;|+ * dict. Use PyArray_GetGastingImpl to lazily register casts at runtime|;|+ * safely.|;|+ *|;|  * @param spec The specification to use as a source|;|  * @param private If private, allow slots not publicly exposed.|;|  * @return 0 on success -1 on failure || PR#28321 - numpy/_core/src/multiarray/dtypemeta.c: @@ -1252,6 +1252,12 @@ dtypemeta_wrap_legacy_descriptor(|;|             return -1|;|;         }|;|     }|;|+    else {|;|+        // ensure the within dtype cast is populated for legacy user dtypes|;|+        if (PyArray_GetCastingImpl(dtype_class, dtype_class) == NULL) {|;|+            return -1|;|;+        }|;|+    }|;| |;|     return 0|;|; } || PR#28321 - numpy/_core/tests/test_multithreading.py: @@ -1,10 +1,13 @@|;|+import concurrent.futures|;| import threading|;|+import string|;| |;| import numpy as np|;| import pytest|;| |;| from numpy.testing import IS_WASM|;| from numpy.testing._private.utils import run_threaded|;|+from numpy._core import _rational_tests|;| |;| if IS_WASM:|;|     pytest.skip(allow_module_level=True, reason=""no threading support in wasm"")|;|@@ -165,3 +168,106 @@ def closure(b):|;|             x = np.repeat(x0, 2, axis=0)[::2]|;| |;|     run_threaded(closure, max_workers=10, pass_barrier=True)|;|+|;|+|;|+def test_structured_advanced_indexing():|;|+    # Test that copyswap(n) used by integer array indexing is threadsafe|;|+    # for structured datatypes, see gh-15387. This test can behave randomly.|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(6000, 8)).view(dt)[:, 0]|;|+|;|+    rng = np.random.default_rng()|;|+|;|+    def func(arr):|;|+        indx = rng.integers(0, len(arr), size=6000, dtype=np.intp)|;|+        arr[indx]|;|+|;|+    tpe = concurrent.futures.ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_structured_threadsafety2():|;|+    # Nonzero (and some other functions) should be threadsafe for|;|+    # structured datatypes, see gh-15387. This test can behave randomly.|;|+    from concurrent.futures import ThreadPoolExecutor|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(5000, 4)).view(dt)[:, 0]|;|+|;|+    def func(arr):|;|+        arr.nonzero()|;|+|;|+    tpe = ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_stringdtype_multithreaded_access_and_mutation(|;|+        dtype, random_string_list):|;|+    # this test uses an RNG and may crash or cause deadlocks if there is a|;|+    # threading bug|;|+    rng = np.random.default_rng(0x4D3D3D3)|;|+|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = rng.choice(chars, size=100 * 10, replace=True)|;|+    random_string_list = ret.view(""U100"")|;|+|;|+    def func(arr):|;|+        rnd = rng.random()|;|+        # either write to random locations in the array, compute a ufunc, or|;|+        # re-initialize the array|;|+        if rnd < 0.25:|;|+            num = np.random.randint(0, arr.size)|;|+            arr[num] = arr[num] + ""hello""|;|+        elif rnd < 0.5:|;|+            if rnd < 0.375:|;|+                np.add(arr, arr)|;|+            else:|;|+                np.add(arr, arr, out=arr)|;|+        elif rnd < 0.75:|;|+            if rnd < 0.875:|;|+                np.multiply(arr, np.int64(2))|;|+            else:|;|+                np.multiply(arr, np.int64(2), out=arr)|;|+        else:|;|+            arr[:] = random_string_list|;|+|;|+    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as tpe:|;|+        arr = np.array(random_string_list, dtype=dtype)|;|+        futures = [tpe.submit(func, arr) for _ in range(500)]|;|+|;|+        for f in futures:|;|+            f.result()|;|+|;|+|;|+def test_legacy_usertype_cast_init_thread_safety():|;|+    def closure(b):|;|+        b.wait()|;|+        np.full((10, 10), 1, _rational_tests.rational)|;|+|;|+    try:|;|+        run_threaded(closure, 250, pass_barrier=True)|;|+    except RuntimeError:|;|+        # The 32 bit linux runner will trigger this with 250 threads. I can|;|+        # trigger it on my Linux laptop with 500 threads but the CI runner is|;|+        # more resource-constrained.|;|+        # Reducing the number of threads means the test doesn't trigger the|;|+        # bug. Better to skip on some platforms than add a useless test.|;|+        pytest.skip(""Couldn't spawn enough threads to run the test"") || PR#28321 - numpy/conftest.py: @@ -2,6 +2,7 @@|;| Pytest configuration and fixtures for the Numpy test suite.|;| """"""|;| import os|;|+import string|;| import sys|;| import tempfile|;| from contextlib import contextmanager|;|@@ -10,9 +11,11 @@|;| import hypothesis|;| import pytest|;| import numpy|;|+import numpy as np|;| |;| from numpy._core._multiarray_tests import get_fpu_mode|;|-from numpy.testing._private.utils import NOGIL_BUILD|;|+from numpy._core.tests._natype import pd_NA|;|+from numpy.testing._private.utils import NOGIL_BUILD, get_stringdtype_dtype|;| |;| try:|;|     from scipy_doctest.conftest import dt_config|;|@@ -204,12 +207,12 @@ def warnings_errors_and_rng(test=None):|;|     dt_config.check_namespace['StringDType'] = numpy.dtypes.StringDType|;| |;|     # temporary skips|;|-    dt_config.skiplist = set([|;|+    dt_config.skiplist = {|;|         'numpy.savez',    # unclosed file|;|         'numpy.matlib.savez',|;|         'numpy.__array_namespace_info__',|;|         'numpy.matlib.__array_namespace_info__',|;|-    ])|;|+    }|;| |;|     # xfail problematic tutorials|;|     dt_config.pytest_extra_xfail = {|;|@@ -231,3 +234,28 @@ def warnings_errors_and_rng(test=None):|;|         'numpy/f2py/_backends/_distutils.py',|;|     ]|;| |;|+|;|+@pytest.fixture|;|+def random_string_list():|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = np.random.choice(chars, size=100 * 10, replace=True)|;|+    return ret.view(""U100"")|;|+|;|+|;|+@pytest.fixture(params=[True, False])|;|+def coerce(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture(|;|+    params=[""unset"", None, pd_NA, np.nan, float(""nan""), ""__nan__""],|;|+    ids=[""unset"", ""None"", ""pandas.NA"", ""np.nan"", ""float('nan')"", ""string nan""],|;|+)|;|+def na_object(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture()|;|+def dtype(na_object, coerce):|;|+    return get_stringdtype_dtype(na_object, coerce) || PR#28321 - numpy/testing/_private/utils.py: @@ -4,6 +4,7 @@|;| """"""|;| import os|;| import sys|;|+import pathlib|;| import platform|;| import re|;| import gc|;|@@ -19,16 +20,19 @@|;| import sysconfig|;| import concurrent.futures|;| import threading|;|+import importlib.metadata|;| |;| import numpy as np|;| from numpy._core import (|;|      intp, float32, empty, arange, array_repr, ndarray, isnat, array)|;| from numpy import isfinite, isnan, isinf|;| import numpy.linalg._umath_linalg|;| from numpy._utils import _rename_parameter|;|+from numpy._core.tests._natype import pd_NA|;| |;| from io import StringIO|;| |;|+|;| __all__ = [|;|         'assert_equal', 'assert_almost_equal', 'assert_approx_equal',|;|         'assert_array_equal', 'assert_array_less', 'assert_string_equal',|;|@@ -42,7 +46,7 @@|;|         'HAS_REFCOUNT', ""IS_WASM"", 'suppress_warnings', 'assert_array_compare',|;|         'assert_no_gc_cycles', 'break_cycles', 'HAS_LAPACK64', 'IS_PYSTON',|;|         'IS_MUSL', 'check_support_sve', 'NOGIL_BUILD',|;|-        'IS_EDITABLE', 'run_threaded',|;|+        'IS_EDITABLE', 'IS_INSTALLED', 'NUMPY_ROOT', 'run_threaded',|;|         ]|;| |;| |;|@@ -54,10 +58,40 @@ class KnownFailureException(Exception):|;| KnownFailureTest = KnownFailureException  # backwards compat|;| verbose = 0|;| |;|+NUMPY_ROOT = pathlib.Path(np.__file__).parent|;|+|;|+try:|;|+    np_dist = importlib.metadata.distribution('numpy')|;|+except importlib.metadata.PackageNotFoundError:|;|+    IS_INSTALLED = IS_EDITABLE = False|;|+else:|;|+    IS_INSTALLED = True|;|+    try:|;|+        if sys.version_info >= (3, 13):|;|+            IS_EDITABLE = np_dist.origin.dir_info.editable|;|+        else:|;|+            # Backport importlib.metadata.Distribution.origin|;|+            import json, types  # noqa: E401|;|+            origin = json.loads(|;|+                np_dist.read_text('direct_url.json') or '{}',|;|+                object_hook=lambda data: types.SimpleNamespace(**data),|;|+            )|;|+            IS_EDITABLE = origin.dir_info.editable|;|+    except AttributeError:|;|+        IS_EDITABLE = False|;|+|;|+    # spin installs numpy directly via meson, instead of using meson-python, and|;|+    # runs the module by setting PYTHONPATH. This is problematic because the|;|+    # resulting installation lacks the Python metadata (.dist-info), and numpy|;|+    # might already be installed on the environment, causing us to find its|;|+    # metadata, even though we are not actually loading that package.|;|+    # Work around this issue by checking if the numpy root matches.|;|+    if not IS_EDITABLE and np_dist.locate_file('numpy') != NUMPY_ROOT:|;|+        IS_INSTALLED = False|;|+|;| IS_WASM = platform.machine() in [""wasm32"", ""wasm64""]|;| IS_PYPY = sys.implementation.name == 'pypy'|;| IS_PYSTON = hasattr(sys, ""pyston_version_info"")|;|-IS_EDITABLE = not bool(np.__path__) or 'editable' in np.__path__[0]|;| HAS_REFCOUNT = getattr(sys, 'getrefcount', None) is not None and not IS_PYSTON|;| HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64|;| |;|@@ -101,14 +135,15 @@ def GetPerformanceAttributes(object, counter, instance=None,|;|         # thread's CPU usage is either 0 or 100).  To read counters like this,|;|         # you should copy this function, but keep the counter open, and call|;|         # CollectQueryData() each time you need to know.|;|-        # See http://msdn.microsoft.com/library/en-us/dnperfmo/html/perfmonpt2.asp (dead link)|;|+        # See http://msdn.microsoft.com/library/en-us/dnperfmo/html/perfmonpt2.asp|;|+        #(dead link)|;|         # My older explanation for this was that the ""AddCounter"" process|;|         # forced the CPU to 100%, but the above makes more sense :)|;|         import win32pdh|;|         if format is None:|;|             format = win32pdh.PDH_FMT_LONG|;|-        path = win32pdh.MakeCounterPath( (machine, object, instance, None,|;|-                                          inum, counter))|;|+        path = win32pdh.MakeCounterPath((machine, object, instance, None,|;|+                                         inum, counter))|;|         hq = win32pdh.OpenQuery()|;|         try:|;|             hc = win32pdh.AddCounter(hq, path)|;|@@ -166,7 +201,7 @@ def jiffies(_proc_pid_stat=f'/proc/{os.getpid()}/stat', _load_time=[]):|;|                 l = f.readline().split(' ')|;|             return int(l[13])|;|         except Exception:|;|-            return int(100*(time.time()-_load_time[0]))|;|+            return int(100 * (time.time() - _load_time[0]))|;| else:|;|     # os.getpid is not in all platforms available.|;|     # Using time is safe but inaccurate, especially when process|;|@@ -182,15 +217,15 @@ def jiffies(_load_time=[]):|;|         import time|;|         if not _load_time:|;|             _load_time.append(time.time())|;|-        return int(100*(time.time()-_load_time[0]))|;|+        return int(100 * (time.time() - _load_time[0]))|;| |;| |;| def build_err_msg(arrays, err_msg, header='Items are not equal:',|;|                   verbose=True, names=('ACTUAL', 'DESIRED'), precision=8):|;|     msg = ['\n' + header]|;|     err_msg = str(err_msg)|;|     if err_msg:|;|-        if err_msg.find('\n') == -1 and len(err_msg) < 79-len(header):|;|+        if err_msg.find('\n') == -1 and len(err_msg) < 79 - len(header):|;|             msg = [msg[0] + ' ' + err_msg]|;|         else:|;|             msg.append(err_msg)|;|@@ -659,14 +694,14 @@ def assert_approx_equal(actual, desired, significant=7, err_msg='',|;|     # Normalized the numbers to be in range (-10.0,10.0)|;|     # scale = float(pow(10,math.floor(math.log10(0.5*(abs(desired)+abs(actual))))))|;|     with np.errstate(invalid='ignore'):|;|-        scale = 0.5*(np.abs(desired) + np.abs(actual))|;|+        scale = 0.5 * (np.abs(desired) + np.abs(actual))|;|         scale = np.power(10, np.floor(np.log10(scale)))|;|     try:|;|-        sc_desired = desired/scale|;|+        sc_desired = desired / scale|;|     except ZeroDivisionError:|;|         sc_desired = 0.0|;|     try:|;|-        sc_actual = actual/scale|;|+        sc_actual = actual / scale|;|     except ZeroDivisionError:|;|         sc_actual = 0.0|;|     msg = build_err_msg(|;|@@ -687,7 +722,7 @@ def assert_approx_equal(actual, desired, significant=7, err_msg='',|;|             return|;|     except (TypeError, NotImplementedError):|;|         pass|;|-    if np.abs(sc_desired - sc_actual) >= np.power(10., -(significant-1)):|;|+    if np.abs(sc_desired - sc_actual) >= np.power(10., -(significant - 1)):|;|         raise AssertionError(msg)|;| |;| |;|@@ -1379,10 +1414,10 @@ def check_support_sve(__cache=[]):|;|     """"""|;|     gh-22982|;|     """"""|;|-    |;|+|;|     if __cache:|;|         return __cache[0]|;|-    |;|+|;|     import subprocess|;|     cmd = 'lscpu'|;|     try:|;|@@ -1543,7 +1578,7 @@ def measure(code_str, times=1, label=None):|;|         i += 1|;|         exec(code, globs, locs)|;|     elapsed = jiffies() - elapsed|;|-    return 0.01*elapsed|;|+    return 0.01 * elapsed|;| |;| |;| def _assert_valid_refcount(op):|;|@@ -1557,7 +1592,7 @@ def _assert_valid_refcount(op):|;|     import gc|;|     import numpy as np|;| |;|-    b = np.arange(100*100).reshape(100, 100)|;|+    b = np.arange(100 * 100).reshape(100, 100)|;|     c = b|;|     i = 1|;| |;|@@ -1735,7 +1770,7 @@ def assert_array_almost_equal_nulp(x, y, nulp=1):|;|     ax = np.abs(x)|;|     ay = np.abs(y)|;|     ref = nulp * np.spacing(np.where(ax > ay, ax, ay))|;|-    if not np.all(np.abs(x-y) <= ref):|;|+    if not np.all(np.abs(x - y) <= ref):|;|         if np.iscomplexobj(x) or np.iscomplexobj(y):|;|             msg = f""Arrays are not equal to {nulp} ULP""|;|         else:|;|@@ -1851,7 +1886,7 @@ def nulp_diff(x, y, dtype=None):|;|                          (x.shape, y.shape))|;| |;|     def _diff(rx, ry, vdt):|;|-        diff = np.asarray(rx-ry, dtype=vdt)|;|+        diff = np.asarray(rx - ry, dtype=vdt)|;|         return np.abs(diff)|;| |;|     rx = integer_repr(x)|;|@@ -2596,7 +2631,7 @@ def check_free_memory(free_bytes):|;|         except ValueError as exc:|;|             raise ValueError(f'Invalid environment variable {env_var}: {exc}')|;| |;|-        msg = (f'{free_bytes/1e9} GB memory required, but environment variable '|;|+        msg = (f'{free_bytes / 1e9} GB memory required, but environment variable '|;|                f'NPY_AVAILABLE_MEM={env_value} set')|;|     else:|;|         mem_free = _get_mem_available()|;|@@ -2607,7 +2642,9 @@ def check_free_memory(free_bytes):|;|                    ""the test."")|;|             mem_free = -1|;|         else:|;|-            msg = f'{free_bytes/1e9} GB memory required, but {mem_free/1e9} GB available'|;|+            free_bytes_gb = free_bytes / 1e9|;|+            mem_free_gb = mem_free / 1e9|;|+            msg = f'{free_bytes_gb} GB memory required, but {mem_free_gb} GB available'|;| |;|     return msg if mem_free < free_bytes else None|;| |;|@@ -2700,8 +2737,23 @@ def run_threaded(func, max_workers=8, pass_count=False,|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|+                all_args = [(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|+                all_args = [(func, *args) for i in range(max_workers)]|;|+            try:|;|+                futures = []|;|+                for arg in all_args:|;|+                    futures.append(tpe.submit(*arg))|;|+            finally:|;|+                if len(futures) < max_workers and pass_barrier:|;|+                    barrier.abort()|;|             for f in futures:|;|                 f.result()|;|+|;|+|;|+def get_stringdtype_dtype(na_object, coerce=True):|;|+    # explicit is check for pd_NA because != with pd_NA returns pd_NA|;|+    if na_object is pd_NA or na_object != ""unset"":|;|+        return np.dtypes.StringDType(na_object=na_object, coerce=coerce)|;|+    else:|;|+        return np.dtypes.StringDType(coerce=coerce) || PR#28321 - requirements/test_requirements.txt: @@ -9,6 +9,7 @@ pytest-cov==4.1.0|;| meson|;| ninja; sys_platform != ""emscripten""|;| pytest-xdist|;|+pytest-timeout|;| # for numpy.random.test.test_extending|;| cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:","BUG: fix race initializing legacy dtype casts || CI: remove pytest-xdist from TSAN and ASAN CI python env || BUG: fix logic error in ensure_castingimpl_exists || BUG: fix data race setting up within dtype cats for legacy user dtypes || MAINT: spawn fewer threads to hopefully fix 32 bit runners || BUG: fix reference counting error || BUG: fix resource cleanup when thread spawning errors || MAINT: refactor run_threaded to use a try/finally block || MAINT: clean up slightly || MAINT: fix linter || MAINT: go back to try/except || MAINT: fix indentation and clarify comment || MAINT: use a try/finally to make the deadlock protection more robust || MAINT: respond to code review || BUG: fix race initializing legacy dtype casts || CI: remove pytest-xdist from TSAN and ASAN CI python env || BUG: fix logic error in ensure_castingimpl_exists || BUG: fix data race setting up within dtype cats for legacy user dtypes || MAINT: spawn fewer threads to hopefully fix 32 bit runners || BUG: fix reference counting error || BUG: fix resource cleanup when thread spawning errors || MAINT: refactor run_threaded to use a try/finally block || MAINT: clean up slightly || MAINT: fix linter || MAINT: go back to try/except || MAINT: fix indentation and clarify comment || MAINT: use a try/finally to make the deadlock protection more robust || MAINT: respond to code review || MAINT: Update some testing files from main

- Checkout numpy/testing/_private/utils.py
- Checkout numpy/_core/tests/test_multithreading.py
- Checkout conftest.py
- Update test_requirements.txt"
numpy/numpy,ngoldbaum,28269,BUG: Inconsistent conversion of object-type bytes array to StringDType,"### Describe the issue:

Converting an array of object dtype and bytes items, or a list of bytes, to variable-width strings results in a spurious `b'...'` tag.
This issue is absent in any other combination of input/output type where the input is bytes and the output is string.

### Reproduce the code example:

```python
>>> import numpy as np

>>> np.array([""foo"", ""bar""], dtype=""O"").astype(""U"")
array(['foo', 'bar'], dtype='<U3')

>>> np.array([""foo"", ""bar""], dtype=""O"").astype(""T"")
array(['foo', 'bar'], dtype=StringDType())

>>> np.array([b""foo"", b""bar""], dtype=""O"").astype(""U"")
array(['foo', 'bar'], dtype='<U3')

>>> np.array([b""foo"", b""bar""], dtype=""S"").astype(""T"")
array(['foo', 'bar'], dtype=StringDType())

>>> np.array([b""foo"", b""bar""], dtype=""T"")
array([""b'foo'"", ""b'bar'""], dtype=StringDType())

>>> np.array([b""foo"", b""bar""], dtype=""O"").astype(""T"")
array([""b'foo'"", ""b'bar'""], dtype=StringDType())
```

### Python and NumPy Versions:

numpy 2.2.2
",Thanks for the report! I can reproduce this. || See https://github.com/numpy/numpy/pull/28276,closed,2025-02-04T15:14:28+00:00,2025-02-05T16:54:42+00:00,crusaderky,00 - Bug,2,"PR#28282 - numpy/_core/src/multiarray/stringdtype/dtype.c: @@ -270,6 +270,15 @@ as_pystring(PyObject *scalar, int coerce)|;|                         ""string coercion is disabled."")|;|;         return NULL|;|;     }|;|+    else if (scalar_type == &PyBytes_Type) {|;|+        // assume UTF-8 encoding|;|+        char *buffer|;|;+        Py_ssize_t length|;|;+        if (PyBytes_AsStringAndSize(scalar, &buffer, &length) < 0) {|;|+            return NULL|;|;+        }|;|+        return PyUnicode_FromStringAndSize(buffer, length)|;|;+    }|;|     else {|;|         // attempt to coerce to str|;|         scalar = PyObject_Str(scalar); || PR#28282 - numpy/_core/tests/test_stringdtype.py: @@ -190,10 +190,14 @@ def test_array_creation_utf8(dtype, data):|;|     ],|;| )|;| def test_scalars_string_conversion(data, dtype):|;|+    try:|;|+        str_vals = [str(d.decode('utf-8')) for d in data]|;|+    except AttributeError:|;|+        str_vals = [str(d) for d in data]|;|     if dtype.coerce:|;|         assert_array_equal(|;|             np.array(data, dtype=dtype),|;|-            np.array([str(d) for d in data], dtype=dtype),|;|+            np.array(str_vals, dtype=dtype),|;|         )|;|     else:|;|         with pytest.raises(ValueError):|;|@@ -284,6 +288,14 @@ def test_bytes_casts(self, dtype, strings):|;|             barr = np.array(utf8_bytes, dtype=bytes_dtype)|;|             assert_array_equal(barr, sarr.astype(bytes_dtype))|;|             assert_array_equal(barr.astype(dtype), sarr)|;|+            if dtype.coerce:|;|+                barr = np.array(utf8_bytes, dtype=dtype)|;|+                assert_array_equal(barr, sarr)|;|+                barr = np.array(utf8_bytes, dtype=""O"")|;|+                assert_array_equal(barr.astype(dtype), sarr)|;|+            else:|;|+                with pytest.raises(ValueError):|;|+                    np.array(utf8_bytes, dtype=dtype)|;|         except UnicodeEncodeError:|;|             with pytest.raises(UnicodeEncodeError):|;|                 sarr.astype(""S20"") || PR#28276 - numpy/_core/src/multiarray/stringdtype/dtype.c: @@ -270,6 +270,15 @@ as_pystring(PyObject *scalar, int coerce)|;|                         ""string coercion is disabled."")|;|;         return NULL|;|;     }|;|+    else if (scalar_type == &PyBytes_Type) {|;|+        // assume UTF-8 encoding|;|+        char *buffer|;|;+        Py_ssize_t length|;|;+        if (PyBytes_AsStringAndSize(scalar, &buffer, &length) < 0) {|;|+            return NULL|;|;+        }|;|+        return PyUnicode_FromStringAndSize(buffer, length)|;|;+    }|;|     else {|;|         // attempt to coerce to str|;|         scalar = PyObject_Str(scalar); || PR#28276 - numpy/_core/tests/test_stringdtype.py: @@ -190,10 +190,14 @@ def test_array_creation_utf8(dtype, data):|;|     ],|;| )|;| def test_scalars_string_conversion(data, dtype):|;|+    try:|;|+        str_vals = [str(d.decode('utf-8')) for d in data]|;|+    except AttributeError:|;|+        str_vals = [str(d) for d in data]|;|     if dtype.coerce:|;|         assert_array_equal(|;|             np.array(data, dtype=dtype),|;|-            np.array([str(d) for d in data], dtype=dtype),|;|+            np.array(str_vals, dtype=dtype),|;|         )|;|     else:|;|         with pytest.raises(ValueError):|;|@@ -284,6 +288,14 @@ def test_bytes_casts(self, dtype, strings):|;|             barr = np.array(utf8_bytes, dtype=bytes_dtype)|;|             assert_array_equal(barr, sarr.astype(bytes_dtype))|;|             assert_array_equal(barr.astype(dtype), sarr)|;|+            if dtype.coerce:|;|+                barr = np.array(utf8_bytes, dtype=dtype)|;|+                assert_array_equal(barr, sarr)|;|+                barr = np.array(utf8_bytes, dtype=""O"")|;|+                assert_array_equal(barr.astype(dtype), sarr)|;|+            else:|;|+                with pytest.raises(ValueError):|;|+                    np.array(utf8_bytes, dtype=dtype)|;|         except UnicodeEncodeError:|;|             with pytest.raises(UnicodeEncodeError):|;|                 sarr.astype(""S20"")",BUG: fix incorrect bytes to stringdtype coercion || BUG: fix incorrect bytes to stringdtype coercion
numpy/numpy,ngoldbaum,28267,BUG: Heap use after free detected using python/numpy compiled with ASAN,"I'm playing around with adding a TSAN CI job and updating the ASAN CI job to use a Python compiled with ASAN.

The latter triggered up a new error I've never seen before:

```
numpy/_core/tests/test_umath.py::test_outer_bad_subclass PASSED
numpy/_core/tests/test_umath.py::test_outer_exceeds_maxdims PASSED
=================================================================
==22221==ERROR: AddressSanitizer: heap-use-after-free on address 0x6080095c7060 at pc 0x00010ac4ce10 bp 0x00016f3a5c90 sp 0x00016f3a5c88
READ of size 4 at 0x6080095c7060 thread T0
    #0 0x00010ac4ce0c in ufunc_at ufunc_object.c:5957
    #1 0x000101cb92dc in method_vectorcall_VARARGS descrobject.c:324
    #2 0x000101c9d2ac in PyObject_Vectorcall call.c:327
    #3 0x000101f75fd0 in _PyEval_EvalFrameDefault generated_cases.c.h:813
    #4 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #5 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #6 0x000101de21ec in slot_tp_call typeobject.c:9539
    #7 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #8 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #9 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #10 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #11 0x000101de21ec in slot_tp_call typeobject.c:9539
    #12 0x000101c9d584 in _PyObject_Call call.c:361
    #13 0x000101f7a010 in _PyEval_EvalFrameDefault generated_cases.c.h:1355
    #14 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #15 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #16 0x000101de21ec in slot_tp_call typeobject.c:9539
    #17 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #18 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #19 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #20 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #21 0x000101de21ec in slot_tp_call typeobject.c:9539
    #22 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #23 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #24 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #25 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #26 0x000101de21ec in slot_tp_call typeobject.c:9539
    #27 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #28 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #29 0x000101f6911c in PyEval_EvalCode ceval.c:602
    #30 0x000101f62590 in builtin_exec bltinmodule.c.h:556
    #31 0x000101d646b8 in cfunction_vectorcall_FASTCALL_KEYWORDS methodobject.c:441
    #32 0x000101c9d2ac in PyObject_Vectorcall call.c:327
    #33 0x000101f75fd0 in _PyEval_EvalFrameDefault generated_cases.c.h:813
    #34 0x0001020c4e6c in pymain_run_module main.c:349
    #35 0x0001020c3e60 in Py_RunMain main.c:776
    #36 0x0001020c4958 in pymain_main main.c:806
    #37 0x0001020c4c58 in Py_BytesMain main.c:830
    #38 0x00018b4cb150  (<unknown module>)
    #39 0xa64cfffffffffffc  (<unknown module>)

0x6080095c7060 is located 64 bytes inside of 96-byte region [0x6080095c7020,0x6080095c7080)
freed by thread T0 here:
    #0 0x00010296b35c in free+0x74 (libclang_rt.asan_osx_dynamic.dylib:arm64+0x5335c)
    #1 0x00010aacba34 in arraymapiter_dealloc mapping.c:3403
    #2 0x00010ac4cc9c in ufunc_at ufunc_object.c:5944
    #3 0x000101cb92dc in method_vectorcall_VARARGS descrobject.c:324
    #4 0x000101c9d2ac in PyObject_Vectorcall call.c:327
    #5 0x000101f75fd0 in _PyEval_EvalFrameDefault generated_cases.c.h:813
    #6 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #7 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #8 0x000101de21ec in slot_tp_call typeobject.c:9539
    #9 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #10 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #11 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #12 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #13 0x000101de21ec in slot_tp_call typeobject.c:9539
    #14 0x000101c9d584 in _PyObject_Call call.c:361
    #15 0x000101f7a010 in _PyEval_EvalFrameDefault generated_cases.c.h:1355
    #16 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #17 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #18 0x000101de21ec in slot_tp_call typeobject.c:9539
    #19 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #20 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #21 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #22 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #23 0x000101de21ec in slot_tp_call typeobject.c:9539
    #24 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #25 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #26 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #27 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #28 0x000101de21ec in slot_tp_call typeobject.c:9539
    #29 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242

previously allocated by thread T0 here:
    #0 0x00010296b270 in malloc+0x70 (libclang_rt.asan_osx_dynamic.dylib:arm64+0x53270)
    #1 0x000101dca970 in _PyType_AllocNoTrack typeobject.c:2043
    #2 0x000101dca754 in PyType_GenericAlloc typeobject.c:2072
    #3 0x00010aa34770 in PyArray_NewFromDescr_int ctors.c:723
    #4 0x00010aa361ec in PyArray_NewLikeArrayWithShape ctors.c:1096
    #5 0x00010aacb584 in PyArray_MapIterArrayCopyIfOverlap mapping.c:3326
    #6 0x00010ac4c738 in ufunc_at ufunc_object.c:5839
    #7 0x000101cb92dc in method_vectorcall_VARARGS descrobject.c:324
    #8 0x000101c9d2ac in PyObject_Vectorcall call.c:327
    #9 0x000101f75fd0 in _PyEval_EvalFrameDefault generated_cases.c.h:813
    #10 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #11 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #12 0x000101de21ec in slot_tp_call typeobject.c:9539
    #13 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #14 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #15 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #16 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #17 0x000101de21ec in slot_tp_call typeobject.c:9539
    #18 0x000101c9d584 in _PyObject_Call call.c:361
    #19 0x000101f7a010 in _PyEval_EvalFrameDefault generated_cases.c.h:1355
    #20 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #21 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #22 0x000101de21ec in slot_tp_call typeobject.c:9539
    #23 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #24 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502
    #25 0x000101c9bc84 in _PyObject_VectorcallDictTstate call.c:146
    #26 0x000101c9e1a8 in _PyObject_Call_Prepend call.c:504
    #27 0x000101de21ec in slot_tp_call typeobject.c:9539
    #28 0x000101c9c0e0 in _PyObject_MakeTpCall call.c:242
    #29 0x000101f7adfc in _PyEval_EvalFrameDefault generated_cases.c.h:1502

SUMMARY: AddressSanitizer: heap-use-after-free ufunc_object.c:5957 in ufunc_at
Shadow bytes around the buggy address:
  0x6080095c6d80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c6e00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c6e80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c6f00: fa fa fa fa fd fd fd fd fd fd fd fd fd fd fd fd
  0x6080095c6f80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
=>0x6080095c7000: fa fa fa fa fd fd fd fd fd fd fd fd[fd]fd fd fd
  0x6080095c7080: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c7100: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c7180: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c7200: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa
  0x6080095c7280: fa fa fa fa fd fd fd fd fd fd fd fd fd fd fd fa
Shadow byte legend (one shadow byte represents 8 application bytes):
  Addressable:           00
  Partially addressable: 01 02 03 04 05 06 07 
  Heap left redzone:       fa
  Freed heap region:       fd
  Stack left redzone:      f1
  Stack mid redzone:       f2
  Stack right redzone:     f3
  Stack after return:      f5
  Stack use after scope:   f8
  Global redzone:          f9
  Global init order:       f6
  Poisoned by user:        f7
  Container overflow:      fc
  Array cookie:            ac
  Intra object redzone:    bb
  ASan internal:           fe
  Left alloca redzone:     ca
  Right alloca redzone:    cb
==22221==ABORTING
Fatal Python error: Aborted

Current thread 0x00000001f36acf80 (most recent call first):
  File ""/Users/runner/work/numpy/numpy/build-install/usr/lib/python3.13/site-packages/numpy/_core/tests/test_umath.py"", line 4851 in test_bad_legacy_ufunc_silent_errors
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/python.py"", line 194 in pytest_pyfunc_call
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/python.py"", line 1788 in runtest
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 169 in pytest_runtest_call
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 262 in <lambda>
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 341 in from_call
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 261 in call_runtest_hook
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 222 in call_and_report
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 133 in runtestprotocol
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/runner.py"", line 114 in pytest_runtest_protocol
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/main.py"", line 349 in pytest_runtestloop
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/main.py"", line 324 in _main
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/main.py"", line 270 in wrap_session
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/main.py"", line 317 in pytest_cmdline_main
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/config/__init__.py"", line 166 in main
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/_pytest/config/__init__.py"", line 189 in console_main
  File ""/Users/runner/.pyenv/versions/3.13-dev/lib/python3.13/site-packages/pytest/__main__.py"", line 5 in <module>
  File ""<frozen runpy>"", line 88 in _run_code
  File ""<frozen runpy>"", line 198 in _run_module_as_main

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, numpy._core._multiarray_tests, numpy._core._rational_tests, numpy._core._umath_tests, cython.cimports.libc.math, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, numpy._core._struct_ufunc_tests, numpy._core._simd, numpy._core._operand_flag_tests, charset_normalizer.md, numpy.linalg.lapack_lite, mypy, mypy.defaults, mypy.errorcodes, mypy.util, mypy.options, mypy.visitor, mypy.strconv, mypy.nodes, mypy.state, mypy.type_visitor, mypy.typetraverser, mypy.typevartuples, mypy.expandtype, mypy.types, mypy.lookup, mypy.message_registry, mypy.copytype, mypy.maptype, mypy.erasetype, mypy.typevars, mypy.typeops, mypy.error_formatter, mypy.scope, mypy.errors, mypy.operators, mypy.applytype, mypy.argmap, mypy.types_utils, mypy.server, mypy.server.trigger, mypy.typestate, mypy.constraints, mypy.subtypes, mypy.messages, mypy.tvar_scope, mypy.plugin, mypy.join, mypy.meet, mypy.checkmember, mypy.parse, mypy.checkstrformat, mypy.graph_utils, mypy.solve, mypy.infer, mypy.literals, mypy.semanal_shared, mypy.semanal_enum, mypy.patterns, mypy.traverser, mypy.typeanal, mypy.checkexpr, mypy.binder, mypy.checkpattern, mypy.mro, mypy.plugins, mypy.fixup, mypy.plugins.common, mypy.plugins.dataclasses, mypy.constant_fold, mypy.reachability, mypy.sharedparse, mypy.fastparse, mypy.exprtotype, mypy.semanal_namedtuple, mypy.semanal_newtype, mypy.semanal_typeddict, mypy.semanal, mypy.treetransform, mypy.checker, mypy.semanal_classprop, mypy.semanal_infer, mypy.mixedtraverser, mypy.semanal_typeargs, mypy.server.aststrip, mypy.semanal_main, mypy.indirection, mypy.partially_defined, mypy.semanal_pass1, mypy.config_parser, mypy.freetree, mypy.fscache, mypy.metastore, mypy.stubinfo, mypy.modulefinder, mypy.plugins.default, mypy.renaming, mypy.stats, mypy.build, mypy.api, checks, limited_api2, mem_policy, _testbuffer (total: 113)
numpy/_core/tests/test_umath.py::test_bad_legacy_ufunc_silent_errors 
```","See [this CI run](https://github.com/ngoldbaum/numpy/actions/runs/13124507788/job/36617943865) on my numpy fork. || Line 3403 in `mapping.c` does `Py_XDECREF(mit->array)`. I guess that frees the array object and then a later call reads from the memory that was free'd.

Refcounting error maybe?

Ping @seberg, it looks like you wrote `test_bad_legacy_ufunc_silent_errors` a couple years ago and maybe have insight. || @ngoldbaum asan CI sounds great, interesting this never showed elsewhere (but maybe it got introduced at some point).
Anyway, the issue is not in the `mapping.c` that is perfect, but rather in the `ufunc.at` code cleanup being the wrong way around `op1_array` can be owned by the iterator. || > interesting this never showed elsewhere

I recently learned how to compile Python with TSAN and then use that Python to build NumPy with TSAN. When I did the same thing with ASAN I found this. The existing ASAN CI misses it because Python itself does the allocation. || Yeah, that is cool! I suppose `PYTHONMALLOC=debug` can't see this because the flags just happen to still be ""valid enough"" even with scrambling.  `valgrind` should I feel, but who knows maybe it even did or something changed since I last ran it (since I didn't run it in a long while, just annoyingly slow).",closed,2025-02-03T23:12:45+00:00,2025-02-05T15:18:12+00:00,ngoldbaum,,1,"PR#28273 - .github/workflows/compiler_sanitizers.yml: @@ -0,0 +1,123 @@|;|+name: Test with compiler sanitizers|;|+|;|+on:|;|+  push:|;|+    branches:|;|+      - main|;|+  pull_request:|;|+    branches:|;|+      - main|;|+      - maintenance/**|;|+|;|+defaults:|;|+  run:|;|+    shell: bash|;|+|;|+concurrency:|;|+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}|;|+  cancel-in-progress: true|;|+|;|+permissions:|;|+  contents: read # to fetch code (actions/checkout)|;|+|;|+jobs:|;|+  clang_ASAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with address sanitizer|;|+      run: ||;|+        CONFIGURE_OPTS=""--with-address-sanitizer"" pyenv install 3.13|;|+        pyenv global 3.13|;|+    - name: Install dependencies|;|+      run: ||;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=address|;|+    - name: Test|;|+      run: ||;|+        # pass -s to pytest to see ASAN errors and warnings, otherwise pytest captures them|;|+        ASAN_OPTIONS=detect_leaks=0:symbolize=1:strict_init_order=true:allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test -- -v -s --timeout=600 --durations=10|;|+|;|+  clang_TSAN:|;|+    # To enable this workflow on a fork, comment out:|;|+    if: github.repository == 'numpy/numpy'|;|+    runs-on: macos-latest|;|+    steps:|;|+    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+      with:|;|+        submodules: recursive|;|+        fetch-tags: true|;|+        persist-credentials: false|;|+    - name: Set up pyenv|;|+      run: ||;|+        git clone https://github.com/pyenv/pyenv.git ""$HOME/.pyenv""|;|+        PYENV_ROOT=""$HOME/.pyenv""|;|+        PYENV_BIN=""$PYENV_ROOT/bin""|;|+        PYENV_SHIMS=""$PYENV_ROOT/shims""|;|+        echo ""$PYENV_BIN"" >> $GITHUB_PATH|;|+        echo ""$PYENV_SHIMS"" >> $GITHUB_PATH|;|+        echo ""PYENV_ROOT=$PYENV_ROOT"" >> $GITHUB_ENV|;|+    - name: Check pyenv is working|;|+      run:|;|+        pyenv --version|;|+    - name: Set up LLVM|;|+      run: ||;|+        brew install llvm@19|;|+        LLVM_PREFIX=$(brew --prefix llvm@19)|;|+        echo CC=""$LLVM_PREFIX/bin/clang"" >> $GITHUB_ENV|;|+        echo CXX=""$LLVM_PREFIX/bin/clang++"" >> $GITHUB_ENV|;|+        echo LDFLAGS=""-L$LLVM_PREFIX/lib"" >> $GITHUB_ENV|;|+        echo CPPFLAGS=""-I$LLVM_PREFIX/include"" >> $GITHUB_ENV|;|+    - name: Build Python with thread sanitizer support|;|+      run: ||;|+        # free-threaded Python is much more likely to trigger races|;|+        CONFIGURE_OPTS=""--with-thread-sanitizer"" pyenv install 3.13t|;|+        pyenv global 3.13t|;|+    - name: Install dependencies|;|+      run: ||;|+        # TODO: remove when a released cython supports free-threaded python|;|+        pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython|;|+        pip install -r requirements/build_requirements.txt|;|+        pip install -r requirements/ci_requirements.txt|;|+        pip install -r requirements/test_requirements.txt|;|+    - name: Build|;|+      run:|;|+        python -m spin build -j2 -- -Db_sanitize=thread|;|+    - name: Test|;|+      run: ||;|+        # These tests are slow, so only run tests in files that do ""import threading"" to make them count|;|+        TSAN_OPTIONS=allocator_may_return_null=1:halt_on_error=1 \|;|+        python -m spin test \|;|+        `find numpy -name ""test*.py"" | xargs grep -l ""import threading"" | tr '\n' ' '` \|;|+        -- -v -s --timeout=600 --durations=10 || PR#28273 - .github/workflows/linux_compiler_sanitizers.yml: @@ -1,59 +0,0 @@|;|-name: Test with compiler sanitizers (Linux)|;|-|;|-on:|;|-  pull_request:|;|-    branches:|;|-      - main|;|-      - maintenance/**|;|-|;|-defaults:|;|-  run:|;|-    shell: bash|;|-|;|-env:|;|-  PYTHON_VERSION: 3.11|;|-|;|-concurrency:|;|-  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}|;|-  cancel-in-progress: true|;|-|;|-permissions:|;|-  contents: read # to fetch code (actions/checkout)|;|-|;|-jobs:|;|-  clang_sanitizers:|;|-    # To enable this workflow on a fork, comment out:|;|-    if: github.repository == 'numpy/numpy'|;|-    runs-on: ubuntu-latest|;|-    steps:|;|-    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|-      with:|;|-        submodules: recursive|;|-        fetch-tags: true|;|-        persist-credentials: false|;|-    - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|-      with:|;|-        python-version: ${{ env.PYTHON_VERSION }}|;|-    - name: Install dependencies|;|-      run: ||;|-        sudo apt update|;|-        sudo apt install -y llvm libstdc++-12-dev|;|-        pip install -r requirements/build_requirements.txt|;|-        pip install -r requirements/ci_requirements.txt|;|-    - name: Build|;|-      shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|-      env:|;|-        TERM: xterm-256color|;|-        PKG_CONFIG_PATH: ${{ github.workspace }}/.openblas|;|-      run:|;|-        CC=clang CXX=clang++ spin build --with-scipy-openblas=32 -- -Db_sanitize=address,undefined|;|-    - name: Test|;|-      shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|-      env:|;|-        TERM: xterm-256color|;|-      run: ||;|-        pip install pytest pytest-xdist hypothesis typing_extensions pytest-timeout|;|-        ASAN_OPTIONS=detect_leaks=0:symbolize=1:strict_init_order=true:allocator_may_return_null=1:halt_on_error=1 \|;|-        UBSAN_OPTIONS=halt_on_error=0 \|;|-        LD_PRELOAD=$(clang --print-file-name=libclang_rt.asan-x86_64.so) \|;|-        python -m spin test -- -v -s --timeout=600 --durations=10 || PR#28273 - numpy/_core/src/umath/ufunc_object.c: @@ -5941,7 +5941,6 @@ ufunc_at(PyUFuncObject *ufunc, PyObject *args)|;|     NPY_AUXDATA_FREE(auxdata)|;|; |;|     Py_XDECREF(op2_array)|;|;-    Py_XDECREF(iter)|;|;     Py_XDECREF(iter2)|;|;     for (int i = 0; i < nop; i++) {|;|         Py_XDECREF(operation_descrs[i])|;|;@@ -5957,9 +5956,13 @@ ufunc_at(PyUFuncObject *ufunc, PyObject *args)|;|         if (PyArray_FLAGS(op1_array) & NPY_ARRAY_WRITEBACKIFCOPY) {|;|             PyArray_DiscardWritebackIfCopy(op1_array)|;|;         }|;|+        // iter might own the last refrence to op1_array,|;|+        // so it must be decref'd second|;|+        Py_XDECREF(iter)|;|;         return NULL|;|;     }|;|     else {|;|+        Py_XDECREF(iter)|;|;         Py_RETURN_NONE|;|;     }|;| } || PR#28273 - numpy/_core/tests/test_indexing.py: @@ -590,32 +590,6 @@ def test_too_many_advanced_indices(self, index, num, original_ndim):|;|         with pytest.raises(IndexError):|;|             arr[(index,) * num] = 1.|;| |;|-    @pytest.mark.skipif(IS_WASM, reason=""no threading"")|;|-    def test_structured_advanced_indexing(self):|;|-        # Test that copyswap(n) used by integer array indexing is threadsafe|;|-        # for structured datatypes, see gh-15387. This test can behave randomly.|;|-        from concurrent.futures import ThreadPoolExecutor|;|-|;|-        # Create a deeply nested dtype to make a failure more likely:|;|-        dt = np.dtype([("""", ""f8"")])|;|-        dt = np.dtype([("""", dt)] * 2)|;|-        dt = np.dtype([("""", dt)] * 2)|;|-        # The array should be large enough to likely run into threading issues|;|-        arr = np.random.uniform(size=(6000, 8)).view(dt)[:, 0]|;|-|;|-        rng = np.random.default_rng()|;|-|;|-        def func(arr):|;|-            indx = rng.integers(0, len(arr), size=6000, dtype=np.intp)|;|-            arr[indx]|;|-|;|-        tpe = ThreadPoolExecutor(max_workers=8)|;|-        futures = [tpe.submit(func, arr) for _ in range(10)]|;|-        for f in futures:|;|-            f.result()|;|-|;|-        assert arr.dtype is dt|;|-|;|     def test_nontuple_ndindex(self):|;|         a = np.arange(25).reshape((5, 5))|;|         assert_equal(a[[0, 1]], np.array([a[0], a[1]])) || PR#28273 - numpy/_core/tests/test_multithreading.py: @@ -1,4 +1,6 @@|;|+import concurrent.futures|;| import threading|;|+import string|;| |;| import numpy as np|;| import pytest|;|@@ -165,3 +167,90 @@ def closure(b):|;|             x = np.repeat(x0, 2, axis=0)[::2]|;| |;|     run_threaded(closure, max_workers=10, pass_barrier=True)|;|+|;|+|;|+def test_structured_advanced_indexing():|;|+    # Test that copyswap(n) used by integer array indexing is threadsafe|;|+    # for structured datatypes, see gh-15387. This test can behave randomly.|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(6000, 8)).view(dt)[:, 0]|;|+|;|+    rng = np.random.default_rng()|;|+|;|+    def func(arr):|;|+        indx = rng.integers(0, len(arr), size=6000, dtype=np.intp)|;|+        arr[indx]|;|+|;|+    tpe = concurrent.futures.ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_structured_threadsafety2():|;|+    # Nonzero (and some other functions) should be threadsafe for|;|+    # structured datatypes, see gh-15387. This test can behave randomly.|;|+    from concurrent.futures import ThreadPoolExecutor|;|+|;|+    # Create a deeply nested dtype to make a failure more likely:|;|+    dt = np.dtype([("""", ""f8"")])|;|+    dt = np.dtype([("""", dt)])|;|+    dt = np.dtype([("""", dt)] * 2)|;|+    # The array should be large enough to likely run into threading issues|;|+    arr = np.random.uniform(size=(5000, 4)).view(dt)[:, 0]|;|+|;|+    def func(arr):|;|+        arr.nonzero()|;|+|;|+    tpe = ThreadPoolExecutor(max_workers=8)|;|+    futures = [tpe.submit(func, arr) for _ in range(10)]|;|+    for f in futures:|;|+        f.result()|;|+|;|+    assert arr.dtype is dt|;|+|;|+|;|+def test_stringdtype_multithreaded_access_and_mutation(|;|+        dtype, random_string_list):|;|+    # this test uses an RNG and may crash or cause deadlocks if there is a|;|+    # threading bug|;|+    rng = np.random.default_rng(0x4D3D3D3)|;|+|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = rng.choice(chars, size=100 * 10, replace=True)|;|+    random_string_list = ret.view(""U100"")|;|+|;|+    def func(arr):|;|+        rnd = rng.random()|;|+        # either write to random locations in the array, compute a ufunc, or|;|+        # re-initialize the array|;|+        if rnd < 0.25:|;|+            num = np.random.randint(0, arr.size)|;|+            arr[num] = arr[num] + ""hello""|;|+        elif rnd < 0.5:|;|+            if rnd < 0.375:|;|+                np.add(arr, arr)|;|+            else:|;|+                np.add(arr, arr, out=arr)|;|+        elif rnd < 0.75:|;|+            if rnd < 0.875:|;|+                np.multiply(arr, np.int64(2))|;|+            else:|;|+                np.multiply(arr, np.int64(2), out=arr)|;|+        else:|;|+            arr[:] = random_string_list|;|+|;|+    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as tpe:|;|+        arr = np.array(random_string_list, dtype=dtype)|;|+        futures = [tpe.submit(func, arr) for _ in range(500)]|;|+|;|+        for f in futures:|;|+            f.result() || PR#28273 - numpy/_core/tests/test_nep50_promotions.py: @@ -5,8 +5,6 @@|;| """"""|;| |;| import operator|;|-import threading|;|-import warnings|;| |;| import numpy as np|;|  || PR#28273 - numpy/_core/tests/test_numeric.py: @@ -1956,29 +1956,6 @@ def __bool__(self):|;|         a = np.array([[ThrowsAfter(15)]] * 10)|;|         assert_raises(ValueError, np.nonzero, a)|;| |;|-    @pytest.mark.skipif(IS_WASM, reason=""wasm doesn't have threads"")|;|-    def test_structured_threadsafety(self):|;|-        # Nonzero (and some other functions) should be threadsafe for|;|-        # structured datatypes, see gh-15387. This test can behave randomly.|;|-        from concurrent.futures import ThreadPoolExecutor|;|-|;|-        # Create a deeply nested dtype to make a failure more likely:|;|-        dt = np.dtype([("""", ""f8"")])|;|-        dt = np.dtype([("""", dt)])|;|-        dt = np.dtype([("""", dt)] * 2)|;|-        # The array should be large enough to likely run into threading issues|;|-        arr = np.random.uniform(size=(5000, 4)).view(dt)[:, 0]|;|-|;|-        def func(arr):|;|-            arr.nonzero()|;|-|;|-        tpe = ThreadPoolExecutor(max_workers=8)|;|-        futures = [tpe.submit(func, arr) for _ in range(10)]|;|-        for f in futures:|;|-            f.result()|;|-|;|-        assert arr.dtype is dt|;|-|;| |;| class TestIndex:|;|     def test_boolean(self): || PR#28273 - numpy/_core/tests/test_stringdtype.py: @@ -1,4 +1,3 @@|;|-import concurrent.futures|;| import itertools|;| import os|;| import pickle|;|@@ -11,48 +10,15 @@|;| |;| from numpy.dtypes import StringDType|;| from numpy._core.tests._natype import pd_NA|;|-from numpy.testing import assert_array_equal, IS_WASM, IS_PYPY|;|+from numpy.testing import assert_array_equal, IS_PYPY|;|+from numpy.testing._private.utils import get_stringdtype_dtype as get_dtype|;| |;| |;| @pytest.fixture|;| def string_list():|;|     return [""abc"", ""def"", ""ghi"" * 10, ""A¢☃€ 😊"" * 100, ""Abc"" * 1000, ""DEF""]|;| |;| |;|-@pytest.fixture|;|-def random_string_list():|;|-    chars = list(string.ascii_letters + string.digits)|;|-    chars = np.array(chars, dtype=""U1"")|;|-    ret = np.random.choice(chars, size=100 * 10, replace=True)|;|-    return ret.view(""U100"")|;|-|;|-|;|-@pytest.fixture(params=[True, False])|;|-def coerce(request):|;|-    return request.param|;|-|;|-|;|-@pytest.fixture(|;|-    params=[""unset"", None, pd_NA, np.nan, float(""nan""), ""__nan__""],|;|-    ids=[""unset"", ""None"", ""pandas.NA"", ""np.nan"", ""float('nan')"", ""string nan""],|;|-)|;|-def na_object(request):|;|-    return request.param|;|-|;|-|;|-def get_dtype(na_object, coerce=True):|;|-    # explicit is check for pd_NA because != with pd_NA returns pd_NA|;|-    if na_object is pd_NA or na_object != ""unset"":|;|-        return StringDType(na_object=na_object, coerce=coerce)|;|-    else:|;|-        return StringDType(coerce=coerce)|;|-|;|-|;|-@pytest.fixture()|;|-def dtype(na_object, coerce):|;|-    return get_dtype(na_object, coerce)|;|-|;|-|;| # second copy for cast tests to do a cartesian product over dtypes|;| @pytest.fixture(params=[True, False])|;| def coerce2(request):|;|@@ -1208,40 +1174,6 @@ def test_growing_strings(dtype):|;|     assert_array_equal(arr, uarr)|;| |;| |;|-@pytest.mark.skipif(IS_WASM, reason=""no threading support in wasm"")|;|-def test_threaded_access_and_mutation(dtype, random_string_list):|;|-    # this test uses an RNG and may crash or cause deadlocks if there is a|;|-    # threading bug|;|-    rng = np.random.default_rng(0x4D3D3D3)|;|-|;|-    def func(arr):|;|-        rnd = rng.random()|;|-        # either write to random locations in the array, compute a ufunc, or|;|-        # re-initialize the array|;|-        if rnd < 0.25:|;|-            num = np.random.randint(0, arr.size)|;|-            arr[num] = arr[num] + ""hello""|;|-        elif rnd < 0.5:|;|-            if rnd < 0.375:|;|-                np.add(arr, arr)|;|-            else:|;|-                np.add(arr, arr, out=arr)|;|-        elif rnd < 0.75:|;|-            if rnd < 0.875:|;|-                np.multiply(arr, np.int64(2))|;|-            else:|;|-                np.multiply(arr, np.int64(2), out=arr)|;|-        else:|;|-            arr[:] = random_string_list|;|-|;|-    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as tpe:|;|-        arr = np.array(random_string_list, dtype=dtype)|;|-        futures = [tpe.submit(func, arr) for _ in range(500)]|;|-|;|-        for f in futures:|;|-            f.result()|;|-|;|-|;| UFUNC_TEST_DATA = [|;|     ""hello"" * 10,|;|     ""Ae¢☃€ 😊"" * 20, || PR#28273 - numpy/conftest.py: @@ -2,6 +2,7 @@|;| Pytest configuration and fixtures for the Numpy test suite.|;| """"""|;| import os|;|+import string|;| import sys|;| import tempfile|;| from contextlib import contextmanager|;|@@ -10,9 +11,11 @@|;| import hypothesis|;| import pytest|;| import numpy|;|+import numpy as np|;| |;| from numpy._core._multiarray_tests import get_fpu_mode|;|-from numpy.testing._private.utils import NOGIL_BUILD|;|+from numpy._core.tests._natype import pd_NA|;|+from numpy.testing._private.utils import NOGIL_BUILD, get_stringdtype_dtype|;| |;| try:|;|     from scipy_doctest.conftest import dt_config|;|@@ -231,3 +234,28 @@ def warnings_errors_and_rng(test=None):|;|         'numpy/f2py/_backends/_distutils.py',|;|     ]|;| |;|+|;|+@pytest.fixture|;|+def random_string_list():|;|+    chars = list(string.ascii_letters + string.digits)|;|+    chars = np.array(chars, dtype=""U1"")|;|+    ret = np.random.choice(chars, size=100 * 10, replace=True)|;|+    return ret.view(""U100"")|;|+|;|+|;|+@pytest.fixture(params=[True, False])|;|+def coerce(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture(|;|+    params=[""unset"", None, pd_NA, np.nan, float(""nan""), ""__nan__""],|;|+    ids=[""unset"", ""None"", ""pandas.NA"", ""np.nan"", ""float('nan')"", ""string nan""],|;|+)|;|+def na_object(request):|;|+    return request.param|;|+|;|+|;|+@pytest.fixture()|;|+def dtype(na_object, coerce):|;|+    return get_stringdtype_dtype(na_object, coerce) || PR#28273 - numpy/testing/_private/utils.py: @@ -25,7 +25,7 @@|;|      intp, float32, empty, arange, array_repr, ndarray, isnat, array)|;| from numpy import isfinite, isnan, isinf|;| import numpy.linalg._umath_linalg|;|-from numpy._utils import _rename_parameter|;|+from numpy._core.tests._natype import pd_NA|;| |;| from io import StringIO|;| |;|@@ -2706,3 +2706,11 @@ def run_threaded(func, max_workers=8, pass_count=False,|;|                 futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|             for f in futures:|;|                 f.result()|;|+|;|+|;|+def get_stringdtype_dtype(na_object, coerce=True):|;|+    # explicit is check for pd_NA because != with pd_NA returns pd_NA|;|+    if na_object is pd_NA or na_object != ""unset"":|;|+        return np.dtypes.StringDType(na_object=na_object, coerce=coerce)|;|+    else:|;|+        return np.dtypes.StringDType(coerce=coerce)",CI: update sanitizer CI to use python compiled with ASAN and TSAN || BUG: fix resource cleanup order in ufunc.at impl || CI: only run tests that might use threads for TSAN run
numpy/numpy,jorenham,28256,TYP: `timedelta64.__divmod__` incorrect inference,"### Describe the issue:

Using `divmod` widens generic type of timedelta64. The last overload should probably use `Self` instead of `timedelta64`, or possible add an overload for the timedelta case.

https://github.com/numpy/numpy/blob/6bc905859780c44193942ea2d0d297abcd691330/numpy/__init__.pyi#L4472-L4477


### Reproduce the code example:

```python
from datetime import timedelta as TD
from typing import assert_type

import numpy as np

td = np.timedelta64(1, ""D"")
assert_type(td, np.timedelta64[TD])  # ✅

n, remainder = divmod(td, td)
assert_type(remainder, np.timedelta64[TD])  # ❌ timedelta64[timedelta | int | None]
```

### Python and NumPy Versions:

2.2.2
3.13.1 (main, Dec  4 2024, 08:54:14) [GCC 11.4.0]

### Type-checker version and settings:

mypy 1.4.1
pyright 1.1.393","Thanks for reporting this. There indeed seem to be some overloads missing, because it should be dual to `__mod__`, which already has those missing overloads that you suggested",closed,2025-01-31T17:44:53+00:00,2025-02-01T19:40:53+00:00,randolf-scholz,41 - Static typing,2,"PR#28266 - numpy/__init__.pyi: @@ -4414,10 +4414,12 @@ class timedelta64(_IntegralMixin, generic[_TD64ItemT_co], Generic[_TD64ItemT_co]|;|     @overload|;|     def __init__(self: timedelta64[None], value: _NaTValue | None, format: _TimeUnitSpec, /) -> None: ...|;|     @overload|;|-    def __init__(self: timedelta64[int], value: dt.timedelta, format: _TimeUnitSpec[_IntTimeUnit], /) -> None: ...|;|+    def __init__(self: timedelta64[L[0]], value: L[0], format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|     @overload|;|     def __init__(self: timedelta64[int], value: _IntLike_co, format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|     @overload|;|+    def __init__(self: timedelta64[int], value: dt.timedelta, format: _TimeUnitSpec[_IntTimeUnit], /) -> None: ...|;|+    @overload|;|     def __init__(|;|         self: timedelta64[dt.timedelta],|;|         value: dt.timedelta | _IntLike_co,|;|@@ -4458,29 +4460,68 @@ class timedelta64(_IntegralMixin, generic[_TD64ItemT_co], Generic[_TD64ItemT_co]|;|     def __mul__(self, x: float | np.floating[Any] | np.integer[Any] | np.bool, /) -> timedelta64: ...|;|     __rmul__ = __mul__|;| |;|+    @overload|;|+    def __mod__(self, x: timedelta64[None | L[0]], /) -> timedelta64[None]: ...|;|     @overload|;|     def __mod__(self: timedelta64[None], x: timedelta64, /) -> timedelta64[None]: ...|;|     @overload|;|+    def __mod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __mod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item | None]: ...|;|+    @overload|;|     def __mod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> dt.timedelta: ...|;|     @overload|;|-    def __mod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item]: ...|;|+    def __mod__(self, x: timedelta64[int], /) -> timedelta64[int | None]: ...|;|     @overload|;|-    def __mod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int]: ...|;|+    def __mod__(self, x: timedelta64, /) -> timedelta64: ...|;|+|;|+    # the L[0] makes __mod__ non-commutative, which the first two overloads reflect|;|     @overload|;|-    def __mod__(self, x: timedelta64[None], /) -> timedelta64[None]: ...|;|+    def __rmod__(self, x: timedelta64[None], /) -> timedelta64[None]: ...|;|     @overload|;|-    def __mod__(self, x: timedelta64[int], /) -> timedelta64[int]: ...|;|+    def __rmod__(self: timedelta64[None | L[0]], x: timedelta64, /) -> timedelta64[None]: ...|;|     @overload|;|-    def __mod__(self, x: timedelta64, /) -> timedelta64: ...|;|-    __rmod__ = __mod__  # at runtime the outcomes differ, but the type signatures are the same|;|+    def __rmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __rmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item | None]: ...|;|+    @overload|;|+    def __rmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> dt.timedelta: ...|;|+    @overload|;|+    def __rmod__(self, x: timedelta64[int], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __rmod__(self, x: timedelta64, /) -> timedelta64: ...|;| |;|+    # keep in sync with __mod__|;|+    @overload|;|+    def __divmod__(self, x: timedelta64[None | L[0]], /) -> tuple[int64, timedelta64[None]]: ...|;|     @overload|;|     def __divmod__(self: timedelta64[None], x: timedelta64, /) -> tuple[int64, timedelta64[None]]: ...|;|     @overload|;|+    def __divmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __divmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> tuple[int64, timedelta64[_AnyTD64Item | None]]: ...|;|+    @overload|;|     def __divmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> tuple[int, dt.timedelta]: ...|;|     @overload|;|+    def __divmod__(self, x: timedelta64[int], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|     def __divmod__(self, x: timedelta64, /) -> tuple[int64, timedelta64]: ...|;|-    __rdivmod__ = __divmod__|;|+|;|+    # keep in sync with __rmod__|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64[None], /) -> tuple[int64, timedelta64[None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[None | L[0]], x: timedelta64, /) -> tuple[int64, timedelta64[None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> tuple[int64, timedelta64[_AnyTD64Item | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> tuple[int, dt.timedelta]: ...|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64[int], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64, /) -> tuple[int64, timedelta64]: ...|;| |;|     @overload|;|     def __sub__(self: timedelta64[None], b: _TD64Like_co, /) -> timedelta64[None]: ... || PR#28266 - numpy/typing/tests/data/reveal/mod.pyi: @@ -1,39 +1,71 @@|;| import datetime as dt|;|-from typing import Any|;|+from typing import Literal as L|;|+|;|+from typing_extensions import assert_type|;| |;| import numpy as np|;| import numpy.typing as npt|;|-from numpy._typing import _32Bit, _64Bit|;|+from numpy._typing import _64Bit|;| |;|-from typing_extensions import assert_type|;|+f8: np.float64|;|+i8: np.int64|;|+u8: np.uint64|;| |;|-f8 = np.float64()|;|-i8 = np.int64()|;|-u8 = np.uint64()|;|+f4: np.float32|;|+i4: np.int32|;|+u4: np.uint32|;| |;|-f4 = np.float32()|;|-i4 = np.int32()|;|-u4 = np.uint32()|;|+m: np.timedelta64|;|+m_nat: np.timedelta64[None]|;|+m_int0: np.timedelta64[L[0]]|;|+m_int: np.timedelta64[int]|;|+m_td: np.timedelta64[dt.timedelta]|;| |;|-td = np.timedelta64(0, ""D"")|;|-b_ = np.bool()|;|+b_: np.bool|;| |;|-b = bool()|;|-f = float()|;|-i = int()|;|+b: bool|;|+i: int|;|+f: float|;| |;| AR_b: npt.NDArray[np.bool]|;| AR_m: npt.NDArray[np.timedelta64]|;| |;| # Time structures|;| |;|-assert_type(td % td, np.timedelta64[dt.timedelta])|;|-assert_type(AR_m % td, npt.NDArray[np.timedelta64])|;|-assert_type(td % AR_m, npt.NDArray[np.timedelta64])|;|-|;|-assert_type(divmod(td, td), tuple[np.int64, np.timedelta64])|;|-assert_type(divmod(AR_m, td), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|-assert_type(divmod(td, AR_m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|+assert_type(m % m, np.timedelta64)|;|+assert_type(m % m_nat, np.timedelta64[None])|;|+assert_type(m % m_int0, np.timedelta64[None])|;|+assert_type(m % m_int, np.timedelta64[int | None])|;|+assert_type(m_nat % m, np.timedelta64[None])|;|+assert_type(m_int % m_nat, np.timedelta64[None])|;|+assert_type(m_int % m_int0, np.timedelta64[None])|;|+assert_type(m_int % m_int, np.timedelta64[int | None])|;|+assert_type(m_int % m_td, np.timedelta64[int | None])|;|+assert_type(m_td % m_nat, np.timedelta64[None])|;|+assert_type(m_td % m_int0, np.timedelta64[None])|;|+assert_type(m_td % m_int, np.timedelta64[int | None])|;|+assert_type(m_td % m_td, np.timedelta64[dt.timedelta | None])|;|+|;|+assert_type(AR_m % m, npt.NDArray[np.timedelta64])|;|+assert_type(m % AR_m, npt.NDArray[np.timedelta64])|;|+|;|+assert_type(divmod(m, m), tuple[np.int64, np.timedelta64])|;|+assert_type(divmod(m, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(m.__divmod__(m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_nat, m), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_int, m_td), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_td, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_td, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_td, m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_td, m_td), tuple[np.int64, np.timedelta64[dt.timedelta | None]])|;|+|;|+assert_type(divmod(AR_m, m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|+assert_type(divmod(m, AR_m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;| |;| # Bool|;| |;|@@ -47,11 +79,12 @@ assert_type(b_ % f8, np.float64)|;| assert_type(b_ % AR_b, npt.NDArray[np.int8])|;| |;| assert_type(divmod(b_, b), tuple[np.int8, np.int8])|;|-assert_type(divmod(b_, i), tuple[np.int_, np.int_])|;|-assert_type(divmod(b_, f), tuple[np.float64, np.float64])|;| assert_type(divmod(b_, b_), tuple[np.int8, np.int8])|;|-assert_type(divmod(b_, i8), tuple[np.int64, np.int64])|;|-assert_type(divmod(b_, u8), tuple[np.uint64, np.uint64])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(b_.__divmod__(i), tuple[np.int_, np.int_])|;|+assert_type(b_.__divmod__(f), tuple[np.float64, np.float64])|;|+assert_type(b_.__divmod__(i8), tuple[np.int64, np.int64])|;|+assert_type(b_.__divmod__(u8), tuple[np.uint64, np.uint64])|;| assert_type(divmod(b_, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(b_, AR_b), tuple[npt.NDArray[np.int8], npt.NDArray[np.int8]])|;| |;|@@ -77,26 +110,27 @@ assert_type(divmod(AR_b, b_), tuple[npt.NDArray[np.int8], npt.NDArray[np.int8]])|;| |;| assert_type(i8 % b, np.int64)|;| assert_type(i8 % i8, np.int64)|;|-assert_type(i8 % f, np.floating[_64Bit])|;|-assert_type(i8 % f8, np.floating[_64Bit])|;|+assert_type(i8 % f, np.float64 | np.floating[_64Bit])|;|+assert_type(i8 % f8, np.float64 | np.floating[_64Bit])|;| assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;| assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;|-assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|-assert_type(divmod(i8, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(i8, f8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|-assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]] | tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|+assert_type(divmod(i8, b), tuple[np.int64, np.int64])|;|+assert_type(divmod(i8, i4), tuple[np.int64, np.int64] | tuple[np.int32, np.int32])|;|+assert_type(divmod(i8, i8), tuple[np.int64, np.int64])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(i8.__divmod__(f), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;|+assert_type(i8.__divmod__(f8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;|+assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float32, np.float32])|;|+assert_type(divmod(i4, i4), tuple[np.int32, np.int32])|;|+assert_type(divmod(i4, f4), tuple[np.float32, np.float32])|;| assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;|-assert_type(b % i8, np.signedinteger[_64Bit])|;|-assert_type(f % i8, np.floating[_64Bit])|;|+assert_type(b % i8, np.int64)|;|+assert_type(f % i8, np.float64 | np.floating[_64Bit])|;| assert_type(i8 % i8, np.int64)|;| assert_type(f8 % i8, np.float64)|;| assert_type(i8 % i4, np.int64 | np.int32)|;|@@ -105,21 +139,22 @@ assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;| assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;|-assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|+assert_type(divmod(b, i8), tuple[np.int64, np.int64])|;|+assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;| assert_type(divmod(i8, i8), tuple[np.int64, np.int64])|;| assert_type(divmod(f8, i8), tuple[np.float64, np.float64])|;|-assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]] | tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;|+assert_type(divmod(i4, i8), tuple[np.int64, np.int64] | tuple[np.int32, np.int32])|;|+assert_type(divmod(i4, i4), tuple[np.int32, np.int32])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(f4.__divmod__(i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float32, np.float32])|;|+assert_type(f4.__divmod__(i4), tuple[np.float32, np.float32])|;|+assert_type(AR_b.__divmod__(i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;|-assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;|+assert_type(i8 % f4, np.floating[_64Bit] | np.float32)|;| assert_type(f4 % f4, np.float32)|;| assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;|@@ -131,15 +166,16 @@ assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;| assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;|-assert_type(f % f8, np.float64)|;|+assert_type(f % f8, np.float64)  # pyright: ignore[reportAssertTypeFailure]  # pyright incorrectly infers `builtins.float`|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;| assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;|-assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;|-assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(f8.__rdivmod__(f), tuple[np.float64, np.float64])|;|+assert_type(f8.__rdivmod__(f4), tuple[np.float64, np.float64])|;|+assert_type(AR_b.__divmod__(f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28259 - numpy/__init__.pyi: @@ -4409,10 +4409,12 @@ class timedelta64(_IntegralMixin, generic[_TD64ItemT_co], Generic[_TD64ItemT_co]|;|     @overload|;|     def __init__(self: timedelta64[None], value: _NaTValue | None, format: _TimeUnitSpec, /) -> None: ...|;|     @overload|;|-    def __init__(self: timedelta64[int], value: dt.timedelta, format: _TimeUnitSpec[_IntTimeUnit], /) -> None: ...|;|+    def __init__(self: timedelta64[L[0]], value: L[0], format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|     @overload|;|     def __init__(self: timedelta64[int], value: _IntLike_co, format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|     @overload|;|+    def __init__(self: timedelta64[int], value: dt.timedelta, format: _TimeUnitSpec[_IntTimeUnit], /) -> None: ...|;|+    @overload|;|     def __init__(|;|         self: timedelta64[dt.timedelta],|;|         value: dt.timedelta | _IntLike_co,|;|@@ -4453,29 +4455,68 @@ class timedelta64(_IntegralMixin, generic[_TD64ItemT_co], Generic[_TD64ItemT_co]|;|     def __mul__(self, x: float | np.floating[Any] | np.integer[Any] | np.bool, /) -> timedelta64: ...|;|     __rmul__ = __mul__|;| |;|+    @overload|;|+    def __mod__(self, x: timedelta64[None | L[0]], /) -> timedelta64[None]: ...|;|     @overload|;|     def __mod__(self: timedelta64[None], x: timedelta64, /) -> timedelta64[None]: ...|;|     @overload|;|+    def __mod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __mod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item | None]: ...|;|+    @overload|;|     def __mod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> dt.timedelta: ...|;|     @overload|;|-    def __mod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item]: ...|;|+    def __mod__(self, x: timedelta64[int], /) -> timedelta64[int | None]: ...|;|     @overload|;|-    def __mod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int]: ...|;|+    def __mod__(self, x: timedelta64, /) -> timedelta64: ...|;|+|;|+    # the L[0] makes __mod__ non-commutative, which the first two overloads reflect|;|     @overload|;|-    def __mod__(self, x: timedelta64[None], /) -> timedelta64[None]: ...|;|+    def __rmod__(self, x: timedelta64[None], /) -> timedelta64[None]: ...|;|     @overload|;|-    def __mod__(self, x: timedelta64[int], /) -> timedelta64[int]: ...|;|+    def __rmod__(self: timedelta64[None | L[0]], x: timedelta64, /) -> timedelta64[None]: ...|;|     @overload|;|-    def __mod__(self, x: timedelta64, /) -> timedelta64: ...|;|-    __rmod__ = __mod__  # at runtime the outcomes differ, but the type signatures are the same|;|+    def __rmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __rmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> timedelta64[_AnyTD64Item | None]: ...|;|+    @overload|;|+    def __rmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> dt.timedelta: ...|;|+    @overload|;|+    def __rmod__(self, x: timedelta64[int], /) -> timedelta64[int | None]: ...|;|+    @overload|;|+    def __rmod__(self, x: timedelta64, /) -> timedelta64: ...|;| |;|+    # keep in sync with __mod__|;|+    @overload|;|+    def __divmod__(self, x: timedelta64[None | L[0]], /) -> tuple[int64, timedelta64[None]]: ...|;|     @overload|;|     def __divmod__(self: timedelta64[None], x: timedelta64, /) -> tuple[int64, timedelta64[None]]: ...|;|     @overload|;|+    def __divmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __divmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> tuple[int64, timedelta64[_AnyTD64Item | None]]: ...|;|+    @overload|;|     def __divmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> tuple[int, dt.timedelta]: ...|;|     @overload|;|+    def __divmod__(self, x: timedelta64[int], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|     def __divmod__(self, x: timedelta64, /) -> tuple[int64, timedelta64]: ...|;|-    __rdivmod__ = __divmod__|;|+|;|+    # keep in sync with __rmod__|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64[None], /) -> tuple[int64, timedelta64[None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[None | L[0]], x: timedelta64, /) -> tuple[int64, timedelta64[None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[int], x: timedelta64[int | dt.timedelta], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[dt.timedelta], x: timedelta64[_AnyTD64Item], /) -> tuple[int64, timedelta64[_AnyTD64Item | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self: timedelta64[dt.timedelta], x: dt.timedelta, /) -> tuple[int, dt.timedelta]: ...|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64[int], /) -> tuple[int64, timedelta64[int | None]]: ...|;|+    @overload|;|+    def __rdivmod__(self, x: timedelta64, /) -> tuple[int64, timedelta64]: ...|;| |;|     @overload|;|     def __sub__(self: timedelta64[None], b: _TD64Like_co, /) -> timedelta64[None]: ... || PR#28259 - numpy/typing/tests/data/reveal/mod.pyi: @@ -1,39 +1,71 @@|;| import datetime as dt|;|-from typing import Any|;|+from typing import Literal as L|;|+|;|+from typing_extensions import assert_type|;| |;| import numpy as np|;| import numpy.typing as npt|;|-from numpy._typing import _32Bit, _64Bit|;|+from numpy._typing import _64Bit|;| |;|-from typing_extensions import assert_type|;|+f8: np.float64|;|+i8: np.int64|;|+u8: np.uint64|;| |;|-f8 = np.float64()|;|-i8 = np.int64()|;|-u8 = np.uint64()|;|+f4: np.float32|;|+i4: np.int32|;|+u4: np.uint32|;| |;|-f4 = np.float32()|;|-i4 = np.int32()|;|-u4 = np.uint32()|;|+m: np.timedelta64|;|+m_nat: np.timedelta64[None]|;|+m_int0: np.timedelta64[L[0]]|;|+m_int: np.timedelta64[int]|;|+m_td: np.timedelta64[dt.timedelta]|;| |;|-td = np.timedelta64(0, ""D"")|;|-b_ = np.bool()|;|+b_: np.bool|;| |;|-b = bool()|;|-f = float()|;|-i = int()|;|+b: bool|;|+i: int|;|+f: float|;| |;| AR_b: npt.NDArray[np.bool]|;| AR_m: npt.NDArray[np.timedelta64]|;| |;| # Time structures|;| |;|-assert_type(td % td, np.timedelta64[dt.timedelta])|;|-assert_type(AR_m % td, npt.NDArray[np.timedelta64])|;|-assert_type(td % AR_m, npt.NDArray[np.timedelta64])|;|-|;|-assert_type(divmod(td, td), tuple[np.int64, np.timedelta64])|;|-assert_type(divmod(AR_m, td), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|-assert_type(divmod(td, AR_m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|+assert_type(m % m, np.timedelta64)|;|+assert_type(m % m_nat, np.timedelta64[None])|;|+assert_type(m % m_int0, np.timedelta64[None])|;|+assert_type(m % m_int, np.timedelta64[int | None])|;|+assert_type(m_nat % m, np.timedelta64[None])|;|+assert_type(m_int % m_nat, np.timedelta64[None])|;|+assert_type(m_int % m_int0, np.timedelta64[None])|;|+assert_type(m_int % m_int, np.timedelta64[int | None])|;|+assert_type(m_int % m_td, np.timedelta64[int | None])|;|+assert_type(m_td % m_nat, np.timedelta64[None])|;|+assert_type(m_td % m_int0, np.timedelta64[None])|;|+assert_type(m_td % m_int, np.timedelta64[int | None])|;|+assert_type(m_td % m_td, np.timedelta64[dt.timedelta | None])|;|+|;|+assert_type(AR_m % m, npt.NDArray[np.timedelta64])|;|+assert_type(m % AR_m, npt.NDArray[np.timedelta64])|;|+|;|+assert_type(divmod(m, m), tuple[np.int64, np.timedelta64])|;|+assert_type(divmod(m, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(m.__divmod__(m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_nat, m), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_int, m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_int, m_td), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_td, m_nat), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_td, m_int0), tuple[np.int64, np.timedelta64[None]])|;|+assert_type(divmod(m_td, m_int), tuple[np.int64, np.timedelta64[int | None]])|;|+assert_type(divmod(m_td, m_td), tuple[np.int64, np.timedelta64[dt.timedelta | None]])|;|+|;|+assert_type(divmod(AR_m, m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;|+assert_type(divmod(m, AR_m), tuple[npt.NDArray[np.int64], npt.NDArray[np.timedelta64]])|;| |;| # Bool|;| |;|@@ -47,11 +79,12 @@ assert_type(b_ % f8, np.float64)|;| assert_type(b_ % AR_b, npt.NDArray[np.int8])|;| |;| assert_type(divmod(b_, b), tuple[np.int8, np.int8])|;|-assert_type(divmod(b_, i), tuple[np.int_, np.int_])|;|-assert_type(divmod(b_, f), tuple[np.float64, np.float64])|;| assert_type(divmod(b_, b_), tuple[np.int8, np.int8])|;|-assert_type(divmod(b_, i8), tuple[np.int64, np.int64])|;|-assert_type(divmod(b_, u8), tuple[np.uint64, np.uint64])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(b_.__divmod__(i), tuple[np.int_, np.int_])|;|+assert_type(b_.__divmod__(f), tuple[np.float64, np.float64])|;|+assert_type(b_.__divmod__(i8), tuple[np.int64, np.int64])|;|+assert_type(b_.__divmod__(u8), tuple[np.uint64, np.uint64])|;| assert_type(divmod(b_, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(b_, AR_b), tuple[npt.NDArray[np.int8], npt.NDArray[np.int8]])|;| |;|@@ -77,26 +110,27 @@ assert_type(divmod(AR_b, b_), tuple[npt.NDArray[np.int8], npt.NDArray[np.int8]])|;| |;| assert_type(i8 % b, np.int64)|;| assert_type(i8 % i8, np.int64)|;|-assert_type(i8 % f, np.floating[_64Bit])|;|-assert_type(i8 % f8, np.floating[_64Bit])|;|+assert_type(i8 % f, np.float64 | np.floating[_64Bit])|;|+assert_type(i8 % f8, np.float64 | np.floating[_64Bit])|;| assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;| assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;|-assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|-assert_type(divmod(i8, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(i8, f8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|-assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]] | tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|+assert_type(divmod(i8, b), tuple[np.int64, np.int64])|;|+assert_type(divmod(i8, i4), tuple[np.int64, np.int64] | tuple[np.int32, np.int32])|;|+assert_type(divmod(i8, i8), tuple[np.int64, np.int64])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(i8.__divmod__(f), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;|+assert_type(i8.__divmod__(f8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;|+assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float32, np.float32])|;|+assert_type(divmod(i4, i4), tuple[np.int32, np.int32])|;|+assert_type(divmod(i4, f4), tuple[np.float32, np.float32])|;| assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;|-assert_type(b % i8, np.signedinteger[_64Bit])|;|-assert_type(f % i8, np.floating[_64Bit])|;|+assert_type(b % i8, np.int64)|;|+assert_type(f % i8, np.float64 | np.floating[_64Bit])|;| assert_type(i8 % i8, np.int64)|;| assert_type(f8 % i8, np.float64)|;| assert_type(i8 % i4, np.int64 | np.int32)|;|@@ -105,21 +139,22 @@ assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;| assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;|-assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;|-assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|+assert_type(divmod(b, i8), tuple[np.int64, np.int64])|;|+assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float64, np.float64])|;| assert_type(divmod(i8, i8), tuple[np.int64, np.int64])|;| assert_type(divmod(f8, i8), tuple[np.float64, np.float64])|;|-assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]] | tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;|-assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;|+assert_type(divmod(i4, i8), tuple[np.int64, np.int64] | tuple[np.int32, np.int32])|;|+assert_type(divmod(i4, i4), tuple[np.int32, np.int32])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(f4.__divmod__(i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.float32, np.float32])|;|+assert_type(f4.__divmod__(i4), tuple[np.float32, np.float32])|;|+assert_type(AR_b.__divmod__(i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;|-assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;|+assert_type(i8 % f4, np.floating[_64Bit] | np.float32)|;| assert_type(f4 % f4, np.float32)|;| assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;|@@ -131,15 +166,16 @@ assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;| assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;|-assert_type(f % f8, np.float64)|;|+assert_type(f % f8, np.float64)  # pyright: ignore[reportAssertTypeFailure]  # pyright incorrectly infers `builtins.float`|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;| assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;|-assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;|-assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;|+# workarounds for https://github.com/microsoft/pyright/issues/9663|;|+assert_type(f8.__rdivmod__(f), tuple[np.float64, np.float64])|;|+assert_type(f8.__rdivmod__(f4), tuple[np.float64, np.float64])|;|+assert_type(AR_b.__divmod__(f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])",TYP: Add missing overloads to ``timedelta64.__divmod__`` || TYP: Take zero division into account in ``timedelta64.__[div]mod__`` || TYP: Add missing overloads to ``timedelta64.__divmod__`` || TYP: Take zero division into account in ``timedelta64.__[div]mod__``
numpy/numpy,lysnikolaou,27342,ENH: Allow for a flatiter index on a flatiter object,"### Proposed new feature or change:

Currently, indexing a `flatiter` with an array object and vice-versa is permitted.

```python
In [1]: a = np.arange(9).reshape((3, 3))

In [2]: a
Out[2]:
array([[0, 1, 2],
       [3, 4, 5],
       [6, 7, 8]])

In [3]: b = np.array([0, 4, 5, 7])

In [4]: b
Out[4]: array([0, 4, 5, 7])

In [5]: a.flat[b]
Out[5]: array([0, 4, 5, 7])

In [6]: a = np.arange(9)

In [7]: a
Out[7]: array([0, 1, 2, 3, 4, 5, 6, 7, 8])

In [8]: a[b.flat]
Out[8]: array([0, 4, 5, 7])
```

However, indexing a `flatiter` with a `flatiter` results in an exception:

```python
In [9]: a.flat[b.flat]
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
Cell In[9], line 1
----> 1 a.flat[b.flat]

IndexError: unsupported iterator index
```

It would be relatively straightforward to allow `flatiter` objects to be index by other `flatiter` objects as well, and it seems that there's no downsides to this. Thoughts?",,closed,2024-09-04T14:28:02+00:00,2025-01-29T23:18:44+00:00,lysnikolaou,,1,"PR#27343 - numpy/_core/src/multiarray/iterators.c: @@ -694,9 +694,23 @@ iter_subscript(PyArrayIterObject *self, PyObject *ind)|;|         obj = ind|;|;     }|;| |;|-    /* Any remaining valid input is an array or has been turned into one */|;|     if (!PyArray_Check(obj)) {|;|-        goto fail|;|;+        PyArrayObject *tmp_arr = (PyArrayObject *) PyArray_FROM_O(obj)|;|;+        if (tmp_arr == NULL) {|;|+            goto fail|;|;+        }|;|+|;|+        if (PyArray_SIZE(tmp_arr) == 0) {|;|+            PyArray_Descr *indtype = PyArray_DescrFromType(NPY_INTP)|;|;+            Py_SETREF(obj, PyArray_FromArray(tmp_arr, indtype, NPY_ARRAY_FORCECAST))|;|;+            Py_DECREF(tmp_arr)|;|;+            if (obj == NULL) {|;|+                goto fail|;|;+            }|;|+        }|;|+        else {|;|+            Py_SETREF(obj, (PyObject *) tmp_arr)|;|;+        }|;|     }|;| |;|     /* Check for Boolean array */ || PR#27343 - numpy/_core/tests/test_indexing.py: @@ -622,6 +622,22 @@ def test_nontuple_ndindex(self):|;|         assert_equal(a[[0, 1], [0, 1]], np.array([0, 6]))|;|         assert_raises(IndexError, a.__getitem__, [slice(None)])|;| |;|+    def test_flat_index_on_flatiter(self):|;|+        a = np.arange(9).reshape((3, 3))|;|+        b = np.array([0, 5, 6])|;|+        assert_equal(a.flat[b.flat], np.array([0, 5, 6]))|;|+|;|+    def test_empty_string_flat_index_on_flatiter(self):|;|+        a = np.arange(9).reshape((3, 3))|;|+        b = np.array([], dtype=""S"")|;|+        assert_equal(a.flat[b.flat], np.array([]))|;|+|;|+    def test_nonempty_string_flat_index_on_flatiter(self):|;|+        a = np.arange(9).reshape((3, 3))|;|+        b = np.array([""a""], dtype=""S"")|;|+        with pytest.raises(IndexError, match=""unsupported iterator index""):|;|+            a.flat[b.flat]|;|+|;| |;| class TestFieldIndexing:|;|     def test_scalar_return_type(self): || PR#27343 - numpy/typing/tests/data/pass/flatiter.py: @@ -14,3 +14,6 @@|;| a[:]|;| a.__array__()|;| a.__array__(np.dtype(np.float64))|;|+|;|+b = np.array([1]).flat|;|+a[b]",ENH: Add support for flat indexing on flat iterator || Merge branch 'main' into flatindex-on-flatiter || Try to cast index to array before failing || Fix refcounting issues
numpy/numpy,agriyakhetarpal,25969,DOC: Add interactive examples with jupyterlite-sphinx,"I'd like to assess interest in adding interactive examples to NumPy's docs. @mattip mentioned in https://github.com/scipy/scipy/issues/19729#issuecomment-1969621588, that this was briefly discussed in one of the NumPy community meetings.

For background info. The [jupyterlite-sphinx](https://jupyterlite-sphinx.readthedocs.io/en/latest/) extension offers the [try_examples](https://jupyterlite-sphinx.readthedocs.io/en/latest/directives/try_examples.html) directive, which adds a button which can be used to swap the rendered examples sections for a docstring in-place with an embedded Jupyterlite notebook. The notebooks run in-browser using a wasm based kernel like [pyodide](https://github.com/jupyterlite/pyodide-kernel) .

 I've deployed SciPy's docs with this extension in action here: https://steppi.github.io/scipy/reference/index.html

Here's a direct link to a page with an example: https://steppi.github.io/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad.

https://github.com/scipy/scipy/pull/20019 was recently merged, adding jupyterlite-sphinx to SciPy's docs. Examples are currently disabled (it's possible to enable or disable them for deployed docs without rebuilding), but we plan to roll them out within the next two weeks.

I'd be interested in getting feedback on the extension, and if there are any changes or new features you'd like to see before it could be used for NumPy. NumPy being able to ship interactive examples would need to wait for Pyodide support for NumPy 2.0, which I suspect would not be too difficult. My understanding is the primary blocker making updates of SciPy in Pyodide difficult is the dependence on Fortran.","Update, 18/06/2024: with the release of NumPy 2.0.0 on 16/06/2024 (#24300), I am working on getting the NumPy documentation to generate interactive examples in one PR, or multiple ones. The documentation for SciPy as mentioned above has now been updated to have interactive examples enabled for the website in scipy/scipy#20918, in order to garner feedback on the utility of said examples.

I shall be updating NumPy in-tree in the Pyodide repository to v2 (or v2.1.0), as downstream packages continue to add support for NumPy – following which the examples can be enabled here for the same reasons. In addition, I shall, like @steppi, deploy this rendition of the docs on GitHub Pages through my fork of NumPy with the extension in action.",closed,2024-03-08T20:33:39+00:00,2025-01-28T13:30:33+00:00,steppi,"01 - Enhancement, component: documentation",1,"PR#26745 - .gitignore: @@ -124,6 +124,7 @@ Thumbs.db|;| doc/source/savefig/|;| doc/source/**/generated/|;| doc/source/release/notes-towncrier.rst|;|+doc/source/.jupyterlite.doit.db|;| |;| # Things specific to this project #|;| ################################### || PR#26745 - doc/Makefile: @@ -50,6 +50,8 @@ help:|;| |;| clean:|;| 	-rm -rf build/*|;|+	-rm -rf source/.jupyterlite.doit.db|;|+	-rm -rf source/contents/*.ipynb|;| 	find . -name generated -type d -prune -exec rm -rf ""{}"" "";""|;| |;| gitwash-update: || PR#26745 - doc/neps/roadmap.rst: @@ -75,7 +75,8 @@ planned improvements. Adding more tutorials is underway in the|;| `numpy-tutorials repo <https://github.com/numpy/numpy-tutorials>`__.|;| |;| We also intend to make all the example code in our documentation interactive -|;|-work is underway to do so via ``jupyterlite-sphinx`` and Pyodide.|;|+work is underway to do so via ``jupyterlite-sphinx`` and Pyodide. NumPy 2.3.0|;|+provides interactive documentation for examples as a pilot for this effort.|;| |;| Our website (https://numpy.org) is in good shape. Further work on expanding the|;| number of languages that the website is translated in is desirable. As are || PR#26745 - doc/release/upcoming_changes/26745.highlight.rst: @@ -0,0 +1,10 @@|;|+Interactive examples in the NumPy documentation|;|+-----------------------------------------------|;|+|;|+The NumPy documentation includes a number of examples that|;|+can now be run interactively in your browser using WebAssembly|;|+and Pyodide.|;|+|;|+Please note that the examples are currently experimental in|;|+nature and may not work as expected for all methods in the|;|+public API. || PR#26745 - doc/source/_static/numpy.css: @@ -1,10 +1,11 @@|;| @import url('https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;0,900;1,400;1,700;1,900&family=Open+Sans:ital,wght@0,400;0,600;1,400;1,600&display=swap')|;|; |;| .navbar-brand img {|;|-   height: 75px|;|;+  height: 75px|;|; }|;|+|;| .navbar-brand {|;|-   height: 75px|;|;+  height: 75px|;|; }|;| |;| body {|;|@@ -71,4 +72,43 @@ div.admonition-legacy>.admonition-title::after {|;| |;| div.admonition-legacy>.admonition-title {|;|   background-color: var(--pst-color-warning-bg)|;|;-}|;|\ No newline at end of file|;|+}|;|+|;|+/* Buttons for JupyterLite-enabled interactive examples */|;|+|;|+.try_examples_button {|;|+  color: white|;|;+  background-color: var(--pst-color-info)|;|;+  border: none|;|;+  padding: 5px 10px|;|;+  border-radius: 0.25rem|;|;+  margin-top: 3px;  /* better alignment under admonitions */|;|+  margin-bottom: 5px !important; /* fix uneven button sizes under admonitions */|;|+  box-shadow: 0 2px 5px rgba(108, 108, 108, 0.2)|;|;+  font-weight: bold|;|;+  font-size: small|;|;+}|;|+|;|+/* Use more acccessible colours for text in dark mode */|;|+[data-theme=dark] .try_examples_button {|;|+  color: black|;|;+}|;|+|;|+.try_examples_button:hover {|;|+  transform: scale(1.02)|;|;+  box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2)|;|;+  cursor: pointer|;|;+}|;|+|;|+.try_examples_button_container {|;|+  display: flex|;|;+  justify-content: flex-start|;|;+  gap: 10px|;|;+  margin-bottom: 20px|;|;+}|;|+|;|+/* Better gaps for examples buttons under admonitions */|;|+|;|+.try_examples_outer_iframe {|;|+  margin-top: 0.4em|;|;+} || PR#26745 - doc/source/conf.py: @@ -89,6 +89,7 @@ class PyTypeObject(ctypes.Structure):|;|     'sphinx_copybutton',|;|     'sphinx_design',|;|     'sphinx.ext.imgconverter',|;|+    'jupyterlite_sphinx',|;| ]|;| |;| skippable_extensions = [|;|@@ -601,4 +602,17 @@ class NumPyLexer(CLexer):|;|     ('c:identifier', 'PyHeapTypeObject'),|;| ]|;| |;|+# -----------------------------------------------------------------------------|;|+# Interactive documentation examples via JupyterLite|;|+# -----------------------------------------------------------------------------|;| |;|+global_enable_try_examples = True|;|+try_examples_global_button_text = ""Try it in your browser!""|;|+try_examples_global_warning_text = (|;|+    ""NumPy's interactive examples are experimental and may not always work""|;|+    "" as expected, with high load times especially on low-resource platforms,""|;|+    "" and the version of NumPy might not be in sync with the one you are""|;|+    "" browsing the documentation for. If you encounter any issues, please""|;|+    "" report them on the""|;|+    "" [NumPy issue tracker](https://github.com/numpy/numpy/issues).""|;|+) || PR#26745 - doc/source/jupyter_lite_config.json: @@ -0,0 +1,5 @@|;|+{|;|+  ""LiteBuildConfig"": {|;|+    ""no_sourcemaps"": true|;|+  }|;|+} || PR#26745 - doc/source/reference/arrays.classes.rst: @@ -405,22 +405,28 @@ alias for ""matrix ""in NumPy.|;| |;| Example 1: Matrix creation from a string|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> a = np.asmatrix('1 2 3; 4 5 3')|;|   >>> print((a*a.T).I)|;|     [[ 0.29239766 -0.13450292]|;|-     [-0.13450292  0.08187135]]|;|+    [-0.13450292  0.08187135]]|;| |;| |;| Example 2: Matrix creation from a nested sequence|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> np.asmatrix([[1,5,10],[1.0,3,4j]])|;|   matrix([[  1.+0.j,   5.+0.j,  10.+0.j],|;|           [  1.+0.j,   3.+0.j,   0.+4.j]])|;| |;| Example 3: Matrix creation from an array|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> np.asmatrix(np.random.rand(3,3)).T|;|   matrix([[4.17022005e-01, 3.02332573e-01, 1.86260211e-01],|;|@@ -457,6 +463,8 @@ array actually get written to disk.|;| |;| Example:|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;| |;|   >>> a = np.memmap('newfile.dat', dtype=float, mode='w+', shape=1000)|;|@@ -605,6 +613,8 @@ This default iterator selects a sub-array of dimension :math:`N-1`|;| from the array. This can be a useful construct for defining recursive|;| algorithms. To loop over the entire array requires :math:`N` for-loops.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> a = np.arange(24).reshape(3,2,4) + 10|;|   >>> for val in a:|;|@@ -629,8 +639,9 @@ As mentioned previously, the flat attribute of ndarray objects returns|;| an iterator that will cycle over the entire array in C-style|;| contiguous order.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|-  >>> a = np.arange(24).reshape(3,2,4) + 10|;|   >>> for i, val in enumerate(a.flat):|;|   ...     if i%5 == 0: print(i, val)|;|   0 10|;|@@ -654,9 +665,12 @@ N-dimensional enumeration|;| Sometimes it may be useful to get the N-dimensional index while|;| iterating. The ndenumerate iterator can achieve this.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> for i, val in np.ndenumerate(a):|;|-  ...     if sum(i)%5 == 0: print(i, val)|;|+  ...     if sum(i)%5 == 0:|;|+              print(i, val)|;|   (0, 0, 0) 10|;|   (1, 1, 3) 25|;|   (2, 0, 3) 29|;|@@ -677,6 +691,8 @@ objects as inputs and returns an iterator that returns tuples|;| providing each of the input sequence elements in the broadcasted|;| result.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> for val in np.broadcast([[1, 0], [2, 3]], [0, 1]):|;|   ...     print(val) || PR#26745 - doc/source/reference/arrays.datetime.rst: @@ -57,6 +57,8 @@ letters, for a ""Not A Time"" value.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     A simple ISO date:|;| |;|     >>> import numpy as np|;|@@ -95,6 +97,8 @@ datetime type with generic units.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.array(['2007-07-13', '2006-01-13', '2010-08-13'], dtype='datetime64')|;|@@ -109,6 +113,8 @@ POSIX timestamps with the given unit.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.array([0, 1577836800], dtype='datetime64[s]')|;|@@ -124,6 +130,8 @@ example :func:`arange` can be used to generate ranges of dates.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     All the dates for one month:|;| |;|     >>> import numpy as np|;|@@ -146,6 +154,8 @@ because the moment of time is still being represented exactly.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.datetime64('2005') == np.datetime64('2005-01-01')|;|@@ -175,6 +185,8 @@ data type also accepts the string ""NAT"" in place of the number for a ""Not A Time|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.timedelta64(1, 'D')|;|@@ -191,6 +203,8 @@ simple datetime calculations.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.datetime64('2009-01-01') - np.datetime64('2008-01-01')|;|@@ -226,6 +240,8 @@ calculating the averaged values from the 400 year leap-year cycle.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> a = np.timedelta64(1, 'Y')|;|@@ -307,6 +323,8 @@ specified in business days to datetimes with a unit of 'D' (day).|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.busday_offset('2011-06-23', 1)|;|@@ -323,6 +341,8 @@ The rules most typically used are 'forward' and 'backward'.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.busday_offset('2011-06-25', 2)|;|@@ -347,6 +367,8 @@ is necessary to get a desired answer.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     The first business day on or after a date:|;| |;|     >>> import numpy as np|;|@@ -370,6 +392,8 @@ weekmask.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')|;|@@ -386,6 +410,8 @@ To test a `datetime64` value to see if it is a valid day, use :func:`is_busday`.|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.is_busday(np.datetime64('2011-07-15'))  # a Friday|;|@@ -405,6 +431,8 @@ dates, use :func:`busday_count`:|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> np.busday_count(np.datetime64('2011-07-11'), np.datetime64('2011-07-18'))|;|@@ -417,6 +445,8 @@ how many of them are valid dates, you can do this:|;| |;| .. admonition:: Example|;| |;|+  .. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> a = np.arange(np.datetime64('2011-07-11'), np.datetime64('2011-07-18'))|;|@@ -466,6 +496,8 @@ given below.|;|     23:59:60.450 UTC"" is a valid timestamp which is not parseable by|;|     `datetime64`:|;| |;|+    .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> np.datetime64(""2016-12-31 23:59:60.450"")|;|@@ -481,6 +513,8 @@ given below.|;|     Compute the number of SI seconds between ""2021-01-01 12:56:23.423 UTC"" and|;|     ""2001-01-01 00:00:00.000 UTC"":|;| |;|+    .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> (|;|@@ -501,7 +535,8 @@ given below.|;|      where UT is `universal time|;|      <https://en.wikipedia.org/wiki/Universal_Time>`_:|;| |;|-    |;|+    .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> a = np.datetime64(""0000-01-01"", ""us"") || PR#26745 - doc/source/reference/arrays.dtypes.rst: @@ -68,6 +68,8 @@ Sub-arrays always have a C-contiguous memory layout.|;|    A simple data type containing a 32-bit big-endian integer:|;|    (see :ref:`arrays.dtypes.constructing` for details on construction)|;| |;|+   .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> dt = np.dtype('>i4')|;|@@ -87,6 +89,8 @@ Sub-arrays always have a C-contiguous memory layout.|;|    A structured data type containing a 16-character string (in field 'name')|;|    and a sub-array of two 64-bit floating-point number (in field 'grades'):|;| |;|+    .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> dt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])|;|@@ -98,6 +102,8 @@ Sub-arrays always have a C-contiguous memory layout.|;|    Items of an array of this data type are wrapped in an :ref:`array|;|    scalar <arrays.scalars>` type that also has two fields:|;| |;|+   .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> x = np.array([('Sarah', (8.0, 7.0)), ('John', (6.0, 7.0))], dtype=dt)|;|@@ -154,6 +160,8 @@ Array-scalar types|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype(np.int32)      # 32-bit integer|;|@@ -199,6 +207,8 @@ Built-in Python types|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype(float)   # Python-compatible floating-point number|;|@@ -229,6 +239,8 @@ One-character strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype('b')  # byte, native byte order|;|@@ -261,6 +273,8 @@ Array-protocol type strings (see :ref:`arrays.interface`)|;| |;|    .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype('i4')   # 32-bit signed integer|;|@@ -294,6 +308,8 @@ String with comma-separated fields|;| |;|    .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|       - field named ``f0`` containing a 32-bit integer|;|       - field named ``f1`` containing a 2 x 3 sub-array|;|         of 64-bit floating-point numbers|;|@@ -316,6 +332,8 @@ Type strings|;| |;|    .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype('uint32')   # 32-bit unsigned integer|;|@@ -331,6 +349,8 @@ Type strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype((np.void, 10))  # 10-byte wide data block|;|@@ -350,6 +370,8 @@ Type strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          >>> import numpy as np|;| |;|          >>> dt = np.dtype((np.int32, (2,2)))          # 2 x 2 integer sub-array|;|@@ -384,6 +406,8 @@ Type strings|;| |;|    .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          Data-type with fields ``big`` (big-endian 32-bit integer) and|;|          ``little`` (little-endian 32-bit integer):|;| |;|@@ -425,6 +449,8 @@ Type strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          Data type with fields ``r``, ``g``, ``b``, ``a``, each being|;|          an 8-bit unsigned integer:|;| |;|@@ -456,6 +482,8 @@ Type strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          Data type containing field ``col1`` (10-character string at|;|          byte position 0), ``col2`` (32-bit float at byte position 10),|;|          and ``col3`` (integers at byte position 14):|;|@@ -481,6 +509,8 @@ Type strings|;| |;|     .. admonition:: Example|;| |;|+      .. try_examples::|;|+|;|          32-bit integer, whose first two bytes are interpreted as an integer|;|          via field ``real``, and the following two bytes via field ``imag``.|;| |;|@@ -505,6 +535,8 @@ When checking for a specific data type, use ``==`` comparison.|;| |;| .. admonition:: Example|;| |;|+   .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> a = np.array([1, 2], dtype=np.float32)|;|@@ -519,6 +551,8 @@ This equivalence can only be handled through ``==``, not through ``is``.|;| |;| .. admonition:: Example|;| |;|+   .. try_examples::|;|+|;|       A :class:`dtype` object is equal to all data type specifications that are|;|       equivalent to it.|;| |;|@@ -540,6 +574,8 @@ Second, there is no guarantee that data type objects are singletons.|;| |;| .. admonition:: Example|;| |;|+   .. try_examples::|;|+|;|       Do not use ``is`` because data type objects may or may not be singletons.|;| |;|       >>> import numpy as np || PR#26745 - doc/source/reference/arrays.ndarray.rst: @@ -32,6 +32,8 @@ objects implementing the :class:`memoryview` or :ref:`array|;| |;| .. admonition:: Example|;| |;|+   .. try_examples::|;|+|;|       A 2-dimensional array of size 2 x 3, composed of 4-byte integer|;|       elements:|;| |;|@@ -362,6 +364,8 @@ Many of these methods take an argument named *axis*. In such cases,|;| |;| .. admonition:: Example of the *axis* argument|;| |;|+   .. try_examples::|;|+|;|       A 3-dimensional array of size 3 x 3 x 3, summed over each of its|;|       three axes:|;|  || PR#26745 - doc/source/reference/arrays.nditer.rst: @@ -32,6 +32,8 @@ using the standard Python iterator interface.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -50,6 +52,8 @@ of that transpose in C order.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -80,6 +84,8 @@ order='C' for C order and order='F' for Fortran order.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -117,6 +123,8 @@ context is exited.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -158,6 +166,8 @@ elements each.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -186,6 +196,8 @@ progression of the index:|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -216,6 +228,8 @@ raise an exception.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.zeros((2,3))|;|@@ -236,6 +250,8 @@ produce identical results to the ones in the previous section.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -279,6 +295,8 @@ is enabled.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3)|;|@@ -323,6 +341,8 @@ data type doesn't match precisely.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3) - 3|;|@@ -339,6 +359,8 @@ specified as an iterator flag.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6).reshape(2,3) - 3|;|@@ -364,6 +386,8 @@ complex to float.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6.)|;|@@ -397,6 +421,8 @@ would violate the casting rule.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(6)|;|@@ -422,6 +448,8 @@ a two dimensional array together.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(3)|;|@@ -436,6 +464,8 @@ which includes the input shapes to help diagnose the problem.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(2)|;|@@ -462,6 +492,8 @@ parameter support.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> def square(a):|;|@@ -501,6 +533,8 @@ reasons.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> def square(a, out=None):|;|@@ -559,6 +593,8 @@ Everything to do with the outer product is handled by the iterator setup.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(3)|;|@@ -593,6 +629,8 @@ For a simple example, consider taking the sum of all elements in an array.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(24).reshape(2,3,4)|;|@@ -614,6 +652,8 @@ sums along the last axis of `a`.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(24).reshape(2,3,4)|;|@@ -650,6 +690,8 @@ buffering.|;| |;| .. admonition:: Example|;| |;|+    .. try_examples::|;|+|;|         >>> import numpy as np|;| |;|         >>> a = np.arange(24).reshape(2,3,4) || PR#26745 - doc/source/reference/arrays.scalars.rst: @@ -191,6 +191,8 @@ Inexact types|;|    This means that variables with equal binary values but whose datatypes are of|;|    different precisions may display differently:|;| |;|+   .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> f16 = np.float16(""0.1"") || PR#26745 - doc/source/reference/constants.rst: @@ -62,6 +62,8 @@ NumPy includes several constants:|;| |;|     .. rubric:: Examples|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> np.inf|;|     inf|;|@@ -91,6 +93,8 @@ NumPy includes several constants:|;| |;|     .. rubric:: Examples|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> np.nan|;|     nan|;|@@ -106,6 +110,8 @@ NumPy includes several constants:|;| |;|     .. rubric:: Examples|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> np.newaxis is None|;|     True || PR#26745 - doc/source/reference/maskedarray.baseclass.rst: @@ -15,6 +15,8 @@ defines several constants.|;|    specific entry of a masked array is masked, or to mask one or several|;|    entries of a masked array::|;| |;|+   .. try_examples::|;|+|;|       >>> import numpy as np|;| |;|       >>> x = np.ma.array([1, 2, 3], mask=[0, 1, 0]) || PR#26745 - doc/source/reference/maskedarray.generic.rst: @@ -35,6 +35,8 @@ masked (invalid).|;| |;| The package ensures that masked entries are not used in computations.|;| |;|+.. try_examples::|;|+|;|    As an illustration, let's consider the following dataset:|;| |;|    >>> import numpy as np|;|@@ -62,6 +64,8 @@ class, which is a subclass of :class:`numpy.ndarray`. The class, its|;| attributes and methods are described in more details in the|;| :ref:`MaskedArray class <maskedarray.baseclass>` section.|;| |;|+.. try_examples::|;|+|;| The :mod:`numpy.ma` module can be used as an addition to :mod:`numpy`:|;| |;|    >>> import numpy as np|;|@@ -108,6 +112,8 @@ There are several ways to construct a masked array.|;|   mask of the view is set to :attr:`nomask` if the array has no named fields,|;|   or an array of boolean with the same structure as the array otherwise.|;| |;|+.. try_examples::|;|+|;|    >>> import numpy as np|;|    >>> x = np.array([1, 2, 3])|;|    >>> x.view(ma.MaskedArray)|;|@@ -194,6 +200,8 @@ To retrieve only the valid entries, we can use the inverse of the mask as an|;| index. The inverse of the mask can be calculated with the|;| :func:`numpy.logical_not` function or simply with the ``~`` operator:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy as np|;|    >>> x = ma.array([[1, 2], [3, 4]], mask=[[0, 1], [1, 0]])|;|    >>> x[~x.mask]|;|@@ -222,6 +230,8 @@ Masking an entry|;| The recommended way to mark one or several specific entries of a masked array|;| as invalid is to assign the special value :attr:`masked` to them:|;| |;|+.. try_examples::|;|+|;|    >>> x = ma.array([1, 2, 3])|;|    >>> x[0] = ma.masked|;|    >>> x|;|@@ -261,6 +271,8 @@ but this usage is discouraged.|;| All the entries of an array can be masked at once by assigning ``True`` to the|;| mask:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3], mask=[0, 0, 1])|;|    >>> x.mask = True|;|@@ -286,6 +298,8 @@ Unmasking an entry|;| To unmask one or several specific entries, we can just assign one or several|;| new valid values to them:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3], mask=[0, 0, 1])|;|    >>> x|;|@@ -307,6 +321,8 @@ new valid values to them:|;|    before the allocation. It can be re-hardened with :meth:`harden_mask` as|;|    follows:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3], mask=[0, 0, 1], hard_mask=True)|;|    >>> x|;|@@ -337,6 +353,8 @@ To unmask all masked entries of a masked array (provided the mask isn't a hard|;| mask), the simplest solution is to assign the constant :attr:`nomask` to the|;| mask:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3], mask=[0, 0, 1])|;|    >>> x|;|@@ -361,6 +379,8 @@ output is either a scalar (if the corresponding entry of the mask is|;| ``False``) or the special value :attr:`masked` (if the corresponding entry of|;| the mask is ``True``):|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3], mask=[0, 0, 1])|;|    >>> x[0]|;|@@ -375,6 +395,8 @@ If the masked array has named fields, accessing a single entry returns a|;| array with the same dtype as the initial array if at least one of the fields|;| is masked.|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> y = ma.masked_array([(1,2), (3, 4)],|;|    ...                mask=[(0, 0), (0, 1)],|;|@@ -391,6 +413,8 @@ mask is either :attr:`nomask` (if there was no invalid entries in the original|;| array) or a view of the corresponding slice of the original mask. The view is|;| required to ensure propagation of any modification of the mask to the original.|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1, 2, 3, 4, 5], mask=[0, 1, 0, 0, 1])|;|    >>> mx = x[:3]|;|@@ -430,6 +454,8 @@ ufuncs. Unary and binary functions that have a validity domain (such as|;| :func:`~numpy.log` or :func:`~numpy.divide`) return the :data:`masked`|;| constant whenever the input is masked or falls outside the validity domain:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> ma.log([-1, 0, 1, 2])|;|    masked_array(data=[--, --, 0.0, 0.6931471805599453],|;|@@ -444,6 +470,8 @@ the name of the ufunc, its arguments and its domain), the context is processed|;| and entries of the output masked array are masked wherever the corresponding|;| input fall outside the validity domain:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([-1, 1, 0, 2, 3], mask=[0, 0, 0, 0, 1])|;|    >>> np.log(x)|;|@@ -462,6 +490,8 @@ Let's consider a list of elements, ``x``, where values of -9999. represent|;| missing data. We wish to compute the average value of the data and the vector|;| of anomalies (deviations from the average):|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = [0.,1.,-9999.,3.,4.]|;|    >>> mx = ma.masked_values (x, -9999.)|;|@@ -479,6 +509,8 @@ Filling in the missing data|;| Suppose now that we wish to print that same data, but with the missing values|;| replaced by the average value.|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> mx = ma.masked_values (x, -9999.)|;|    >>> print(mx.filled(mx.mean()))|;|@@ -491,6 +523,8 @@ Numerical operations|;| Numerical operations can be easily performed without worrying about missing|;| values, dividing by zero, square roots of negative numbers, etc.::|;| |;|+.. try_examples::|;|+|;|    >>> import numpy.ma as ma|;|    >>> x = ma.array([1., -1., 3., 4., 5., 6.], mask=[0,0,0,0,1,0])|;|    >>> y = ma.array([1., 2., 0., 4., 5., 6.], mask=[0,0,0,0,0,1])|;|@@ -509,6 +543,8 @@ Let's consider an array ``d`` of floats between 0 and 1. We wish to|;| compute the average of the values of ``d`` while ignoring any data outside|;| the range ``[0.2, 0.9]``:|;| |;|+.. try_examples::|;|+|;|    >>> import numpy as np|;|    >>> import numpy.ma as ma|;|    >>> d = np.linspace(0, 1, 20) || PR#26745 - doc/source/reference/random/generator.rst: @@ -72,6 +72,8 @@ By default, `Generator.permuted` returns a copy.  To operate in-place with|;| `Generator.permuted`, pass the same array as the first argument *and* as|;| the value of the ``out`` parameter.  For example,|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> rng = np.random.default_rng()|;|     >>> x = np.arange(0, 15).reshape(3, 5)|;|@@ -101,6 +103,8 @@ which dimension of the input array to use as the sequence. In the case of a|;| two-dimensional array, ``axis=0`` will, in effect, rearrange the rows of the|;| array, and  ``axis=1`` will rearrange the columns.  For example|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> rng = np.random.default_rng()|;|     >>> x = np.arange(0, 15).reshape(3, 5)|;|@@ -121,6 +125,8 @@ how `numpy.sort` treats it.  Each slice along the given axis is shuffled|;| independently of the others.  Compare the following example of the use of|;| `Generator.permuted` to the above example of `Generator.permutation`:|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> rng = np.random.default_rng()|;|     >>> rng.permuted(x, axis=1) #doctest: +SKIP|;|@@ -137,6 +143,8 @@ Shuffling non-NumPy sequences|;| `Generator.shuffle` works on non-NumPy sequences.  That is, if it is given|;| a sequence that is not a NumPy array, it shuffles that sequence in-place.|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;|     >>> rng = np.random.default_rng()|;|     >>> a = ['A', 'B', 'C', 'D', 'E'] || PR#26745 - doc/source/reference/random/index.rst: @@ -18,16 +18,24 @@ probability distributions. In general, users will create a `Generator` instance|;| with `default_rng` and call the various methods on it to obtain samples from|;| different distributions.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> rng = np.random.default_rng()|;|-  # Generate one random float uniformly distributed over the range [0, 1)|;|+|;|+  Generate one random float uniformly distributed over the range [0, 1)|;|+|;|   >>> rng.random()  #doctest: +SKIP|;|   0.06369197489564249  # may vary|;|-  # Generate an array of 10 numbers according to a unit Gaussian distribution|;|+|;|+  Generate an array of 10 numbers according to a unit Gaussian distribution|;|+|;|   >>> rng.standard_normal(10)  #doctest: +SKIP|;|   array([-0.31018314, -1.8922078 , -0.3628523 , -0.63526532,  0.43181166,  # may vary|;|           0.51640373,  1.25693945,  0.07779185,  0.84090247, -2.13406828])|;|-  # Generate an array of 5 integers uniformly over the range [0, 10)|;|+|;|+  Generate an array of 5 integers uniformly over the range [0, 10)|;|+|;|   >>> rng.integers(low=0, high=10, size=5)  #doctest: +SKIP|;|   array([8, 7, 6, 2, 0])  # may vary|;| |;|@@ -38,6 +46,8 @@ generate different numbers each time. The pseudo-random sequences will be|;| independent for all practical purposes, at least those purposes for which our|;| pseudo-randomness was good for in the first place.|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> rng1 = np.random.default_rng()|;|   >>> rng1.random()  #doctest: +SKIP|;|@@ -63,6 +73,9 @@ intentionally *trying* to reproduce their result. A convenient way to get|;| such a seed number is to use :py:func:`secrets.randbits` to get an|;| arbitrary 128-bit integer.|;| |;|+|;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> import secrets|;|   >>> secrets.randbits(128)  #doctest: +SKIP || PR#26745 - doc/source/reference/routines.char.rst: @@ -16,6 +16,8 @@ Legacy fixed-width string functionality|;| The `numpy.char` module provides a set of vectorized string|;| operations for arrays of type `numpy.str_` or `numpy.bytes_`. For example|;| |;|+.. try_examples::|;|+|;|    >>> import numpy as np|;|    >>> np.char.capitalize([""python"", ""numpy""])|;|    array(['Python', 'Numpy'], dtype='<U6') || PR#26745 - doc/source/reference/routines.polynomials.rst: @@ -85,6 +85,8 @@ instance representing the expression :math:`x^{2} + 2x + 3` to a|;| `~numpy.polynomial.polynomial.Polynomial` instance representing the same|;| expression:|;| |;|+.. try_examples::|;|+|;|     >>> import numpy as np|;| |;|     >>> p1d = np.poly1d([1, 2, 3]) || PR#26745 - doc/source/reference/routines.rec.rst: @@ -13,6 +13,8 @@ Most commonly, ndarrays contain elements of a single type, e.g. floats,|;| integers, bools etc.  However, it is possible for elements to be combinations|;| of these using structured types, such as:|;| |;|+.. try_examples::|;|+|;|   >>> import numpy as np|;|   >>> a = np.array([(1, 2.0), (1, 2.0)],|;|   ...     dtype=[('x', np.int64), ('y', np.float64)]) || PR#26745 - doc/source/reference/routines.rst: @@ -4,11 +4,9 @@|;| Routines and objects by topic|;| *****************************|;| |;|-In this chapter routine docstrings are presented, grouped by functionality.|;|+In this chapter, routine docstrings are presented, grouped by functionality.|;| Many docstrings contain example code, which demonstrates basic usage|;|-of the routine. The examples assume that NumPy is imported with::|;|-|;|-  >>> import numpy as np|;|+of the routine.|;| |;| A convenient way to execute examples is the ``%doctest_mode`` mode of|;| IPython, which allows for pasting of multi-line examples and preserves || PR#26745 - doc/source/reference/routines.strings.rst: @@ -9,10 +9,12 @@ String functionality|;| |;| The `numpy.strings` module provides a set of universal functions operating|;| on arrays of type `numpy.str_` or `numpy.bytes_`.|;|-For example|;|+For example,|;| |;|-      >>> np.strings.add([""num"", ""doc""], [""py"", ""umentation""])|;|-      array(['numpy', 'documentation'], dtype='<U13')|;|+.. try_examples::|;|+|;|+   >>> np.strings.add([""num"", ""doc""], [""py"", ""umentation""])|;|+   array(['numpy', 'documentation'], dtype='<U13')|;| |;| These universal functions are also used in `numpy.char`, which provides|;| the `numpy.char.chararray` array subclass, in order for those routines || PR#26745 - doc/source/try_examples.json: @@ -0,0 +1,8 @@|;|+{|;|+    ""global_min_height"": ""400px"",|;|+    ""ignore_patterns"": [|;|+        ""distutils.html*"",|;|+        ""reference\/typing.html*"",|;|+        ""numpy.__array_namespace_info__.html*""|;|+    ]|;|+} || PR#26745 - doc/source/user/absolute_beginners.rst: @@ -42,6 +42,10 @@ enter in a script or at a Python prompt. Everything else is **output**, the|;| results of running your code. Note that ``>>>`` and ``...`` are not part of the|;| code and may cause an error if entered at a Python prompt.|;| |;|+To run the code in the examples, you can copy and paste it into a Python script or|;|+REPL, or use the experimental interactive examples in the browser provided in various|;|+locations in the documentation.|;|+|;| Why use NumPy?|;| --------------|;|  || PR#26745 - environment.yml: @@ -39,6 +39,9 @@ dependencies:|;|   - pydata-sphinx-theme>=0.15.2|;|   - doxygen|;|   - towncrier|;|+  - jupyterlite-sphinx>=0.18.0|;|+  # see https://github.com/jupyterlite/pyodide-kernel#compatibility|;|+  - jupyterlite-pyodide-kernel==0.5.2 # supports Pyodide 0.27.1|;|   # NOTE: breathe 4.33.0 collides with sphinx.ext.graphviz|;|   - breathe>4.33.0|;|   # For linting || PR#26745 - numpy/_core/code_generators/ufunc_docstrings.py: @@ -426,10 +426,10 @@ def add_newdoc(place, name, doc):|;| |;|     Examples|;|     --------|;|+|;|     We expect the arctan of 0 to be 0, and of 1 to be pi/4:|;| |;|     >>> import numpy as np|;|-|;|     >>> np.arctan([0, 1])|;|     array([ 0.        ,  0.78539816])|;| |;|@@ -507,10 +507,10 @@ def add_newdoc(place, name, doc):|;| |;|     Examples|;|     --------|;|+|;|     Consider four points in different quadrants:|;| |;|     >>> import numpy as np|;|-|;|     >>> x = np.array([-1, +1, +1, -1])|;|     >>> y = np.array([-1, -1, +1, +1])|;|     >>> np.arctan2(y, x) * 180 / np.pi|;|@@ -989,7 +989,6 @@ def add_newdoc(place, name, doc):|;|     Convert a radian array to degrees|;| |;|     >>> import numpy as np|;|-|;|     >>> rad = np.arange(12.)*np.pi/6|;|     >>> np.degrees(rad)|;|     array([   0.,   30.,   60.,   90.,  120.,  150.,  180.,  210.,  240.,|;|@@ -1224,6 +1223,7 @@ def add_newdoc(place, name, doc):|;|     >>> import numpy as np|;| |;|     >>> import matplotlib.pyplot as plt|;|+    >>> import numpy as np|;| |;|     >>> x = np.linspace(-2*np.pi, 2*np.pi, 100)|;|     >>> xx = x + 1j * x[:, np.newaxis] # a + ib over complex plane|;|@@ -1298,12 +1298,12 @@ def add_newdoc(place, name, doc):|;| |;|     Examples|;|     --------|;|+|;|     The true value of ``exp(1e-10) - 1`` is ``1.00000000005e-10`` to|;|     about 32 significant digits. This example shows the superiority of|;|     expm1 in this case.|;| |;|     >>> import numpy as np|;|-|;|     >>> np.expm1(1e-10)|;|     1.00000000005e-10|;|     >>> np.exp(1e-10) - 1|;|@@ -2839,7 +2839,6 @@ def add_newdoc(place, name, doc):|;|     For 2-D arrays it is the matrix product:|;| |;|     >>> import numpy as np|;|-|;|     >>> a = np.array([[1, 0],|;|     ...               [0, 1]])|;|     >>> b = np.array([[4, 1], || PR#26745 - numpy/lib/_polynomial_impl.py: @@ -101,6 +101,7 @@ def poly(seq_of_zeros):|;| |;|     Examples|;|     --------|;|+|;|     Given a sequence of a polynomial's zeros:|;| |;|     >>> import numpy as np|;|@@ -298,6 +299,7 @@ def polyint(p, m=1, k=None):|;| |;|     Examples|;|     --------|;|+|;|     The defining property of the antiderivative:|;| |;|     >>> import numpy as np|;|@@ -395,6 +397,7 @@ def polyder(p, m=1):|;| |;|     Examples|;|     --------|;|+|;|     The derivative of the polynomial :math:`x^3 + x^2 + x^1 + 1` is:|;| |;|     >>> import numpy as np|;|@@ -883,6 +886,7 @@ def polysub(a1, a2):|;| |;|     Examples|;|     --------|;|+|;|     .. math:: (2 x^2 + 10 x - 2) - (3 x^2 + 10 x -4) = (-x^2 + 2)|;| |;|     >>> import numpy as np|;|@@ -1020,9 +1024,11 @@ def polydiv(u, v):|;| |;|     Examples|;|     --------|;|+|;|     .. math:: \\frac{3x^2 + 5x + 2}{2x + 1} = 1.5x + 1.75, remainder 0.25|;| |;|     >>> import numpy as np|;|+|;|     >>> x = np.array([3.0, 5.0, 2.0])|;|     >>> y = np.array([2.0, 1.0])|;|     >>> np.polydiv(x, y)|;|@@ -1111,6 +1117,8 @@ class poly1d:|;| |;|     Examples|;|     --------|;|+    >>> import numpy as np|;|+|;|     Construct the polynomial :math:`x^2 + 2x + 3`:|;| |;|     >>> import numpy as np || PR#26745 - numpy/linalg/_linalg.py: @@ -1294,8 +1294,9 @@ def eigvalsh(a, UPLO='L'):|;|            [0.+2.j, 2.+0.j]])|;|     >>> wa = LA.eigvalsh(a)|;|     >>> wb = LA.eigvals(b)|;|-    >>> wa; wb|;|+    >>> wa|;|     array([1., 6.])|;|+    >>> wb|;|     array([6.+0.j, 1.+0.j])|;| |;|     """""" || PR#26745 - requirements/doc_requirements.txt: @@ -17,5 +17,12 @@ pickleshare|;| towncrier|;| toml|;| |;|+|;| # for doctests, also needs pytz which is in test_requirements|;| scipy-doctest==1.6.0|;|+|;|+# interactive documentation utilities|;|+# see https://github.com/jupyterlite/pyodide-kernel#compatibility|;|+jupyterlite-sphinx>=0.18.0|;|+# Works with Pyodide 0.27.1|;|+jupyterlite-pyodide-kernel==0.5.2","DOC: Remove JupyterLite artifacts with make clean || DOC: Git-ignore JupyterLite DB file || DEP: Add interactive documentation requirements || DOC: Add JupyterLite configuration || DOC: Configure a minimum height for the buttons || DOC: Configure CSS for `TryExamples` buttons

Co-Authored-By: Albert Steppi <1953382+steppi@users.noreply.github.com> || DOC, TST: Add `>>> import numpy as np` stub to docstrings || DOC: Add `.. try_examples::` directive to API reference || DOC, API: Add `>>> import numpy as np` stub to `numpy/_core/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/lib/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/ma/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/linalg/_linalg.py` || DOC, API: Add `>>> import numpy as np` stub to `numpy/fft/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/random/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/polynomial/` || DOC, API: Add `>>> import numpy as np` stub to `numpy/exceptions.py` || REL: Add notes about interactive examples || DOC: Remove generated notebooks with `make clean`

[skip cirrus] [skip azp] || REL: Add release note for gh-26745

[skip cirrus] [skip azp] || STY: Fix failing doctests

[skip cirrus] [skip azp] || Merge remote-tracking branch 'upstream/main' into interactive-docs || DOC: inherit styles from PST, fix alignments

[skip cirrus] [skip azp] || REL: Update release note to highlight in-browser support

[skip cirrus] [skip azp]

Co-authored-by: M Bussonnier <bussonniermatthias@gmail.com> || DOC: Fix ""Inexact types"" example not rendering

[skip cirrus] [skip azp] || DOC: Add margins to `try_examples_outer_iframe`

Co-Authored-By: M Bussonnier <bussonniermatthias@gmail.com> || REL: Fix unneeded words and typos in release note

[skip cirrus] [skip azp] || DOC: Fix indents in ""N-dimensional enumeration"" example

[skip cirrus] [skip azp] || Merge branch 'main' into interactive-docs || DOC, DEP: Bump to `jupyterlite-sphinx` v0.16.2

[skip cirrus] [skip azp] || STY: Add newline at the end of `numpy.css`

[skip cirrus] [skip azp] || STY: Fix punctuation for global warning text || STY: Add EOF newline in TryExamples config file || Merge branch 'main' into interactive-docs || DOC: Remove some duplicate `import numpy` statements

[skip cirrus] [skip azp] || DOC: Remove implicit assumption about import

[skip cirrus] [skip azp] || DOC, REL: Update interactivity goal to NumPy v2.1.0

Co-Authored-By: Ralf Gommers <ralf.gommers@gmail.com> || DOC: Add missing `np.strings.add` interactive example || DOC: Disable a few non-relevant pages

Pages such as those related to packaging
via `numpy.distutils`, `typing`, and `f2py`
are not necessarily required to run in
interactive mode and do not offer much in
terms of examples to the user in general. || DOC: Remove code block directives (`_typing/_add_docstring.py`)

[skip azp] [skip cirrus] || DOC: Fix docs build failure from rubrics warnings

This reverts commit 905279a38266c43a7a0ed78c163c2690860184f5.

[skip azp] [skip cirrus] || DOC: Fix indentation for `np.strings.add()` example || DOC: Clean up file paths to be ignored

[skip actions] [skip azp] [skip cirrus] || DOC: Fix dark text for interactive example buttons

[skip azp] [skip cirrus] [skip actions] || DOC: Make `numpy.strings` pages non-interactive

and properly escape regex patterns for other pages.

[skip azp] [skip cirrus] [skip actions] || DOC: Better selector ordering for dark mode || Merge branch 'main' into interactive-docs || Bump to `jupyterlite-sphinx` version 0.16.4

[skip azp] [skip cirrus] [skip actions] || Bump to `jupyterlite-sphinx` v0.16.5 || Bump to `jupyterlite-sphinx` >=0.17.1, `jupyterlite-pyodide-kernel` 0.4.7 || Update milestone for interactive documentation || Merge branch 'main' into interactive-docs || Use Pyodide kernel from `pip` in the meantime || NumPy strings API examples should now work || Disable JupyterLite source maps for smaller builds

[skip actions] [skip azp] [skip cirrus] || `jupyterlite-pyodide-kernel` 0.4.7 is now available on conda-forge

This reverts commit ef3f14b13ab539078dab72b5b38d282d0780d8aa.

[skip actions] [skip azp] [skip cirrus] || Bump `jupyterlite-sphinx` and associated Pyodide kernel

[skip actions] [skip azp] [skip cirrus] || Bump JupyterLite dependencies in docs reqs as well

[skip actions] [skip azp] [skip cirrus] || Fix incorrect constraint for `jupyterlite-sphinx`

[skip actions] [skip azp] [skip cirrus] || Bump to Pyodide kernel 0.5.1; brings Pyodide 0.27.1

[skip actions] [skip azp] [skip cirrus] || Merge branch 'main' into interactive-docs || Bump to `jupyterlite-pyodide-kernel` 0.5.2

[skip actions] [skip azp] [skip cirrus]"
numpy/numpy,jorenham,28239,TYP: `union1d` outputs `dtype[floating[_64Bit]]` which is incompatible with `dtype[float64]]`,"### Describe the issue:

While type checking, `numpy.union1d` outputs an array of type `ndarray[tuple[int, ...], dtype[floating[_64Bit]]]` even if both the arguments are of the type `ndarray[tuple[int, ...], dtype[float64]]` -- failing mypy checks.

### Reproduce the code example:

```python
import numpy.typing as npt
import numpy as np


def do_something(a: npt.NDArray[np.float64], b: npt.NDArray[np.float64]) -> npt.NDArray[np.float64]:
    return np.union1d(a, b)
```

### Error message:

```shell
% mypy mypy_rep.py

mypy_rep.py:6: error: Incompatible return value type (got ""ndarray[tuple[int, ...], dtype[floating[_64Bit]]]"", expected ""ndarray[tuple[int, ...], dtype[float64]]"")  [return-value]
Found 1 error in 1 file (checked 1 source file)
```

### Python and NumPy Versions:

2.2.2
3.13.1 (main, Dec  3 2024, 17:59:52) [Clang 16.0.0 (clang-1600.0.26.4)]

---

mypy 1.14.1 (compiled: yes)
No extra configuration

### Runtime Environment:

[{'numpy_version': '2.2.2',
  'python': '3.13.1 (main, Dec  3 2024, 17:59:52) [Clang 16.0.0 '
            '(clang-1600.0.26.4)]',
  'uname': uname_result(system='Darwin', node='Saranshs-MacBook-Pro.local', release='24.2.0', version='Darwin Kernel Version 24.2.0: Fri Dec  6 19:02:41 PST 2024; root:xnu-11215.61.5~2/RELEASE_ARM64_T6030', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}}]


### Context for the issue:

_No response_","Oops, filed it under BUG instead of TYP, my bad! Have included type checker's information in the original report. || > Oops, filed it under BUG instead of TYP, my bad! Have included type checker's information in the original report.

No worries :)  || Thanks for this report! I certainly agree that this is an annoying issue...


## minimal `.pyi` repro

```pyi
import numpy as np

a: np.ndarray[tuple[int, ...], np.dtype[np.float64]]
reveal_type(np.union1d(a, a))
```

## mypy 1.14.1

```
Revealed type is ""ndarray[tuple[int, ...], dtype[floating[_64Bit]]]""
```

<sub>(I removed the module prefixes to make it ~more readable~ less unreadable)</sub>

## pyright 1.1.392 (PyLance)

```
Type of ""np.union1d(a, a)"" is ""ndarray[tuple[int, ...], dtype[floating[_64Bit]]]""
```

## possible workarounds

- explicitly `typing.cast` the result of `np.union1d` to `npt.NDArray[np.float64]`
- sneakily modify `do_something` to return `npt.NDArray[np.double]` (but depending on what you do with the returned value, this might require more such changes) || Thanks for fixing this!",closed,2025-01-28T15:22:48+00:00,2025-01-28T17:41:49+00:00,Saransh-cpp,"00 - Bug, 41 - Static typing",2,"PR#28243 - numpy/lib/_arraysetops_impl.pyi: @@ -10,35 +10,7 @@ from typing import (|;| from typing_extensions import deprecated|;| |;| import numpy as np|;|-from numpy import (|;|-    generic,|;|-    number,|;|-    ushort,|;|-    ubyte,|;|-    uintc,|;|-    uint,|;|-    ulonglong,|;|-    short,|;|-    int8,|;|-    byte,|;|-    intc,|;|-    int_,|;|-    intp,|;|-    longlong,|;|-    half,|;|-    single,|;|-    double,|;|-    longdouble,|;|-    csingle,|;|-    cdouble,|;|-    clongdouble,|;|-    timedelta64,|;|-    datetime64,|;|-    object_,|;|-    str_,|;|-    bytes_,|;|-    void,|;|-)|;|+from numpy import generic, number, int8, intp, timedelta64, object_|;| |;| from numpy._typing import (|;|     ArrayLike,|;|@@ -75,33 +47,17 @@ _NumberType = TypeVar(""_NumberType"", bound=number[Any])|;| # Only relevant if two or more arguments are parametrized, (e.g. `setdiff1d`)|;| # which could result in, for example, `int64` and `float64`producing a|;| # `number[_64Bit]` array|;|-_SCTNoCast = TypeVar(|;|-    ""_SCTNoCast"",|;|+_EitherSCT = TypeVar(|;|+    ""_EitherSCT"",|;|     np.bool,|;|-    ushort,|;|-    ubyte,|;|-    uintc,|;|-    uint,|;|-    ulonglong,|;|-    short,|;|-    byte,|;|-    intc,|;|-    int_,|;|-    longlong,|;|-    half,|;|-    single,|;|-    double,|;|-    longdouble,|;|-    csingle,|;|-    cdouble,|;|-    clongdouble,|;|-    timedelta64,|;|-    datetime64,|;|-    object_,|;|-    str_,|;|-    bytes_,|;|-    void,|;|-)|;|+    np.int8, np.int16, np.int32, np.int64, np.intp,|;|+    np.uint8, np.uint16, np.uint32, np.uint64, np.uintp,|;|+    np.float16, np.float32, np.float64, np.longdouble,|;|+    np.complex64, np.complex128, np.clongdouble,|;|+    np.timedelta64, np.datetime64,|;|+    np.bytes_, np.str_, np.void, np.object_,|;|+    np.integer, np.floating, np.complexfloating, np.character,|;|+)  # fmt: skip|;| |;| class UniqueAllResult(NamedTuple, Generic[_SCT]):|;|     values: NDArray[_SCT]|;|@@ -339,11 +295,11 @@ def unique_values(x: ArrayLike, /) -> NDArray[Any]: ...|;| |;| @overload|;| def intersect1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|     return_indices: L[False] = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def intersect1d(|;|     ar1: ArrayLike,|;|@@ -353,11 +309,11 @@ def intersect1d(|;| ) -> NDArray[Any]: ...|;| @overload|;| def intersect1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|     return_indices: L[True] = ...,|;|-) -> tuple[NDArray[_SCTNoCast], NDArray[intp], NDArray[intp]]: ...|;|+) -> tuple[NDArray[_EitherSCT], NDArray[intp], NDArray[intp]]: ...|;| @overload|;| def intersect1d(|;|     ar1: ArrayLike,|;|@@ -368,10 +324,10 @@ def intersect1d(|;| |;| @overload|;| def setxor1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def setxor1d(|;|     ar1: ArrayLike,|;|@@ -400,9 +356,9 @@ def in1d(|;| |;| @overload|;| def union1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|-) -> NDArray[_SCTNoCast]: ...|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def union1d(|;|     ar1: ArrayLike,|;|@@ -411,10 +367,10 @@ def union1d(|;| |;| @overload|;| def setdiff1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def setdiff1d(|;|     ar1: ArrayLike, || PR#28243 - numpy/typing/tests/data/reveal/arraysetops.pyi: @@ -2,10 +2,7 @@ from typing import Any|;| |;| import numpy as np|;| import numpy.typing as npt|;|-from numpy.lib._arraysetops_impl import (|;|-    UniqueAllResult, UniqueCountsResult, UniqueInverseResult|;|-)|;|-from numpy._typing import _64Bit|;|+from numpy.lib._arraysetops_impl import UniqueAllResult, UniqueCountsResult, UniqueInverseResult|;| |;| from typing_extensions import assert_type|;| |;|@@ -28,7 +25,7 @@ assert_type(np.intersect1d(AR_M, AR_M, assume_unique=True), npt.NDArray[np.datet|;| assert_type(np.intersect1d(AR_f8, AR_i8), npt.NDArray[Any])|;| assert_type(|;|     np.intersect1d(AR_f8, AR_f8, return_indices=True),|;|-    tuple[npt.NDArray[np.floating[_64Bit]], npt.NDArray[np.intp], npt.NDArray[np.intp]],|;|+    tuple[npt.NDArray[np.float64], npt.NDArray[np.intp], npt.NDArray[np.intp]],|;| )|;| |;| assert_type(np.setxor1d(AR_i8, AR_i8), npt.NDArray[np.int64]) || PR#28241 - numpy/lib/_arraysetops_impl.pyi: @@ -10,35 +10,7 @@ from typing import (|;| from typing_extensions import deprecated|;| |;| import numpy as np|;|-from numpy import (|;|-    generic,|;|-    number,|;|-    ushort,|;|-    ubyte,|;|-    uintc,|;|-    uint,|;|-    ulonglong,|;|-    short,|;|-    int8,|;|-    byte,|;|-    intc,|;|-    int_,|;|-    intp,|;|-    longlong,|;|-    half,|;|-    single,|;|-    double,|;|-    longdouble,|;|-    csingle,|;|-    cdouble,|;|-    clongdouble,|;|-    timedelta64,|;|-    datetime64,|;|-    object_,|;|-    str_,|;|-    bytes_,|;|-    void,|;|-)|;|+from numpy import generic, number, int8, intp, timedelta64, object_|;| |;| from numpy._typing import (|;|     ArrayLike,|;|@@ -75,33 +47,17 @@ _NumberType = TypeVar(""_NumberType"", bound=number[Any])|;| # Only relevant if two or more arguments are parametrized, (e.g. `setdiff1d`)|;| # which could result in, for example, `int64` and `float64`producing a|;| # `number[_64Bit]` array|;|-_SCTNoCast = TypeVar(|;|-    ""_SCTNoCast"",|;|+_EitherSCT = TypeVar(|;|+    ""_EitherSCT"",|;|     np.bool,|;|-    ushort,|;|-    ubyte,|;|-    uintc,|;|-    uint,|;|-    ulonglong,|;|-    short,|;|-    byte,|;|-    intc,|;|-    int_,|;|-    longlong,|;|-    half,|;|-    single,|;|-    double,|;|-    longdouble,|;|-    csingle,|;|-    cdouble,|;|-    clongdouble,|;|-    timedelta64,|;|-    datetime64,|;|-    object_,|;|-    str_,|;|-    bytes_,|;|-    void,|;|-)|;|+    np.int8, np.int16, np.int32, np.int64, np.intp,|;|+    np.uint8, np.uint16, np.uint32, np.uint64, np.uintp,|;|+    np.float16, np.float32, np.float64, np.longdouble,|;|+    np.complex64, np.complex128, np.clongdouble,|;|+    np.timedelta64, np.datetime64,|;|+    np.bytes_, np.str_, np.void, np.object_,|;|+    np.integer, np.floating, np.complexfloating, np.character,|;|+)  # fmt: skip|;| |;| class UniqueAllResult(NamedTuple, Generic[_SCT]):|;|     values: NDArray[_SCT]|;|@@ -339,11 +295,11 @@ def unique_values(x: ArrayLike, /) -> NDArray[Any]: ...|;| |;| @overload|;| def intersect1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|     return_indices: L[False] = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def intersect1d(|;|     ar1: ArrayLike,|;|@@ -353,11 +309,11 @@ def intersect1d(|;| ) -> NDArray[Any]: ...|;| @overload|;| def intersect1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|     return_indices: L[True] = ...,|;|-) -> tuple[NDArray[_SCTNoCast], NDArray[intp], NDArray[intp]]: ...|;|+) -> tuple[NDArray[_EitherSCT], NDArray[intp], NDArray[intp]]: ...|;| @overload|;| def intersect1d(|;|     ar1: ArrayLike,|;|@@ -368,10 +324,10 @@ def intersect1d(|;| |;| @overload|;| def setxor1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def setxor1d(|;|     ar1: ArrayLike,|;|@@ -400,9 +356,9 @@ def in1d(|;| |;| @overload|;| def union1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|-) -> NDArray[_SCTNoCast]: ...|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def union1d(|;|     ar1: ArrayLike,|;|@@ -411,10 +367,10 @@ def union1d(|;| |;| @overload|;| def setdiff1d(|;|-    ar1: _ArrayLike[_SCTNoCast],|;|-    ar2: _ArrayLike[_SCTNoCast],|;|+    ar1: _ArrayLike[_EitherSCT],|;|+    ar2: _ArrayLike[_EitherSCT],|;|     assume_unique: bool = ...,|;|-) -> NDArray[_SCTNoCast]: ...|;|+) -> NDArray[_EitherSCT]: ...|;| @overload|;| def setdiff1d(|;|     ar1: ArrayLike, || PR#28241 - numpy/typing/tests/data/reveal/arraysetops.pyi: @@ -2,10 +2,7 @@ from typing import Any|;| |;| import numpy as np|;| import numpy.typing as npt|;|-from numpy.lib._arraysetops_impl import (|;|-    UniqueAllResult, UniqueCountsResult, UniqueInverseResult|;|-)|;|-from numpy._typing import _64Bit|;|+from numpy.lib._arraysetops_impl import UniqueAllResult, UniqueCountsResult, UniqueInverseResult|;| |;| from typing_extensions import assert_type|;| |;|@@ -28,7 +25,7 @@ assert_type(np.intersect1d(AR_M, AR_M, assume_unique=True), npt.NDArray[np.datet|;| assert_type(np.intersect1d(AR_f8, AR_i8), npt.NDArray[Any])|;| assert_type(|;|     np.intersect1d(AR_f8, AR_f8, return_indices=True),|;|-    tuple[npt.NDArray[np.floating[_64Bit]], npt.NDArray[np.intp], npt.NDArray[np.intp]],|;|+    tuple[npt.NDArray[np.float64], npt.NDArray[np.intp], npt.NDArray[np.intp]],|;| )|;| |;| assert_type(np.setxor1d(AR_i8, AR_i8), npt.NDArray[np.int64])",TYP: Avoid upcasting ``float64`` in the set-ops || TYP: Avoid upcasting ``float64`` in the set-ops
numpy/numpy,ngoldbaum,28106,Building NumPy from source for Windows on ARM using Clang-cl compiler,"Hello Developers,

- I am facing an issue while trying to build NumPy for Windows on ARM (WoA) using the Clang-cl compiler. Building NumPy from source requires C and C++ compilers with proper intrinsic support.
- Previously, I was able to successfully compile NumPy for WoA using the MSVC-optimized C/C++ CL compiler, enabling CPU baseline features that support ARM. 
- However, I encountered limitations with the MSVC C/C++ CL compiler, as it does not support certain CPU dispatcher features like ASIMDHP, ASIMDFHM, and SVE. Is there any specific reason why these CPU dispatch features are not supported for WoA in MSVC?
- Meanwhile, I attempted to compile NumPy for WoA using the clang-cl compiler (both from MSVC and LLVM toolchains) to check if the CPU dispatcher features would be enabled. While I found that, apart from SVE, all other test features—including baseline features—were supported, I ran into compilation errors due to unidentified instructions.

Steps to Reproduce

1. Clone the Source code of NumPy and checkout to latest branch
2. Install LLVM toolchain/MSVC clang toolset 
3. Remove the clang and clang++ from the bin directory to avoid conflicts 
4. Add the bin path at the top of environment path variable

Compilers used for compilation:
![image](https://github.com/user-attachments/assets/a37987bf-80a3-420a-9891-5c8a4df74bf0)

Error and Workaround:

1. While building meson_cpu target, got an error with respect to invalid operand ""fstcw"" in multiarray_tests_c source file. Upon going through source code, the fstcw is floating-point control instructions for x86 assembly. So I made workaround to make one more condition to check whether it is a ARM64 arch build. Then the build proceeded:
![Screenshot 2025-01-06 123245](https://github.com/user-attachments/assets/b43a2620-179e-4c51-9fe1-0498a84d3dea)
Workaround:
before:
![image](https://github.com/user-attachments/assets/50835ace-b063-49b8-ae0a-f0c750c7071d)
After:
![image](https://github.com/user-attachments/assets/dc3bea26-fc30-4438-9583-5f8116545f8c)

Issue:

1. Currently the build fails at 240+ targets while compiling meson_cpu due to unidentified assembly instructions:
![image](https://github.com/user-attachments/assets/9acb3673-e660-481f-ac77-17df9500dd2d)

Can anyone give some suggestions to overcome this issue? I need enable CPU dispatch support for NumPy on WoA to get better optimised version of NumPy.

Thanks! 
 ","Ping @Mousius, might be interesting to you (or you have a quick idea). || @Mousius Any suggestions on this issue?
 || These look like MSVC intrinsics - https://learn.microsoft.com/en-us/cpp/intrinsics/arm64-intrinsics?view=msvc-170. We do not have support for all of these in clang-cl at the moment.

Just 2 days ago someone asked about this in fact - https://github.com/llvm/llvm-project/issues/121689.

Without knwoing the numpy source code I can't suggest how to work around this, but the table on the Microsoft page tells you what each one does and for example, one of them produces the https://developer.arm.com/documentation/100069/0606/Data-Transfer-Instructions/LDARB instruction. So in theory you could use alternative APIs to do the same thing.

If anyone needs help figuring out the details of what the instructions do, I can help with that.

As for adding these intrinsics to clang-cl, I'll expand on that in the LLVM issue. || Ah, sorry, I misdiagnosed thinking it was related to SIMD (the second screenshot is so small... text would be easier).

This seems to be related to the atomics definitions, ping @ngoldbaum, I thought these are borrowed from Python, so it seems a bit surprising. || As a temporary workaround, it might work to edit the source so that the `#ifdef STDC_ATOMICS` branch is used instead (https://github.com/numpy/numpy/blob/1d7708233e801f032c22656413f9172fda00b7a1/numpy/_core/src/common/npy_atomic.h#L37).

> I thought these are borrowed from Python

I recall Linaro doing work for Windows on Arm Python but it may not have been using clang-cl.

Edit: It was all done with msvc/Visual Studio not clang-cl. || Is there any other workarounds I could perform for compiling NumPy on WoA? || Unless you want to dig into it yourself, please be patient for at least a few days.  This will be fixed, but don't expect it to be fixed within hours. || I can install Windows in a VM on my ARM Macbook and hopefully reproduce this. Sorry for the trouble...

By the way, what command are you using to build NumPy? IIRC you need to go a little out of your way to build with clang-cl properly. || > As a temporary workaround, it might work to edit the source so that the #ifdef STDC_ATOMICS branch is used instead

Is there a reason why STDC_ATOMICS isn't defined on the reporter's system? || I just successfully built NumPy after making the patch to `_multiarray_tests.c.src` suggested by OP. I do not see the same error about missing intrinsics as it seems clang-cl on my system is going into the `STDC_ATOMICS` branch as I expected it to do originally.

I suspect that there is something subtly wrong about the OP's compilation environment. Here's how I built NumPy, doing all this in a checkout of the NumPy repo:

```powershell
""[binaries]"",""c = 'clang-cl'"",""cpp = 'clang-cl'"",""ar = 'llvm-lib'"",""c_ld = 'lld-link'"",""cpp_ld = 'lld-link'"" | Out-File $PWD/clang-cl-build.ini -Encoding ascii
pip install -r requirements/build_requirements.txt
spin build -- --vsenv --native-file=$PWD/clang-cl-build.ini
```

Or alternatively via `pip` to actually install the numpy build:

```powershell
python -m pip install -v . --no-build-isolation -C'setup-args=--vsenv' -C'setup-args=--native-file='$PWD'\clang-cl-build.ini'
```

I did this following our CI setup on github actions for clang-cl. || OP is short for original post, I was referring to the patch you found for the multiarray tests file.

You should be able to build NumPy using one of the commands I shared in my last comment after applying the patch you suggested for the tests file. 

At least right now with `clang-cl` it is *not* sufficient to build just use `spin build`, you need to do something a little more involved to insure the clang toolchain is being used.

Please feel free to send in a pull request for the fix you found for the multiarray tests file. || @ngoldbaum the following is my workflow to build NumPy natively on WoA

1. Installed LLVM toolchain for WoA 19.1.0 from releases.
2. Added the LLVM\bin path to the environment variables
3. Then I applied the patch in the OP to make sure that it was able to compile multiarray_umath_Test with out any errors
4. Then I created the build configuration file clang_cl_ini.build that you were mentioning in the below command
`""[binaries]"",""c = 'clang-cl'"",""cpp = 'clang-cl'"",""ar = 'llvm-lib'"",""c_ld = 'lld-link'"",""cpp_ld = 'lld-link'"" | Out-File $PWD/clang-cl-build.ini -Encoding ascii`
5. Before getting starting with the build, I make sure that build uses LLVM's clang-cl rather than msvc build of clang-cl
![image](https://github.com/user-attachments/assets/d7120a92-d2a5-45d0-a541-7ba7928e8128)
6. I proceeded with build by using the following commands:
`pip install -r requirements/build_requirements.txt
spin build -- --vsenv --native-file=$PWD/clang-cl-build.ini`

But still the error points out to the same issue:
![image](https://github.com/user-attachments/assets/a551fd7c-2c24-434c-85d8-4f6b2e5a696d)

As per logic you said the code flow should enter stdatomic but still the definiton fails out to enter it || I used MSVC's build of clang-cl. I don't know if it's possible to use clang's. Ping @rgommers who knows more about this than me. || It should be possible in principle; we use `clang-cl` from the Clang feedstock in conda-forge to build SciPy for example. 

I have no knowledge specific to WoA + Clang-cl though. || I'm confused why `STDC_ATOMIC` isn't defined on your setup - it definitely should be on clang 19. I would try to debug why that's happening. || Just to say - I also have a WoA machine, with clang-cl (from the LLVM install), and cl, and I get the same error (after applying the same fix as above to get the compilation to that point).

I think the problem occurs because - at the stage of the error - this is a C++ compile (of `../numpy/_core/src/umath/dispatching.cpp`) and, sure enough,  `__STDC_VERSION__` is not defined for the C++ compile.

Does this relate to the comment in `npy_atomic.h`: `\\ TODO: support C++ atomics as well if this header is ever needed in C++`? || > Does this relate to the comment in npy_atomic.h: \\ TODO: support C++ atomics as well if this header is ever needed in C++?

That makes perfect sense!!

Yes, I suspect making that header properly support C++ would fix this. There must be some hack or subtlety in how the defines are set up on Unix GCC and Clang that lets it find the correct define but clang-cl doesn't pick it up. || See https://github.com/numpy/numpy/pull/28234 || I marked that PR as fixing this issue but I didn't actually test that, I'd appreciate it if someone with a WoA system and clang-cl installed outside of MSVC can test. || I'm sure you saw this in my comment on your PR - but yes - with my other PR (version of @Mugundanmcw fix above for FPU instruction) - WoA compile runs to completion with `clang-cl`. || Thanks to @matthew-brett and @ngoldbaum for addressing the issue! Now I can able to build NumPy with LLVM clang-cl on a Native WoA device.",closed,2025-01-06T07:14:58+00:00,2025-01-27T17:09:03+00:00,Mugundanmcw,component: SIMD,2,"PR#28236 - numpy/_core/src/common/npy_atomic.h: @@ -9,11 +9,18 @@|;| |;| #include ""numpy/npy_common.h""|;| |;|-#if defined(__STDC_VERSION__) && __STDC_VERSION__ >= 201112L \|;|+#ifdef __cplusplus|;|+    extern ""C++"" {|;|+        #include <atomic>|;|+    }|;|+    #define _NPY_USING_STD using namespace std|;|+    #define _Atomic(tp) atomic<tp>|;|+    #define STDC_ATOMICS|;|+#elif defined(__STDC_VERSION__) && __STDC_VERSION__ >= 201112L \|;|     && !defined(__STDC_NO_ATOMICS__)|;|-// TODO: support C++ atomics as well if this header is ever needed in C++|;|     #include <stdatomic.h>|;|     #include <stdint.h>|;|+    #define _NPY_USING_STD|;|     #define STDC_ATOMICS|;| #elif _MSC_VER|;|     #include <intrin.h>|;|@@ -35,6 +42,7 @@|;| static inline npy_uint8|;| npy_atomic_load_uint8(const npy_uint8 *obj) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     return (npy_uint8)atomic_load((const _Atomic(uint8_t)*)obj)|;|; #elif defined(MSC_ATOMICS)|;| #if defined(_M_X64) || defined(_M_IX86)|;|@@ -50,6 +58,7 @@ npy_atomic_load_uint8(const npy_uint8 *obj) {|;| static inline void*|;| npy_atomic_load_ptr(const void *obj) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     return atomic_load((const _Atomic(void *)*)obj)|;|; #elif defined(MSC_ATOMICS)|;| #if SIZEOF_VOID_P == 8|;|@@ -73,6 +82,7 @@ npy_atomic_load_ptr(const void *obj) {|;| static inline void|;| npy_atomic_store_uint8(npy_uint8 *obj, npy_uint8 value) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     atomic_store((_Atomic(uint8_t)*)obj, value)|;|; #elif defined(MSC_ATOMICS)|;|     _InterlockedExchange8((volatile char *)obj, (char)value)|;|;@@ -85,6 +95,7 @@ static inline void|;| npy_atomic_store_ptr(void *obj, void *value)|;| {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     atomic_store((_Atomic(void *)*)obj, value)|;|; #elif defined(MSC_ATOMICS)|;|     _InterlockedExchangePointer((void * volatile *)obj, (void *)value); || PR#28234 - numpy/_core/src/common/npy_atomic.h: @@ -9,11 +9,18 @@|;| |;| #include ""numpy/npy_common.h""|;| |;|-#if defined(__STDC_VERSION__) && __STDC_VERSION__ >= 201112L \|;|+#ifdef __cplusplus|;|+    extern ""C++"" {|;|+        #include <atomic>|;|+    }|;|+    #define _NPY_USING_STD using namespace std|;|+    #define _Atomic(tp) atomic<tp>|;|+    #define STDC_ATOMICS|;|+#elif defined(__STDC_VERSION__) && __STDC_VERSION__ >= 201112L \|;|     && !defined(__STDC_NO_ATOMICS__)|;|-// TODO: support C++ atomics as well if this header is ever needed in C++|;|     #include <stdatomic.h>|;|     #include <stdint.h>|;|+    #define _NPY_USING_STD|;|     #define STDC_ATOMICS|;| #elif _MSC_VER|;|     #include <intrin.h>|;|@@ -35,6 +42,7 @@|;| static inline npy_uint8|;| npy_atomic_load_uint8(const npy_uint8 *obj) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     return (npy_uint8)atomic_load((const _Atomic(uint8_t)*)obj)|;|; #elif defined(MSC_ATOMICS)|;| #if defined(_M_X64) || defined(_M_IX86)|;|@@ -50,6 +58,7 @@ npy_atomic_load_uint8(const npy_uint8 *obj) {|;| static inline void*|;| npy_atomic_load_ptr(const void *obj) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     return atomic_load((const _Atomic(void *)*)obj)|;|; #elif defined(MSC_ATOMICS)|;| #if SIZEOF_VOID_P == 8|;|@@ -73,6 +82,7 @@ npy_atomic_load_ptr(const void *obj) {|;| static inline void|;| npy_atomic_store_uint8(npy_uint8 *obj, npy_uint8 value) {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     atomic_store((_Atomic(uint8_t)*)obj, value)|;|; #elif defined(MSC_ATOMICS)|;|     _InterlockedExchange8((volatile char *)obj, (char)value)|;|;@@ -85,6 +95,7 @@ static inline void|;| npy_atomic_store_ptr(void *obj, void *value)|;| {|;| #ifdef STDC_ATOMICS|;|+    _NPY_USING_STD|;|;     atomic_store((_Atomic(void *)*)obj, value)|;|; #elif defined(MSC_ATOMICS)|;|     _InterlockedExchangePointer((void * volatile *)obj, (void *)value);","BUG: Add cpp atomic support (#28234)

* BUG: add C++ support to npy_atomic.h

* MAINT: delete outdated comment || BUG: add C++ support to npy_atomic.h || MAINT: delete outdated comment"
numpy/numpy,ngoldbaum,28157,BUG: `StringDType`: `na_object` ignored in `full`,"### Describe the issue:

Creating a `StringDType` ndarray with `na_object` using `full` (and `full_like`) coerces the `nan` sentinel to a string. 

I can work around this using `arr[:] = np.nan`, but think the behavior is unexpected.

### Reproduce the code example:

```python
import numpy as np

arr1 = np.full((1,), fill_value=np.nan, dtype=np.dtypes.StringDType(na_object=np.nan))

arr2 = np.full_like(arr1, fill_value=np.nan)

assert arr1.item() is np.nan
assert arr2.item() is np.nan
```

### Error message:

```python traceback
Traceback (most recent call last):
  File ""/Users/goldbaum/Documents/numpy/../numpy-experiments/test.py"", line 7, in <module>
    assert arr1.item() is np.nan
           ^^^^^^^^^^^^^^^^^^^^^
AssertionError
```

### Python and NumPy Versions:

2.2.1
3.12.8 | packaged by conda-forge | (main, Dec  5 2024, 14:24:40) [GCC 13.3.0]

### Runtime Environment:

[{'numpy_version': '2.2.1',
  'python': '3.12.8 | packaged by conda-forge | (main, Dec  5 2024, 14:24:40) '
            '[GCC 13.3.0]',
  'uname': uname_result(system='Linux', node='poisson', release='6.8.0-51-generic', version='#52~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Dec  9 15:00:52 UTC 2', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL',
                                    'AVX512_SPR']}},
 {'architecture': 'Haswell',
  'filepath': '/home/mathause/.conda/envs/regionmask_dev/lib/libopenblasp-r0.3.28.so',
  'internal_api': 'openblas',
  'num_threads': 8,
  'prefix': 'libopenblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

### Context for the issue:

_No response_","Thanks for the report, I can reproduce this on `main`. I agree that this is a bug. || See https://github.com/numpy/numpy/pull/28091#issuecomment-2596325417. I think I'll wait for that PR to land before fixing this. It will be a lot easier to debug without having to trace through macros in a C debugger too... || I opened https://github.com/numpy/numpy/pull/28228 || Thanks! ",closed,2025-01-15T15:07:14+00:00,2025-01-27T17:10:00+00:00,mathause,"00 - Bug, component: numpy.strings",1,"PR#28228 - numpy/_core/src/multiarray/stringdtype/casts.cpp: @@ -1208,14 +1208,35 @@ float_to_string(|;|     PyArray_StringDTypeObject *descr =|;|             (PyArray_StringDTypeObject *)context->descriptors[1]|;|;     npy_string_allocator *allocator = NpyString_acquire_allocator(descr)|;|;+    // borrowed reference|;|+    PyObject *na_object = descr->na_object|;|; |;|     while (N--) {|;|         PyObject *scalar_val = PyArray_Scalar(in, float_descr, NULL)|;|;+        if (descr->has_nan_na) {|;|+            // check for case when scalar_val is the na_object and store a null string|;|+            int na_cmp = na_eq_cmp(scalar_val, na_object)|;|;+            if (na_cmp < 0) {|;|+                Py_DECREF(scalar_val)|;|;+                goto fail|;|;+            }|;|+            if (na_cmp) {|;|+                Py_DECREF(scalar_val)|;|;+                if (NpyString_pack_null(allocator, (npy_packed_static_string *)out) < 0) {|;|+                    PyErr_SetString(PyExc_MemoryError,|;|+                                    ""Failed to pack null string during float ""|;|+                                    ""to string cast"")|;|;+                    goto fail|;|;+                }|;|+                goto next_step|;|;+            }|;|+        }|;|         // steals reference to scalar_val|;|         if (pyobj_to_string(scalar_val, out, allocator) == -1) {|;|             goto fail|;|;         }|;| |;|+      next_step:|;|         in += in_stride|;|;         out += out_stride|;|;     } || PR#28228 - numpy/_core/src/multiarray/stringdtype/dtype.c: @@ -144,7 +144,7 @@ new_stringdtype_instance(PyObject *na_object, int coerce)|;|     return NULL|;|; }|;| |;|-static int|;|+NPY_NO_EXPORT int|;| na_eq_cmp(PyObject *a, PyObject *b) {|;|     if (a == b) {|;|         // catches None and other singletons like Pandas.NA || PR#28228 - numpy/_core/src/multiarray/stringdtype/dtype.h: @@ -52,6 +52,9 @@ _eq_comparison(int scoerce, int ocoerce, PyObject *sna, PyObject *ona)|;|; NPY_NO_EXPORT int|;| stringdtype_compatible_na(PyObject *na1, PyObject *na2, PyObject **out_na)|;|; |;|+NPY_NO_EXPORT int|;|+na_eq_cmp(PyObject *a, PyObject *b)|;|;+|;| #ifdef __cplusplus|;| }|;| #endif || PR#28228 - numpy/_core/tests/test_stringdtype.py: @@ -735,6 +735,21 @@ def test_float_casts(typename):|;|     assert_array_equal(eres, res)|;| |;| |;|+def test_float_nan_cast_na_object():|;|+    # gh-28157|;|+    dt = np.dtypes.StringDType(na_object=np.nan)|;|+    arr1 = np.full((1,), fill_value=np.nan, dtype=dt)|;|+    arr2 = np.full_like(arr1, fill_value=np.nan)|;|+|;|+    assert arr1.item() is np.nan|;|+    assert arr2.item() is np.nan|;|+|;|+    inp = [1.2, 2.3, np.nan]|;|+    arr = np.array(inp).astype(dt)|;|+    assert arr[2] is np.nan|;|+    assert arr[0] == '1.2'|;|+|;|+|;| @pytest.mark.parametrize(|;|     ""typename"",|;|     [",BUG: handle case when StringDType na_object ia nan in float to string cast
numpy/numpy,sterrettm2,27983,MAINT: unused function warnings,"I get the following new compiler warnings on my Mac after pulling today:

```
../numpy/_core/src/umath/loops_hyperbolic.dispatch.cpp.src:154:30: warning: function 'lut_16_f64' is not needed and will not be emitted [-Wunneeded-internal-declaration]
  154 | HWY_ATTR NPY_FINLINE vec_f64 lut_16_f64(const double * lut, vec_u64 idx){
      |                              ^~~~~~~~~~
../numpy/_core/src/umath/loops_hyperbolic.dispatch.cpp.src:478:30: warning: function 'lut_32_f32' is not needed and will not be emitted [-Wunneeded-internal-declaration]
  478 | HWY_ATTR NPY_FINLINE vec_f32 lut_32_f32(const float * lut, vec_u32 idx){
      |                              ^~~~~~~~~~
2 warnings generated.
```

This is new but I'm not sure which recently merged PR it started with.","Must be https://github.com/numpy/numpy/pull/25934, CC @Mousius and @sterrettm2.",closed,2024-12-11T19:48:10+00:00,2025-01-24T15:32:52+00:00,ngoldbaum,,1,"PR#28223 - numpy/_core/src/umath/loops_hyperbolic.dispatch.cpp.src: @@ -151,7 +151,7 @@ store_vector(vtype vec, type_t* dst, npy_intp sdst, npy_intp len){|;| |;| #if NPY_SIMD_F64|;| |;|-HWY_ATTR NPY_FINLINE vec_f64 lut_16_f64(const double * lut, vec_u64 idx){|;|+[[maybe_unused]] HWY_ATTR NPY_FINLINE vec_f64 lut_16_f64(const double * lut, vec_u64 idx){|;|     if constexpr(hn::Lanes(f64) == 8){|;|         const vec_f64 lut0 = hn::Load(f64, lut)|;|;         const vec_f64 lut1 = hn::Load(f64, lut + 8)|;|;@@ -475,7 +475,7 @@ HWY_ATTR NPY_FINLINE hwy_f32x2 zip_f32(vec_f32 a, vec_f32 b){|;|     return res|;|; }|;| |;|-HWY_ATTR NPY_FINLINE vec_f32 lut_32_f32(const float * lut, vec_u32 idx){|;|+[[maybe_unused]] HWY_ATTR NPY_FINLINE vec_f32 lut_32_f32(const float * lut, vec_u32 idx){|;|     if constexpr(hn::Lanes(f32) == 16){|;|         const vec_f32 lut0 = hn::Load(f32, lut)|;|;         const vec_f32 lut1 = hn::Load(f32, lut + 16);",Add [[maybe_unused] to silence some warnings
numpy/numpy,ngoldbaum,28197,BUG: segfault in PyArray_Repeat on free-threaded build,"This script will sometimes segfault on the free-threaded build:

```python
import functools
import numpy as np
import threading

def somersd(x, y=None, alternative='two-sided'):
    return 

x0 = np.arange(10)
x1 = np.arange(10)
partialfunc = functools.partial(somersd, alternative='two-sided')

n_workers = 10
n_iterations = 100
barrier = threading.Barrier(n_workers)

def closure(*args, **kwargs):
    barrier.wait()
    for _ in range(n_iterations):
        x = np.repeat(x0, 2, axis=0)[::2]
        y = np.repeat(x1, 2, axis=0)[::2]
        partialfunc(x, y)

workers = []
for _ in range(0, n_workers):
    worker_kwargs = {}
    workers.append(
                threading.Thread(target=closure, args=tuple(), kwargs=worker_kwargs)
                    )

for worker in workers:
    worker.start()

for worker in workers:
    worker.join()
```

```
python3.13(7926,0x171eff000) malloc: Incorrect checksum for freed object 0x15482d400: probably modified after being freed.
Corrupt value: 0x0
python3.13(7926,0x171eff000) malloc: *** set a breakpoint in malloc_error_break to debug
```

lldb gives me the following C backtrace for one of the threads that segfaulted:

```
  * frame #0: 0x0000000100d91864 _multiarray_umath.cpython-313t-darwin.so`PyArray_Repeat at item_selection.c:796:21 [opt]
    frame #1: 0x0000000100d91810 _multiarray_umath.cpython-313t-darwin.so`PyArray_Repeat [inlined] npy_fastrepeat(n_outer=1, n=<unavailable>, nel=1, chunk=8, broadcast=<unavailable>, counts=0x0000600002dd08c0, new_data=<unavailable>, old_data=<unavailable>, elsize=8, cast_info=0x0000000170e06428, needs_custom_copy=0) at item_selection.c:842:20 [opt]
    frame #2: 0x0000000100d91740 _multiarray_umath.cpython-313t-darwin.so`PyArray_Repeat(aop=<unavailable>, op=<unavailable>, axis=<unavailable>) at item_selection.c:963:9 [opt]
    frame #3: 0x0000000100da652c _multiarray_umath.cpython-313t-darwin.so`array_repeat(self=0x0000053226ab8500, args=<unavailable>, kwds=<unavailable>) at methods.c:1224:44 [opt]
    frame #4: 0x000000010076b5e0 libpython3.13t.dylib`cfunction_call + 92
    frame #5: 0x000000010070772c libpython3.13t.dylib`_PyObject_Call + 244
    frame #6: 0x00000001008467d0 libpython3.13t.dylib`_PyEval_EvalFrameDefault + 13328
    frame #7: 0x000000010070756c libpython3.13t.dylib`PyObject_Vectorcall + 88
    frame #8: 0x0000000100d4fe90 _multiarray_umath.cpython-313t-darwin.so`dispatcher_vectorcall(self=0x0000053226a58570, args=<unavailable>, len_args=<unavailable>, kwnames=0x00000532260b9510) at arrayfunction_override.c:580:18 [opt]
    frame #9: 0x000000010070756c libpython3.13t.dylib`PyObject_Vectorcall + 88
    frame #10: 0x0000000100846f20 libpython3.13t.dylib`_PyEval_EvalFrameDefault + 15200
    frame #11: 0x000000010070a3e0 libpython3.13t.dylib`method_vectorcall + 328
    frame #12: 0x00000001009384b0 libpython3.13t.dylib`thread_run + 128
    frame #13: 0x00000001008ce538 libpython3.13t.dylib`pythread_wrapper + 28
    frame #14: 0x000000018d51c2e4 libsystem_pthread.dylib`_pthread_start + 136
```

 _Originally posted by @serge-sans-paille in [#2271](https://github.com/serge-sans-paille/pythran/issues/2271#issuecomment-2600960259)_","TSAN prints several errors, but the first thing it complains about is the in-place manipulation of the output of PyArray_DIMS here:

https://github.com/numpy/numpy/blob/1688e70e6dde01a00b25db8bd12f6729a5088fc1/numpy/_core/src/multiarray/item_selection.c#L926-L934

<details>

```
==================
WARNING: ThreadSanitizer: data race (pid=37880)
  Read of size 8 at 0x000105d01700 by thread T2:
    #0 PyArray_Repeat item_selection.c:902 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x1aec6c)
    #1 array_repeat methods.c:1224 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x1d0ae0)
    #2 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x1151c0)
    #3 _PyObject_Call call.c:361 (libpython3.13t.dylib:arm64+0x8024c)
    #4 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x8033c)
    #5 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe18)
    #6 _PyEval_Vector ceval.c:1811 (libpython3.13t.dylib:arm64+0x255288)
    #7 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80660)
    #8 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x7ffe4)
    #9 dispatcher_vectorcall arrayfunction_override.c:580 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x147fc0)
    #10 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x7ffe4)
    #11 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f3d8)
    #12 _PyEval_Vector ceval.c:1811 (libpython3.13t.dylib:arm64+0x255288)
    #13 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80660)
    #14 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x842cc)
    #15 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x802a4)
    #16 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x8033c)
    #17 thread_run _threadmodule.c:337 (libpython3.13t.dylib:arm64+0x3b6e78)
    #18 pythread_wrapper thread_pthread.h:243 (libpython3.13t.dylib:arm64+0x320c6c)

  Previous write of size 8 at 0x000105d01700 by thread T10:
    #0 PyArray_Repeat item_selection.c:926 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x1aed94)
    #1 array_repeat methods.c:1224 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x1d0ae0)
    #2 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x1151c0)
    #3 _PyObject_Call call.c:361 (libpython3.13t.dylib:arm64+0x8024c)
    #4 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x8033c)
    #5 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe18)
    #6 _PyEval_Vector ceval.c:1811 (libpython3.13t.dylib:arm64+0x255288)
    #7 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80660)
    #8 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x7ffe4)
    #9 dispatcher_vectorcall arrayfunction_override.c:580 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x147fc0)
    #10 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x7ffe4)
    #11 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f3d8)
    #12 _PyEval_Vector ceval.c:1811 (libpython3.13t.dylib:arm64+0x255288)
    #13 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80660)
    #14 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x842cc)
    #15 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x802a4)
    #16 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x8033c)
    #17 thread_run _threadmodule.c:337 (libpython3.13t.dylib:arm64+0x3b6e78)
    #18 pythread_wrapper thread_pthread.h:243 (libpython3.13t.dylib:arm64+0x320c6c)

  Location is heap block of size 16 at 0x000105d01700 allocated by main thread:
    #0 malloc <null> (libclang_rt.tsan_osx_dynamic.dylib:arm64+0x61a84)
    #1 _PyMem_RawMalloc obmalloc.c:62 (libpython3.13t.dylib:arm64+0x140c88)
    #2 PyMem_RawMalloc obmalloc.c:948 (libpython3.13t.dylib:arm64+0x142844)
    #3 npy_alloc_cache_dim alloc.c:208 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x136c38)
    #4 PyArray_NewFromDescr_int ctors.c:757 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x167fd0)
    #5 PyArray_ArangeObj ctors.c:3407 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x170770)
    #6 array_arange multiarraymodule.c:3100 (_multiarray_umath.cpython-313t-darwin.so:arm64+0x1dd438)
    #7 cfunction_vectorcall_FASTCALL_KEYWORDS methodobject.c:441 (libpython3.13t.dylib:arm64+0x1144dc)
    #8 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x7ffe4)
    #9 _PyEval_EvalFrameDefault generated_cases.c.h:813 (libpython3.13t.dylib:arm64+0x25e5e0)
    #10 PyEval_EvalCode ceval.c:601 (libpython3.13t.dylib:arm64+0x254f78)
    #11 run_eval_code_obj pythonrun.c:1337 (libpython3.13t.dylib:arm64+0x305234)
    #12 run_mod pythonrun.c:1422 (libpython3.13t.dylib:arm64+0x3049c0)
    #13 _PyRun_SimpleFileObject pythonrun.c:490 (libpython3.13t.dylib:arm64+0x3006f4)
    #14 _PyRun_AnyFileObject pythonrun.c:77 (libpython3.13t.dylib:arm64+0x2fff60)
    #15 pymain_run_file main.c:429 (libpython3.13t.dylib:arm64+0x336a60)
    #16 Py_RunMain main.c:776 (libpython3.13t.dylib:arm64+0x335d28)
    #17 pymain_main main.c:806 (libpython3.13t.dylib:arm64+0x3360cc)
    #18 Py_BytesMain main.c:830 (libpython3.13t.dylib:arm64+0x3361a4)
    #19 main <null> (python3.13:arm64+0x100003ec4)

  Thread T2 (tid=74654464, running) created by main thread at:
    #0 pthread_create <null> (libclang_rt.tsan_osx_dynamic.dylib:arm64+0x31050)
    #1 do_start_joinable_thread thread_pthread.h:290 (libpython3.13t.dylib:arm64+0x31f8d8)
    #2 PyThread_start_joinable_thread thread_pthread.h:314 (libpython3.13t.dylib:arm64+0x31f71c)
    #3 do_start_new_thread _threadmodule.c:1849 (libpython3.13t.dylib:arm64+0x3b6a24)
    #4 thread_PyThread_start_joinable_thread _threadmodule.c:1972 (libpython3.13t.dylib:arm64+0x3b5ae0)
    #5 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x1151c0)
    #6 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f428)
    #7 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x80080)
    #8 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f3d8)
    #9 PyEval_EvalCode ceval.c:601 (libpython3.13t.dylib:arm64+0x254f78)
    #10 run_eval_code_obj pythonrun.c:1337 (libpython3.13t.dylib:arm64+0x305234)
    #11 run_mod pythonrun.c:1422 (libpython3.13t.dylib:arm64+0x3049c0)
    #12 _PyRun_SimpleFileObject pythonrun.c:490 (libpython3.13t.dylib:arm64+0x3006f4)
    #13 _PyRun_AnyFileObject pythonrun.c:77 (libpython3.13t.dylib:arm64+0x2fff60)
    #14 pymain_run_file main.c:429 (libpython3.13t.dylib:arm64+0x336a60)
    #15 Py_RunMain main.c:776 (libpython3.13t.dylib:arm64+0x335d28)
    #16 pymain_main main.c:806 (libpython3.13t.dylib:arm64+0x3360cc)
    #17 Py_BytesMain main.c:830 (libpython3.13t.dylib:arm64+0x3361a4)
    #18 main <null> (python3.13:arm64+0x100003ec4)

  Thread T10 (tid=74654472, running) created by main thread at:
    #0 pthread_create <null> (libclang_rt.tsan_osx_dynamic.dylib:arm64+0x31050)
    #1 do_start_joinable_thread thread_pthread.h:290 (libpython3.13t.dylib:arm64+0x31f8d8)
    #2 PyThread_start_joinable_thread thread_pthread.h:314 (libpython3.13t.dylib:arm64+0x31f71c)
    #3 do_start_new_thread _threadmodule.c:1849 (libpython3.13t.dylib:arm64+0x3b6a24)
    #4 thread_PyThread_start_joinable_thread _threadmodule.c:1972 (libpython3.13t.dylib:arm64+0x3b5ae0)
    #5 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x1151c0)
    #6 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f428)
    #7 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x80080)
    #8 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f3d8)
    #9 PyEval_EvalCode ceval.c:601 (libpython3.13t.dylib:arm64+0x254f78)
    #10 run_eval_code_obj pythonrun.c:1337 (libpython3.13t.dylib:arm64+0x305234)
    #11 run_mod pythonrun.c:1422 (libpython3.13t.dylib:arm64+0x3049c0)
    #12 _PyRun_SimpleFileObject pythonrun.c:490 (libpython3.13t.dylib:arm64+0x3006f4)
    #13 _PyRun_AnyFileObject pythonrun.c:77 (libpython3.13t.dylib:arm64+0x2fff60)
    #14 pymain_run_file main.c:429 (libpython3.13t.dylib:arm64+0x336a60)
    #15 Py_RunMain main.c:776 (libpython3.13t.dylib:arm64+0x335d28)
    #16 pymain_main main.c:806 (libpython3.13t.dylib:arm64+0x3360cc)
    #17 Py_BytesMain main.c:830 (libpython3.13t.dylib:arm64+0x3361a4)
    #18 main <null> (python3.13:arm64+0x100003ec4)

SUMMARY: ThreadSanitizer: data race item_selection.c:902 in PyArray_Repeat
```

</details> || btw @serge-sans-paille I bet it would be productive to run the pythran tests using a Python stack compiled with TSAN, see: https://py-free-threading.github.io/debugging/#compile-free-threaded-cpython-with-tsan || Grepping the codebase finds this pattern in a few more places:

```
± rg ""PyArray_DIMS.+=.+""\;
numpy/_core/src/multiarray/shape.c
703:        PyArray_DIMS(ret)[i] = PyArray_DIMS(ap)[permutation[i]];

numpy/_core/src/multiarray/ctors.c
3609:                PyArray_DIMS(r)[0] = *nread;
3721:        PyArray_DIMS(ret)[0] = nread;
4048:            PyArray_DIMS(ret)[0] = elcount;
4105:    PyArray_DIMS(ret)[0] = i;

numpy/_core/src/multiarray/getset.c
459:            PyArray_DIMS(self)[axis] *= newdim;
472:            PyArray_DIMS(self)[axis] = newdim / newtype->elsize;
```

The only problematic one is in `getset.c`, and happens inside `array_descr_set`, if you replace an array's descriptor with a dtype that has a bigger or smaller `elsize`, it will expand or shrink the last dimension to fit. In that case you *are* mutating the array, so I don't think we can really make it thread safe without adding locking. || Also it looks like creating a function-local `NPY_NDIMS` dimensions array and copying the original array's dimensions into that seems to fix the segfault and all the TSAN warnings.",closed,2025-01-20T16:04:12+00:00,2025-01-21T15:31:05+00:00,ngoldbaum,39 - free-threading,2,"PR#28203 - numpy/_core/src/multiarray/item_selection.c: @@ -922,16 +922,23 @@ PyArray_Repeat(PyArrayObject *aop, PyObject *op, int axis)|;|         }|;|     }|;| |;|+    /* Fill in dimensions of new array */|;|+    npy_intp dims[NPY_MAXDIMS] = {0}|;|;+|;|+    for (int i = 0; i < PyArray_NDIM(aop); i++) {|;|+        dims[i] = PyArray_DIMS(aop)[i]|;|;+    }|;|+|;|+    dims[axis] = total|;|;+|;|     /* Construct new array */|;|-    PyArray_DIMS(aop)[axis] = total|;|;     Py_INCREF(PyArray_DESCR(aop))|;|;     ret = (PyArrayObject *)PyArray_NewFromDescr(Py_TYPE(aop),|;|                                                 PyArray_DESCR(aop),|;|                                                 PyArray_NDIM(aop),|;|-                                                PyArray_DIMS(aop),|;|+                                                dims,|;|                                                 NULL, NULL, 0,|;|                                                 (PyObject *)aop)|;|;-    PyArray_DIMS(aop)[axis] = n|;|;     if (ret == NULL) {|;|         goto fail|;|;     } || PR#28203 - numpy/_core/tests/test_multithreading.py: @@ -38,7 +38,7 @@ def f(b):|;|         b.wait()|;|         return a.sum()|;| |;|-    run_threaded(f, NUM_THREADS, max_workers=NUM_THREADS, pass_barrier=True)|;|+    run_threaded(f, NUM_THREADS, pass_barrier=True)|;| |;| |;| def test_temp_elision_thread_safety():|;|@@ -129,8 +129,7 @@ def closure(b):|;|         b.wait()|;|         np.sum(x)|;| |;|-    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS,|;|-                 pass_barrier=True)|;|+    run_threaded(closure, NUM_THREADS, pass_barrier=True)|;| |;| |;| def test_parallel_flat_iterator():|;|@@ -155,3 +154,14 @@ def closure(x, b):|;|             y.flat[x] = x|;| |;|     run_threaded(closure, pass_barrier=True, prepare_args=prepare_args)|;|+|;|+|;|+def test_multithreaded_repeat():|;|+    x0 = np.arange(10)|;|+|;|+    def closure(b):|;|+        b.wait()|;|+        for _ in range(100):|;|+            x = np.repeat(x0, 2, axis=0)[::2]|;|+|;|+    run_threaded(closure, max_workers=10, pass_barrier=True) || PR#28203 - numpy/testing/_private/utils.py: @@ -2686,7 +2686,7 @@ def _get_glibc_version():|;| _glibc_older_than = lambda x: (_glibcver != '0.0' and _glibcver < x)|;| |;| |;|-def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|+def run_threaded(func, max_workers=8, pass_count=False,|;|                  pass_barrier=False, outer_iterations=1,|;|                  prepare_args=None):|;|     """"""Runs a function many times in parallel""""""|;|@@ -2698,15 +2698,11 @@ def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|             else:|;|                 args = prepare_args()|;|             if pass_barrier:|;|-                if max_workers != iters:|;|-                    raise RuntimeError(|;|-                        ""Must set max_workers equal to the number of ""|;|-                        ""iterations to avoid deadlocks."")|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(iters)]|;|+                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(iters)]|;|+                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|             for f in futures:|;|                 f.result() || PR#28209 - numpy/_core/src/multiarray/item_selection.c: @@ -922,16 +922,23 @@ PyArray_Repeat(PyArrayObject *aop, PyObject *op, int axis)|;|         }|;|     }|;| |;|+    /* Fill in dimensions of new array */|;|+    npy_intp dims[NPY_MAXDIMS] = {0}|;|;+|;|+    for (int i = 0; i < PyArray_NDIM(aop); i++) {|;|+        dims[i] = PyArray_DIMS(aop)[i]|;|;+    }|;|+|;|+    dims[axis] = total|;|;+|;|     /* Construct new array */|;|-    PyArray_DIMS(aop)[axis] = total|;|;     Py_INCREF(PyArray_DESCR(aop))|;|;     ret = (PyArrayObject *)PyArray_NewFromDescr(Py_TYPE(aop),|;|                                                 PyArray_DESCR(aop),|;|                                                 PyArray_NDIM(aop),|;|-                                                PyArray_DIMS(aop),|;|+                                                dims,|;|                                                 NULL, NULL, 0,|;|                                                 (PyObject *)aop)|;|;-    PyArray_DIMS(aop)[axis] = n|;|;     if (ret == NULL) {|;|         goto fail|;|;     } || PR#28209 - numpy/_core/tests/test_multithreading.py: @@ -38,7 +38,7 @@ def f(b):|;|         b.wait()|;|         return a.sum()|;| |;|-    run_threaded(f, NUM_THREADS, max_workers=NUM_THREADS, pass_barrier=True)|;|+    run_threaded(f, NUM_THREADS, pass_barrier=True)|;| |;| |;| def test_temp_elision_thread_safety():|;|@@ -129,8 +129,7 @@ def closure(b):|;|         b.wait()|;|         np.sum(x)|;| |;|-    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS,|;|-                 pass_barrier=True)|;|+    run_threaded(closure, NUM_THREADS, pass_barrier=True)|;| |;| |;| def test_parallel_flat_iterator():|;|@@ -155,3 +154,14 @@ def closure(x, b):|;|             y.flat[x] = x|;| |;|     run_threaded(closure, pass_barrier=True, prepare_args=prepare_args)|;|+|;|+|;|+def test_multithreaded_repeat():|;|+    x0 = np.arange(10)|;|+|;|+    def closure(b):|;|+        b.wait()|;|+        for _ in range(100):|;|+            x = np.repeat(x0, 2, axis=0)[::2]|;|+|;|+    run_threaded(closure, max_workers=10, pass_barrier=True) || PR#28209 - numpy/testing/_private/utils.py: @@ -2685,7 +2685,7 @@ def _get_glibc_version():|;| _glibc_older_than = lambda x: (_glibcver != '0.0' and _glibcver < x)|;| |;| |;|-def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|+def run_threaded(func, max_workers=8, pass_count=False,|;|                  pass_barrier=False, outer_iterations=1,|;|                  prepare_args=None):|;|     """"""Runs a function many times in parallel""""""|;|@@ -2697,15 +2697,11 @@ def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|             else:|;|                 args = prepare_args()|;|             if pass_barrier:|;|-                if max_workers != iters:|;|-                    raise RuntimeError(|;|-                        ""Must set max_workers equal to the number of ""|;|-                        ""iterations to avoid deadlocks."")|;|                 barrier = threading.Barrier(max_workers)|;|                 args.append(barrier)|;|             if pass_count:|;|-                futures = [tpe.submit(func, i, *args) for i in range(iters)]|;|+                futures = [tpe.submit(func, i, *args) for i in range(max_workers)]|;|             else:|;|-                futures = [tpe.submit(func, *args) for _ in range(iters)]|;|+                futures = [tpe.submit(func, *args) for _ in range(max_workers)]|;|             for f in futures:|;|                 f.result()",TST: remove unnecessary iters argument from run_threaded helper || TST: add failing test for multithreaded repeat || BUG: avoid data race in PyArray_Repeat || TST: remove unnecessary iters argument from run_threaded helper || TST: add failing test for multithreaded repeat || BUG: avoid data race in PyArray_Repeat
numpy/numpy,hauntsaninja,28054,"CI, TYP: Large-scale integration type-testing with `mypy_primer`","Our type-tests aren't perfect, we don't type-check our stubs, and don't use stubtest. But even if we would do all that, there's always a chance that seemingly innocent changes to the stubs could unintentionally lead to unforeseen typing issues in downstream packages. 

The [`mypy_primer`](https://github.com/hauntsaninja/mypy_primer) tool was built to help with issues like these, and helps reduce the number of these static-typing-related *unknown unknowns*.

From https://github.com/hauntsaninja/mypy_primer `README.MD`:

> mypy_primer is a tool for regression testing Python static type checkers.
> 
> mypy_primer makes it easy to run different versions of a type checker over several million lines of open source Python projects with typing for the purpose of evaluating changes.

> Here's what mypy_primer does:
> - Clones a copy of mypy (potentially from a fork you specified)
> - Checks out a ""new"" and ""old"" revision of mypy
> - Clones a hardcoded list of projects (potentially filtered by you)
> - Installs necessary stubs and dependencies per project
> - Runs the appropriate mypy command per project
> - Shows you the potentially differing results!
> - Lets you bisect to find the mypy commit that causes a given change

I have little knowledge about NumPy's CI, but I think it could help a lot if we could incorporate mypy_primer in it, and preferably run it only if changes are made to at least one `.pyi` stub file.","https://github.com/python/typeshed/pull/11830#issuecomment-2075258037 and https://github.com/python/typeshed/pull/13021#issuecomment-2480668866 are examples of how it's used by `typeshed` || This would be very useful. It may also be helpful to do this on a cron against the nightly wheels. And we may need to choose mypy vs pyright, depending on what the project itself uses (they may no longer be making an effort to be compatible with mypy, e.g.). || > It may also be helpful to do this on a cron against the nightly wheels.

There will be cases when we will deliberately choose to ignore the mypy_primer output. So I can imagine that doing this periodically would be more annoying than it would be helpful 🤔.

> And we may need to choose mypy vs pyright, depending on what the project itself uses (they may no longer be making an effort to be compatible with mypy, e.g.).

Unlike the name suggests, `mypy_primer` isn't exclusive to `mypy`. If I understand correctly,  for each project it can be configured to use `mypy`, `pyright`, both, or forks (e.g.  `basedmypy` or `basedpyright`). || Isn't the problem that there are very few external projects to run CI on that actually have good type annotations? I'm thinking that a single job to sometimes run against `scipy-stubs` (anything else?) that you trust is good, but much more is going to be a pain.

The usual solution for this problem that we encourage is for downstream packages to test numpy nightlies. Quite a few projects do this now, so getting them to run their typing tests as well on those nightlies if they have any is probably more effective. || Yes, we'd be happy to add a daily/weekly check like that to skimage and the SP Lecture Notes, e.g. || > Isn't the problem that there are very few external projects to run CI on that actually have good type annotations?

It doesn't matter if the projects are currently correctly typed, or even typed at all. Mypy_primer reports the diffs of the mypy/pyright outputs of that project, that our change causes.  || Awesome that you already thought of this! I went ahead and added a few features to mypy_primer to make this easy to add to numpy.
- `--known-dependency-selector numpy`. This lets you select all projects in mypy_primer's corpus where we at some point recorded that numpy is a dependency. There are currently 19 of these.
- `--(old/new)-prepend-path`. This lets you effectively add a new entry to `sys.path` for the new and old runs. Two gotchas: a) you'll want to make sure there's a `numpy` dir and a `numpy/py.typed` in the path you prepend, b) there may be some weirdness with namespace packages (which I guess doesn't apply to numpy)

I was able to get some potentially believable output with:
```
mypy_primer --type-checker mypy --new v1.14.0 --old v1.14.0 --known-dependency-selector numpy --old-prepend-path ~/tmp/nump1/numpy --new-prepend-path ~/tmp/nump2/numpy --output concise
```
where I checked out numpy v2.1.3 and v2.2.0 to nump1 and nump2 respectively. Make sure to explicitly set `--new` and `--old` to the same thing, otherwise you'll also get type checker version differences.

mypy_primer supports pyright and mypy. It probably also supports basedpyright via the `--repo` flag.

I do see mypy hit some errors when using v2.1.3 on the lines of `AssertionError: numpy._typing._nbit_base._8Bit`. This is somewhat surprising, because we should have seen those in mypy and typeshed CI. Any chance that error is at all familiar to you? It's possible I messed something up.

Anything I should know before opening a PR? || Wow, thanks a lot for that @hauntsaninja, that indeed sounds very helpful.

---

> I do see mypy hit some errors when using v2.1.3 on the lines of `AssertionError: numpy._typing._nbit_base._8Bit`. This is somewhat surprising, because we should have seen those in mypy and typeshed CI. Any chance that error is at all familiar to you? It's possible I messed something up.

Hmm, maybe it has something to do with the mypy plugin (https://github.com/numpy/numpy/blob/main/numpy/typing/mypy_plugin.py)? It is used for system-dependent scalar types, like `np.longdouble`, so that the types match match the runtime, for which it uses those `_typing._nbit_base` types. But I don't see any asserts in the mypy plugin itself, so the `AssertionError` could then perhaps come from mypy itself or something? 
🤷🏻 

> Anything I should know before opening a PR?

Nothing in particular I suppose. 
Just don't forget to use a `CI: ` prefix for your commit messages and PR title (or whichever one seems appropriate, see https://numpy.org/doc/stable/dev/development_workflow.html#writing-the-commit-message). || Thanks! Ah, the plugin is a good guess. It looks like the plugin imports numpy but I didn't bother rebuilding numpy, so it's possible I introduced some skew.",closed,2024-12-22T18:19:09+00:00,2024-12-30T17:09:13+00:00,jorenham,"component: CI, 41 - Static typing",1,"PR#28073 - .github/workflows/mypy_primer.yml: @@ -0,0 +1,99 @@|;|+name: Run mypy_primer|;|+|;|+on:|;|+  # Only run on PR, since we diff against main|;|+  pull_request:|;|+    paths:|;|+      - ""**/*.pyi""|;|+      - "".github/workflows/mypy_primer.yml""|;|+      - "".github/workflows/mypy_primer_comment.yml""|;|+|;|+concurrency:|;|+  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}|;|+  cancel-in-progress: true|;|+|;|+permissions:|;|+  contents: read|;|+|;|+jobs:|;|+  mypy_primer:|;|+    name: Run|;|+    runs-on: ubuntu-latest|;|+    strategy:|;|+      matrix:|;|+        shard-index: [0]  # e.g. change this to [0, 1, 2] and --num-shards below to 3|;|+      fail-fast: false|;|+    steps:|;|+      - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2|;|+        with:|;|+          path: numpy_to_test|;|+          fetch-depth: 0|;|+      - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|+        with:|;|+          python-version: ""3.12""|;|+      - name: Install dependencies|;|+        run: pip install git+https://github.com/hauntsaninja/mypy_primer.git|;|+      - name: Run mypy_primer|;|+        shell: bash|;|+        run: ||;|+          cd numpy_to_test|;|+          MYPY_VERSION=$(grep mypy== requirements/test_requirements.txt | sed -n 's/mypy==\([^;]*\).*/\1/p')|;|+|;|+          echo ""new commit""|;|+          git checkout $GITHUB_SHA|;|+          git rev-list --format=%s --max-count=1 HEAD|;|+|;|+          MERGE_BASE=$(git merge-base $GITHUB_SHA origin/$GITHUB_BASE_REF)|;|+          git worktree add ../numpy_base $MERGE_BASE|;|+          cd ../numpy_base|;|+|;|+          echo ""base commit""|;|+          git rev-list --format=%s --max-count=1 HEAD|;|+|;|+          echo ''|;|+          cd ..|;|+          # fail action if exit code isn't zero or one|;|+          # TODO: note that we don't build numpy, so if a project attempts to use the|;|+          # numpy mypy plugin, we may see some issues involving version skew.|;|+          (|;|+            mypy_primer \|;|+            --new v${MYPY_VERSION} --old v${MYPY_VERSION} \|;|+            --known-dependency-selector numpy \|;|+            --old-prepend-path numpy_base --new-prepend-path numpy_to_test \|;|+            --num-shards 1 --shard-index ${{ matrix.shard-index }} \|;|+            --debug \|;|+            --output concise \|;|+            | tee diff_${{ matrix.shard-index }}.txt|;|+          ) || [ $? -eq 1 ]|;|+      - if: ${{ matrix.shard-index == 0 }}|;|+        name: Save PR number|;|+        run: ||;|+          echo ${{ github.event.pull_request.number }} | tee pr_number.txt|;|+      - name: Upload mypy_primer diff + PR number|;|+        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b # v4.5.0|;|+        if: ${{ matrix.shard-index == 0 }}|;|+        with:|;|+          name: mypy_primer_diffs-${{ matrix.shard-index }}|;|+          path: ||;|+            diff_${{ matrix.shard-index }}.txt|;|+            pr_number.txt|;|+      - name: Upload mypy_primer diff|;|+        uses: actions/upload-artifact@6f51ac03b9356f520e9adb1b1b7802705f340c2b # v4.5.0|;|+        if: ${{ matrix.shard-index != 0 }}|;|+        with:|;|+          name: mypy_primer_diffs-${{ matrix.shard-index }}|;|+          path: diff_${{ matrix.shard-index }}.txt|;|+|;|+  join_artifacts:|;|+    name: Join artifacts|;|+    runs-on: ubuntu-latest|;|+    needs: [mypy_primer]|;|+    permissions:|;|+      contents: read|;|+    steps:|;|+      - name: Merge artifacts|;|+        uses: actions/upload-artifact/merge@6f51ac03b9356f520e9adb1b1b7802705f340c2b # v4.5.0|;|+        with:|;|+          name: mypy_primer_diffs|;|+          pattern: mypy_primer_diffs-*|;|+          delete-merged: true || PR#28073 - .github/workflows/mypy_primer_comment.yml: @@ -0,0 +1,96 @@|;|+name: Comment with mypy_primer diff|;|+|;|+on:|;|+  workflow_run:|;|+    workflows:|;|+      - Run mypy_primer|;|+    types:|;|+      - completed|;|+|;|+permissions:|;|+  contents: read|;|+  pull-requests: write|;|+|;|+jobs:|;|+  comment:|;|+    name: Comment PR from mypy_primer|;|+    runs-on: ubuntu-latest|;|+    if: ${{ github.event.workflow_run.conclusion == 'success' }}|;|+    steps:|;|+      - name: Hide old comments|;|+        uses: kanga333/comment-hider@c12bb20b48aeb8fc098e35967de8d4f8018fffdf  # v0.4.0|;|+        with:|;|+          github_token: ${{ secrets.GITHUB_TOKEN }}|;|+          issue_number: ${{ steps.post-comment.outputs.result }}|;|+|;|+      - name: Download diffs|;|+        uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea  # v7.0.1|;|+        with:|;|+          script: ||;|+            const fs = require('fs')|;|;+            const artifacts = await github.rest.actions.listWorkflowRunArtifacts({|;|+               owner: context.repo.owner,|;|+               repo: context.repo.repo,|;|+               run_id: ${{ github.event.workflow_run.id }},|;|+            })|;|;+            const [matchArtifact] = artifacts.data.artifacts.filter((artifact) =>|;|+              artifact.name == ""mypy_primer_diffs"")|;|;+|;|+            const download = await github.rest.actions.downloadArtifact({|;|+               owner: context.repo.owner,|;|+               repo: context.repo.repo,|;|+               artifact_id: matchArtifact.id,|;|+               archive_format: ""zip"",|;|+            })|;|;+            fs.writeFileSync(""diff.zip"", Buffer.from(download.data))|;|;+|;|+      - run: unzip diff.zip|;|+      - run: ||;|+          cat diff_*.txt | tee fulldiff.txt|;|+|;|+      - name: Post comment|;|+        id: post-comment|;|+        uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea  # v7.0.1|;|+        with:|;|+          github-token: ${{ secrets.GITHUB_TOKEN }}|;|+          script: ||;|+            const MAX_CHARACTERS = 50000|;|+            const MAX_CHARACTERS_PER_PROJECT = MAX_CHARACTERS / 3|;|+|;|+            const fs = require('fs')|;|+            let data = fs.readFileSync('fulldiff.txt', { encoding: 'utf8' })|;|+|;|+            function truncateIfNeeded(original, maxLength) {|;|+              if (original.length <= maxLength) {|;|+                return original|;|+              }|;|+              let truncated = original.substring(0, maxLength)|;|+              // further, remove last line that might be truncated|;|+              truncated = truncated.substring(0, truncated.lastIndexOf('\n'))|;|+              let lines_truncated = original.split('\n').length - truncated.split('\n').length|;|+              return `${truncated}\n\n... (truncated ${lines_truncated} lines) ...`|;|+            }|;|+|;|+            const projects = data.split('\n\n')|;|+            // don't let one project dominate|;|+            data = projects.map(project => truncateIfNeeded(project, MAX_CHARACTERS_PER_PROJECT)).join('\n\n')|;|+            // posting comment fails if too long, so truncate|;|+            data = truncateIfNeeded(data, MAX_CHARACTERS)|;|+|;|+            console.log(""Diff from mypy_primer:"")|;|+            console.log(data)|;|+|;|+            let body|;|+            if (data.trim()) {|;|+              body = 'Diff from [mypy_primer](https://github.com/hauntsaninja/mypy_primer), '|;|+              body += 'showing the effect of this PR on type check results on a corpus of open source code:\n```diff\n'|;|+              body += data + '```'|;|+              const prNumber = parseInt(fs.readFileSync(""pr_number.txt"", { encoding: ""utf8"" }))|;|+              await github.rest.issues.createComment({|;|+                issue_number: prNumber,|;|+                owner: context.repo.owner,|;|+                repo: context.repo.repo,|;|+                body|;|+              })|;|+            }|;|+            return prNumber","TYP: use mypy_primer to surface type checking regressions

Resolves #28054 || introduce temporary regression || Revert ""introduce temporary regression""

This reverts commit 3aa89c6832de067078467e549157af353a479287. || add todo || reduce shards || only comment if there's a diff || fix sharding and add comment || add hashes || split string"
numpy/numpy,yakovdan,28068,BUG: `numpy.format_float_positional` causes Segmentaion Fault when accepting a large `pad_left`,"### Describe the issue:

I was working on plfuzz, an automatic Python library testing tool, and the tool found that if we pass a large `pad_left` to `numpy.format_float_positional`, NumPy crashes with Segmentation Fault. 

The documentation says:

> pad_left: non-negative integer, optional
Pad the left side of the string with whitespace until at least that many characters are to the left of the decimal point.

It's seams that a large `pad_left` meets the requirement of ""non-negative integer"", but the `numpy.format_float_positional` crashes.  
I think this is not a serious bug, but it might be a good idea to fix it so that it is more user-friendly in the event of a user error.

### Reproduce the code example:

```python
args= [1.0471, 2, True, True, ""k"", 2048, int(1e5), 0, 0]
import numpy as np
np.format_float_positional(*args)
```


### Error message:

```shell
(py313) root@a475b702ecc0:~/plfuzz# gdb python
GNU gdb (Ubuntu 12.1-0ubuntu1~22.04.2) 12.1
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...
(gdb) set args bugs/bug5_pendding.py 
(gdb) r
Starting program: /root/miniconda3/envs/py313/bin/python bugs/bug5_pendding.py 
warning: Error disabling address space randomization: Operation not permitted
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7f9250fff640 (LWP 98733)]
[New Thread 0x7f92507fe640 (LWP 98734)]
[New Thread 0x7f924fffd640 (LWP 98735)]
[New Thread 0x7f924f7fc640 (LWP 98736)]
[New Thread 0x7f924effb640 (LWP 98737)]
[New Thread 0x7f924e7fa640 (LWP 98738)]
[New Thread 0x7f924dff9640 (LWP 98739)]
[New Thread 0x7f924d7f8640 (LWP 98740)]
[New Thread 0x7f924cff7640 (LWP 98741)]
[New Thread 0x7f924c7f6640 (LWP 98742)]
[New Thread 0x7f924bff5640 (LWP 98743)]
[New Thread 0x7f924b7f4640 (LWP 98744)]
[New Thread 0x7f924aff3640 (LWP 98745)]
[New Thread 0x7f924a7f2640 (LWP 98746)]
[New Thread 0x7f9249ff1640 (LWP 98747)]
[New Thread 0x7f92497f0640 (LWP 98748)]
[New Thread 0x7f9248fef640 (LWP 98749)]
[New Thread 0x7f92487ee640 (LWP 98750)]
[New Thread 0x7f9247fed640 (LWP 98751)]
[New Thread 0x7f92477ec640 (LWP 98752)]
[New Thread 0x7f9246feb640 (LWP 98753)]
[New Thread 0x7f92467ea640 (LWP 98754)]
[New Thread 0x7f9245fe9640 (LWP 98755)]
[New Thread 0x7f92457e8640 (LWP 98756)]
[New Thread 0x7f9244fe7640 (LWP 98757)]
[New Thread 0x7f92447e6640 (LWP 98758)]
[New Thread 0x7f9243fe5640 (LWP 98759)]
[New Thread 0x7f92437e4640 (LWP 98760)]
[New Thread 0x7f9242fe3640 (LWP 98761)]
[New Thread 0x7f92427e2640 (LWP 98762)]
[New Thread 0x7f9241fe1640 (LWP 98763)]
[New Thread 0x7f92417e0640 (LWP 98764)]
[New Thread 0x7f9240fdf640 (LWP 98765)]
[New Thread 0x7f92407de640 (LWP 98766)]
[New Thread 0x7f923ffdd640 (LWP 98767)]
[New Thread 0x7f923f7dc640 (LWP 98768)]
[New Thread 0x7f923efdb640 (LWP 98769)]
[New Thread 0x7f923e7da640 (LWP 98770)]
[New Thread 0x7f923dfd9640 (LWP 98771)]
[New Thread 0x7f923d7d8640 (LWP 98772)]
[New Thread 0x7f923cfd7640 (LWP 98773)]
[New Thread 0x7f923c7d6640 (LWP 98774)]
[New Thread 0x7f923bfd5640 (LWP 98775)]
[New Thread 0x7f923b7d4640 (LWP 98776)]
[New Thread 0x7f923afd3640 (LWP 98777)]
[New Thread 0x7f923a7d2640 (LWP 98778)]
[New Thread 0x7f9239fd1640 (LWP 98779)]
[New Thread 0x7f92397d0640 (LWP 98780)]
[New Thread 0x7f9238fcf640 (LWP 98781)]
[New Thread 0x7f92387ce640 (LWP 98782)]
[New Thread 0x7f9237fcd640 (LWP 98783)]
[New Thread 0x7f92377cc640 (LWP 98784)]
[New Thread 0x7f9236fcb640 (LWP 98785)]
[New Thread 0x7f92367ca640 (LWP 98786)]
[New Thread 0x7f9235fc9640 (LWP 98787)]
[New Thread 0x7f92357c8640 (LWP 98788)]
[New Thread 0x7f9234fc7640 (LWP 98789)]
[New Thread 0x7f92347c6640 (LWP 98790)]
[New Thread 0x7f9233fc5640 (LWP 98791)]
[New Thread 0x7f92337c4640 (LWP 98792)]
[New Thread 0x7f9232fc3640 (LWP 98793)]
[New Thread 0x7f92327c2640 (LWP 98794)]
[New Thread 0x7f9231fc1640 (LWP 98795)]
before call

Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
__memset_evex_unaligned_erms () at ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:250
250     ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S: No such file or directory.
(gdb) bt
#0  __memset_evex_unaligned_erms () at ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:250
#1  0x00007f92d32e2090 in Format_floatbits.constprop.0.isra.0 () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#2  0x00007f92d32e5d42 in Dragon4_Positional () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#3  0x00007f92d331020a in dragon4_positional () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#4  0x0000000000563395 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=0x7f92d3b57010, args=0x7f92d4200120, nargsf=<optimized out>, kwnames=0x7f92d199b0d0) at /usr/local/src/conda/python-3.13.0/Include/cpython/methodobject.h:50
#5  0x0000000000537aa1 in _PyObject_VectorcallTstate (kwnames=0x7f92d199b0d0, nargsf=9223372036854775809, args=0x7f92d4200120, callable=0x7f92d3b57010, tstate=0x8eac80 <_PyRuntime+282976>) at /usr/local/src/conda/python-3.13.0/Include/internal/pycore_call.h:168
#6  PyObject_Vectorcall (callable=0x7f92d3b57010, args=0x7f92d4200120, nargsf=9223372036854775809, kwnames=0x7f92d199b0d0) at /usr/local/src/conda/python-3.13.0/Objects/call.c:327
#7  0x000000000055292b in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at /usr/local/src/conda/python-3.13.0/Python/generated_cases.c.h:1502
#8  0x000000000060902e in PyEval_EvalCode (co=<optimized out>, globals=0x7f92d3c4bac0, locals=<optimized out>) at /usr/local/src/conda/python-3.13.0/Python/ceval.c:596
#9  0x000000000062eedd in run_eval_code_obj (tstate=0x8eac80 <_PyRuntime+282976>, co=0x7f92d3de6af0, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1323
#10 0x0000000000629d9d in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0, flags=<optimized out>, arena=<optimized out>, interactive_src=0x0, generate_new_source=0) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1408
#11 0x0000000000648890 in pyrun_file (fp=0x20ce2e0, filename=0x7f92d3ca2100, start=<optimized out>, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1241
#12 0x00000000006473fb in _PyRun_SimpleFileObject (fp=0x20ce2e0, filename=0x7f92d3ca2100, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:490
#13 0x000000000064711b in _PyRun_AnyFileObject (fp=0x20ce2e0, filename=0x7f92d3ca2100, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:77
#14 0x0000000000640b67 in pymain_run_file_obj (skip_source_first_line=0, filename=0x7f92d3ca2100, program_name=0x7f92d3cb8080) at /usr/local/src/conda/python-3.13.0/Modules/main.c:409
#15 pymain_run_file (config=0x8bd378 <_PyRuntime+96344>) at /usr/local/src/conda/python-3.13.0/Modules/main.c:428
#16 pymain_run_python (exitcode=0x7fff78fa0d3c) at /usr/local/src/conda/python-3.13.0/Modules/main.c:696
#17 Py_RunMain () at /usr/local/src/conda/python-3.13.0/Modules/main.c:775
#18 0x00000000005f9509 in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at /usr/local/src/conda/python-3.13.0/Modules/main.c:829
#19 0x00007f92d3f0ad90 in __libc_start_call_main (main=main@entry=0x5f9440 <main>, argc=argc@entry=2, argv=argv@entry=0x7fff78fa0f98) at ../sysdeps/nptl/libc_start_call_main.h:58
#20 0x00007f92d3f0ae40 in __libc_start_main_impl (main=0x5f9440 <main>, argc=2, argv=0x7fff78fa0f98, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fff78fa0f88) at ../csu/libc-start.c:392
#21 0x00000000005f885d in _start ()
(gdb)
```


### Python and NumPy Versions:

2.2.1
3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, 21:29:38) [GCC 11.2.0]

### Runtime Environment:

[{'numpy_version': '2.2.1',
  'python': '3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, '
            '21:29:38) [GCC 11.2.0]',
  'uname': uname_result(system='Linux', node='a475b702ecc0', release='5.4.0-150-generic', version='#167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX'],
                      'not_found': ['AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'SkylakeX',
  'filepath': '/root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 64,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

### Context for the issue:

_No response_","@EgodPrime Thanks for reporting this, I can confirm the issue with `np.format_float_positional(x=1.047, precision=2, pad_left=int(1e5))`

The crash might be a buffer overflow caused here:

https://github.com/numpy/numpy/blob/a07c6c5f12eec1322d2487f0ed935c5c13b8d883/numpy/_core/src/multiarray/dragon4.c#L3039-L3042 || Thanks for opening the issue!  Ping @ahaldane maybe you have time to look into it.  It is pretty easy to add a hot-fix for this, but it seems to me what we really need is a slightly more invasive refactor to add an error return to this (and all possible similar) paths.

I.e. we shouldn't just avoid failing, we should ensure the return is a proper Python error (or success, but I don't think that is worth the trouble).",closed,2024-12-27T05:37:00+00:00,2025-01-21T08:17:10+00:00,EgodPrime,00 - Bug,1,"PR#28149 - numpy/_core/src/multiarray/dragon4.c: @@ -1615,7 +1615,8 @@ typedef struct Dragon4_Options {|;|  *|;|  * See Dragon4_Options for description of remaining arguments.|;|  */|;|-static npy_uint32|;|+|;|+static npy_int32|;| FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                  npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                  npy_bool hasUnequalMargins, DigitMode digit_mode,|;|@@ -1646,7 +1647,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|         buffer[pos++] = '-'|;|;         has_sign = 1|;|;     }|;|-|;|+        |;|     numDigits = Dragon4(mantissa, exponent, mantissaBit, hasUnequalMargins,|;|                         digit_mode, cutoff_mode, precision, min_digits,|;|                         buffer + has_sign, maxPrintLen - has_sign,|;|@@ -1658,14 +1659,14 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     /* if output has a whole number */|;|     if (printExponent >= 0) {|;|         /* leave the whole number at the start of the buffer */|;|-        numWholeDigits = printExponent+1|;|;+        numWholeDigits = printExponent+1;        |;|         if (numDigits <= numWholeDigits) {|;|             npy_int32 count = numWholeDigits - numDigits|;|;             pos += numDigits|;|; |;|-            /* don't overflow the buffer */|;|-            if (pos + count > maxPrintLen) {|;|-                count = maxPrintLen - pos|;|;+            if (count > maxPrintLen - pos) {|;|+                PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+                return -1|;|;             }|;| |;|             /* add trailing zeros up to the decimal point */|;|@@ -1767,9 +1768,12 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|              pos < maxPrintLen) {|;|         /* add trailing zeros up to add_digits length */|;|         /* compute the number of trailing zeros needed */|;|+        |;|         npy_int32 count = desiredFractionalDigits - numFractionDigits|;|;-        if (pos + count > maxPrintLen) {|;|-            count = maxPrintLen - pos|;|;+        |;|+        if (count > maxPrintLen - pos) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;|         numFractionDigits += count|;|; |;|@@ -1802,7 +1806,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     }|;| |;|     /* add any whitespace padding to right side */|;|-    if (digits_right >= numFractionDigits) {|;|+    if (digits_right >= numFractionDigits) {        |;|         npy_int32 count = digits_right - numFractionDigits|;|; |;|         /* in trim_mode DptZeros, if right padding, add a space for the . */|;|@@ -1811,8 +1815,9 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|             buffer[pos++] = ' '|;|;         }|;| |;|-        if (pos + count > maxPrintLen) {|;|-            count = maxPrintLen - pos|;|;+        if (count > maxPrintLen - pos) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;| |;|         for ( ; count > 0; count--) {|;|@@ -1823,14 +1828,16 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     if (digits_left > numWholeDigits + has_sign) {|;|         npy_int32 shift = digits_left - (numWholeDigits + has_sign)|;|;         npy_int32 count = pos|;|;-|;|-        if (count + shift > maxPrintLen) {|;|-            count = maxPrintLen - shift|;|;+                |;|+        if (count > maxPrintLen - shift) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;| |;|         if (count > 0) {|;|             memmove(buffer + shift, buffer, count)|;|;         }|;|+|;|         pos = shift + count|;|;         for ( ; shift > 0; shift--) {|;|             buffer[shift - 1] = ' '|;|;@@ -1860,7 +1867,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|  *|;|  * See Dragon4_Options for description of remaining arguments.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| FormatScientific (char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                   npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                   npy_bool hasUnequalMargins, DigitMode digit_mode,|;|@@ -2158,7 +2165,7 @@ PrintInfNan(char *buffer, npy_uint32 bufferSize, npy_uint64 mantissa,|;|  * Helper function that takes Dragon4 parameters and options and|;|  * calls Dragon4.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Format_floatbits(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                  npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                  npy_bool hasUnequalMargins, Dragon4_Options *opt)|;|@@ -2187,7 +2194,7 @@ Format_floatbits(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|  * exponent:  5 bits|;|  * mantissa: 10 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary16(|;|         npy_half *value, Dragon4_Options *opt)|;| {|;|@@ -2274,7 +2281,7 @@ Dragon4_PrintFloat_IEEE_binary16(|;|  * exponent:  8 bits|;|  * mantissa: 23 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary32(|;|         npy_float32 *value,|;|         Dragon4_Options *opt)|;|@@ -2367,7 +2374,7 @@ Dragon4_PrintFloat_IEEE_binary32(|;|  * exponent: 11 bits|;|  * mantissa: 52 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary64(|;|         npy_float64 *value, Dragon4_Options *opt)|;| {|;|@@ -2482,7 +2489,7 @@ typedef struct FloatVal128 {|;|  * intbit     1 bit,  first u64|;|  * mantissa: 63 bits, first u64|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended(|;|     FloatVal128 value, Dragon4_Options *opt)|;| {|;|@@ -2580,7 +2587,7 @@ Dragon4_PrintFloat_Intel_extended(|;|  * system. But numpy defines NPY_FLOAT80, so if we come across it, assume it is|;|  * an Intel extended format.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended80(|;|     npy_float80 *value, Dragon4_Options *opt)|;| {|;|@@ -2604,7 +2611,7 @@ Dragon4_PrintFloat_Intel_extended80(|;| |;| #ifdef HAVE_LDOUBLE_INTEL_EXTENDED_12_BYTES_LE|;| /* Intel's 80-bit IEEE extended precision format, 96-bit storage */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended96(|;|     npy_float96 *value, Dragon4_Options *opt)|;| {|;|@@ -2628,7 +2635,7 @@ Dragon4_PrintFloat_Intel_extended96(|;| |;| #ifdef HAVE_LDOUBLE_MOTOROLA_EXTENDED_12_BYTES_BE|;| /* Motorola Big-endian equivalent of the Intel-extended 96 fp format */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Motorola_extended96(|;|     npy_float96 *value, Dragon4_Options *opt)|;| {|;|@@ -2665,7 +2672,7 @@ typedef union FloatUnion128|;| |;| #ifdef HAVE_LDOUBLE_INTEL_EXTENDED_16_BYTES_LE|;| /* Intel's 80-bit IEEE extended precision format, 128-bit storage */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended128(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2694,7 +2701,7 @@ Dragon4_PrintFloat_Intel_extended128(|;|  * I am not sure if the arch also supports uint128, and C does not seem to|;|  * support int128 literals. So we use uint64 to do manipulation.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128(|;|     FloatVal128 val128, Dragon4_Options *opt)|;| {|;|@@ -2779,7 +2786,7 @@ Dragon4_PrintFloat_IEEE_binary128(|;| }|;| |;| #if defined(HAVE_LDOUBLE_IEEE_QUAD_LE)|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128_le(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2799,7 +2806,7 @@ Dragon4_PrintFloat_IEEE_binary128_le(|;|  * This function is untested, very few, if any, architectures implement|;|  * big endian IEEE binary128 floating point.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128_be(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2854,7 +2861,7 @@ Dragon4_PrintFloat_IEEE_binary128_be(|;|  * https://gcc.gnu.org/wiki/Ieee128PowerPCA|;|  * https://www.ibm.com/support/knowledgecenter/en/ssw_aix_71/com.ibm.aix.genprogc/128bit_long_double_floating-point_datatype.htm|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IBM_double_double(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -3041,6 +3048,7 @@ Dragon4_PrintFloat_IBM_double_double(|;|  * which goes up to about 10^4932. The Dragon4_scratch struct provides a string|;|  * buffer of this size.|;|  */|;|+|;| #define make_dragon4_typefuncs_inner(Type, npy_type, format) \|;| \|;| PyObject *\ || PR#28149 - numpy/_core/tests/test_scalarprint.py: @@ -8,7 +8,8 @@|;| |;| from tempfile import TemporaryFile|;| import numpy as np|;|-from numpy.testing import assert_, assert_equal, assert_raises, IS_MUSL|;|+from numpy.testing import (|;|+    assert_, assert_equal, assert_raises, assert_raises_regex, IS_MUSL)|;| |;| class TestRealScalars:|;|     def test_str(self):|;|@@ -258,53 +259,93 @@ def test_dragon4(self):|;|         assert_equal(fpos64('324', unique=False, precision=5,|;|                                    fractional=False), ""324.00"")|;| |;|-    def test_dragon4_interface(self):|;|-        tps = [np.float16, np.float32, np.float64]|;|+    available_float_dtypes = [np.float16, np.float32, np.float64, np.float128]\|;|+        if hasattr(np, 'float128') else [np.float16, np.float32, np.float64]|;|+    |;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_positional_interface(self, tp):|;|         # test is flaky for musllinux on np.float128|;|-        if hasattr(np, 'float128') and not IS_MUSL:|;|-            tps.append(np.float128)|;|-|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                |;|+        fpos = np.format_float_positional|;|+        |;|+        # test padding|;|+        assert_equal(fpos(tp('1.0'), pad_left=4, pad_right=4), ""   1.    "")|;|+        assert_equal(fpos(tp('-1.0'), pad_left=4, pad_right=4), ""  -1.    "")|;|+        assert_equal(fpos(tp('-10.2'),|;|+                        pad_left=4, pad_right=4), "" -10.2   "")|;|+        |;|+        # test fixed (non-unique) mode|;|+        assert_equal(fpos(tp('1.0'), unique=False, precision=4), ""1.0000"")|;|+|;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_positional_interface_trim(self, tp):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                        |;|         fpos = np.format_float_positional|;|+        # test trimming|;|+        # trim of 'k' or '.' only affects non-unique mode, since unique|;|+        # mode will not output trailing 0s.|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='k'),|;|+                        ""1.0000"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='.'),|;|+                        ""1."")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='.'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='0'),|;|+                        ""1.0"")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='0'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+        assert_equal(fpos(tp('1.'), trim='0'), ""1.0"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='-'),|;|+                        ""1"")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='-'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+        assert_equal(fpos(tp('1.'), trim='-'), ""1"")|;|+        assert_equal(fpos(tp('1.001'), precision=1, trim='-'), ""1"")|;|+                |;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    @pytest.mark.parametrize(""pad_val"", [10**5, np.iinfo(""int32"").max])|;|+    def test_dragon4_positional_interface_overflow(self, tp, pad_val):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                |;|+        fpos = np.format_float_positional|;|+|;|+        #gh-28068            |;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), unique=False, precision=pad_val)|;|+|;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), precision=2, pad_left=pad_val)|;|+|;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), precision=2, pad_right=pad_val)|;|+|;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_scientific_interface(self, tp):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                        |;|         fsci = np.format_float_scientific|;| |;|-        for tp in tps:|;|-            # test padding|;|-            assert_equal(fpos(tp('1.0'), pad_left=4, pad_right=4), ""   1.    "")|;|-            assert_equal(fpos(tp('-1.0'), pad_left=4, pad_right=4), ""  -1.    "")|;|-            assert_equal(fpos(tp('-10.2'),|;|-                         pad_left=4, pad_right=4), "" -10.2   "")|;|-|;|-            # test exp_digits|;|-            assert_equal(fsci(tp('1.23e1'), exp_digits=5), ""1.23e+00001"")|;|-|;|-            # test fixed (non-unique) mode|;|-            assert_equal(fpos(tp('1.0'), unique=False, precision=4), ""1.0000"")|;|-            assert_equal(fsci(tp('1.0'), unique=False, precision=4),|;|-                         ""1.0000e+00"")|;|-|;|-            # test trimming|;|-            # trim of 'k' or '.' only affects non-unique mode, since unique|;|-            # mode will not output trailing 0s.|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='k'),|;|-                         ""1.0000"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='.'),|;|-                         ""1."")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='.'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='0'),|;|-                         ""1.0"")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='0'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-            assert_equal(fpos(tp('1.'), trim='0'), ""1.0"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='-'),|;|-                         ""1"")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='-'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-            assert_equal(fpos(tp('1.'), trim='-'), ""1"")|;|-            assert_equal(fpos(tp('1.001'), precision=1, trim='-'), ""1"")|;|+        # test exp_digits|;|+        assert_equal(fsci(tp('1.23e1'), exp_digits=5), ""1.23e+00001"")|;|+|;|+        # test fixed (non-unique) mode|;|+        assert_equal(fsci(tp('1.0'), unique=False, precision=4),|;|+                        ""1.0000e+00"")|;| |;|     @pytest.mark.skipif(not platform.machine().startswith(""ppc64""),|;|                         reason=""only applies to ppc float128 values"")","DOC: added limits to pad_left, pad_right || TST: Added tests for correct handling of overflow || BUG: fixed pad_left and pad_right causing overflow if too large || DOC: modified doc for simpler exception || TST: added overflow test and fixed formatting || BUG: fixed overflow checks and simplified error handling || BUG: rewritten excpetion message and fixed overflow check || TST: split test into smaller tests, added large input value || Apply suggestions from code review"
numpy/numpy,seberg,28068,BUG: `numpy.format_float_positional` causes Segmentaion Fault when accepting a large `pad_left`,"### Describe the issue:

I was working on plfuzz, an automatic Python library testing tool, and the tool found that if we pass a large `pad_left` to `numpy.format_float_positional`, NumPy crashes with Segmentation Fault. 

The documentation says:

> pad_left: non-negative integer, optional
Pad the left side of the string with whitespace until at least that many characters are to the left of the decimal point.

It's seams that a large `pad_left` meets the requirement of ""non-negative integer"", but the `numpy.format_float_positional` crashes.  
I think this is not a serious bug, but it might be a good idea to fix it so that it is more user-friendly in the event of a user error.

### Reproduce the code example:

```python
args= [1.0471, 2, True, True, ""k"", 2048, int(1e5), 0, 0]
import numpy as np
np.format_float_positional(*args)
```


### Error message:

```shell
(py313) root@a475b702ecc0:~/plfuzz# gdb python
GNU gdb (Ubuntu 12.1-0ubuntu1~22.04.2) 12.1
Copyright (C) 2022 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...
(gdb) set args bugs/bug5_pendding.py 
(gdb) r
Starting program: /root/miniconda3/envs/py313/bin/python bugs/bug5_pendding.py 
warning: Error disabling address space randomization: Operation not permitted
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7f9250fff640 (LWP 98733)]
[New Thread 0x7f92507fe640 (LWP 98734)]
[New Thread 0x7f924fffd640 (LWP 98735)]
[New Thread 0x7f924f7fc640 (LWP 98736)]
[New Thread 0x7f924effb640 (LWP 98737)]
[New Thread 0x7f924e7fa640 (LWP 98738)]
[New Thread 0x7f924dff9640 (LWP 98739)]
[New Thread 0x7f924d7f8640 (LWP 98740)]
[New Thread 0x7f924cff7640 (LWP 98741)]
[New Thread 0x7f924c7f6640 (LWP 98742)]
[New Thread 0x7f924bff5640 (LWP 98743)]
[New Thread 0x7f924b7f4640 (LWP 98744)]
[New Thread 0x7f924aff3640 (LWP 98745)]
[New Thread 0x7f924a7f2640 (LWP 98746)]
[New Thread 0x7f9249ff1640 (LWP 98747)]
[New Thread 0x7f92497f0640 (LWP 98748)]
[New Thread 0x7f9248fef640 (LWP 98749)]
[New Thread 0x7f92487ee640 (LWP 98750)]
[New Thread 0x7f9247fed640 (LWP 98751)]
[New Thread 0x7f92477ec640 (LWP 98752)]
[New Thread 0x7f9246feb640 (LWP 98753)]
[New Thread 0x7f92467ea640 (LWP 98754)]
[New Thread 0x7f9245fe9640 (LWP 98755)]
[New Thread 0x7f92457e8640 (LWP 98756)]
[New Thread 0x7f9244fe7640 (LWP 98757)]
[New Thread 0x7f92447e6640 (LWP 98758)]
[New Thread 0x7f9243fe5640 (LWP 98759)]
[New Thread 0x7f92437e4640 (LWP 98760)]
[New Thread 0x7f9242fe3640 (LWP 98761)]
[New Thread 0x7f92427e2640 (LWP 98762)]
[New Thread 0x7f9241fe1640 (LWP 98763)]
[New Thread 0x7f92417e0640 (LWP 98764)]
[New Thread 0x7f9240fdf640 (LWP 98765)]
[New Thread 0x7f92407de640 (LWP 98766)]
[New Thread 0x7f923ffdd640 (LWP 98767)]
[New Thread 0x7f923f7dc640 (LWP 98768)]
[New Thread 0x7f923efdb640 (LWP 98769)]
[New Thread 0x7f923e7da640 (LWP 98770)]
[New Thread 0x7f923dfd9640 (LWP 98771)]
[New Thread 0x7f923d7d8640 (LWP 98772)]
[New Thread 0x7f923cfd7640 (LWP 98773)]
[New Thread 0x7f923c7d6640 (LWP 98774)]
[New Thread 0x7f923bfd5640 (LWP 98775)]
[New Thread 0x7f923b7d4640 (LWP 98776)]
[New Thread 0x7f923afd3640 (LWP 98777)]
[New Thread 0x7f923a7d2640 (LWP 98778)]
[New Thread 0x7f9239fd1640 (LWP 98779)]
[New Thread 0x7f92397d0640 (LWP 98780)]
[New Thread 0x7f9238fcf640 (LWP 98781)]
[New Thread 0x7f92387ce640 (LWP 98782)]
[New Thread 0x7f9237fcd640 (LWP 98783)]
[New Thread 0x7f92377cc640 (LWP 98784)]
[New Thread 0x7f9236fcb640 (LWP 98785)]
[New Thread 0x7f92367ca640 (LWP 98786)]
[New Thread 0x7f9235fc9640 (LWP 98787)]
[New Thread 0x7f92357c8640 (LWP 98788)]
[New Thread 0x7f9234fc7640 (LWP 98789)]
[New Thread 0x7f92347c6640 (LWP 98790)]
[New Thread 0x7f9233fc5640 (LWP 98791)]
[New Thread 0x7f92337c4640 (LWP 98792)]
[New Thread 0x7f9232fc3640 (LWP 98793)]
[New Thread 0x7f92327c2640 (LWP 98794)]
[New Thread 0x7f9231fc1640 (LWP 98795)]
before call

Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
__memset_evex_unaligned_erms () at ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:250
250     ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S: No such file or directory.
(gdb) bt
#0  __memset_evex_unaligned_erms () at ../sysdeps/x86_64/multiarch/memset-vec-unaligned-erms.S:250
#1  0x00007f92d32e2090 in Format_floatbits.constprop.0.isra.0 () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#2  0x00007f92d32e5d42 in Dragon4_Positional () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#3  0x00007f92d331020a in dragon4_positional () from /root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy/_core/_multiarray_umath.cpython-313-x86_64-linux-gnu.so
#4  0x0000000000563395 in cfunction_vectorcall_FASTCALL_KEYWORDS (func=0x7f92d3b57010, args=0x7f92d4200120, nargsf=<optimized out>, kwnames=0x7f92d199b0d0) at /usr/local/src/conda/python-3.13.0/Include/cpython/methodobject.h:50
#5  0x0000000000537aa1 in _PyObject_VectorcallTstate (kwnames=0x7f92d199b0d0, nargsf=9223372036854775809, args=0x7f92d4200120, callable=0x7f92d3b57010, tstate=0x8eac80 <_PyRuntime+282976>) at /usr/local/src/conda/python-3.13.0/Include/internal/pycore_call.h:168
#6  PyObject_Vectorcall (callable=0x7f92d3b57010, args=0x7f92d4200120, nargsf=9223372036854775809, kwnames=0x7f92d199b0d0) at /usr/local/src/conda/python-3.13.0/Objects/call.c:327
#7  0x000000000055292b in _PyEval_EvalFrameDefault (tstate=<optimized out>, frame=<optimized out>, throwflag=<optimized out>) at /usr/local/src/conda/python-3.13.0/Python/generated_cases.c.h:1502
#8  0x000000000060902e in PyEval_EvalCode (co=<optimized out>, globals=0x7f92d3c4bac0, locals=<optimized out>) at /usr/local/src/conda/python-3.13.0/Python/ceval.c:596
#9  0x000000000062eedd in run_eval_code_obj (tstate=0x8eac80 <_PyRuntime+282976>, co=0x7f92d3de6af0, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1323
#10 0x0000000000629d9d in run_mod (mod=<optimized out>, filename=<optimized out>, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0, flags=<optimized out>, arena=<optimized out>, interactive_src=0x0, generate_new_source=0) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1408
#11 0x0000000000648890 in pyrun_file (fp=0x20ce2e0, filename=0x7f92d3ca2100, start=<optimized out>, globals=0x7f92d3c4bac0, locals=0x7f92d3c4bac0, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:1241
#12 0x00000000006473fb in _PyRun_SimpleFileObject (fp=0x20ce2e0, filename=0x7f92d3ca2100, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:490
#13 0x000000000064711b in _PyRun_AnyFileObject (fp=0x20ce2e0, filename=0x7f92d3ca2100, closeit=1, flags=0x7fff78fa0d48) at /usr/local/src/conda/python-3.13.0/Python/pythonrun.c:77
#14 0x0000000000640b67 in pymain_run_file_obj (skip_source_first_line=0, filename=0x7f92d3ca2100, program_name=0x7f92d3cb8080) at /usr/local/src/conda/python-3.13.0/Modules/main.c:409
#15 pymain_run_file (config=0x8bd378 <_PyRuntime+96344>) at /usr/local/src/conda/python-3.13.0/Modules/main.c:428
#16 pymain_run_python (exitcode=0x7fff78fa0d3c) at /usr/local/src/conda/python-3.13.0/Modules/main.c:696
#17 Py_RunMain () at /usr/local/src/conda/python-3.13.0/Modules/main.c:775
#18 0x00000000005f9509 in Py_BytesMain (argc=<optimized out>, argv=<optimized out>) at /usr/local/src/conda/python-3.13.0/Modules/main.c:829
#19 0x00007f92d3f0ad90 in __libc_start_call_main (main=main@entry=0x5f9440 <main>, argc=argc@entry=2, argv=argv@entry=0x7fff78fa0f98) at ../sysdeps/nptl/libc_start_call_main.h:58
#20 0x00007f92d3f0ae40 in __libc_start_main_impl (main=0x5f9440 <main>, argc=2, argv=0x7fff78fa0f98, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fff78fa0f88) at ../csu/libc-start.c:392
#21 0x00000000005f885d in _start ()
(gdb)
```


### Python and NumPy Versions:

2.2.1
3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, 21:29:38) [GCC 11.2.0]

### Runtime Environment:

[{'numpy_version': '2.2.1',
  'python': '3.13.0 | packaged by Anaconda, Inc. | (main, Oct  7 2024, '
            '21:29:38) [GCC 11.2.0]',
  'uname': uname_result(system='Linux', node='a475b702ecc0', release='5.4.0-150-generic', version='#167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX'],
                      'not_found': ['AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'SkylakeX',
  'filepath': '/root/miniconda3/envs/py313/lib/python3.13/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 64,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

### Context for the issue:

_No response_","@EgodPrime Thanks for reporting this, I can confirm the issue with `np.format_float_positional(x=1.047, precision=2, pad_left=int(1e5))`

The crash might be a buffer overflow caused here:

https://github.com/numpy/numpy/blob/a07c6c5f12eec1322d2487f0ed935c5c13b8d883/numpy/_core/src/multiarray/dragon4.c#L3039-L3042 || Thanks for opening the issue!  Ping @ahaldane maybe you have time to look into it.  It is pretty easy to add a hot-fix for this, but it seems to me what we really need is a slightly more invasive refactor to add an error return to this (and all possible similar) paths.

I.e. we shouldn't just avoid failing, we should ensure the return is a proper Python error (or success, but I don't think that is worth the trouble).",closed,2024-12-27T05:37:00+00:00,2025-01-21T08:17:10+00:00,EgodPrime,00 - Bug,1,"PR#28149 - numpy/_core/src/multiarray/dragon4.c: @@ -1615,7 +1615,8 @@ typedef struct Dragon4_Options {|;|  *|;|  * See Dragon4_Options for description of remaining arguments.|;|  */|;|-static npy_uint32|;|+|;|+static npy_int32|;| FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                  npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                  npy_bool hasUnequalMargins, DigitMode digit_mode,|;|@@ -1646,7 +1647,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|         buffer[pos++] = '-'|;|;         has_sign = 1|;|;     }|;|-|;|+        |;|     numDigits = Dragon4(mantissa, exponent, mantissaBit, hasUnequalMargins,|;|                         digit_mode, cutoff_mode, precision, min_digits,|;|                         buffer + has_sign, maxPrintLen - has_sign,|;|@@ -1658,14 +1659,14 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     /* if output has a whole number */|;|     if (printExponent >= 0) {|;|         /* leave the whole number at the start of the buffer */|;|-        numWholeDigits = printExponent+1|;|;+        numWholeDigits = printExponent+1;        |;|         if (numDigits <= numWholeDigits) {|;|             npy_int32 count = numWholeDigits - numDigits|;|;             pos += numDigits|;|; |;|-            /* don't overflow the buffer */|;|-            if (pos + count > maxPrintLen) {|;|-                count = maxPrintLen - pos|;|;+            if (count > maxPrintLen - pos) {|;|+                PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+                return -1|;|;             }|;| |;|             /* add trailing zeros up to the decimal point */|;|@@ -1767,9 +1768,12 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|              pos < maxPrintLen) {|;|         /* add trailing zeros up to add_digits length */|;|         /* compute the number of trailing zeros needed */|;|+        |;|         npy_int32 count = desiredFractionalDigits - numFractionDigits|;|;-        if (pos + count > maxPrintLen) {|;|-            count = maxPrintLen - pos|;|;+        |;|+        if (count > maxPrintLen - pos) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;|         numFractionDigits += count|;|; |;|@@ -1802,7 +1806,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     }|;| |;|     /* add any whitespace padding to right side */|;|-    if (digits_right >= numFractionDigits) {|;|+    if (digits_right >= numFractionDigits) {        |;|         npy_int32 count = digits_right - numFractionDigits|;|; |;|         /* in trim_mode DptZeros, if right padding, add a space for the . */|;|@@ -1811,8 +1815,9 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|             buffer[pos++] = ' '|;|;         }|;| |;|-        if (pos + count > maxPrintLen) {|;|-            count = maxPrintLen - pos|;|;+        if (count > maxPrintLen - pos) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;| |;|         for ( ; count > 0; count--) {|;|@@ -1823,14 +1828,16 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|     if (digits_left > numWholeDigits + has_sign) {|;|         npy_int32 shift = digits_left - (numWholeDigits + has_sign)|;|;         npy_int32 count = pos|;|;-|;|-        if (count + shift > maxPrintLen) {|;|-            count = maxPrintLen - shift|;|;+                |;|+        if (count > maxPrintLen - shift) {|;|+            PyErr_SetString(PyExc_RuntimeError, ""Float formating result too large"")|;|;+            return -1|;|;         }|;| |;|         if (count > 0) {|;|             memmove(buffer + shift, buffer, count)|;|;         }|;|+|;|         pos = shift + count|;|;         for ( ; shift > 0; shift--) {|;|             buffer[shift - 1] = ' '|;|;@@ -1860,7 +1867,7 @@ FormatPositional(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|  *|;|  * See Dragon4_Options for description of remaining arguments.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| FormatScientific (char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                   npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                   npy_bool hasUnequalMargins, DigitMode digit_mode,|;|@@ -2158,7 +2165,7 @@ PrintInfNan(char *buffer, npy_uint32 bufferSize, npy_uint64 mantissa,|;|  * Helper function that takes Dragon4 parameters and options and|;|  * calls Dragon4.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Format_floatbits(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|                  npy_int32 exponent, char signbit, npy_uint32 mantissaBit,|;|                  npy_bool hasUnequalMargins, Dragon4_Options *opt)|;|@@ -2187,7 +2194,7 @@ Format_floatbits(char *buffer, npy_uint32 bufferSize, BigInt *mantissa,|;|  * exponent:  5 bits|;|  * mantissa: 10 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary16(|;|         npy_half *value, Dragon4_Options *opt)|;| {|;|@@ -2274,7 +2281,7 @@ Dragon4_PrintFloat_IEEE_binary16(|;|  * exponent:  8 bits|;|  * mantissa: 23 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary32(|;|         npy_float32 *value,|;|         Dragon4_Options *opt)|;|@@ -2367,7 +2374,7 @@ Dragon4_PrintFloat_IEEE_binary32(|;|  * exponent: 11 bits|;|  * mantissa: 52 bits|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary64(|;|         npy_float64 *value, Dragon4_Options *opt)|;| {|;|@@ -2482,7 +2489,7 @@ typedef struct FloatVal128 {|;|  * intbit     1 bit,  first u64|;|  * mantissa: 63 bits, first u64|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended(|;|     FloatVal128 value, Dragon4_Options *opt)|;| {|;|@@ -2580,7 +2587,7 @@ Dragon4_PrintFloat_Intel_extended(|;|  * system. But numpy defines NPY_FLOAT80, so if we come across it, assume it is|;|  * an Intel extended format.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended80(|;|     npy_float80 *value, Dragon4_Options *opt)|;| {|;|@@ -2604,7 +2611,7 @@ Dragon4_PrintFloat_Intel_extended80(|;| |;| #ifdef HAVE_LDOUBLE_INTEL_EXTENDED_12_BYTES_LE|;| /* Intel's 80-bit IEEE extended precision format, 96-bit storage */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended96(|;|     npy_float96 *value, Dragon4_Options *opt)|;| {|;|@@ -2628,7 +2635,7 @@ Dragon4_PrintFloat_Intel_extended96(|;| |;| #ifdef HAVE_LDOUBLE_MOTOROLA_EXTENDED_12_BYTES_BE|;| /* Motorola Big-endian equivalent of the Intel-extended 96 fp format */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Motorola_extended96(|;|     npy_float96 *value, Dragon4_Options *opt)|;| {|;|@@ -2665,7 +2672,7 @@ typedef union FloatUnion128|;| |;| #ifdef HAVE_LDOUBLE_INTEL_EXTENDED_16_BYTES_LE|;| /* Intel's 80-bit IEEE extended precision format, 128-bit storage */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_Intel_extended128(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2694,7 +2701,7 @@ Dragon4_PrintFloat_Intel_extended128(|;|  * I am not sure if the arch also supports uint128, and C does not seem to|;|  * support int128 literals. So we use uint64 to do manipulation.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128(|;|     FloatVal128 val128, Dragon4_Options *opt)|;| {|;|@@ -2779,7 +2786,7 @@ Dragon4_PrintFloat_IEEE_binary128(|;| }|;| |;| #if defined(HAVE_LDOUBLE_IEEE_QUAD_LE)|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128_le(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2799,7 +2806,7 @@ Dragon4_PrintFloat_IEEE_binary128_le(|;|  * This function is untested, very few, if any, architectures implement|;|  * big endian IEEE binary128 floating point.|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IEEE_binary128_be(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -2854,7 +2861,7 @@ Dragon4_PrintFloat_IEEE_binary128_be(|;|  * https://gcc.gnu.org/wiki/Ieee128PowerPCA|;|  * https://www.ibm.com/support/knowledgecenter/en/ssw_aix_71/com.ibm.aix.genprogc/128bit_long_double_floating-point_datatype.htm|;|  */|;|-static npy_uint32|;|+static npy_int32|;| Dragon4_PrintFloat_IBM_double_double(|;|     npy_float128 *value, Dragon4_Options *opt)|;| {|;|@@ -3041,6 +3048,7 @@ Dragon4_PrintFloat_IBM_double_double(|;|  * which goes up to about 10^4932. The Dragon4_scratch struct provides a string|;|  * buffer of this size.|;|  */|;|+|;| #define make_dragon4_typefuncs_inner(Type, npy_type, format) \|;| \|;| PyObject *\ || PR#28149 - numpy/_core/tests/test_scalarprint.py: @@ -8,7 +8,8 @@|;| |;| from tempfile import TemporaryFile|;| import numpy as np|;|-from numpy.testing import assert_, assert_equal, assert_raises, IS_MUSL|;|+from numpy.testing import (|;|+    assert_, assert_equal, assert_raises, assert_raises_regex, IS_MUSL)|;| |;| class TestRealScalars:|;|     def test_str(self):|;|@@ -258,53 +259,93 @@ def test_dragon4(self):|;|         assert_equal(fpos64('324', unique=False, precision=5,|;|                                    fractional=False), ""324.00"")|;| |;|-    def test_dragon4_interface(self):|;|-        tps = [np.float16, np.float32, np.float64]|;|+    available_float_dtypes = [np.float16, np.float32, np.float64, np.float128]\|;|+        if hasattr(np, 'float128') else [np.float16, np.float32, np.float64]|;|+    |;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_positional_interface(self, tp):|;|         # test is flaky for musllinux on np.float128|;|-        if hasattr(np, 'float128') and not IS_MUSL:|;|-            tps.append(np.float128)|;|-|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                |;|+        fpos = np.format_float_positional|;|+        |;|+        # test padding|;|+        assert_equal(fpos(tp('1.0'), pad_left=4, pad_right=4), ""   1.    "")|;|+        assert_equal(fpos(tp('-1.0'), pad_left=4, pad_right=4), ""  -1.    "")|;|+        assert_equal(fpos(tp('-10.2'),|;|+                        pad_left=4, pad_right=4), "" -10.2   "")|;|+        |;|+        # test fixed (non-unique) mode|;|+        assert_equal(fpos(tp('1.0'), unique=False, precision=4), ""1.0000"")|;|+|;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_positional_interface_trim(self, tp):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                        |;|         fpos = np.format_float_positional|;|+        # test trimming|;|+        # trim of 'k' or '.' only affects non-unique mode, since unique|;|+        # mode will not output trailing 0s.|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='k'),|;|+                        ""1.0000"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='.'),|;|+                        ""1."")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='.'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='0'),|;|+                        ""1.0"")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='0'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+        assert_equal(fpos(tp('1.'), trim='0'), ""1.0"")|;|+|;|+        assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='-'),|;|+                        ""1"")|;|+        assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='-'),|;|+                        ""1.2"" if tp != np.float16 else ""1.2002"")|;|+        assert_equal(fpos(tp('1.'), trim='-'), ""1"")|;|+        assert_equal(fpos(tp('1.001'), precision=1, trim='-'), ""1"")|;|+                |;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    @pytest.mark.parametrize(""pad_val"", [10**5, np.iinfo(""int32"").max])|;|+    def test_dragon4_positional_interface_overflow(self, tp, pad_val):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                |;|+        fpos = np.format_float_positional|;|+|;|+        #gh-28068            |;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), unique=False, precision=pad_val)|;|+|;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), precision=2, pad_left=pad_val)|;|+|;|+        with pytest.raises(RuntimeError, |;|+                           match=""Float formating result too large""):|;|+            fpos(tp('1.047'), precision=2, pad_right=pad_val)|;|+|;|+    @pytest.mark.parametrize(""tp"", available_float_dtypes)|;|+    def test_dragon4_scientific_interface(self, tp):|;|+        # test is flaky for musllinux on np.float128|;|+        if IS_MUSL and tp == np.float128:|;|+            pytest.skip(""Skipping flaky test of float128 on musllinux"")|;|+                        |;|         fsci = np.format_float_scientific|;| |;|-        for tp in tps:|;|-            # test padding|;|-            assert_equal(fpos(tp('1.0'), pad_left=4, pad_right=4), ""   1.    "")|;|-            assert_equal(fpos(tp('-1.0'), pad_left=4, pad_right=4), ""  -1.    "")|;|-            assert_equal(fpos(tp('-10.2'),|;|-                         pad_left=4, pad_right=4), "" -10.2   "")|;|-|;|-            # test exp_digits|;|-            assert_equal(fsci(tp('1.23e1'), exp_digits=5), ""1.23e+00001"")|;|-|;|-            # test fixed (non-unique) mode|;|-            assert_equal(fpos(tp('1.0'), unique=False, precision=4), ""1.0000"")|;|-            assert_equal(fsci(tp('1.0'), unique=False, precision=4),|;|-                         ""1.0000e+00"")|;|-|;|-            # test trimming|;|-            # trim of 'k' or '.' only affects non-unique mode, since unique|;|-            # mode will not output trailing 0s.|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='k'),|;|-                         ""1.0000"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='.'),|;|-                         ""1."")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='.'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='0'),|;|-                         ""1.0"")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='0'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-            assert_equal(fpos(tp('1.'), trim='0'), ""1.0"")|;|-|;|-            assert_equal(fpos(tp('1.'), unique=False, precision=4, trim='-'),|;|-                         ""1"")|;|-            assert_equal(fpos(tp('1.2'), unique=False, precision=4, trim='-'),|;|-                         ""1.2"" if tp != np.float16 else ""1.2002"")|;|-            assert_equal(fpos(tp('1.'), trim='-'), ""1"")|;|-            assert_equal(fpos(tp('1.001'), precision=1, trim='-'), ""1"")|;|+        # test exp_digits|;|+        assert_equal(fsci(tp('1.23e1'), exp_digits=5), ""1.23e+00001"")|;|+|;|+        # test fixed (non-unique) mode|;|+        assert_equal(fsci(tp('1.0'), unique=False, precision=4),|;|+                        ""1.0000e+00"")|;| |;|     @pytest.mark.skipif(not platform.machine().startswith(""ppc64""),|;|                         reason=""only applies to ppc float128 values"")","DOC: added limits to pad_left, pad_right || TST: Added tests for correct handling of overflow || BUG: fixed pad_left and pad_right causing overflow if too large || DOC: modified doc for simpler exception || TST: added overflow test and fixed formatting || BUG: fixed overflow checks and simplified error handling || BUG: rewritten excpetion message and fixed overflow check || TST: split test into smaller tests, added large input value || Apply suggestions from code review"
numpy/numpy,ngoldbaum,28190,BUG: np.searchsorted segfaults on structured arrays in 2.2.2,"### Describe the issue:

The reproducer below succeeded on numpy 2.2.1 

- https://github.com/ratt-ru/xarray-ms/actions/runs/12827528711/job/35769680579

but fails on numpy 2.2.2

- https://github.com/ratt-ru/xarray-ms/actions/runs/12859992829/job/35851244780

### Reproduce the code example:

**Edit**: updated reproducer to include pytest

```python
import numpy as np
import pytest
from numpy.testing import assert_array_equal


@pytest.mark.parametrize(""na"", [7])
def test_lexical_binary_search(na):
  rng = np.random.default_rng(seed=42)

  time = np.arange(20.0, dtype=np.float64)[:, None]
  ant1, ant2 = (a.astype(np.int32)[None, :] for a in np.triu_indices(na, 1))
  named_arrays = [(""time"", time), (""antenna1"", ant1), (""antenna2"", ant2)]
  names, arrays = zip(*named_arrays)
  arrays = tuple(a.ravel() for a in np.broadcast_arrays(*arrays))
  structured_dtype = np.dtype([(n, a.dtype) for n, a in zip(names, arrays)])

  carray = np.zeros(arrays[0].size, structured_dtype)
  for n, a in zip(names, arrays):
    carray[n] = a

  choice = rng.choice(np.arange(carray.size), 10)

  sarray = np.zeros(choice.size, structured_dtype)

  sarray[""time""] = carray[""time""][choice]
  sarray[""antenna1""] = carray[""antenna1""][choice]
  sarray[""antenna2""] = carray[""antenna2""][choice]

  idx = np.searchsorted(carray, sarray)
  assert_array_equal(carray[idx], sarray)
```

### Error message:

```shell
Fatal Python error: Segmentation fault

Current thread 0x00007c21e7cad080 (most recent call first):
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/terminal.py"", line 463 in write_ensure_prefix
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/terminal.py"", line 633 in pytest_runtest_logreport
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/runner.py"", line 246 in call_and_report
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/runner.py"", line 132 in runtestprotocol
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/main.py"", line 337 in _main
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/main.py"", line 283 in wrap_session
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_callers.py"", line 103 in _multicall
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_manager.py"", line 120 in _hookexec
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/pluggy/_hooks.py"", line 513 in __call__
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 175 in main
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/_pytest/config/__init__.py"", line 201 in console_main
  File ""/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/bin/py.test"", line 8 in <module>

Extension modules: numpy._core._multiarray_umath, numpy.linalg._umath_linalg, pyarrow.lib, arcae.lib.arrow_tables, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, yaml._yaml, psutil._psutil_linux, psutil._psutil_posix, markupsafe._speedups, tornado.speedups, numcodecs.compat_ext, numcodecs.blosc, numcodecs.zstd, numcodecs.lz4, numcodecs._shuffle, msgpack._cmsgpack, numcodecs.jenkins, numcodecs.vlen, numcodecs.fletcher32 (total: 68)
Segmentation fault (core dumped)
```

### Python and NumPy Versions:

2.2.2
3.11.11 (main, Dec  4 2024, 08:55:08) [GCC 13.2.0]

### Runtime Environment:

[{'numpy_version': '2.2.2',
  'python': '3.11.11 (main, Dec  4 2024, 08:55:08) [GCC 13.2.0]',
  'uname': uname_result(system='Linux', node='simon-t14', release='6.8.0-51-generic', version='#52-Ubuntu SMP PREEMPT_DYNAMIC Thu Dec  5 13:09:44 UTC 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Haswell',
  'filepath': '/home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 12,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]

### Context for the issue:

This isn't high priority for me as the test case where this failed demonstrates an idea rather than core functionality.

- https://github.com/ratt-ru/xarray-ms/blob/9664cbc82bc4799a87424c45013c75e11316a98d/tests/test_basic.py#L1-L30

","Hmmm, thanks for the issue.  I can't reproduce on Mac or my linux machine even though the linux machine looks rather similar setup wise.

Maybe someone else will be able to do but maybe you can answer a few things?
* I assume this is a pip intalled NumPy?  (we got `show_runtime`, so likely nothing new).
* Please try the example as pasted here (always good)?  It seems possible to me that it isn't actually a reproducer and the crash happens only in the test suite.  In that case we don't know if it is just random, or the problem is earlier.
* Am I correct to think that this is new in 2.2.2 and the example succeeded in 2.2.1? Because that makes it more important to look into it.

Since you can reproduce this (whether only in pytest or not).  Could you please try running with gdb?  That is either:
* `gdb --args python`, then `r` or `run`.  Then you can just copy paste the code (or put it in a script to run and include it in the initial argument).
* If you run it as the full test suite, use: `gdb --args python -m pytest -p no:faulthandler <pytest args>` where `<pytest args` is whatever you are currently using.  Then again `r` to.
  (I hope this works, I haven't had to use the `-p no:faulthandler` before, but I think it may be needed now.)

After the `r` things should run normally until the crash happens.  After the crash run `bt` to get the backtrace and copy paste it here from the start.  (We probably only need the first 10 entries or so, you can stop after a few lines if you are clearly inside Python.)

It would be good to just add `PYTHONMALLOC=malloc_debug` before the gdb/python call (additionally or on its own).  Since that is a quick and easy way to find some types of issues. || Apologies, I should have tested the reproducer further  on my end.  You're correct, it doesn't reproduce but it does reproduce within pytest

```python
import numpy as np
import pytest
from numpy.testing import assert_array_equal


#@pytest.mark.skip(reason=""https://github.com/numpy/numpy/issues/28190"")
@pytest.mark.parametrize(""na"", [7])
def test_lexical_binary_search(na):
  rng = np.random.default_rng(seed=42)

  time = np.arange(20.0, dtype=np.float64)[:, None]
  ant1, ant2 = (a.astype(np.int32)[None, :] for a in np.triu_indices(na, 1))
  named_arrays = [(""time"", time), (""antenna1"", ant1), (""antenna2"", ant2)]
  names, arrays = zip(*named_arrays)
  arrays = tuple(a.ravel() for a in np.broadcast_arrays(*arrays))
  structured_dtype = np.dtype([(n, a.dtype) for n, a in zip(names, arrays)])

  carray = np.zeros(arrays[0].size, structured_dtype)
  for n, a in zip(names, arrays):
    carray[n] = a

  choice = rng.choice(np.arange(carray.size), 10)

  sarray = np.zeros(choice.size, structured_dtype)

  sarray[""time""] = carray[""time""][choice]
  sarray[""antenna1""] = carray[""antenna1""][choice]
  sarray[""antenna2""] = carray[""antenna2""][choice]

  idx = np.searchsorted(carray, sarray)
  assert_array_equal(carray[idx], sarray)
```


<details> <summary> gdb trace follows </summary>


```bash
$ gdb --args python -m pytest -p no:faulthandler -k test_lexical_binary_search
GNU gdb (Ubuntu 15.0.50.20240403-0ubuntu1) 15.0.50.20240403-git
Copyright (C) 2024 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...

This GDB supports auto-downloading debuginfo from the following URLs:
  <https://debuginfod.ubuntu.com>
Enable debuginfod for this session? (y or [n]) n
Debuginfod has been disabled.
To make this setting permanent, add 'set debuginfod enabled off' to .gdbinit.
(No debugging symbols found in python)
(gdb) r
Starting program: /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/bin/python -m pytest -p no:faulthandler -k test_lexical_binary_search
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffdba006c0 (LWP 1704498)]
[New Thread 0x7fffdb0006c0 (LWP 1704499)]
[New Thread 0x7fffda6006c0 (LWP 1704500)]
[New Thread 0x7fffd9c006c0 (LWP 1704501)]
[New Thread 0x7fffd92006c0 (LWP 1704502)]
[New Thread 0x7fffd88006c0 (LWP 1704503)]
[New Thread 0x7fffd7e006c0 (LWP 1704504)]
[New Thread 0x7fffd74006c0 (LWP 1704505)]
[New Thread 0x7fffd6a006c0 (LWP 1704506)]
[New Thread 0x7fffd60006c0 (LWP 1704507)]
[New Thread 0x7fffd56006c0 (LWP 1704508)]
[New Thread 0x7fffd00006c0 (LWP 1704515)]
===================================================================================== test session starts ======================================================================================
platform linux -- Python 3.11.11, pytest-8.3.3, pluggy-1.5.0
rootdir: /home/simon/code/xarray-ms
configfile: pyproject.toml
collecting ... warning: could not find '.gnu_debugaltlink' file for /lib/x86_64-linux-gnu/libncursesw.so.6
warning: could not find '.gnu_debugaltlink' file for /lib/x86_64-linux-gnu/libtinfo.so.6
collected 56 items / 55 deselected / 1 selected                                                                                                                                                

tests/test_basic.py 
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x000000000052cb28 in ?? ()
(gdb) bt
#0  0x000000000052cb28 in ?? ()
#1  0x0000000000540ad1 in _PyEval_EvalFrameDefault ()
#2  0x0000000000583d88 in ?? ()
#3  0x0000000000583706 in ?? ()
#4  0x000000000056e817 in PyObject_Call ()
#5  0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#6  0x0000000000583613 in ?? ()
#7  0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#8  0x0000000000563eaf in _PyFunction_Vectorcall ()
#9  0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
#10 0x000000000056c361 in _PyObject_Call_Prepend ()
#11 0x0000000000654489 in ?? ()
#12 0x000000000052ebf3 in _PyObject_MakeTpCall ()
#13 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#14 0x0000000000563eaf in _PyFunction_Vectorcall ()
#15 0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#16 0x0000000000563eaf in _PyFunction_Vectorcall ()
#17 0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
#18 0x000000000056c361 in _PyObject_Call_Prepend ()
#19 0x0000000000654489 in ?? ()
#20 0x000000000052ebf3 in _PyObject_MakeTpCall ()
#21 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#22 0x0000000000563eaf in _PyFunction_Vectorcall ()
#23 0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#24 0x0000000000563eaf in _PyFunction_Vectorcall ()
#25 0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
#26 0x000000000056c361 in _PyObject_Call_Prepend ()
#27 0x0000000000654489 in ?? ()
#28 0x000000000052ebf3 in _PyObject_MakeTpCall ()
#29 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#30 0x0000000000563eaf in _PyFunction_Vectorcall ()
#31 0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#32 0x0000000000563eaf in _PyFunction_Vectorcall ()
#33 0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
--Type <RET> for more, q to quit, c to continue without paging--
#34 0x000000000056c361 in _PyObject_Call_Prepend ()
#35 0x0000000000654489 in ?? ()
#36 0x000000000052ebf3 in _PyObject_MakeTpCall ()
#37 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#38 0x000000000060f1ed in ?? ()
#39 0x000000000060e998 in PyEval_EvalCode ()
#40 0x0000000000627228 in ?? ()
#41 0x000000000054b179 in ?? ()
#42 0x000000000054b051 in PyObject_Vectorcall ()
#43 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#44 0x0000000000563eaf in _PyFunction_Vectorcall ()
#45 0x0000000000639122 in ?? ()
#46 0x0000000000638a27 in Py_RunMain ()
#47 0x00000000005ffc8d in Py_BytesMain ()
#48 0x00007ffff7c2a1ca in __libc_start_call_main (main=main@entry=0x5ffbe0, argc=argc@entry=7, argv=argv@entry=0x7fffffffd2a8) at ../sysdeps/nptl/libc_start_call_main.h:58
#49 0x00007ffff7c2a28b in __libc_start_main_impl (main=0x5ffbe0, argc=7, argv=0x7fffffffd2a8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffd298)
    at ../csu/libc-start.c:360
#50 0x00000000005ffb15 in _start ()
(gdb) 
```

The pytest version is 8.3.3

```bash
$ pip freeze | grep pytest
pytest==8.3.3
``` || With PYTHON_MALLOC  **(seberg: This is the interesting traceback)**

<details>


```bash
$ PYTHONMALLOC=malloc_debug gdb --args python -m pytest -p no:faulthandler -k test_lexical_binary_search
GNU gdb (Ubuntu 15.0.50.20240403-0ubuntu1) 15.0.50.20240403-git
Copyright (C) 2024 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...

This GDB supports auto-downloading debuginfo from the following URLs:
  <https://debuginfod.ubuntu.com>
Enable debuginfod for this session? (y or [n]) 
Debuginfod has been disabled.
To make this setting permanent, add 'set debuginfod enabled off' to .gdbinit.
(No debugging symbols found in python)
(gdb) run
Starting program: /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/bin/python -m pytest -p no:faulthandler -k test_lexical_binary_search
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fffdc6006c0 (LWP 1706199)]
[New Thread 0x7fffdbc006c0 (LWP 1706200)]
[New Thread 0x7fffdb2006c0 (LWP 1706201)]
[New Thread 0x7fffda8006c0 (LWP 1706202)]
[New Thread 0x7fffd9e006c0 (LWP 1706203)]
[New Thread 0x7fffd94006c0 (LWP 1706204)]
[New Thread 0x7fffd8a006c0 (LWP 1706205)]
[New Thread 0x7fffd80006c0 (LWP 1706206)]
[New Thread 0x7fffd76006c0 (LWP 1706207)]
[New Thread 0x7fffd6c006c0 (LWP 1706208)]
[New Thread 0x7fffd62006c0 (LWP 1706209)]
[New Thread 0x7fffd0c006c0 (LWP 1706210)]
===================================================================================== test session starts ======================================================================================
platform linux -- Python 3.11.11, pytest-8.3.3, pluggy-1.5.0
rootdir: /home/simon/code/xarray-ms
configfile: pyproject.toml
collecting ... warning: could not find '.gnu_debugaltlink' file for /lib/x86_64-linux-gnu/libncursesw.so.6
warning: could not find '.gnu_debugaltlink' file for /lib/x86_64-linux-gnu/libtinfo.so.6
collected 56 items / 55 deselected / 1 selected                                                                                                                                                

tests/test_basic.py 
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
0x00007ffff7173174 in PyArray_GetClearFunction ()
   from /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/numpy/_core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so
(gdb) bt
#0  0x00007ffff7173174 in PyArray_GetClearFunction ()
   from /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/numpy/_core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so
#1  0x00007ffff71b38c8 in PyArray_ClearArray ()
   from /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/numpy/_core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so
#2  0x00007ffff7128c68 in array_dealloc ()
   from /home/simon/.cache/pypoetry/virtualenvs/xarray-ms-jDhc3Ane-py3.11/lib/python3.11/site-packages/numpy/_core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so
#3  0x0000000000563f5f in _PyFunction_Vectorcall ()
#4  0x000000000056e817 in PyObject_Call ()
#5  0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#6  0x0000000000563eaf in _PyFunction_Vectorcall ()
#7  0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#8  0x0000000000563eaf in _PyFunction_Vectorcall ()
#9  0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
#10 0x000000000056c361 in _PyObject_Call_Prepend ()
#11 0x0000000000654489 in ?? ()
#12 0x000000000052ebf3 in _PyObject_MakeTpCall ()
#13 0x000000000053c3fd in _PyEval_EvalFrameDefault ()
#14 0x0000000000563eaf in _PyFunction_Vectorcall ()
#15 0x0000000000540cdb in _PyEval_EvalFrameDefault ()
#16 0x0000000000563eaf in _PyFunction_Vectorcall ()
#17 0x0000000000533bf2 in _PyObject_FastCallDictTstate ()
#18 0x000000000056c361 in _PyObject_Call_Prepend ()
#19 0x0000000000654489 in ?? ()
``` || > * I assume this is a pip intalled NumPy?  (we got `show_runtime`, so likely nothing new).

correct
  
> * Am I correct to think that this is new in 2.2.2 and the example succeeded in 2.2.1? Because that makes it more important to look into it.

yes, it worked on 2.2.1 and failed on 2.2.2 (just pip installed 2.2.1 in the venv and it succeeded in gdb)
 || Thanks, the second backtrace seems to point at a very clear direction.  I suspect that there is a reference count bug in `searchsorted` on the `dtype`. (i.e. presumably we lose one references to the structured dtype and at cleanup that bytes us). || Just FYI, I tried around a bit and I can reproduce this locally only on linux and only with `2.2.3` or `2.2.x` particularly not on `main` (indeed `pytest` is not requires, calling at as function is sufficient).

So the ""when/where"" it happens is a bit cryptic to me right now (maybe it is just random), but probably best to just dig and find out what is wrong and the rest will become clear. || @ngoldbaum seems to be related to gh-28154.  Adding an incref in the path where `in_descr` is given seems to fix it.  I'll come back to it later, I _think_ that is probably correct and the whole code path was just *always* broken (the comments are confusing me a bit of where and when references do get stolen).

This is a very strange code path, if you pass in a `descr` why not make sure it is in native byte-order _before_ passing it in.

A subtle, but unintentionally large, change I missed/forgot, is that making the dtype canonical does two things for structured dtypes (meaning that something happens now):
* All included dtypes are byte-swapped to be native. 
* The dtype is also made ""compact"" (fields put into order without gaps).

I doubt this matters here as such (the problem is rather that we always take the path), and I think it is likely an OK change, but an unfortunately large one for a backport :/.


EDIT: Still a bit unclear why it isn't showing on main for me.  Might just be random... It does die while cleaning/clearing which explains needing `debug` allocations because the flags would normally prevent any cleanup work (filling with `0xdddddd` probably sets the `HASREF` flag). || Here's a shorter reproducer, which crashes for me on a Mac with 2.2.3 as well as a self-built linux build.

```
In [1]: import numpy as np

In [2]: x = np.array([(0, 1.)], dtype=[('time', '<i8'), ('value', '<f8')])

In [3]: y = np.array((0, 0.), dtype=[('time', '<i8'), ('value', '<f8')])

In [4]: x.searchsorted(y)
Segmentation fault: 11
``` || I bisected this crash to #28160 . || > I doubt this matters here as such (the problem is rather that we always take the path), and I think it is likely an OK change, but an unfortunately large one for a backport :/.

FWIW, I never added the backport flag... 

@charris maybe check with me before backporting PRs I didn't explicitly mark as being ready to backport?

@seberg what do you think about going with the more minimal change I originally suggested that didn't touch the branch that structured DTypes go into? || Yeah, I saw the backport coming through I think and just didn't think it wasn't a big deal, but I missed this reason against it.

My gut-feeling is to just do the original minimal fix for backporting (probably on main).  For long-term, I think just adding the `INCREF` may be fine, but we should maybe re-organize `searchsorted` anyway to normalize the descriptor first (and not rely on this flag). || > My gut-feeling is to just do the original minimal fix for backporting (probably on main)..

I'll take this on today so we can get a quick 2.2.3 out with a fix for the crash on the stable release series.

> For long-term, I think just adding the INCREF may be fine, but we should maybe re-organize searchsorted anyway to normalize the descriptor first (and not rely on this flag).

If you could take this on I'd appreciate it :) || > https://github.com/numpy/numpy/issues/28190#issuecomment-2602746796 

This does trigger on main. Still not totally clear to me why the original script doesn't, but I used this as a regression test. See https://github.com/numpy/numpy/pull/28198.",closed,2025-01-20T07:13:40+00:00,2025-03-05T20:48:45+00:00,sjperkins,"00 - Bug, 06 - Regression",1,"PR#28201 - numpy/_core/src/multiarray/ctors.c: @@ -1829,12 +1829,18 @@ PyArray_CheckFromAny_int(PyObject *op, PyArray_Descr *in_descr,|;| {|;|     PyObject *obj|;|;     if (requires & NPY_ARRAY_NOTSWAPPED) {|;|-        if (!in_descr && PyArray_Check(op)) {|;|-            in_descr = PyArray_DESCR((PyArrayObject *)op)|;|;-            Py_INCREF(in_descr)|;|;+        if (!in_descr && PyArray_Check(op) &&|;|+                PyArray_ISBYTESWAPPED((PyArrayObject* )op)) {|;|+            in_descr = PyArray_DescrNew(PyArray_DESCR((PyArrayObject *)op))|;|;+            if (in_descr == NULL) {|;|+                return NULL|;|;+            }|;|+        }|;|+        else if (in_descr && !PyArray_ISNBO(in_descr->byteorder)) {|;|+            PyArray_DESCR_REPLACE(in_descr)|;|;         }|;|-        if (in_descr) {|;|-            PyArray_DESCR_REPLACE_CANONICAL(in_descr)|;|;+        if (in_descr && in_descr->byteorder != NPY_IGNORE && in_descr->byteorder != NPY_NATIVE) {|;|+            in_descr->byteorder = NPY_NATIVE|;|;         }|;|     }|;| ",BUG: fix data race in a more minimal way
numpy/numpy,HaoZeke,28014,BUG: f2py regression,"### Describe the issue:

`numpy==2.2.0` crashes (2.1.3 is fine) on the example code below. I tracked this down to #27728, which ends up not lower-casing the `IU` on the `integer :: IU` line, due to the following line having a `!f2py` directive.

### Reproduce the code example:

```python
$ cat > repro_lower.F90 <<EOF
subroutine inquire_next(IU)
   IMPLICIT NONE
   integer :: IU
   !f2py intent(in) IU

end subroutine
EOF

$ python -m numpy.f2py -m _repro_lower repro_lower.F90 --lower
```


### Error message:

```shell
[...]
getctype: No C-type found in ""{'attrspec': [], 'intent': ['in']}"", assuming void.
getctype: No C-type found in ""{'attrspec': [], 'intent': ['in']}"", assuming void.
getctype: No C-type found in ""{'attrspec': [], 'intent': ['in']}"", assuming void.
Traceback (most recent call last):
  File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/__main__.py"", line 5, in <module>
    main()
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/f2py2e.py"", line 783, in main
    run_main(sys.argv[1:])
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/f2py2e.py"", line 507, in run_main
    ret = buildmodules(postlist)
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/f2py2e.py"", line 412, in buildmodules
    dict_append(ret[name], rules.buildmodule(module, um))
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/rules.py"", line 1300, in buildmodule
    api, wrap = buildapi(nb)
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/rules.py"", line 1478, in buildapi
    vrd = capi_maps.sign2map(a, var[a])
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/capi_maps.py"", line 583, in sign2map
    ret['pydocsign'], ret['pydocsignout'] = getpydocsign(a, var)
  File ""/workspaces/openggcm/.venv/lib/python3.10/site-packages/numpy/f2py/capi_maps.py"", line 377, in getpydocsign
    sig = '%s : %s %s%s' % (a, opt, c2py_map[ctype], init)
KeyError: 'void'
```


### Python and NumPy Versions:

2.2.0
3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]

### Runtime Environment:

_No response_

### Context for the issue:

I can work around it by lower-casing the variable name in the Fortran source, but this bug looks like it may have broad impacts on f2py users, and (ask me how I know) it wasn't trivial to even track down the source of the breakage to the latest numpy being pulled into pip's build environment.

I did track it down to commit ab3aee356d3ee0877fba4a5319b5f14d0978894b, and I think the breakage was partially fixed by c95c2f009e5c7da0b95fd3adfac7b545816700be, but I'd think the proper fix might be to not lower-case f2py directives, but still lower-case the Fortran code.","@HaoZeke Ping. || My bad, the changes there in #27728 needed to be scoped to `callstatement` and `callprotoargument` which are treated as `C` code (and are therefore case sensitive). I'll have a fix and test up soon, am travelling.

Thanks for the report @germasch (and @charris), sorry for the breakage :'D",closed,2024-12-16T19:32:16+00:00,2024-12-23T14:15:11+00:00,germasch,"00 - Bug, 06 - Regression, component: numpy.f2py",2,"PR#28056 - numpy/f2py/auxfuncs.py: @@ -26,7 +26,7 @@|;|     'hasexternals', 'hasinitvalue', 'hasnote', 'hasresultnote',|;|     'isallocatable', 'isarray', 'isarrayofstrings',|;|     'ischaracter', 'ischaracterarray', 'ischaracter_or_characterarray',|;|-    'iscomplex',|;|+    'iscomplex', 'iscstyledirective',|;|     'iscomplexarray', 'iscomplexfunction', 'iscomplexfunction_warn',|;|     'isdouble', 'isdummyroutine', 'isexternal', 'isfunction',|;|     'isfunction_wrap', 'isint1', 'isint1array', 'isinteger', 'isintent_aux',|;|@@ -423,6 +423,11 @@ def isrequired(var):|;|     return not isoptional(var) and isintent_nothide(var)|;| |;| |;|+def iscstyledirective(f2py_line):|;|+    directives = {""callstatement"", ""callprotoargument"", ""pymethoddef""}|;|+    return any(directive in f2py_line.lower() for directive in directives)|;|+|;|+|;| def isintent_in(var):|;|     if 'intent' not in var:|;|         return 1 || PR#28056 - numpy/f2py/crackfortran.py: @@ -511,11 +511,9 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 origfinalline = ''|;|             else:|;|                 if localdolowercase:|;|-                    # lines with intent() should be lowered otherwise|;|-                    # TestString::test_char fails due to mixed case|;|-                    # f2py directives without intent() should be left untouched|;|-                    # gh-2547, gh-27697, gh-26681|;|-                    finalline = ll.lower() if ""intent"" in ll.lower() or not is_f2py_directive else ll|;|+                    # only skip lowering for C style constructs|;|+                    # gh-2547, gh-27697, gh-26681, gh-28014|;|+                    finalline = ll.lower() if not (is_f2py_directive and iscstyledirective(ll)) else ll|;|                 else:|;|                     finalline = ll|;|                 origfinalline = ll || PR#28056 - numpy/f2py/tests/src/regression/lower_f2py_fortran.f90: @@ -0,0 +1,5 @@|;|+subroutine inquire_next(IU)|;|+   IMPLICIT NONE|;|+   integer :: IU|;|+   !f2py intent(in) IU|;|+end subroutine || PR#28056 - numpy/f2py/tests/test_regression.py: @@ -124,6 +124,15 @@ def test_gh26148b(self):|;|         assert res[0] == 8|;|         assert res[1] == 15|;| |;|+class TestLowerF2PYDirectives(util.F2PyTest):|;|+    # Check variables are cased correctly|;|+    sources = [util.getpath(""tests"", ""src"", ""regression"", ""lower_f2py_fortran.f90"")]|;|+|;|+    @pytest.mark.slow|;|+    def test_gh28014(self):|;|+        self.module.inquire_next(3)|;|+        assert True|;|+|;| @pytest.mark.slow|;| def test_gh26623():|;|     # Including libraries with . should not generate an incorrect meson.build || PR#28175 - numpy/f2py/auxfuncs.py: @@ -26,7 +26,7 @@|;|     'hasexternals', 'hasinitvalue', 'hasnote', 'hasresultnote',|;|     'isallocatable', 'isarray', 'isarrayofstrings',|;|     'ischaracter', 'ischaracterarray', 'ischaracter_or_characterarray',|;|-    'iscomplex',|;|+    'iscomplex', 'iscstyledirective',|;|     'iscomplexarray', 'iscomplexfunction', 'iscomplexfunction_warn',|;|     'isdouble', 'isdummyroutine', 'isexternal', 'isfunction',|;|     'isfunction_wrap', 'isint1', 'isint1array', 'isinteger', 'isintent_aux',|;|@@ -423,6 +423,11 @@ def isrequired(var):|;|     return not isoptional(var) and isintent_nothide(var)|;| |;| |;|+def iscstyledirective(f2py_line):|;|+    directives = {""callstatement"", ""callprotoargument"", ""pymethoddef""}|;|+    return any(directive in f2py_line.lower() for directive in directives)|;|+|;|+|;| def isintent_in(var):|;|     if 'intent' not in var:|;|         return 1 || PR#28175 - numpy/f2py/crackfortran.py: @@ -510,11 +510,9 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 origfinalline = ''|;|             else:|;|                 if localdolowercase:|;|-                    # lines with intent() should be lowered otherwise|;|-                    # TestString::test_char fails due to mixed case|;|-                    # f2py directives without intent() should be left untouched|;|-                    # gh-2547, gh-27697, gh-26681|;|-                    finalline = ll.lower() if ""intent"" in ll.lower() or not is_f2py_directive else ll|;|+                    # only skip lowering for C style constructs|;|+                    # gh-2547, gh-27697, gh-26681, gh-28014|;|+                    finalline = ll.lower() if not (is_f2py_directive and iscstyledirective(ll)) else ll|;|                 else:|;|                     finalline = ll|;|                 origfinalline = ll || PR#28175 - numpy/f2py/tests/src/regression/lower_f2py_fortran.f90: @@ -0,0 +1,5 @@|;|+subroutine inquire_next(IU)|;|+   IMPLICIT NONE|;|+   integer :: IU|;|+   !f2py intent(in) IU|;|+end subroutine || PR#28175 - numpy/f2py/tests/test_regression.py: @@ -122,6 +122,15 @@ def test_gh26148b(self):|;|         assert(res[0] == 8)|;|         assert(res[1] == 15)|;| |;|+class TestLowerF2PYDirectives(util.F2PyTest):|;|+    # Check variables are cased correctly|;|+    sources = [util.getpath(""tests"", ""src"", ""regression"", ""lower_f2py_fortran.f90"")]|;|+|;|+    @pytest.mark.slow|;|+    def test_gh28014(self):|;|+        self.module.inquire_next(3)|;|+        assert True|;|+|;| @pytest.mark.slow|;| def test_gh26623():|;|     # Including libraries with . should not generate an incorrect meson.build","TST: Add f2py case regression

Co-authored-by: germasch <germasch@users.noreply.github.com> || BUG: Fix casing for f2py directives || TST: Add f2py case regression

Co-authored-by: germasch <germasch@users.noreply.github.com> || BUG: Fix casing for f2py directives"
numpy/numpy,HaoZeke,25207,BUG: c2capi_map entries missing for iso_c_binding in f2py,"### Describe the issue:

In https://github.com/numpy/numpy/pull/24555 the implementation of f2cmap was supplemented by definitions from iso_c_binding, however, due to an oversight there are no corresponding c2capi_map entries which results in `KeyError` during an f2py run.

### Reproduce the code example:

```python
subroutine add(A, B, C, N)
   use iso_c_binding, only: c_int64_t
   implicit none
   integer(c_int64_t), intent(in) :: A(*)
   integer(c_int64_t), intent(in) :: B(*)
   integer(c_int64_t), intent(out) :: C(*)
   integer, intent(in) :: N
   integer :: j

   do j = 1, N
      C(j) = A(j)+B(j)
   end do
end subroutine
```


### Error message:

```shell
$ python3 -m numpy.f2py -m add add.f90
Reading fortran codes...
        Reading file 'add.f90' (format:free)
Post-processing...
        Block: add
                        Block: add
In: :add:add.f90:add
get_useparameters: no module iso_c_binding info used by add
Applying post-processing hooks...
  character_backward_compatibility_hook
Post-processing (stage 2)...
Building modules...
    Building module ""add""...
    Generating possibly empty wrappers""
    Maybe empty ""add-f2pywrappers.f""
        Constructing wrapper function ""add""...
getarrdims:warning: assumed shape array, using 0 instead of '*'
Traceback (most recent call last):
  File ""<frozen runpy>"", line 198, in _run_module_as_main
  File ""<frozen runpy>"", line 88, in _run_code
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/__main__.py"", line 5, in <module>
    main()
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/f2py2e.py"", line 734, in main
    run_main(sys.argv[1:])
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/f2py2e.py"", line 496, in run_main
    ret = buildmodules(postlist)
          ^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/f2py2e.py"", line 418, in buildmodules
    dict_append(ret[name], rules.buildmodule(module, um))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/rules.py"", line 1298, in buildmodule
    api, wrap = buildapi(nb)
                ^^^^^^^^^^^^
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/rules.py"", line 1476, in buildapi
    vrd = capi_maps.sign2map(a, var[a])
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/capi_maps.py"", line 602, in sign2map
    ret['pydocsign'], ret['pydocsignout'] = getpydocsign(a, var)
                                            ^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib64/python3.12/site-packages/numpy/f2py/capi_maps.py"", line 410, in getpydocsign
    c2pycode_map[
KeyError: 'int64_t'
```

### Runtime information:

```python
>>> import sys, numpy; print(numpy.__version__); print(sys.version)
1.26.2
3.12.0 (main, Oct  2 2023, 00:00:00) [GCC 13.2.1 20230918 (Red Hat 13.2.1-3)]
>>> print(numpy.show_runtime())
WARNING: `threadpoolctl` not found in system! Install it by `pip install threadpoolctl`. Once installed, try `np.show_runtime` again for more detailed build information
[{'numpy_version': '1.26.2',
  'python': '3.12.0 (main, Oct  2 2023, 00:00:00) [GCC 13.2.1 20230918 (Red '
            'Hat 13.2.1-3)]',
  'uname': uname_result(system='Linux', node='0794a3b936a4', release='5.15.0-78-generic', version='#85~20.04.1-Ubuntu SMP Mon Jul 17 09:42:39 UTC 2023', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX'],
                      'not_found': ['AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}}]
None
```

### Context for the issue:

Workaround: Create a `.f2py_f2cmap` with the contents
```
{'integer':{'c_int64_t':'long_long'}}
```",,closed,2023-11-20T19:49:37+00:00,2023-12-18T17:03:24+00:00,hmenke,"00 - Bug, component: numpy.f2py",1,"PR#25226 - numpy/f2py/_isocbind.py: @@ -9,48 +9,53 @@|;| |;| NO WARRANTY IS EXPRESSED OR IMPLIED.  USE AT YOUR OWN RISK.|;| """"""|;|+# These map to keys in c2py_map, via forced casting for now, see gh-25229|;| iso_c_binding_map = {|;|     'integer': {|;|         'c_int': 'int',|;|-        'c_short': 'short int',|;|-        'c_long': 'long int',|;|-        'c_long_long': 'long long int',|;|-        'c_signed_char': 'signed char',|;|-        'c_size_t': 'size_t',|;|-        'c_int8_t': 'int8_t',|;|-        'c_int16_t': 'int16_t',|;|-        'c_int32_t': 'int32_t',|;|-        'c_int64_t': 'int64_t',|;|-        'c_int_least8_t': 'int_least8_t',|;|-        'c_int_least16_t': 'int_least16_t',|;|-        'c_int_least32_t': 'int_least32_t',|;|-        'c_int_least64_t': 'int_least64_t',|;|-        'c_int_fast8_t': 'int_fast8_t',|;|-        'c_int_fast16_t': 'int_fast16_t',|;|-        'c_int_fast32_t': 'int_fast32_t',|;|-        'c_int_fast64_t': 'int_fast64_t',|;|-        'c_intmax_t': 'intmax_t',|;|-        'c_intptr_t': 'intptr_t',|;|-        'c_ptrdiff_t': 'intptr_t',|;|+        'c_short': 'short',  # 'short' <=> 'int' for now|;|+        'c_long': 'long',  # 'long' <=> 'int' for now|;|+        'c_long_long': 'long_long',|;|+        'c_signed_char': 'signed_char',|;|+        'c_size_t': 'unsigned',  # size_t <=> 'unsigned' for now|;|+        'c_int8_t': 'signed_char',  # int8_t <=> 'signed_char' for now|;|+        'c_int16_t': 'short',  # int16_t <=> 'short' for now|;|+        'c_int32_t': 'int',  # int32_t <=> 'int' for now|;|+        'c_int64_t': 'long_long',|;|+        'c_int_least8_t': 'signed_char',  # int_least8_t <=> 'signed_char' for now|;|+        'c_int_least16_t': 'short',  # int_least16_t <=> 'short' for now|;|+        'c_int_least32_t': 'int',  # int_least32_t <=> 'int' for now|;|+        'c_int_least64_t': 'long_long',|;|+        'c_int_fast8_t': 'signed_char',  # int_fast8_t <=> 'signed_char' for now|;|+        'c_int_fast16_t': 'short',  # int_fast16_t <=> 'short' for now|;|+        'c_int_fast32_t': 'int',  # int_fast32_t <=> 'int' for now|;|+        'c_int_fast64_t': 'long_long',|;|+        'c_intmax_t': 'long_long',  # intmax_t <=> 'long_long' for now|;|+        'c_intptr_t': 'long',  # intptr_t <=> 'long' for now|;|+        'c_ptrdiff_t': 'long',  # ptrdiff_t <=> 'long' for now|;|     },|;|     'real': {|;|         'c_float': 'float',|;|         'c_double': 'double',|;|-        'c_long_double': 'long double'|;|+        'c_long_double': 'long_double'|;|     },|;|     'complex': {|;|-        'c_float_complex': 'float _Complex',|;|-        'c_double_complex': 'double _Complex',|;|-        'c_long_double_complex': 'long double _Complex'|;|+        'c_float_complex': 'complex_float',|;|+        'c_double_complex': 'complex_double',|;|+        'c_long_double_complex': 'complex_long_double'|;|     },|;|     'logical': {|;|-        'c_bool': '_Bool'|;|+        'c_bool': 'unsigned_char'  # _Bool <=> 'unsigned_char' for now|;|     },|;|     'character': {|;|         'c_char': 'char'|;|     }|;| }|;| |;|+# TODO: See gh-25229|;|+isoc_c2pycode_map = {}|;|+iso_c2py_map = {}|;|+|;| isoc_kindmap = {}|;| for fortran_type, c_type_dict in iso_c_binding_map.items():|;|     for c_type in c_type_dict.keys(): || PR#25226 - numpy/f2py/auxfuncs.py: @@ -44,7 +44,7 @@|;|     'isunsigned_long_longarray', 'isunsigned_short',|;|     'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess',|;|     'replace', 'show', 'stripcomma', 'throw_error', 'isattr_value',|;|-    'deep_merge', 'getuseblocks'|;|+    'getuseblocks', 'process_f2cmap_dict'|;| ]|;| |;| |;|@@ -893,28 +893,6 @@ def applyrules(rules, d, var={}):|;|                 del ret[k]|;|     return ret|;| |;|-def deep_merge(dict1, dict2):|;|-    """"""Recursively merge two dictionaries into a new dictionary.|;|-|;|-    Parameters:|;|-    - dict1: The base dictionary.|;|-    - dict2: The dictionary to merge into a copy of dict1.|;|-             If a key exists in both, the dict2 value will take precedence.|;|-|;|-    Returns:|;|-    - A new merged dictionary.|;|-    """"""|;|-    merged_dict = deepcopy(dict1)|;|-    for key, value in dict2.items():|;|-        if key in merged_dict:|;|-            if isinstance(merged_dict[key], dict) and isinstance(value, dict):|;|-                merged_dict[key] = deep_merge(merged_dict[key], value)|;|-            else:|;|-                merged_dict[key] = value|;|-        else:|;|-            merged_dict[key] = value|;|-    return merged_dict|;|-|;| _f2py_module_name_match = re.compile(r'\s*python\s*module\s*(?P<name>[\w_]+)',|;|                                      re.I).match|;| _f2py_user_module_name_match = re.compile(r'\s*python\s*module\s*(?P<name>[\w_]*?'|;|@@ -939,3 +917,72 @@ def getuseblocks(pymod):|;|             if modblock.get('use'):|;|                 all_uses.extend([x for x in modblock.get(""use"").keys() if ""__"" not in x])|;|     return all_uses|;|+|;|+def process_f2cmap_dict(f2cmap_all, new_map, c2py_map, verbose = False):|;|+    """"""|;|+    Update the Fortran-to-C type mapping dictionary with new mappings and|;|+    return a list of successfully mapped C types.|;|+|;|+    This function integrates a new mapping dictionary into an existing|;|+    Fortran-to-C type mapping dictionary. It ensures that all keys are in|;|+    lowercase and validates new entries against a given C-to-Python mapping|;|+    dictionary. Redefinitions and invalid entries are reported with a warning.|;|+|;|+    Parameters|;|+    ----------|;|+    f2cmap_all : dict|;|+        The existing Fortran-to-C type mapping dictionary that will be updated.|;|+        It should be a dictionary of dictionaries where the main keys represent|;|+        Fortran types and the nested dictionaries map Fortran type specifiers|;|+        to corresponding C types.|;|+|;|+    new_map : dict|;|+        A dictionary containing new type mappings to be added to `f2cmap_all`.|;|+        The structure should be similar to `f2cmap_all`, with keys representing|;|+        Fortran types and values being dictionaries of type specifiers and their|;|+        C type equivalents.|;|+|;|+    c2py_map : dict|;|+        A dictionary used for validating the C types in `new_map`. It maps C|;|+        types to corresponding Python types and is used to ensure that the C|;|+        types specified in `new_map` are valid.|;|+|;|+    verbose : boolean|;|+        A flag used to provide information about the types mapped|;|+|;|+    Returns|;|+    -------|;|+    tuple of (dict, list)|;|+        The updated Fortran-to-C type mapping dictionary and a list of|;|+        successfully mapped C types.|;|+    """"""|;|+    f2cmap_mapped = []|;|+|;|+    new_map_lower = {}|;|+    for k, d1 in new_map.items():|;|+        d1_lower = {k1.lower(): v1 for k1, v1 in d1.items()}|;|+        new_map_lower[k.lower()] = d1_lower|;|+|;|+    for k, d1 in new_map_lower.items():|;|+        if k not in f2cmap_all:|;|+            f2cmap_all[k] = {}|;|+|;|+        for k1, v1 in d1.items():|;|+            if v1 in c2py_map:|;|+                if k1 in f2cmap_all[k]:|;|+                    outmess(|;|+                        ""\tWarning: redefinition of {'%s':{'%s':'%s'->'%s'}}\n""|;|+                        % (k, k1, f2cmap_all[k][k1], v1)|;|+                    )|;|+                f2cmap_all[k][k1] = v1|;|+                if verbose:|;|+                    outmess('\tMapping ""%s(kind=%s)"" to ""%s""\n' % (k, k1, v1))|;|+                f2cmap_mapped.append(v1)|;|+            else:|;|+                if verbose:|;|+                    errmess(|;|+                        ""\tIgnoring map {'%s':{'%s':'%s'}}: '%s' must be in %s\n""|;|+                        % (k, k1, v1, v1, list(c2py_map.keys()))|;|+                    )|;|+|;|+    return f2cmap_all, f2cmap_mapped || PR#25226 - numpy/f2py/capi_maps.py: @@ -14,7 +14,7 @@|;| import os|;| from .crackfortran import markoutercomma|;| from . import cb_rules|;|-from ._isocbind import iso_c_binding_map|;|+from ._isocbind import iso_c_binding_map, isoc_c2pycode_map, iso_c2py_map|;| |;| # The environment provided by auxfuncs.py is needed for some calls to eval.|;| # As the needed functions cannot be determined by static inspection of the|;|@@ -24,7 +24,7 @@|;| __all__ = [|;|     'getctype', 'getstrlength', 'getarrdims', 'getpydocsign',|;|     'getarrdocsign', 'getinit', 'sign2map', 'routsign2map', 'modsign2map',|;|-    'cb_sign2map', 'cb_routsign2map', 'common_sign2map'|;|+    'cb_sign2map', 'cb_routsign2map', 'common_sign2map', 'process_f2cmap_dict'|;| ]|;| |;| |;|@@ -126,13 +126,17 @@|;|               'byte': {'': 'char'},|;|               }|;| |;|-f2cmap_all = deep_merge(f2cmap_all, iso_c_binding_map)|;|+# Add ISO_C handling|;|+c2pycode_map.update(isoc_c2pycode_map)|;|+c2py_map.update(iso_c2py_map)|;|+f2cmap_all, _ = process_f2cmap_dict(f2cmap_all, iso_c_binding_map, c2py_map)|;|+# End ISO_C handling|;| f2cmap_default = copy.deepcopy(f2cmap_all)|;| |;| f2cmap_mapped = []|;| |;| def load_f2cmap_file(f2cmap_file):|;|-    global f2cmap_all|;|+    global f2cmap_all, f2cmap_mapped|;| |;|     f2cmap_all = copy.deepcopy(f2cmap_default)|;| |;|@@ -151,29 +155,11 @@ def load_f2cmap_file(f2cmap_file):|;|         outmess('Reading f2cmap from {!r} ...\n'.format(f2cmap_file))|;|         with open(f2cmap_file) as f:|;|             d = eval(f.read().lower(), {}, {})|;|-        for k, d1 in d.items():|;|-            for k1 in d1.keys():|;|-                d1[k1.lower()] = d1[k1]|;|-            d[k.lower()] = d[k]|;|-        for k in d.keys():|;|-            if k not in f2cmap_all:|;|-                f2cmap_all[k] = {}|;|-            for k1 in d[k].keys():|;|-                if d[k][k1] in c2py_map:|;|-                    if k1 in f2cmap_all[k]:|;|-                        outmess(|;|-                            ""\tWarning: redefinition of {'%s':{'%s':'%s'->'%s'}}\n"" % (k, k1, f2cmap_all[k][k1], d[k][k1]))|;|-                    f2cmap_all[k][k1] = d[k][k1]|;|-                    outmess('\tMapping ""%s(kind=%s)"" to ""%s""\n' %|;|-                            (k, k1, d[k][k1]))|;|-                    f2cmap_mapped.append(d[k][k1])|;|-                else:|;|-                    errmess(""\tIgnoring map {'%s':{'%s':'%s'}}: '%s' must be in %s\n"" % (|;|-                        k, k1, d[k][k1], d[k][k1], list(c2py_map.keys())))|;|+        f2cmap_all, f2cmap_mapped = process_f2cmap_dict(f2cmap_all, d, c2py_map, True)|;|         outmess('Successfully applied user defined f2cmap changes\n')|;|     except Exception as msg:|;|-        errmess(|;|-            'Failed to apply user defined f2cmap changes: %s. Skipping.\n' % (msg))|;|+        errmess('Failed to apply user defined f2cmap changes: %s. Skipping.\n' % (msg))|;|+|;| |;| cformat_map = {'double': '%g',|;|                'float': '%g', || PR#25226 - numpy/f2py/cfuncs.py: @@ -822,6 +822,8 @@|;| }|;| """"""|;| |;|+# TODO: These should be dynamically generated, too many mapped to int things,|;|+# see note in _isocbind.py|;| needs['char_from_pyobj'] = ['int_from_pyobj']|;| cfuncs['char_from_pyobj'] = """"""|;| static int || PR#25226 - numpy/f2py/tests/src/isocintrin/isoCtests.f90: @@ -1,5 +1,5 @@|;|   module coddity|;|-    use iso_c_binding, only: c_double, c_int|;|+    use iso_c_binding, only: c_double, c_int, c_int64_t|;|     implicit none|;|     contains|;|       subroutine c_add(a, b, c) bind(c, name=""c_add"")|;|@@ -14,4 +14,21 @@ function wat(x, y) result(z) bind(c)|;| |;|           z = x + 7|;|       end function wat|;|+      ! gh-25207|;|+      subroutine c_add_int64(a, b, c) bind(c)|;|+        integer(c_int64_t), intent(in) :: a, b|;|+        integer(c_int64_t), intent(out) :: c|;|+        c = a + b|;|+      end subroutine c_add_int64|;|+      ! gh-25207|;|+      subroutine add_arr(A, B, C)|;|+         integer(c_int64_t), intent(in) :: A(3)|;|+         integer(c_int64_t), intent(in) :: B(3)|;|+         integer(c_int64_t), intent(out) :: C(3)|;|+         integer :: j|;|+|;|+         do j = 1, 3|;|+            C(j) = A(j)+B(j)|;|+         end do|;|+      end subroutine|;|   end module coddity || PR#25226 - numpy/f2py/tests/test_isoc.py: @@ -1,6 +1,7 @@|;| from . import util|;| import numpy as np|;| import pytest|;|+from numpy.testing import assert_allclose|;| |;| class TestISOC(util.F2PyTest):|;|     sources = [|;|@@ -19,3 +20,34 @@ def test_bindc_function(self):|;|         out = self.module.coddity.wat(1, 20)|;|         exp_out = 8|;|         assert  out == exp_out|;|+|;|+    # gh-25207|;|+    def test_bindc_kinds(self):|;|+        out = self.module.coddity.c_add_int64(1, 20)|;|+        exp_out = 21|;|+        assert  out == exp_out|;|+|;|+    # gh-25207|;|+    def test_bindc_add_arr(self):|;|+        a = np.array([1,2,3])|;|+        b = np.array([1,2,3])|;|+        out = self.module.coddity.add_arr(a, b)|;|+        exp_out = a*2|;|+        assert_allclose(out, exp_out)|;|+|;|+|;|+def test_process_f2cmap_dict():|;|+    from numpy.f2py.auxfuncs import process_f2cmap_dict|;|+|;|+    f2cmap_all = {""integer"": {""8"": ""rubbish_type""}}|;|+    new_map = {""INTEGER"": {""4"": ""int""}}|;|+    c2py_map = {""int"": ""int"", ""rubbish_type"": ""long""}|;|+|;|+    exp_map, exp_maptyp = ({""integer"": {""8"": ""rubbish_type"", ""4"": ""int""}}, [""int""])|;|+|;|+    # Call the function|;|+    res_map, res_maptyp = process_f2cmap_dict(f2cmap_all, new_map, c2py_map)|;|+|;|+    # Assert the result is as expected|;|+    assert res_map == exp_map|;|+    assert res_maptyp == exp_maptyp","TST: Add one for gh-25207 || BUG: Work with the ISOC_BINDINGS more consisently

Closes gh-25207 || MAINT: Kill now unused deep-merge [f2py] || ENH: Populate all maps for iso_c bindings || MAINT: Correctly return mapped types [f2py] || DOC: Add a note on the iso_c2py_map implementation || MAINT: Reduce chatter to pass tests || BUG: Map to types with bindings [f2py]

Fixes gh-25226

MAINT: Cleanup and scope fix better [f2py] || TST: Add a another test for gh-25207"
numpy/numpy,jorenham,28162,TYP: Return type for logical_or too narrow,"### Describe the issue:

It seems that `logical_or` is annotated to return `""ndarray[tuple[int, ...], dtype[Any]]""`, but it returns a single bool when called with scalar arguments. Probably other `logical_xxx` functions show the same behavior.

I could try to fix it (Returning a union of bool and the current annotation), but need someone pointing me at the location of the annotation.

### Reproduce the code example:

```python
import numpy as np

components_proper = np.random.random([3,3]) - .5
components_improper = np.random.random([3,3]) - .5

if np.random.randint(1,3) > 1:
    in_SST_ = np.logical_or(np.all(components_proper   >= 0.0,axis=-1),
                            np.all(components_improper >= 0.0,axis=-1))
else:
    in_SST_ = np.all(components_proper >= 0.0,axis=-1)
```

### Error message:

```shell
error: Incompatible types in assignment (expression has type ""numpy.bool[builtins.bool] | ndarray[tuple[int, ...], dtype[numpy.bool[builtins.bool]]]"", variable has type ""ndarray[tuple[int, ...], dtype[Any]]"")  [assignment]
Found 1 error in 1 file (checked 1 source file)
```

### Python and NumPy Versions:

NumPy 2.2.1
Python 3.13.1


### Type-checker version and settings:

MyPy: 1.14.0


### Additional typing packages.

n/a","This error is caused by a limitation in mypy's type inference system, and won't occur with other typecheckers like pyright or basedpyright. See https://github.com/numpy/numpy/issues/27957 for a (rather lengthy) discussion on this in detail.

Luckily, there's an easy workaround:

```py
import numpy as np
import numpy.typing as npt

components_proper = np.random.random([3, 3]) - 0.5
components_improper = np.random.random([3, 3]) - 0.5

in_SST_: npt.NDArray[np.bool] | np.bool
if np.random.randint(1, 3) > 1:
    in_SST_ = np.logical_or(
        np.all(components_proper >= 0.0, axis=-1),
        np.all(components_improper >= 0.0, axis=-1),
    )
else:
    in_SST_ = np.all(components_proper >= 0.0, axis=-1)
```

This helps mypy to understand what the common denominator of `in_SST_` is, because it isn't able to figure that it by itself.
If possible for you, you might also want to consider switching to pyright or basedpyright, which don't have this issue.

But even so, you're right in saying that the return type of `logical_or` is too narrow. Because, like `np.all`, its return type should also include to possibility for scalars, not only arrays. 
But as you can see in https://github.com/numpy/numpy/blob/1e10174ab16cbc57bd277eca753108ffcec55cd1/numpy/_typing/_ufunc.pyi#L163-L190, the second that accepts any ""array-like"" (which includes scalars), is annotated to return `NDArray[Any]`. If a *union* of scalar and array is passed, we get an incorrect result.

Somehow this has gone by unnoticed for 4 years, so thanks for reporting this!

Some related issues:
- https://github.com/numpy/numpy/issues/16544
- https://github.com/numpy/numpy/issues/27032
- https://github.com/numpy/numpy/issues/27957 || FYI, there's a newer [`v1.14.1`](https://github.com/python/mypy/compare/v1.14.0...v1.14.1) mypy release available || @jorenham 
thanks for the quick reply and the detailed explanation.

Actually, I think everything is correct for the typehint in line 190, at least for the case I had in mind. If only one of the arguments of `np.logical_and` is a scalar, the return value is an array. Only two scalars (the other `@overload`) will give a scalar. The problem is just that mypy apparently infers the type from the first assignment instead of checking all assignments for a common denominator. || The bug is rather subtle:


```pyi
import numpy as np
import numpy.typing as npt

a: npt.NDArray[np.float64] | np.float64
b: npt.NDArray[np.float64] | np.float64
out = np.logical_or(a, b)
reveal_type(out)  # npt.NDArray[Any]
```

So `out` is inferred as array, even though both inputs could also be a scalar.",closed,2025-01-16T11:28:35+00:00,2025-01-16T22:34:53+00:00,MarDiehl,41 - Static typing,2,"PR#28176 - numpy/_typing/_ufunc.pyi: @@ -4,32 +4,32 @@ The signatures of the ufuncs are too varied to reasonably type|;| with a single class. So instead, `ufunc` has been expanded into|;| four private subclasses, one for each combination of|;| `~ufunc.nin` and `~ufunc.nout`.|;|-|;| """"""|;| |;| from typing import (|;|     Any,|;|     Generic,|;|+    Literal,|;|     NoReturn,|;|-    TypedDict,|;|-    overload,|;|+    Protocol,|;|+    SupportsIndex,|;|     TypeAlias,|;|+    TypedDict,|;|     TypeVar,|;|-    Literal,|;|-    SupportsIndex,|;|-    Protocol,|;|+    overload,|;|     type_check_only,|;| )|;|+|;| from typing_extensions import LiteralString, Unpack|;| |;| import numpy as np|;|-from numpy import ufunc, _CastingKind, _OrderKACF|;|+from numpy import _CastingKind, _OrderKACF, ufunc|;| from numpy.typing import NDArray|;| |;|-from ._shape import _ShapeLike|;|-from ._scalars import _ScalarLike_co|;| from ._array_like import ArrayLike, _ArrayLikeBool_co, _ArrayLikeInt_co|;| from ._dtype_like import DTypeLike|;|+from ._scalars import _ScalarLike_co|;|+from ._shape import _ShapeLike|;| |;| _T = TypeVar(""_T"")|;| _2Tuple: TypeAlias = tuple[_T, _T]|;|@@ -61,6 +61,13 @@ class _SupportsArrayUFunc(Protocol):|;|         **kwargs: Any,|;|     ) -> Any: ...|;| |;|+@type_check_only|;|+class _UFunc3Kwargs(TypedDict, total=False):|;|+    where: _ArrayLikeBool_co | None|;|+    casting: _CastingKind|;|+    order: _OrderKACF|;|+    subok: bool|;|+    signature: _3Tuple[str | None] | str | None|;| |;| # NOTE: `reduce`, `accumulate`, `reduceat` and `outer` raise a ValueError for|;| # ufuncs that don't accept two input arguments and return one output argument.|;|@@ -72,6 +79,8 @@ class _SupportsArrayUFunc(Protocol):|;| # NOTE: If 2 output types are returned then `out` must be a|;| # 2-tuple of arrays. Otherwise `None` or a plain array are also acceptable|;| |;|+# pyright: reportIncompatibleMethodOverride=false|;|+|;| @type_check_only|;| class _UFunc_Nin1_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: ignore[misc]|;|     @property|;|@@ -162,34 +171,61 @@ class _UFunc_Nin2_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: i|;|     @property|;|     def signature(self) -> None: ...|;| |;|-    @overload|;|+    @overload  # (scalar, scalar) -> scalar|;|     def __call__(|;|         self,|;|-        __x1: _ScalarLike_co,|;|-        __x2: _ScalarLike_co,|;|-        out: None = ...,|;|+        x1: _ScalarLike_co,|;|+        x2: _ScalarLike_co,|;|+        /,|;|+        out: None = None,|;|         *,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> Any: ...|;|-    @overload|;|+    @overload  # (array-like, array) -> array|;|     def __call__(|;|         self,|;|-        __x1: ArrayLike,|;|-        __x2: ArrayLike,|;|-        out: None | NDArray[Any] | tuple[NDArray[Any]] = ...,|;|+        x1: ArrayLike,|;|+        x2: NDArray[np.generic],|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|         *,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array, array-like) -> array|;|+    def __call__(|;|+        self,|;|+        x1: NDArray[np.generic],|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like, out=array) -> array|;|+    def __call__(|;|+        self,|;|+        x1: ArrayLike,|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]],|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like) -> array | scalar|;|+    def __call__(|;|+        self,|;|+        x1: ArrayLike,|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any] | Any: ...|;| |;|     def at(|;|         self,|;|@@ -227,35 +263,61 @@ class _UFunc_Nin2_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: i|;|         out: None | NDArray[Any] = ...,|;|     ) -> NDArray[Any]: ...|;| |;|-    # Expand `**kwargs` into explicit keyword-only arguments|;|-    @overload|;|+    @overload  # (scalar, scalar) -> scalar|;|     def outer(|;|         self,|;|         A: _ScalarLike_co,|;|         B: _ScalarLike_co,|;|-        /, *,|;|-        out: None = ...,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        /,|;|+        *,|;|+        out: None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> Any: ...|;|-    @overload|;|-    def outer(  # type: ignore[misc]|;|+    @overload  # (array-like, array) -> array|;|+    def outer(|;|         self,|;|         A: ArrayLike,|;|+        B: NDArray[np.generic],|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array, array-like) -> array|;|+    def outer(|;|+        self,|;|+        A: NDArray[np.generic],|;|         B: ArrayLike,|;|-        /, *,|;|-        out: None | NDArray[Any] | tuple[NDArray[Any]] = ...,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like, out=array) -> array|;|+    def outer(|;|+        self,|;|+        A: ArrayLike,|;|+        B: ArrayLike,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]],|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like) -> array | scalar|;|+    def outer(|;|+        self,|;|+        A: ArrayLike,|;|+        B: ArrayLike,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any] | Any: ...|;| |;| @type_check_only|;| class _UFunc_Nin1_Nout2(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: ignore[misc] || PR#28168 - numpy/_typing/_ufunc.pyi: @@ -4,32 +4,32 @@ The signatures of the ufuncs are too varied to reasonably type|;| with a single class. So instead, `ufunc` has been expanded into|;| four private subclasses, one for each combination of|;| `~ufunc.nin` and `~ufunc.nout`.|;|-|;| """"""|;| |;| from typing import (|;|     Any,|;|     Generic,|;|+    Literal,|;|     NoReturn,|;|-    TypedDict,|;|-    overload,|;|+    Protocol,|;|+    SupportsIndex,|;|     TypeAlias,|;|+    TypedDict,|;|     TypeVar,|;|-    Literal,|;|-    SupportsIndex,|;|-    Protocol,|;|+    overload,|;|     type_check_only,|;| )|;|+|;| from typing_extensions import LiteralString, Unpack|;| |;| import numpy as np|;|-from numpy import ufunc, _CastingKind, _OrderKACF|;|+from numpy import _CastingKind, _OrderKACF, ufunc|;| from numpy.typing import NDArray|;| |;|-from ._shape import _ShapeLike|;|-from ._scalars import _ScalarLike_co|;| from ._array_like import ArrayLike, _ArrayLikeBool_co, _ArrayLikeInt_co|;| from ._dtype_like import DTypeLike|;|+from ._scalars import _ScalarLike_co|;|+from ._shape import _ShapeLike|;| |;| _T = TypeVar(""_T"")|;| _2Tuple: TypeAlias = tuple[_T, _T]|;|@@ -60,6 +60,14 @@ class _SupportsArrayUFunc(Protocol):|;|         **kwargs: Any,|;|     ) -> Any: ...|;| |;|+@type_check_only|;|+class _UFunc3Kwargs(TypedDict, total=False):|;|+    where: _ArrayLikeBool_co | None|;|+    casting: _CastingKind|;|+    order: _OrderKACF|;|+    subok: bool|;|+    signature: _3Tuple[str | None] | str | None|;|+|;| # NOTE: `reduce`, `accumulate`, `reduceat` and `outer` raise a ValueError for|;| # ufuncs that don't accept two input arguments and return one output argument.|;| # In such cases the respective methods return `NoReturn`|;|@@ -70,6 +78,8 @@ class _SupportsArrayUFunc(Protocol):|;| # NOTE: If 2 output types are returned then `out` must be a|;| # 2-tuple of arrays. Otherwise `None` or a plain array are also acceptable|;| |;|+# pyright: reportIncompatibleMethodOverride=false|;|+|;| @type_check_only|;| class _UFunc_Nin1_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: ignore[misc]|;|     @property|;|@@ -160,34 +170,61 @@ class _UFunc_Nin2_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: i|;|     @property|;|     def signature(self) -> None: ...|;| |;|-    @overload|;|+    @overload  # (scalar, scalar) -> scalar|;|     def __call__(|;|         self,|;|-        __x1: _ScalarLike_co,|;|-        __x2: _ScalarLike_co,|;|-        out: None = ...,|;|+        x1: _ScalarLike_co,|;|+        x2: _ScalarLike_co,|;|+        /,|;|+        out: None = None,|;|         *,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> Any: ...|;|-    @overload|;|+    @overload  # (array-like, array) -> array|;|     def __call__(|;|         self,|;|-        __x1: ArrayLike,|;|-        __x2: ArrayLike,|;|-        out: None | NDArray[Any] | tuple[NDArray[Any]] = ...,|;|+        x1: ArrayLike,|;|+        x2: NDArray[np.generic],|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|         *,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> NDArray[Any]: ...|;|+    @overload  # (array, array-like) -> array|;|+    def __call__(|;|+        self,|;|+        x1: NDArray[np.generic],|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like, out=array) -> array|;|+    def __call__(|;|+        self,|;|+        x1: ArrayLike,|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]],|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like) -> array | scalar|;|+    def __call__(|;|+        self,|;|+        x1: ArrayLike,|;|+        x2: ArrayLike,|;|+        /,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        *,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any] | Any: ...|;| |;|     def at(|;|         self,|;|@@ -225,35 +262,61 @@ class _UFunc_Nin2_Nout1(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: i|;|         out: None | NDArray[Any] = ...,|;|     ) -> NDArray[Any]: ...|;| |;|-    # Expand `**kwargs` into explicit keyword-only arguments|;|-    @overload|;|+    @overload  # (scalar, scalar) -> scalar|;|     def outer(|;|         self,|;|         A: _ScalarLike_co,|;|         B: _ScalarLike_co,|;|-        /, *,|;|-        out: None = ...,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        /,|;|+        *,|;|+        out: None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> Any: ...|;|-    @overload|;|-    def outer(  # type: ignore[misc]|;|+    @overload  # (array-like, array) -> array|;|+    def outer(|;|         self,|;|         A: ArrayLike,|;|+        B: NDArray[np.generic],|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array, array-like) -> array|;|+    def outer(|;|+        self,|;|+        A: NDArray[np.generic],|;|         B: ArrayLike,|;|-        /, *,|;|-        out: None | NDArray[Any] | tuple[NDArray[Any]] = ...,|;|-        where: None | _ArrayLikeBool_co = ...,|;|-        casting: _CastingKind = ...,|;|-        order: _OrderKACF = ...,|;|-        dtype: DTypeLike = ...,|;|-        subok: bool = ...,|;|-        signature: str | _3Tuple[None | str] = ...,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|     ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like, out=array) -> array|;|+    def outer(|;|+        self,|;|+        A: ArrayLike,|;|+        B: ArrayLike,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]],|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any]: ...|;|+    @overload  # (array-like, array-like) -> array | scalar|;|+    def outer(|;|+        self,|;|+        A: ArrayLike,|;|+        B: ArrayLike,|;|+        /,|;|+        *,|;|+        out: NDArray[np.generic] | tuple[NDArray[np.generic]] | None = None,|;|+        dtype: DTypeLike | None = None,|;|+        **kwds: Unpack[_UFunc3Kwargs],|;|+    ) -> NDArray[Any] | Any: ...|;| |;| @type_check_only|;| class _UFunc_Nin1_Nout2(ufunc, Generic[_NameType, _NTypes, _IDType]):  # type: ignore[misc]",TYP: Fix overlapping overloads issue in 2->1 ufuncs || TYP: Fix overlapping overloads issue in 2->1 ufuncs
numpy/numpy,ngoldbaum,28143,BUG: Race on `descr->byteorder` under free threading,"### Describe the issue:

When running the following code under TSAN and free-threading, TSAN reports an apparently real race:

### Reproduce the code example:

```python
import concurrent.futures
import functools
import threading

import numpy as np

num_threads = 20

def closure(b, x):
  b.wait()
  for _ in range(100):
    y = np.arange(10)
    y.flat[x] = x

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
  for i in range(1000):
    b = threading.Barrier(num_threads)
    for _ in range(num_threads):
      x = np.arange(100)
      executor.submit(functools.partial(closure, b, x))
```


### Error message:

```shell
# TSAN error

WARNING: ThreadSanitizer: data race (pid=3673664)
  Read of size 1 at 0x7f2973cd94a2 by main thread:
    #0 PyArray_PromoteTypes /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/convert_datatype.c:1001:16 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x248c2e) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #1 handle_promotion /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/array_coercion.c:720:32 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x224e6c) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #2 handle_scalar /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/array_coercion.c:777:9 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x22499c) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #3 PyArray_DiscoverDTypeAndShape_Recursive /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/array_coercion.c:1022:20 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x223b45) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #4 PyArray_DiscoverDTypeAndShape /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/array_coercion.c:1307:16 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x225162) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #5 PyArray_DTypeFromObject /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/common.c:132:12 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x241ecd) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #6 PyArray_DescrFromObject /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/ctors.c:2628:9 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x25c02b) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #7 PyArray_ArangeObj /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/ctors.c:3340:9 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x25c02b)
    #8 array_arange /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/multiarraymodule.c:3100:13 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2db297) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #9 cfunction_vectorcall_FASTCALL_KEYWORDS /usr/local/google/home/phawkins/p/cpython/Objects/methodobject.c:441:24 (python3.13+0x289f20) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #10 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1eafea) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #11 PyObject_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c:327:12 (python3.13+0x1eafea)
    #12 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:813:23 (python3.13+0x3e290b) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #13 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de712) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #14 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1807:12 (python3.13+0x3de712)
    #15 PyEval_EvalCode /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:597:21 (python3.13+0x3de712)
    #16 run_eval_code_obj /usr/local/google/home/phawkins/p/cpython/Python/pythonrun.c:1337:9 (python3.13+0x4a0a7e) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #17 run_mod /usr/local/google/home/phawkins/p/cpython/Python/pythonrun.c:1422:19 (python3.13+0x4a01a5) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #18 pyrun_file /usr/local/google/home/phawkins/p/cpython/Python/pythonrun.c:1255:15 (python3.13+0x49c2a0) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #19 _PyRun_SimpleFileObject /usr/local/google/home/phawkins/p/cpython/Python/pythonrun.c:490:13 (python3.13+0x49c2a0)
    #20 _PyRun_AnyFileObject /usr/local/google/home/phawkins/p/cpython/Python/pythonrun.c:77:15 (python3.13+0x49b968) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #21 pymain_run_file_obj /usr/local/google/home/phawkins/p/cpython/Modules/main.c:410:15 (python3.13+0x4d7e8f) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #22 pymain_run_file /usr/local/google/home/phawkins/p/cpython/Modules/main.c:429:15 (python3.13+0x4d7e8f)
    #23 pymain_run_python /usr/local/google/home/phawkins/p/cpython/Modules/main.c:697:21 (python3.13+0x4d70dc) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #24 Py_RunMain /usr/local/google/home/phawkins/p/cpython/Modules/main.c:776:5 (python3.13+0x4d70dc)
    #25 pymain_main /usr/local/google/home/phawkins/p/cpython/Modules/main.c:806:12 (python3.13+0x4d7518) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #26 Py_BytesMain /usr/local/google/home/phawkins/p/cpython/Modules/main.c:830:12 (python3.13+0x4d759b) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #27 main /usr/local/google/home/phawkins/p/cpython/./Programs/python.c:15:12 (python3.13+0x15c7eb) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)

  Previous write of size 1 at 0x7f2973cd94a2 by thread T147:
    #0 PyArray_CheckFromAny_int /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/ctors.c:1843:33 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x259d09) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #1 PyArray_CheckFromAny /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/ctors.c:1811:22 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x25999d) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #2 iter_ass_subscript /usr/local/google/home/phawkins/p/numpy/.mesonpy-v3nmau22/../numpy/_core/src/multiarray/iterators.c:1016:19 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2b3e0b) (BuildId: 01f027aee9bd9e769c42b1931cadc90163397cb6)
    #3 PyObject_SetItem /usr/local/google/home/phawkins/p/cpython/Objects/abstract.c:232:19 (python3.13+0x1b9728) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #4 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:5777:27 (python3.13+0x3f5fcb) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #5 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3dea3a) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #6 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1807:12 (python3.13+0x3dea3a)
    #7 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #8 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x572352) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #9 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x572352)
    #10 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #11 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #12 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #13 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e4af2) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #14 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3dea3a) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #15 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1807:12 (python3.13+0x3dea3a)
    #16 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb65f) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #17 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef62f) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #18 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef62f)
    #19 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb2d3) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #20 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb2d3)
    #21 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb355) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #22 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x564a32) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)
    #23 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bddb7) (BuildId: 19c569fa942016d8ac49d19fd40ccb1ddded939b)

  Location is global 'LONG_Descr' of size 136 at 0x7f2973cd9478 (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0xad94a2)
```


### Python and NumPy Versions:

```
2.3.0.dev0+git20250110.dc78e30
3.13.1+ experimental free-threading build (heads/3.13:65da5db28a3, Jan 10 2025, 14:52:18) [Clang 18.1.8 (11)]
```

### Runtime Environment:

[{'numpy_version': '2.3.0.dev0+git20250110.dc78e30',
  'python': '3.13.1+ experimental free-threading build '
            '(heads/3.13:65da5db28a3, Jan 10 2025, 14:52:18) [Clang 18.1.8 '
            '(11)]',
  'uname': uname_result(system='Linux', node='redacted', release='6.10.11-redacted-amd64', version='#1 SMP PREEMPT_DYNAMIC Debian 6.10.11-redacted(2024-10-16)', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Zen',
  'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.27.so',
  'internal_api': 'openblas',
  'num_threads': 128,
  'prefix': 'libopenblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.27'}]

### Context for the issue:

Found when running the JAX test suite with TSAN and free-threading.","this (kinda silly) diff seems to fix the race:

```diff
diff --git a/numpy/_core/src/multiarray/ctors.c b/numpy/_core/src/multiarray/ctors.c
index 0723e54f34..8379480389 100644
--- a/numpy/_core/src/multiarray/ctors.c
+++ b/numpy/_core/src/multiarray/ctors.c
@@ -1839,7 +1839,7 @@ PyArray_CheckFromAny_int(PyObject *op, PyArray_Descr *in_descr,
         else if (in_descr && !PyArray_ISNBO(in_descr->byteorder)) {
             PyArray_DESCR_REPLACE(in_descr);
         }
-        if (in_descr && in_descr->byteorder != NPY_IGNORE) {
+        if (in_descr && in_descr->byteorder != NPY_IGNORE && in_descr->byteorder != NPY_NATIVE) {
             in_descr->byteorder = NPY_NATIVE;
         }
     }
```

@hawkinsp in your opinion, are changes like above the sort of thing we need to do now or is this the sort of thing it makes sense to write a suppression for? I'll also wait for Sebastian to comment before sending that in since I don't have context if a bigger refactor to avoid writing to effectively global descriptor objects makes sense. || There's no such thing as a benign race, e.g., see usenix.org/legacy/events/hotpar11/tech/final_files/Boehm.pdf or similar. Even things you think might be safe at a hardware level are extremely difficult to reason about as soon as there is an optimizing compiler involved. So it's probably sensible to fix pretty much anything tsan tells you about.

Is this particular bug the most urgent? No. For my own purposes, I *have* added a tsan suppression and moved on with my life, but I don't want the issue to be forgotten, and hence this bug. But, contrast that with, say, https://github.com/numpy/numpy/issues/28048 which I can't work around: I'd rate that sort of issue higher priority. || > But, contrast that with, say, https://github.com/numpy/numpy/issues/28048 which I can't work around: I'd rate that sort of issue higher priority.

For sure, that's definitely high up on my priority queue to fix, and thank you for finding and reporting these issues. || No arcane knowledge. Just need to look 2 lines up, it should be part of the `elif` (and then doesn't need the if even). || Sorry, nonsense of course...  Yeah, I think the fix is good, cose just has a bit weird flow and not sure how well the descr replacement works for user-dtypes but that is a different issue.",closed,2025-01-10T20:01:51+00:00,2025-01-15T23:53:56+00:00,hawkinsp,"00 - Bug, 39 - free-threading",1,"PR#28154 - numpy/_core/src/multiarray/ctors.c: @@ -1829,18 +1829,12 @@ PyArray_CheckFromAny_int(PyObject *op, PyArray_Descr *in_descr,|;| {|;|     PyObject *obj|;|;     if (requires & NPY_ARRAY_NOTSWAPPED) {|;|-        if (!in_descr && PyArray_Check(op) &&|;|-                PyArray_ISBYTESWAPPED((PyArrayObject* )op)) {|;|-            in_descr = PyArray_DescrNew(PyArray_DESCR((PyArrayObject *)op))|;|;-            if (in_descr == NULL) {|;|-                return NULL|;|;-            }|;|-        }|;|-        else if (in_descr && !PyArray_ISNBO(in_descr->byteorder)) {|;|-            PyArray_DESCR_REPLACE(in_descr)|;|;+        if (!in_descr && PyArray_Check(op)) {|;|+            in_descr = PyArray_DESCR((PyArrayObject *)op)|;|;+            Py_INCREF(in_descr)|;|;         }|;|-        if (in_descr && in_descr->byteorder != NPY_IGNORE) {|;|-            in_descr->byteorder = NPY_NATIVE|;|;+        if (in_descr) {|;|+            PyArray_DESCR_REPLACE_CANONICAL(in_descr)|;|;         }|;|     }|;|  || PR#28154 - numpy/_core/src/multiarray/dtypemeta.h: @@ -285,6 +285,11 @@ PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v)|;|             v, itemptr, arr)|;|; }|;| |;|+// Like PyArray_DESCR_REPLACE, but calls ensure_canonical instead of DescrNew|;|+#define PyArray_DESCR_REPLACE_CANONICAL(descr) do { \|;|+                PyArray_Descr *_new_ = NPY_DT_CALL_ensure_canonical(descr); \|;|+                Py_XSETREF(descr, _new_);  \|;|+        } while(0)|;| |;| |;| #endif  /* NUMPY_CORE_SRC_MULTIARRAY_DTYPEMETA_H_ */ || PR#28154 - numpy/_core/tests/test_multithreading.py: @@ -134,6 +134,7 @@ def closure(b):|;| |;| |;| def test_parallel_flat_iterator():|;|+    # gh-28042|;|     x = np.arange(20).reshape(5, 4).T|;| |;|     def closure(b):|;|@@ -142,3 +143,15 @@ def closure(b):|;|             list(x.flat)|;| |;|     run_threaded(closure, outer_iterations=100, pass_barrier=True)|;|+|;|+    # gh-28143|;|+    def prepare_args():|;|+        return [np.arange(10)]|;|+|;|+    def closure(x, b):|;|+        b.wait()|;|+        for _ in range(100):|;|+            y = np.arange(10)|;|+            y.flat[x] = x|;|+|;|+    run_threaded(closure, pass_barrier=True, prepare_args=prepare_args) || PR#28154 - numpy/testing/_private/utils.py: @@ -2687,12 +2687,16 @@ def _get_glibc_version():|;| |;| |;| def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|-                 pass_barrier=False, outer_iterations=1):|;|+                 pass_barrier=False, outer_iterations=1,|;|+                 prepare_args=None):|;|     """"""Runs a function many times in parallel""""""|;|     for _ in range(outer_iterations):|;|         with (concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)|;|               as tpe):|;|-            args = []|;|+            if prepare_args is None:|;|+                args = []|;|+            else:|;|+                args = prepare_args()|;|             if pass_barrier:|;|                 if max_workers != iters:|;|                     raise RuntimeError(",BUG: Avoid data race in PyArray_CheckFromAny_int || TST: add test || MAINT: simplify byteswapping code in PyArray_CheckFromAny_int || MAINT: drop ISBYTESWAPPED check
numpy/numpy,ngoldbaum,28042,BUG: Race in PyArray_UpdateFlags under free threading,"### Describe the issue:

thread-sanitizer reports a race in PyArray_UpdateFlags under free threading.

It may take a few runs to reproduce this race.

### Reproduce the code example:

```python
import concurrent.futures
import functools
import threading

import numpy as np

num_threads = 8


def closure(b, x):
  b.wait()
  for _ in range(100):
    list(x.flat)

with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:
  for _ in range(100):
    b = threading.Barrier(num_threads)
    x = np.arange(20).reshape(5, 4).T
    for _ in range(num_threads):
      executor.submit(functools.partial(closure, b, x))
```


### Error message:

```shell
WARNING: ThreadSanitizer: data race (pid=409824)
  Write of size 4 at 0x7fadb72e6db0 by thread T135:
    #0 PyArray_UpdateFlags <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x296e4b) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #1 PyArray_RawIterBaseInit <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2ac9cd) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #2 PyArray_IterNew <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2ad200) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #3 array_flat_get getset.c (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x29a045) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #4 getset_get /usr/local/google/home/phawkins/p/cpython/Objects/descrobject.c:193:16 (python3.13+0x1ffa68) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #5 _PyObject_GenericGetAttrWithDict /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1635:19 (python3.13+0x295de1) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #6 PyObject_GenericGetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1717:12 (python3.13+0x295c32) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #7 PyObject_GetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1231:18 (python3.13+0x294597) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #8 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:3766:28 (python3.13+0x3eddf0) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #9 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de62a) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #10 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1811:12 (python3.13+0x3de62a)
    #11 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb61f) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #12 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x571bb2) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #13 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x571bb2)
    #14 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb293) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #15 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb293)
    #16 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb315) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #17 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e46e2) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #18 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de62a) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #19 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1811:12 (python3.13+0x3de62a)
    #20 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb61f) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #21 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5ef) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #22 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5ef)
    #23 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb293) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #24 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb293)
    #25 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb315) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #26 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x564292) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #27 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bd637) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)

  Previous write of size 4 at 0x7fadb72e6db0 by thread T132:
    #0 PyArray_UpdateFlags <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x296e4b) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #1 PyArray_RawIterBaseInit <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2ac9cd) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #2 PyArray_IterNew <null> (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x2ad200) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #3 array_flat_get getset.c (_multiarray_umath.cpython-313t-x86_64-linux-gnu.so+0x29a045) (BuildId: a138a702a237ca030803af4168ee423ada9702f7)
    #4 getset_get /usr/local/google/home/phawkins/p/cpython/Objects/descrobject.c:193:16 (python3.13+0x1ffa68) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #5 _PyObject_GenericGetAttrWithDict /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1635:19 (python3.13+0x295de1) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #6 PyObject_GenericGetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1717:12 (python3.13+0x295c32) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #7 PyObject_GetAttr /usr/local/google/home/phawkins/p/cpython/Objects/object.c:1231:18 (python3.13+0x294597) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #8 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:3766:28 (python3.13+0x3eddf0) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #9 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de62a) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #10 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1811:12 (python3.13+0x3de62a)
    #11 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb61f) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #12 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x571bb2) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #13 partial_vectorcall /usr/local/google/home/phawkins/p/cpython/./Modules/_functoolsmodule.c:252:16 (python3.13+0x571bb2)
    #14 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb293) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #15 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb293)
    #16 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb315) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #17 _PyEval_EvalFrameDefault /usr/local/google/home/phawkins/p/cpython/Python/generated_cases.c.h:1355:26 (python3.13+0x3e46e2) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #18 _PyEval_EvalFrame /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_ceval.h:119:16 (python3.13+0x3de62a) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #19 _PyEval_Vector /usr/local/google/home/phawkins/p/cpython/Python/ceval.c:1811:12 (python3.13+0x3de62a)
    #20 _PyFunction_Vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/call.c (python3.13+0x1eb61f) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #21 _PyObject_VectorcallTstate /usr/local/google/home/phawkins/p/cpython/./Include/internal/pycore_call.h:168:11 (python3.13+0x1ef5ef) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #22 method_vectorcall /usr/local/google/home/phawkins/p/cpython/Objects/classobject.c:70:20 (python3.13+0x1ef5ef)
    #23 _PyVectorcall_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:273:16 (python3.13+0x1eb293) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #24 _PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:348:16 (python3.13+0x1eb293)
    #25 PyObject_Call /usr/local/google/home/phawkins/p/cpython/Objects/call.c:373:12 (python3.13+0x1eb315) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #26 thread_run /usr/local/google/home/phawkins/p/cpython/./Modules/_threadmodule.c:337:21 (python3.13+0x564292) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
    #27 pythread_wrapper /usr/local/google/home/phawkins/p/cpython/Python/thread_pthread.h:243:5 (python3.13+0x4bd637) (BuildId: 9c1c16fb1bb8a435fa6fa4c6944da5d41f654e96)
```


### Python and NumPy Versions:

2.3.0.dev0+git20241219.35b2c4a
3.13.1 experimental free-threading build (tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 (11)]

### Runtime Environment:

[{'numpy_version': '2.3.0.dev0+git20241219.35b2c4a',
'python': '3.13.1 experimental free-threading build '
'(tags/v3.13.1:06714517797, Dec 15 2024, 15:38:01) [Clang 18.1.8 '
'(11)]',
'uname': uname_result(system='Linux', node='', release='', version='https://github.com/numpy/numpy/pull/1 SMP PREEMPT_DYNAMIC Debian 6.redacted (2024-10-16)', machine='x86_64')},
{'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
'found': ['SSSE3',
'SSE41',
'POPCNT',
'SSE42',
'AVX',
'F16C',
'FMA3',
'AVX2'],
'not_found': ['AVX512F',
'AVX512CD',
'AVX512_KNL',
'AVX512_SKX',
'AVX512_CLX',
'AVX512_CNL',
'AVX512_ICL']}},
{'architecture': 'Zen',
'filepath': '/usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.27.so',
'internal_api': 'openblas',
'num_threads': 128,
'prefix': 'libopenblas',
'threading_layer': 'pthreads',
'user_api': 'blas',
'version': '0.3.27'}]

### Context for the issue:

Found when working on free-threading support in JAX.",This call to updateflags is just an unnecessary remnant of a more defensive past: Flags must always be up to date.,closed,2024-12-19T17:30:27+00:00,2025-01-10T21:37:58+00:00,hawkinsp,"00 - Bug, sprintable - C, 39 - free-threading",2,"PR#28145 - numpy/_core/src/multiarray/iterators.c: @@ -136,7 +136,6 @@ PyArray_RawIterBaseInit(PyArrayIterObject *it, PyArrayObject *ao)|;|     nd = PyArray_NDIM(ao)|;|;     /* The legacy iterator only supports 32 dimensions */|;|     assert(nd <= NPY_MAXDIMS_LEGACY_ITERS)|;|;-    PyArray_UpdateFlags(ao, NPY_ARRAY_C_CONTIGUOUS)|;|;     if (PyArray_ISCONTIGUOUS(ao)) {|;|         it->contiguous = 1|;|;     } || PR#28145 - numpy/_core/tests/test_multithreading.py: @@ -18,6 +18,7 @@ def func(seed):|;| |;|     run_threaded(func, 500, pass_count=True)|;| |;|+|;| def test_parallel_ufunc_execution():|;|     # if the loop data cache or dispatch cache are not thread-safe|;|     # computing ufuncs simultaneously in multiple threads leads|;|@@ -31,18 +32,14 @@ def func():|;|     # see gh-26690|;|     NUM_THREADS = 50|;| |;|-    b = threading.Barrier(NUM_THREADS)|;|-|;|     a = np.ones(1000)|;| |;|-    def f():|;|+    def f(b):|;|         b.wait()|;|         return a.sum()|;| |;|-    threads = [threading.Thread(target=f) for _ in range(NUM_THREADS)]|;|+    run_threaded(f, NUM_THREADS, max_workers=NUM_THREADS, pass_barrier=True)|;| |;|-    [t.start() for t in threads]|;|-    [t.join() for t in threads]|;| |;| def test_temp_elision_thread_safety():|;|     amid = np.ones(50000)|;|@@ -121,16 +118,27 @@ def legacy_125():|;|     task1.start()|;|     task2.start()|;| |;|+|;| def test_parallel_reduction():|;|     # gh-28041|;|     NUM_THREADS = 50|;| |;|-    b = threading.Barrier(NUM_THREADS)|;|-|;|     x = np.arange(1000)|;| |;|-    def closure():|;|+    def closure(b):|;|         b.wait()|;|         np.sum(x)|;| |;|-    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS)|;|+    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS,|;|+                 pass_barrier=True)|;|+|;|+|;|+def test_parallel_flat_iterator():|;|+    x = np.arange(20).reshape(5, 4).T|;|+|;|+    def closure(b):|;|+        b.wait()|;|+        for _ in range(100):|;|+            list(x.flat)|;|+|;|+    run_threaded(closure, outer_iterations=100, pass_barrier=True) || PR#28145 - numpy/testing/_private/utils.py: @@ -18,6 +18,7 @@|;| import pprint|;| import sysconfig|;| import concurrent.futures|;|+import threading|;| |;| import numpy as np|;| from numpy._core import (|;|@@ -2684,12 +2685,23 @@ def _get_glibc_version():|;| _glibc_older_than = lambda x: (_glibcver != '0.0' and _glibcver < x)|;| |;| |;|-def run_threaded(func, iters, pass_count=False, max_workers=8):|;|+def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|+                 pass_barrier=False, outer_iterations=1):|;|     """"""Runs a function many times in parallel""""""|;|-    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as tpe:|;|-        if pass_count:|;|-            futures = [tpe.submit(func, i) for i in range(iters)]|;|-        else:|;|-            futures = [tpe.submit(func) for _ in range(iters)]|;|-        for f in futures:|;|-            f.result()|;|+    for _ in range(outer_iterations):|;|+        with (concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)|;|+              as tpe):|;|+            args = []|;|+            if pass_barrier:|;|+                if max_workers != iters:|;|+                    raise RuntimeError(|;|+                        ""Must set max_workers equal to the number of ""|;|+                        ""iterations to avoid deadlocks."")|;|+                barrier = threading.Barrier(max_workers)|;|+                args.append(barrier)|;|+            if pass_count:|;|+                futures = [tpe.submit(func, i, *args) for i in range(iters)]|;|+            else:|;|+                futures = [tpe.submit(func, *args) for _ in range(iters)]|;|+            for f in futures:|;|+                f.result() || PR#28144 - numpy/_core/src/multiarray/iterators.c: @@ -136,7 +136,6 @@ PyArray_RawIterBaseInit(PyArrayIterObject *it, PyArrayObject *ao)|;|     nd = PyArray_NDIM(ao)|;|;     /* The legacy iterator only supports 32 dimensions */|;|     assert(nd <= NPY_MAXDIMS_LEGACY_ITERS)|;|;-    PyArray_UpdateFlags(ao, NPY_ARRAY_C_CONTIGUOUS)|;|;     if (PyArray_ISCONTIGUOUS(ao)) {|;|         it->contiguous = 1|;|;     } || PR#28144 - numpy/_core/tests/test_multithreading.py: @@ -18,6 +18,7 @@ def func(seed):|;| |;|     run_threaded(func, 500, pass_count=True)|;| |;|+|;| def test_parallel_ufunc_execution():|;|     # if the loop data cache or dispatch cache are not thread-safe|;|     # computing ufuncs simultaneously in multiple threads leads|;|@@ -31,18 +32,14 @@ def func():|;|     # see gh-26690|;|     NUM_THREADS = 50|;| |;|-    b = threading.Barrier(NUM_THREADS)|;|-|;|     a = np.ones(1000)|;| |;|-    def f():|;|+    def f(b):|;|         b.wait()|;|         return a.sum()|;| |;|-    threads = [threading.Thread(target=f) for _ in range(NUM_THREADS)]|;|+    run_threaded(f, NUM_THREADS, max_workers=NUM_THREADS, pass_barrier=True)|;| |;|-    [t.start() for t in threads]|;|-    [t.join() for t in threads]|;| |;| def test_temp_elision_thread_safety():|;|     amid = np.ones(50000)|;|@@ -121,16 +118,27 @@ def legacy_125():|;|     task1.start()|;|     task2.start()|;| |;|+|;| def test_parallel_reduction():|;|     # gh-28041|;|     NUM_THREADS = 50|;| |;|-    b = threading.Barrier(NUM_THREADS)|;|-|;|     x = np.arange(1000)|;| |;|-    def closure():|;|+    def closure(b):|;|         b.wait()|;|         np.sum(x)|;| |;|-    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS)|;|+    run_threaded(closure, NUM_THREADS, max_workers=NUM_THREADS,|;|+                 pass_barrier=True)|;|+|;|+|;|+def test_parallel_flat_iterator():|;|+    x = np.arange(20).reshape(5, 4).T|;|+|;|+    def closure(b):|;|+        b.wait()|;|+        for _ in range(100):|;|+            list(x.flat)|;|+|;|+    run_threaded(closure, outer_iterations=100, pass_barrier=True) || PR#28144 - numpy/testing/_private/utils.py: @@ -18,6 +18,7 @@|;| import pprint|;| import sysconfig|;| import concurrent.futures|;|+import threading|;| |;| import numpy as np|;| from numpy._core import (|;|@@ -2685,12 +2686,23 @@ def _get_glibc_version():|;| _glibc_older_than = lambda x: (_glibcver != '0.0' and _glibcver < x)|;| |;| |;|-def run_threaded(func, iters, pass_count=False, max_workers=8):|;|+def run_threaded(func, iters=8, pass_count=False, max_workers=8,|;|+                 pass_barrier=False, outer_iterations=1):|;|     """"""Runs a function many times in parallel""""""|;|-    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as tpe:|;|-        if pass_count:|;|-            futures = [tpe.submit(func, i) for i in range(iters)]|;|-        else:|;|-            futures = [tpe.submit(func) for _ in range(iters)]|;|-        for f in futures:|;|-            f.result()|;|+    for _ in range(outer_iterations):|;|+        with (concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)|;|+              as tpe):|;|+            args = []|;|+            if pass_barrier:|;|+                if max_workers != iters:|;|+                    raise RuntimeError(|;|+                        ""Must set max_workers equal to the number of ""|;|+                        ""iterations to avoid deadlocks."")|;|+                barrier = threading.Barrier(max_workers)|;|+                args.append(barrier)|;|+            if pass_count:|;|+                futures = [tpe.submit(func, i, *args) for i in range(iters)]|;|+            else:|;|+                futures = [tpe.submit(func, *args) for _ in range(iters)]|;|+            for f in futures:|;|+                f.result()",BUG: remove unnecessary call to PyArray_UpdateFlags || TST: add some features to the run_threaded helper || TST: add test from gh-28042 || BUG: remove unnecessary call to PyArray_UpdateFlags || TST: add some features to the run_threaded helper || TST: add test from gh-28042
numpy/numpy,ngoldbaum,28122,BUG: data race in f2py callback tests on free-threaded build,"To reproduce this you need to build CPython and NumPy from source with thread sanitizer. See [here](https://py-free-threading.github.io/debugging/#compile-free-threaded-cpython-with-tsan) for more details on how to do that.

If you run the f2py callback tests, you'll see the following warnings reported:

<details>

```
± CC=/opt/homebrew/opt/llvm/bin/clang CXX=/opt/homebrew/opt/llvm/bin/clang++ spin test -- -sv numpy/f2py/tests/test_callback.py
python(32402,0x1f6dfc240) malloc: nano zone abandoned due to inability to reserve vm space.
Invoking `build` prior to running tests:
$ /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/python vendored-meson/meson/meson.py compile -C build
python(32457,0x1f6dfc240) malloc: nano zone abandoned due to inability to reserve vm space.
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/ninja -C /Users/goldbaum/Documents/numpy/build
ninja: Entering directory `/Users/goldbaum/Documents/numpy/build'
[1/1] Generating numpy/generate-version with a custom command
Saving version to numpy/version.py
$ /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/python vendored-meson/meson/meson.py install --only-changed -C build --destdir ../build-install
$ export PYTHONPATH=""/Users/goldbaum/Documents/numpy/build-install/usr/lib/python3.13t/site-packages""
$ /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/python -P -c 'import numpy'
python(32488,0x1f6dfc240) malloc: nano zone abandoned due to inability to reserve vm space.
$ cd /Users/goldbaum/Documents/numpy/build-install/usr/lib/python3.13t/site-packages
$ /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/python -P -m pytest -m 'not slow' -sv numpy/f2py/tests/test_callback.py
python(32490,0x1f6dfc240) malloc: nano zone abandoned due to inability to reserve vm space.
=========================================================== test session starts ===========================================================
platform darwin -- Python 3.13.1+, pytest-8.3.4, pluggy-1.5.0 -- /Users/goldbaum/.pyenv/versions/3.13t-dev-tsan/bin/python
cachedir: .pytest_cache
hypothesis profile 'np.test() profile' -> database=None, deadline=None, print_blob=True, derandomize=True, suppress_health_check=[HealthCheck.data_too_large, HealthCheck.filter_too_much, HealthCheck.too_slow, HealthCheck.large_base_example, HealthCheck.function_scoped_fixture, HealthCheck.differing_executors]
rootdir: /Users/goldbaum/Documents/numpy
configfile: pytest.ini
plugins: hypothesis-6.123.2, xdist-3.6.1
collected 18 items / 7 deselected / 11 selected

numpy/f2py/tests/test_callback.py::TestF77Callback::test_docstring PASSED
numpy/f2py/tests/test_callback.py::TestF77Callback::test_string_callback PASSED
numpy/f2py/tests/test_callback.py::TestF77Callback::test_string_callback_array PASSED
numpy/f2py/tests/test_callback.py::TestF77Callback::test_threadsafety ==================
WARNING: ThreadSanitizer: data race (pid=32490)
  Atomic read of size 8 at 0x000165cbda48 by thread T5:
    #0 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x803f4)
    #1 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #2 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #3 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #4 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x84714)
    #5 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #6 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #7 thread_run _threadmodule.c:337 (libpython3.13t.dylib:arm64+0x3b6e40)
    #8 pythread_wrapper thread_pthread.h:243 (libpython3.13t.dylib:arm64+0x320c88)

  Previous write of size 8 at 0x000165cbda48 by thread T4:
    #0 type_ready typeobject.c:8206 (libpython3.13t.dylib:arm64+0x17382c)
    #1 PyType_Ready typeobject.c:8266 (libpython3.13t.dylib:arm64+0x16d56c)
    #2 _PyObject_GenericGetAttrWithDict object.c:1655 (libpython3.13t.dylib:arm64+0x120690)
    #3 PyObject_GenericGetAttr object.c:1747 (libpython3.13t.dylib:arm64+0x120570)
    #4 fortran_getattr fortranobject.c:429 (_test_callback_TestF77Callback_ext_module.cpython-313t-darwin.so:arm64+0x9354)
    #5 PyObject_GetOptionalAttrString object.c:1364 (libpython3.13t.dylib:arm64+0x11f1ec)
    #6 PyObject_HasAttrStringWithError object.c:1140 (libpython3.13t.dylib:arm64+0x11ef94)
    #7 PyObject_HasAttrString object.c:1149 (libpython3.13t.dylib:arm64+0x11f488)
    #8 create_cb_arglist _test_callback_TestF77Callback_ext_modulemodule.c:269 (_test_callback_TestF77Callback_ext_module.cpython-313t-darwin.so:arm64+0x69a8)
    #9 f2py_rout__test_callback_TestF77Callback_ext_module_t _test_callback_TestF77Callback_ext_modulemodule.c:1291 (_test_callback_TestF77Callback_ext_module.cpython-313t-darwin.so:arm64+0x4f2c)
    #10 fortran_call fortranobject.c (_test_callback_TestF77Callback_ext_module.cpython-313t-darwin.so:arm64+0x9c84)
    #11 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #12 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #13 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #14 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #15 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #16 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x84714)
    #17 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #18 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #19 thread_run _threadmodule.c:337 (libpython3.13t.dylib:arm64+0x3b6e40)
    #20 pythread_wrapper thread_pthread.h:243 (libpython3.13t.dylib:arm64+0x320c88)

  Location is global 'PyFortran_Type' at 0x000165cbd990 (_test_callback_TestF77Callback_ext_module.cpython-313t-darwin.so+0x15a48)

  Thread T5 (tid=39377788, running) created by main thread at:
    #0 pthread_create <null> (libclang_rt.tsan_osx_dynamic.dylib:arm64+0x31050)
    #1 do_start_joinable_thread thread_pthread.h:290 (libpython3.13t.dylib:arm64+0x31f8f4)
    #2 PyThread_start_joinable_thread thread_pthread.h:314 (libpython3.13t.dylib:arm64+0x31f738)
    #3 do_start_new_thread _threadmodule.c:1849 (libpython3.13t.dylib:arm64+0x3b69ec)
    #4 thread_PyThread_start_joinable_thread _threadmodule.c:1972 (libpython3.13t.dylib:arm64+0x3b5aa8)
    #5 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x115600)
    #6 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #7 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #8 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #9 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #10 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #11 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x84714)
    #12 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #13 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #14 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe5c)
    #15 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #16 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #17 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #18 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #19 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #20 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #21 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #22 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #23 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #24 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #25 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #26 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #27 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #28 _PyObject_Call call.c:361 (libpython3.13t.dylib:arm64+0x80694)
    #29 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #30 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe5c)
    #31 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #32 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #33 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #34 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #35 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #36 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #37 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #38 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #39 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #40 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #41 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #42 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #43 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #44 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #45 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #46 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #47 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #48 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #49 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #50 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #51 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #52 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #53 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #54 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #55 PyEval_EvalCode ceval.c:597 (libpython3.13t.dylib:arm64+0x254fbc)
    #56 builtin_exec bltinmodule.c.h:556 (libpython3.13t.dylib:arm64+0x24f920)
    #57 cfunction_vectorcall_FASTCALL_KEYWORDS methodobject.c:441 (libpython3.13t.dylib:arm64+0x11491c)
    #58 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x8042c)
    #59 _PyEval_EvalFrameDefault generated_cases.c.h:813 (libpython3.13t.dylib:arm64+0x25e624)
    #60 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #61 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #62 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #63 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #64 pymain_run_module main.c:349 (libpython3.13t.dylib:arm64+0x3362a4)
    #65 Py_RunMain main.c:776 (libpython3.13t.dylib:arm64+0x3359a4)
    #66 pymain_main main.c:806 (libpython3.13t.dylib:arm64+0x336040)
    #67 Py_BytesMain main.c:830 (libpython3.13t.dylib:arm64+0x336118)
    #68 main <null> (python3.13:arm64+0x100003ec4)

  Thread T4 (tid=39377787, running) created by main thread at:
    #0 pthread_create <null> (libclang_rt.tsan_osx_dynamic.dylib:arm64+0x31050)
    #1 do_start_joinable_thread thread_pthread.h:290 (libpython3.13t.dylib:arm64+0x31f8f4)
    #2 PyThread_start_joinable_thread thread_pthread.h:314 (libpython3.13t.dylib:arm64+0x31f738)
    #3 do_start_new_thread _threadmodule.c:1849 (libpython3.13t.dylib:arm64+0x3b69ec)
    #4 thread_PyThread_start_joinable_thread _threadmodule.c:1972 (libpython3.13t.dylib:arm64+0x3b5aa8)
    #5 cfunction_call methodobject.c:540 (libpython3.13t.dylib:arm64+0x115600)
    #6 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #7 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #8 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #9 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #10 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #11 method_vectorcall classobject.c:70 (libpython3.13t.dylib:arm64+0x84714)
    #12 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #13 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #14 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe5c)
    #15 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #16 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #17 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #18 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #19 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #20 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #21 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #22 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #23 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #24 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #25 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #26 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #27 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #28 _PyObject_Call call.c:361 (libpython3.13t.dylib:arm64+0x80694)
    #29 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #30 _PyEval_EvalFrameDefault generated_cases.c.h:1355 (libpython3.13t.dylib:arm64+0x25fe5c)
    #31 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #32 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #33 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #34 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #35 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #36 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #37 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #38 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #39 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #40 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #41 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #42 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #43 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #44 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #45 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #46 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #47 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #48 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #49 _PyObject_VectorcallDictTstate call.c:146 (libpython3.13t.dylib:arm64+0x7f604)
    #50 _PyObject_Call_Prepend call.c:504 (libpython3.13t.dylib:arm64+0x810f0)
    #51 slot_tp_call typeobject.c:9533 (libpython3.13t.dylib:arm64+0x17b194)
    #52 _PyObject_MakeTpCall call.c:242 (libpython3.13t.dylib:arm64+0x7f870)
    #53 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x804c8)
    #54 _PyEval_EvalFrameDefault generated_cases.c.h:1502 (libpython3.13t.dylib:arm64+0x25f41c)
    #55 PyEval_EvalCode ceval.c:597 (libpython3.13t.dylib:arm64+0x254fbc)
    #56 builtin_exec bltinmodule.c.h:556 (libpython3.13t.dylib:arm64+0x24f920)
    #57 cfunction_vectorcall_FASTCALL_KEYWORDS methodobject.c:441 (libpython3.13t.dylib:arm64+0x11491c)
    #58 PyObject_Vectorcall call.c:327 (libpython3.13t.dylib:arm64+0x8042c)
    #59 _PyEval_EvalFrameDefault generated_cases.c.h:813 (libpython3.13t.dylib:arm64+0x25e624)
    #60 _PyEval_Vector ceval.c:1807 (libpython3.13t.dylib:arm64+0x2552cc)
    #61 _PyFunction_Vectorcall call.c (libpython3.13t.dylib:arm64+0x80aa8)
    #62 _PyObject_Call call.c:348 (libpython3.13t.dylib:arm64+0x806ec)
    #63 PyObject_Call call.c:373 (libpython3.13t.dylib:arm64+0x80784)
    #64 pymain_run_module main.c:349 (libpython3.13t.dylib:arm64+0x3362a4)
    #65 Py_RunMain main.c:776 (libpython3.13t.dylib:arm64+0x3359a4)
    #66 pymain_main main.c:806 (libpython3.13t.dylib:arm64+0x336040)
    #67 Py_BytesMain main.c:830 (libpython3.13t.dylib:arm64+0x336118)
    #68 main <null> (python3.13:arm64+0x100003ec4)

SUMMARY: ThreadSanitizer: data race call.c:327 in PyObject_Vectorcall

```

</details>",(these are the only thread sanitizer hits I see running the full NumPy tests),closed,2025-01-07T18:43:55+00:00,2025-01-10T02:51:42+00:00,ngoldbaum,"00 - Bug, 39 - free-threading",2,"PR#28133 - numpy/f2py/rules.py: @@ -245,6 +245,11 @@|;|     if (! PyErr_Occurred())|;|         on_exit(f2py_report_on_exit,(void*)\""#modulename#\"")|;|; #endif|;|+|;|+    if (PyType_Ready(&PyFortran_Type) < 0) {|;|+        return NULL|;|;+    }|;|+|;|     return m|;|; }|;| #ifdef __cplusplus || PR#28137 - numpy/f2py/rules.py: @@ -245,6 +245,11 @@|;|     if (! PyErr_Occurred())|;|         on_exit(f2py_report_on_exit,(void*)\""#modulename#\"")|;|; #endif|;|+|;|+    if (PyType_Ready(&PyFortran_Type) < 0) {|;|+        return NULL|;|;+    }|;|+|;|     return m|;|; }|;| #ifdef __cplusplus",BUG: call PyType_Ready in f2py to avoid data races || BUG: call PyType_Ready in f2py to avoid data races
numpy/numpy,DWesl,23070,Cygwin CI job fails with `f2py` errors,"See for example [this CI log](https://github.com/numpy/numpy/actions/runs/3981840176/jobs/6825839167). Failures:

 =========================== short test summary info ============================
FAILED ../../f2py/tests/test_compile_function.py::test_f2py_init_compile[extra_args0]
FAILED ../../f2py/tests/test_compile_function.py::test_compile_from_strings[program test_f2py\nend program test_f2py0]
FAILED ../../f2py/tests/test_compile_function.py::test_compile_from_strings[program test_f2py\nend program test_f2py1]
FAILED ../../tests/test_public_api.py::test_import_lazy_import[testing] - Blo...
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh18684 - B...
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh6308 - Bl...
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh4519 - Bl...
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_gh3425 - Bl...
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_character_bc[new]
ERROR ../../f2py/tests/test_character.py::TestMiscCharacter::test_character_bc[old]
ERROR ../../f2py/tests/test_crackfortran.py::TestCrackFortran::test_gh2848 - ...
ERROR ../../f2py/tests/test_string.py::TestDocStringArguments::test_example
= 4 failed, 27912 passed, 203 skipped, 1306 deselected, 35 xfailed, 1 xpassed, 8 errors in 546.40s (0:09:06) 

Cc @DWesl have you seen this before? May be due to the 22 Jan Cygwin release, not sure.","I've seen fork() failures a bunch; I was hoping the rebase script would fix those.  It might be that there's too many test modules imported and they're starting to overlap with each other.  I can try to create a list of compiled extension modules and rebase them withing the tests; I've made that work once, but have had problems the last few years (I think my first CI PR here might have included this, and removing it fixed some test problems).  The other option is to try to split the NumPy tests into two runs that each have few enough extension modules imported to avoid problems, or to use `pytest-forked` to run each of the tests that import a compiled extension module in a separate process.  I'll try moving the F2PY tests to a separate runtests call and see if that does anything.

The recent updates: https://cygwin.com/pipermail/cygwin-announce/2023-January/date.html
don't indicate many relevant things in the last few days (`getent` and `dash` might be relevant, but I don't think we use the rest), and there seem to have been Cygwin CI runs passing since the mirrors would have grabbed the [Cygwin bugfix on Thursday](https://cygwin.com/pipermail/cygwin/2023-January/252900.html). || I wonder a bit if vfork use might be safer than fork in cygwin, but it seems even newer Python's (which can use it) wouldn't since they guard using `__linux__`.

There isn't any chance that the rebase script started failing, I guess?  It would be nice if it was more verbose in CI to know that it did something. || > I wonder a bit if vfork use might be safer than fork in cygwin, but it seems even newer Python's (which can use it) wouldn't since they guard using `__linux__`.

It looks like Cygwin `vfork` is a small wrapper around `fork`:
https://cygwin.com/cygwin-api/std-notes.html

> There isn't any chance that the rebase script started failing, I guess? 

It's not reporting an error, and it looks like the problems are with modules compiled as part of the testing, after the rebase script is run.  It's looking like I'll need to add a rebase step to the tests between the compile and import steps to make that go away.

> It would be nice if it was more verbose in CI to know that it did something.

I tried adding more debug information in #23073; I'm still waiting on results.",closed,2023-01-23T10:08:37+00:00,2023-01-30T17:21:53+00:00,rgommers,00 - Bug,1,"PR#23073 - .github/workflows/cygwin.yml: @@ -66,8 +66,9 @@ jobs:|;|         run: ||;|           dash ""tools/rebase_installed_dlls_cygwin.sh"" 3.9|;|       - name: Run NumPy test suite|;|-        run: >-|;|-          dash -c ""/usr/bin/python3.9 runtests.py -n""|;|+        shell: ""C:\\tools\\cygwin\\bin\\bash.exe -o igncr -eo pipefail {0}""|;|+        run: ||;|+          /usr/bin/python3.9 runtests.py -n|;|       - name: Upload wheel if tests fail|;|         uses: actions/upload-artifact@v3|;|         if: failure() || PR#23073 - numpy/f2py/tests/util.py: @@ -6,6 +6,7 @@|;| - determining paths to tests|;| |;| """"""|;|+import glob|;| import os|;| import sys|;| import subprocess|;|@@ -30,6 +31,10 @@|;| _module_dir = None|;| _module_num = 5403|;| |;|+if sys.platform == ""cygwin"":|;|+    NUMPY_INSTALL_ROOT = Path(__file__).parent.parent.parent|;|+    _module_list = list(NUMPY_INSTALL_ROOT.glob(""**/*.dll""))|;|+|;| |;| def _cleanup():|;|     global _module_dir|;|@@ -147,6 +152,21 @@ def build_module(source_files, options=[], skip=[], only=[], module_name=None):|;|         for fn in dst_sources:|;|             os.unlink(fn)|;| |;|+    # Rebase (Cygwin-only)|;|+    if sys.platform == ""cygwin"":|;|+        # If someone starts deleting modules after import, this will|;|+        # need to change to record how big each module is, rather than|;|+        # relying on rebase being able to find that from the files.|;|+        _module_list.extend(|;|+            glob.glob(os.path.join(d, ""{:s}*"".format(module_name)))|;|+        )|;|+        subprocess.check_call(|;|+            [""/usr/bin/rebase"", ""--database"", ""--oblivious"", ""--verbose""]|;|+            + _module_list|;|+        )|;|+|;|+|;|+|;|     # Import|;|     return import_module(module_name)|;|  || PR#23073 - runtests.py: @@ -545,6 +545,17 @@ def build_project(args):|;|             print(""Build failed!"")|;|         sys.exit(1)|;| |;|+    # Rebase|;|+    if sys.platform == ""cygwin"":|;|+        from pathlib import path|;|+        testenv_root = Path(config_vars[""platbase""])|;|+        dll_list = testenv_root.glob(""**/*.dll"")|;|+        rebase_cmd = [""/usr/bin/rebase"", ""--database"", ""--oblivious""]|;|+        rebase_cmd.extend(dll_list)|;|+        if subprocess.run(rebase_cmd):|;|+            print(""Rebase failed"")|;|+            sys.exit(1)|;|+|;|     return site_dir, site_dir_noarch|;| |;| def asv_compare_config(bench_path, args, h_commits): || PR#23073 - tools/list_installed_dll_dependencies_cygwin.sh: @@ -14,11 +14,11 @@|;| py_ver=${1}|;| dll_list=`/bin/dash tools/list_numpy_dlls.sh ${py_ver}`|;| echo ""Checks for existence, permissions and file type""|;|-ls -l ${dll_list}|;|-file ${dll_list}|;|+/usr/bin/timeout 10m /usr/bin/ls -l ${dll_list}|;|+/usr/bin/timeout 10m /usr/bin/file ${dll_list}|;| echo ""Dependency checks""|;|-ldd ${dll_list} | grep -F -e "" => not found"" && exit 1|;|-cygcheck ${dll_list} >cygcheck_dll_list 2>cygcheck_missing_deps|;|+/usr/bin/timeout 10m /usr/bin/ldd ${dll_list} | grep -F -e "" => not found"" && exit 1|;|+/usr/bin/timeout 10m /usr/bin/cygcheck ${dll_list} >cygcheck_dll_list 2>cygcheck_missing_deps|;| grep -F -e ""cygcheck: track_down: could not find "" cygcheck_missing_deps && exit 1|;| echo ""Import tests""|;| mkdir -p dist/|;|@@ -31,5 +31,5 @@ do|;| 			 -e ""s/^\/+(home|usr).*?site-packages\/+//"" \|;| 			 -e ""s/.cpython-3.m?-x86(_64)?-cygwin.dll$//"" \|;| 			 -e ""s/\//./g""`|;|-    python${py_ver} -c ""import ${ext_module}""|;|+    /usr/bin/timeout 2m /usr/bin/python${py_ver} -c ""import ${ext_module}""|;| done || PR#23073 - tools/rebase_installed_dlls_cygwin.sh: @@ -2,4 +2,6 @@|;| # Rebase the dlls installed by NumPy|;| |;| py_ver=${1}|;|-/usr/bin/rebase --database --oblivious `/bin/dash tools/list_numpy_dlls.sh ${py_ver}`|;|+numpy_dlls=""`/bin/dash tools/list_numpy_dlls.sh ${py_ver}`""|;|+/usr/bin/rebase --verbose --database --oblivious ${numpy_dlls}|;|+/usr/bin/rebase --verbose --info ${numpy_dlls}","CI: Split up NumPy compiled extension test modules

This seems to be causing fork failures on Cygwin.  Let's see if this reduces the number of failures. || CI: Use -k to split test cases instead of --ignore

--ignore led to more failures, which is not ideal. || CI: Split tests by submodule to see if that works. || FIX: Make sure CI fails if tests fail. || CI: Print more debug information while rebasing.

Let's see if this shows why everything's got a fork() failure now. || CI: Put timeouts on Cygwin dependency checks.

It should be plenty of time; each of these commands should complete in maybe five seconds per file on a slow day. || TST: Rebase F2Py test modules on Cygwin.

Let's see if this fixes the 8-50 fork failures. || FIX: Add glob import for test module rebase.

Forgot to check this earlier. || CI: Run each F2Py test in a separate process

Hopefully this will keep the main memory space clear enough to allow all tests to succeed. || CI: Split F2Py and non-F2Py tests again

This should help debugging a bit. || CI: Run F2Py tests in parallel on Cygwin

Hopefully this helps, since --forked takes almost five hours. || Revert ""TST: Rebase F2Py test modules on Cygwin.""

This reverts commit 608864613b801b9c85573186a9d07eeac5e7e465. || Revert ""FIX: Add glob import for test module rebase.""

This reverts commit 33709afdbbc47b7adb7dd06a730246d8c02f724f. || CI: Increase number of processes for F2Py tests

Let's see if this eliminates the fork failures.

It's back to around where it was before I started tinkering, so this approach may not work. || CI: Revert increase in parallel test processes.

Tests hang, which is less than ideal.
Hopefully this one works well. || TST: Rebase F2Py-built extension modules.

Also adjust CI so they don't immediately collide with NumPy.
I forgot to do that last time, which caused problems. || CI: Unsplit the Cygwin tests.

Ideally this works nicely and I can change the PR name.
If not, I put the split back, then the parallelization if that still doesn't work. || CI: Rebase numpy DLLs in runtests.py.

This assumes NumPy is rebased before tests run,
but does not assume the locations are in the database."
numpy/numpy,DWesl,25273,CI: Cygwin CI is failing,"Ah no, looks like a real failure. Multiarray doesn't import and then the diagnostic check finds:

```
Dependency checks
	cygblas-0.dll => not found
	cygblas-0.dll => not found
	cyglapack-0.dll => not found
	cyglapack-0.dll => not found
```

I know nothing about cygwin so don't know if this is related to this change...

_Originally posted by @ngoldbaum in https://github.com/numpy/numpy/issues/25271#issuecomment-1832126259_

See any recently updated PR: https://github.com/numpy/numpy/pulls?q=is%3Apr+is%3Aopen+sort%3Aupdated-desc","It looks like lapack and blas are installed but then at runtime loading the dynamic library fails. Maybe a PATH issue?

@mkoeppe it looks like you were the last human to substantively touch the cygwin CI setup - any chance you have some idea what's going wrong? || Also ping @DWesl, maybe you have an idea? || [Cygwin Lapack updated to 3.12.0 this morning](https://cygwin.com/pipermail/cygwin-announce/2023-November/011396.html), though [it looks like the DLLs are in the same place they have been](https://cygwin.com/cgi-bin2/package-cat.cgi?file=x86_64%2Fliblapack0%2Fliblapack0-3.12.0-1).  CI sets `PATH` to include this here:
https://github.com/numpy/numpy/blob/b2e06482a7a624c76d691384e8f59eb4491c94f8/.github/workflows/cygwin.yml#L35-L38
[This morning's Cygwin update](https://cygwin.com/pipermail/cygwin-announce/2023-November/011397.html) mentions no changes to the `/lib`/`/usr/lib` handling, so they should still be equivalent.
I will check the `mount` table to see if that is still the case, and whether the DLLs have execute permissions. || Should we mark the cygwin CI job as known failing until this gets resolved? || It looks like the problem is that [the new `liblapack-devel` does not have a dependency on `liblapack0`](https://github.com/numpy/numpy/actions/runs/7033517957/job/19143044862#step:14:98).  We could add that manually to the installer until the maintainer uploads a new version.",closed,2023-11-29T15:32:32+00:00,2023-11-30T20:52:39+00:00,seberg,,1,"PR#25284 - .github/workflows/cygwin.yml: @@ -31,7 +31,7 @@ jobs:|;|           install-dir: 'C:\tools\cygwin'|;|           packages: >-|;|             python39-devel python39-pip python-pip-wheel python-setuptools-wheel|;|-            liblapack-devel gcc-fortran gcc-g++ git dash cmake ninja|;|+            liblapack-devel liblapack0 gcc-fortran gcc-g++ git dash cmake ninja|;|       - name: Set Windows PATH|;|         uses: egor-tensin/cleanup-path@8469525c8ee3eddabbd3487658621a6235b3c581 # v3|;|         with:","CI: Install Lapack runtime on Cygwin.

Missed dependency on the new version: this should be a short-term workaround."
numpy/numpy,ArvidJB,8579,Feature request: vectorized character slice,"Inspecting `numpy.core.defchararray` and [the online docs for string operations](https://docs.scipy.org/doc/numpy/reference/routines.char.html), it seems there is a missing feature to slice a string array in a vectorized way.

It would be nice to have `numpy.core.defchararray.slice(a, start, stop[, step])`

[This Q/A](http://stackoverflow.com/q/39042214/327026) seems to reflect this missing feature, with a few example implementations.","Yes, this seems like a very straightforward and obviously useful addition.

I encourage you to put together a pull request.",closed,2017-02-08T04:56:43+00:00,2025-01-08T15:31:45+00:00,mwtoews,,1,"PR#27789 - doc/release/upcoming_changes/27789.new_function.rst: @@ -0,0 +1,4 @@|;|+* New function `numpy.strings.slice`|;|+  The new function `numpy.strings.slice` was added, which implements fast|;|+  native slicing of string arrays. It supports the full slicing API including|;|+  negative slice offsets and steps.|;|\ No newline at end of file || PR#27789 - doc/source/reference/routines.strings.rst: @@ -46,6 +46,7 @@ String operations|;|    rjust|;|    rpartition|;|    rstrip|;|+   slice|;|    strip|;|    swapcase|;|    title || PR#27789 - numpy/_core/code_generators/generate_umath.py: @@ -1338,6 +1338,11 @@ def english_upper(s):|;|           docstrings.get('numpy._core.umath._rpartition'),|;|           None,|;|           ),|;|+'_slice':|;|+    Ufunc(4, 1, None,|;|+          docstrings.get('numpy._core.umath._slice'),|;|+          None,|;|+          ),|;| }|;| |;| def indent(st, spaces): || PR#27789 - numpy/_core/code_generators/ufunc_docstrings.py: @@ -5451,3 +5451,40 @@ def add_newdoc(place, name, doc):|;|      array(['', '  ', 'Bba'], dtype=StringDType()))|;| |;|     """""")|;|+|;|+add_newdoc('numpy._core.umath', '_slice',|;|+    """"""|;|+    Slice the strings in `a` by slices specified by `start`, `stop`, `step`.|;|+    Like in the regular Python `slice` object, if only `start` is|;|+    specified then it is interpreted as the `stop`.|;|+|;|+    Parameters|;|+    ----------|;|+    a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype|;|+|;|+    start : the start of the slice, an integer or an array of integers|;|+            which can be broadcasted to`a`'s shape|;|+|;|+    stop : the end point of the slice, an integer or an array of integers|;|+           which can be broadcasted to`a`'s shape|;|+|;|+    step : the step for the slice, an integer or an array of integers|;|+           which can be broadcasted to`a`'s shape|;|+|;|+    Returns|;|+    -------|;|+    out : ndarray|;|+        Output array of str or unicode, depending on input type|;|+|;|+    Examples|;|+    --------|;|+    >>> import numpy as np|;|+|;|+    The ufunc is used most easily via ``np.strings.slice``,|;|+    which calls it under the hood::|;|+|;|+    >>> a = np.array(['hello', 'world'])|;|+    >>> np.strings.slice(a, 2)|;|+    array(['he', 'wo'], dtype='<U5')|;|+|;|+    """""") || PR#27789 - numpy/_core/defchararray.py: @@ -1272,7 +1272,7 @@ class adds the following functionality:|;|         fastest).  If order is 'A', then the returned array may|;|         be in any order (either C-, Fortran-contiguous, or even|;|         discontiguous).|;|-    |;|+|;|     Examples|;|     --------|;|  || PR#27789 - numpy/_core/src/umath/string_ufuncs.cpp: @@ -633,6 +633,67 @@ string_partition_index_loop(PyArrayMethod_Context *context,|;| }|;| |;| |;|+template <ENCODING enc>|;|+static int|;|+string_slice_loop(PyArrayMethod_Context *context,|;|+        char *const data[], npy_intp const dimensions[],|;|+        npy_intp const strides[], NpyAuxData *NPY_UNUSED(auxdata))|;|+{|;|+    int insize = context->descriptors[0]->elsize|;|;+    int outsize = context->descriptors[4]->elsize|;|;+|;|+    char *in_ptr = data[0]|;|;+    char *start_ptr = data[1]|;|;+    char *stop_ptr = data[2]|;|;+    char *step_ptr = data[3]|;|;+    char *out_ptr = data[4]|;|;+|;|+    npy_intp N = dimensions[0]|;|;+|;|+    while (N--) {|;|+        Buffer<enc> inbuf(in_ptr, insize)|;|;+        Buffer<enc> outbuf(out_ptr, outsize)|;|;+|;|+        // get the slice|;|+        npy_intp start = *(npy_intp*)start_ptr|;|;+        npy_intp stop = *(npy_intp*)stop_ptr|;|;+        npy_intp step = *(npy_intp*)step_ptr|;|;+|;|+        // adjust slice to string length in codepoints|;|+        // and handle negative indices|;|+        size_t num_codepoints = inbuf.num_codepoints()|;|;+        npy_intp slice_length = PySlice_AdjustIndices(num_codepoints, &start, &stop, step)|;|;+|;|+        // iterate over slice and copy each character of the string|;|+        inbuf.advance_chars_or_bytes(start)|;|;+        for (npy_intp i = 0; i < slice_length; i++) {|;|+            // copy one codepoint|;|+            inbuf.buffer_memcpy(outbuf, 1)|;|;+|;|+            // Move in inbuf by step.|;|+            inbuf += step|;|;+|;|+            // Move in outbuf by the number of chars or bytes written|;|+            outbuf.advance_chars_or_bytes(1)|;|;+        }|;|+|;|+        // fill remaining outbuf with zero bytes|;|+        for (char *tmp = outbuf.buf; tmp < outbuf.after; tmp++) {|;|+            *tmp = 0|;|;+        }|;|+|;|+        // Go to the next array element|;|+        in_ptr += strides[0]|;|;+        start_ptr += strides[1]|;|;+        stop_ptr += strides[2]|;|;+        step_ptr += strides[3]|;|;+        out_ptr += strides[4]|;|;+    }|;|+|;|+    return 0|;|;+}|;|+|;|+|;| /* Resolve descriptors & promoter functions */|;| |;| static NPY_CASTING|;|@@ -1064,6 +1125,53 @@ string_partition_resolve_descriptors(|;| }|;| |;| |;|+static int|;|+string_slice_promoter(PyObject *NPY_UNUSED(ufunc),|;|+        PyArray_DTypeMeta *const op_dtypes[], PyArray_DTypeMeta *const signature[],|;|+        PyArray_DTypeMeta *new_op_dtypes[])|;|+{|;|+    Py_INCREF(op_dtypes[0])|;|;+    new_op_dtypes[0] = op_dtypes[0]|;|;+    new_op_dtypes[1] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    new_op_dtypes[2] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    new_op_dtypes[3] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    Py_INCREF(op_dtypes[0])|;|;+    new_op_dtypes[4] = op_dtypes[0]|;|;+    return 0|;|;+}|;|+|;|+static NPY_CASTING|;|+string_slice_resolve_descriptors(|;|+        PyArrayMethodObject *self,|;|+        PyArray_DTypeMeta *const NPY_UNUSED(dtypes[5]),|;|+        PyArray_Descr *const given_descrs[5],|;|+        PyArray_Descr *loop_descrs[5],|;|+        npy_intp *NPY_UNUSED(view_offset))|;|+{|;|+    if (given_descrs[4]) {|;|+        PyErr_Format(PyExc_TypeError,|;|+                     ""The '%s' ufunc does not ""|;|+                     ""currently support the 'out' keyword"",|;|+                     self->name)|;|;+        return _NPY_ERROR_OCCURRED_IN_CAST|;|;+    }|;|+|;|+    for (int i = 0; i < 4; i++) {|;|+        loop_descrs[i] = NPY_DT_CALL_ensure_canonical(given_descrs[i])|;|;+        if (loop_descrs[i] == NULL) {|;|+            return _NPY_ERROR_OCCURRED_IN_CAST|;|;+        }|;|+    }|;|+|;|+    loop_descrs[4] = PyArray_DescrNew(loop_descrs[0])|;|;+    if (loop_descrs[4] == NULL) {|;|+        return _NPY_ERROR_OCCURRED_IN_CAST|;|;+    }|;|+    loop_descrs[4]->elsize = loop_descrs[0]->elsize|;|;+|;|+    return NPY_NO_CASTING|;|;+}|;|+|;| /*|;|  * Machinery to add the string loops to the existing ufuncs.|;|  */|;|@@ -1744,6 +1852,28 @@ init_string_ufuncs(PyObject *umath)|;|         }|;|     }|;| |;|+    dtypes[0] = NPY_OBJECT|;|;+    dtypes[1] = NPY_INTP|;|;+    dtypes[2] = NPY_INTP|;|;+    dtypes[3] = NPY_INTP|;|;+    dtypes[4] = NPY_OBJECT|;|;+    if (init_ufunc(|;|+            umath, ""_slice"", 4, 1, dtypes, ENCODING::ASCII,|;|+            string_slice_loop<ENCODING::ASCII>,|;|+            string_slice_resolve_descriptors, NULL) < 0) {|;|+        return -1|;|;+    }|;|+    if (init_ufunc(|;|+            umath, ""_slice"", 4, 1, dtypes, ENCODING::UTF32,|;|+            string_slice_loop<ENCODING::UTF32>,|;|+            string_slice_resolve_descriptors, NULL) < 0) {|;|+        return -1|;|;+    }|;|+    if (init_promoter(umath, ""_slice"", 4, 1,|;|+            string_slice_promoter) < 0) {|;|+        return -1|;|;+    }|;|+|;|     return 0|;|; }|;|  || PR#27789 - numpy/_core/src/umath/stringdtype_ufuncs.cpp: @@ -26,6 +26,8 @@|;| #include ""stringdtype/dtype.h""|;| #include ""stringdtype/utf8_utils.h""|;| |;|+#include <vector>|;|+|;| #define LOAD_TWO_INPUT_STRINGS(CONTEXT)                                            \|;|         const npy_packed_static_string *ps1 = (npy_packed_static_string *)in1;     \|;|         npy_static_string s1 = {0, NULL};                                          \|;|@@ -2142,6 +2144,180 @@ string_inputs_promoter(|;|     return 0|;|; }|;| |;|+static int|;|+slice_promoter(PyObject *NPY_UNUSED(ufunc),|;|+        PyArray_DTypeMeta *const op_dtypes[], PyArray_DTypeMeta *const signature[],|;|+        PyArray_DTypeMeta *new_op_dtypes[])|;|+{|;|+    Py_INCREF(op_dtypes[0])|;|;+    new_op_dtypes[0] = op_dtypes[0]|;|;+    new_op_dtypes[1] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    new_op_dtypes[2] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    new_op_dtypes[3] = NPY_DT_NewRef(&PyArray_IntpDType)|;|;+    Py_INCREF(op_dtypes[0])|;|;+    new_op_dtypes[4] = op_dtypes[0]|;|;+    return 0|;|;+}|;|+|;|+static NPY_CASTING|;|+slice_resolve_descriptors(PyArrayMethodObject *self,|;|+                          PyArray_DTypeMeta *const NPY_UNUSED(dtypes[5]),|;|+                          PyArray_Descr *const given_descrs[5],|;|+                          PyArray_Descr *loop_descrs[5],|;|+                          npy_intp *NPY_UNUSED(view_offset))|;|+{|;|+    if (given_descrs[4]) {|;|+        PyErr_Format(PyExc_TypeError,|;|+                     ""The StringDType '%s' ufunc does not ""|;|+                     ""currently support the 'out' keyword"",|;|+                     self->name)|;|;+        return _NPY_ERROR_OCCURRED_IN_CAST|;|;+    }|;|+|;|+    for (int i = 0; i < 4; i++) {|;|+        Py_INCREF(given_descrs[i])|;|;+        loop_descrs[i] = given_descrs[i]|;|;+    }|;|+|;|+    PyArray_StringDTypeObject *in_descr =|;|+            (PyArray_StringDTypeObject *)loop_descrs[0]|;|;+    int out_coerce = in_descr->coerce|;|;+    PyObject *out_na_object = in_descr->na_object|;|;+    loop_descrs[4] = (PyArray_Descr *)new_stringdtype_instance(out_na_object,|;|+                                                               out_coerce)|;|;+    if (loop_descrs[4] == NULL) {|;|+        return _NPY_ERROR_OCCURRED_IN_CAST|;|;+    }|;|+|;|+    return NPY_NO_CASTING|;|;+}|;|+|;|+static int|;|+slice_strided_loop(PyArrayMethod_Context *context, char *const data[],|;|+                   npy_intp const dimensions[], npy_intp const strides[],|;|+                   NpyAuxData *NPY_UNUSED(auxdata))|;|+{|;|+    char *iptr = data[0]|;|;+    char *start_ptr = data[1]|;|;+    char *stop_ptr = data[2]|;|;+    char *step_ptr = data[3]|;|;+    char *optr = data[4]|;|;+|;|+    npy_intp N = dimensions[0]|;|;+|;|+    npy_string_allocator *allocators[5] = {}|;|;+    NpyString_acquire_allocators(5, context->descriptors, allocators)|;|;+    npy_string_allocator *iallocator = allocators[0]|;|;+    npy_string_allocator *oallocator = allocators[4]|;|;+|;|+    // Build up an index mapping codepoint indices to locations in the encoded|;|+    // string.|;|+    std::vector<unsigned char *> codepoint_offsets|;|;+|;|+    while (N--) {|;|+        // get the slice|;|+        npy_intp start = *(npy_intp *)start_ptr|;|;+        npy_intp stop = *(npy_intp *)stop_ptr|;|;+        npy_intp step = *(npy_intp *)step_ptr|;|;+|;|+        npy_static_string is = {0, NULL}|;|;+        const npy_packed_static_string *ips = (npy_packed_static_string *)iptr|;|;+        npy_static_string os = {0, NULL}|;|;+        npy_packed_static_string *ops = (npy_packed_static_string *)optr|;|;+        int is_isnull = NpyString_load(iallocator, ips, &is)|;|;+        if (is_isnull == -1) {|;|+            npy_gil_error(PyExc_MemoryError, ""Failed to load string in slice"")|;|;+            goto fail|;|;+        }|;|+        else if (is_isnull) {|;|+            npy_gil_error(PyExc_TypeError, ""Cannot slice null string"")|;|;+            goto fail|;|;+        }|;|+|;|+        // number of codepoints in string|;|+        size_t num_codepoints = 0|;|;+        // leaves capacity the same as in previous loop iterations to avoid|;|+        // heap thrashing|;|+        codepoint_offsets.clear()|;|;+        {|;|+            const char *inbuf_ptr = is.buf|;|;+            const char *inbuf_ptr_end = is.buf + is.size|;|;+|;|+            // ignore trailing nulls|;|+            while (inbuf_ptr < inbuf_ptr_end && *(inbuf_ptr_end - 1) == 0) {|;|+                inbuf_ptr_end--|;|;+            }|;|+|;|+            while (inbuf_ptr < inbuf_ptr_end) {|;|+                num_codepoints++|;|;+                int num_bytes = num_bytes_for_utf8_character(|;|+                        ((unsigned char *)inbuf_ptr))|;|;+                codepoint_offsets.push_back((unsigned char *)inbuf_ptr)|;|;+                inbuf_ptr += num_bytes|;|;+            }|;|+        }|;|+|;|+        // adjust slice to string length in codepoints|;|+        // and handle negative indices|;|+        npy_intp slice_length =|;|+                PySlice_AdjustIndices(num_codepoints, &start, &stop, step)|;|;+|;|+        if (step == 1) {|;|+            // step == 1 is the easy case, we can just use memcpy|;|+            npy_intp outsize = ((size_t)stop < num_codepoints|;|+                                        ? codepoint_offsets[stop]|;|+                                        : (unsigned char *)is.buf + is.size) -|;|+                               codepoint_offsets[start]|;|;+|;|+            if (load_new_string(ops, &os, outsize, oallocator, ""slice"") < 0) {|;|+                goto fail|;|;+            }|;|+|;|+            /* explicitly discard const; initializing new buffer */|;|+            char *buf = (char *)os.buf|;|;+|;|+            memcpy(buf, codepoint_offsets[start], outsize)|;|;+        }|;|+        else {|;|+            // handle step != 1|;|+            // compute outsize|;|+            npy_intp outsize = 0|;|;+            for (int i = start; step > 0 ? i < stop : i > stop; i += step) {|;|+                outsize += num_bytes_for_utf8_character(codepoint_offsets[i])|;|;+            }|;|+|;|+            if (outsize > 0) {|;|+                if (load_new_string(ops, &os, outsize, oallocator, ""slice"") < 0) {|;|+                    goto fail|;|;+                }|;|+|;|+                /* explicitly discard const; initializing new buffer */|;|+                char *buf = (char *)os.buf|;|;+|;|+                for (npy_intp i_idx = start, o_idx = 0; o_idx < slice_length; o_idx++, i_idx += step) {|;|+                    int num_bytes = num_bytes_for_utf8_character(codepoint_offsets[i_idx])|;|;+                    memcpy(buf, codepoint_offsets[i_idx], num_bytes)|;|;+                    buf += num_bytes|;|;+                }|;|+            }|;|+        }|;|+|;|+        // move to next step|;|+        iptr += strides[0]|;|;+        start_ptr += strides[1]|;|;+        stop_ptr += strides[2]|;|;+        step_ptr += strides[3]|;|;+        optr += strides[4]|;|;+    }|;|+|;|+    NpyString_release_allocators(5, allocators)|;|;+    return 0|;|;+|;|+fail:|;|+    NpyString_release_allocators(5, allocators)|;|;+    return -1|;|;+}|;|+|;| static int|;| string_object_bool_output_promoter(|;|         PyObject *ufunc, PyArray_DTypeMeta *const op_dtypes[],|;|@@ -2921,5 +3097,32 @@ init_stringdtype_ufuncs(PyObject *umath)|;|         }|;|     }|;| |;|+    PyArray_DTypeMeta *slice_dtypes[] = {|;|+        &PyArray_StringDType,|;|+        &PyArray_IntpDType,|;|+        &PyArray_IntpDType,|;|+        &PyArray_IntpDType,|;|+        &PyArray_StringDType,|;|+    }|;|;+|;|+    if (init_ufunc(umath, ""_slice"", slice_dtypes, slice_resolve_descriptors,|;|+                   slice_strided_loop, 4, 1, NPY_NO_CASTING,|;|+                   (NPY_ARRAYMETHOD_FLAGS) 0, NULL) < 0) {|;|+        return -1|;|;+    }|;|+|;|+    PyArray_DTypeMeta *slice_promoter_dtypes[] = {|;|+        &PyArray_StringDType,|;|+        &PyArray_IntAbstractDType,|;|+        &PyArray_IntAbstractDType,|;|+        &PyArray_IntAbstractDType,|;|+        &PyArray_StringDType,|;|+    }|;|;+|;|+    if (add_promoter(umath, ""_slice"", slice_promoter_dtypes, 5,|;|+                     slice_promoter) < 0) {|;|+        return -1|;|;+    }|;|+|;|     return 0|;|; } || PR#27789 - numpy/_core/strings.py: @@ -46,6 +46,7 @@|;|     _partition_index,|;|     _rpartition,|;|     _rpartition_index,|;|+    _slice,|;| )|;| |;| |;|@@ -68,7 +69,7 @@ def _override___module__():|;|     ""isupper"", ""istitle"", ""isdecimal"", ""isnumeric"", ""str_len"", ""find"",|;|     ""rfind"", ""index"", ""rindex"", ""count"", ""startswith"", ""endswith"", ""lstrip"",|;|     ""rstrip"", ""strip"", ""replace"", ""expandtabs"", ""center"", ""ljust"", ""rjust"",|;|-    ""zfill"", ""partition"", ""rpartition"",|;|+    ""zfill"", ""partition"", ""rpartition"", ""slice"",|;| |;|     # _vec_string - Will gradually become ufuncs as well|;|     ""upper"", ""lower"", ""swapcase"", ""capitalize"", ""title"",|;|@@ -1639,3 +1640,81 @@ def translate(a, table, deletechars=None):|;|             'translate',|;|             [table] + _clean_args(deletechars)|;|         )|;|+|;|+@set_module(""numpy.strings"")|;|+def slice(a, start=None, stop=None, step=None, /):|;|+    """"""|;|+    Slice the strings in `a` by slices specified by `start`, `stop`, `step`.|;|+    Like in the regular Python `slice` object, if only `start` is|;|+    specified then it is interpreted as the `stop`.|;|+|;|+    Parameters|;|+    ----------|;|+    a : array-like, with ``StringDType``, ``bytes_``, or ``str_`` dtype|;|+|;|+    start : the start of the slice, can be None, an integer or|;|+            an array of integers which can be broadcasted to`a`'s shape|;|+|;|+    stop : the end point of the slice, can be None, and integer or|;|+           an array of integers which can be broadcasted to`a`'s shape|;|+|;|+    step : the step for the slice, can be None, an integer or|;|+           an array of integers which can be broadcasted to`a`'s shape|;|+|;|+    Returns|;|+    -------|;|+    out : ndarray|;|+        Output array of str or unicode, depending on input type|;|+|;|+    Examples|;|+    --------|;|+    >>> import numpy as np|;|+    >>> a = np.array(['hello', 'world'])|;|+    >>> np.strings.slice(a, 2)|;|+    array(['he', 'wo'], dtype='<U5')|;|+|;|+    >>> np.strings.slice(a, 1, 5, 2)|;|+    array(['el', 'ol'], dtype='<U5')|;|+|;|+    One can specify different start/stop/step for different array entries:|;|+|;|+    >>> np.strings.slice(a, np.array([1, 2]), np.array([4, 5]))|;|+    array(['ell', 'rld'], dtype='<U5')|;|+|;|+    Negative slices have the same meaning as in regular Python:|;|+|;|+    >>> b = np.array(['hello world', 'γεια σου κόσμε', '你好世界', '👋 🌍'],|;|+    ...              dtype=np.dtypes.StringDType())|;|+    >>> np.strings.slice(b, -2)|;|+    array(['hello wor', 'γεια σου κόσ', '你好', '👋'], dtype=StringDType())|;|+|;|+    >>> np.strings.slice(b, [3, -10, 2, -3], [-1, -2, -1, 3])|;|+    array(['lo worl', ' σου κόσ', '世', '👋 🌍'], dtype=StringDType())|;|+|;|+    >>> np.strings.slice(b, None, None, -1)|;|+    array(['dlrow olleh', 'εμσόκ υοσ αιεγ', '界世好你', '🌍 👋'],|;|+          dtype=StringDType())|;|+|;|+    """"""|;|+    # Just like in the construction of a regular slice object, if only start|;|+    # is speficied then start will become stop, see logic in slice_new.|;|+    if stop is None:|;|+        stop = start|;|+        start = None|;|+|;|+    # adjust start, stop, step to be integers, see logic in PySlice_Unpack|;|+    if step is None:|;|+        step = 1|;|+    step = np.asanyarray(step)|;|+    if not np.issubdtype(step.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {step.dtype} for operand 'step'"")|;|+    if np.any(step == 0):|;|+        raise ValueError(""slice step cannot be zero"")|;|+|;|+    if start is None:|;|+        start = np.where(step < 0, np.iinfo(np.intp).max, 0)|;|+|;|+    if stop is None:|;|+        stop = np.where(step < 0, np.iinfo(np.intp).min, np.iinfo(np.intp).max)|;|+|;|+    return _slice(a, start, stop, step) || PR#27789 - numpy/_core/tests/test_strings.py: @@ -941,6 +941,57 @@ def test_rpartition(self, buf, sep, res1, res2, res3, dt):|;|         assert_array_equal(act3, res3)|;|         assert_array_equal(act1 + act2 + act3, buf)|;| |;|+    @pytest.mark.parametrize(""args"", [|;|+        (None,),|;|+        (0,),|;|+        (1,),|;|+        (3,),|;|+        (5,),|;|+        (6,),  # test index past the end|;|+        (-1,),|;|+        (-3,),|;|+        ([3, 4],),|;|+        ([2, 4],),|;|+        ([-3, 5],),|;|+        ([0, -5],),|;|+        (1, 4),|;|+        (-3, 5),|;|+        (None, -1),|;|+        (0, [4, 2]),|;|+        ([1, 2], [-1, -2]),|;|+        (1, 5, 2),|;|+        (None, None, -1),|;|+        ([0, 6], [-1, 0], [2, -1]),|;|+    ])|;|+    def test_slice(self, args, dt):|;|+        buf = np.array([""hello"", ""world""], dtype=dt)|;|+        act = np.strings.slice(buf, *args)|;|+        bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)|;|+        res = np.array([s[slice(*arg)]|;|+                        for s, arg in zip(buf, zip(*bcast_args))],|;|+                       dtype=dt)|;|+        assert_array_equal(act, res)|;|+|;|+    def test_slice_unsupported(self, dt):|;|+        with pytest.raises(TypeError, match=""did not contain a loop""):|;|+            np.strings.slice(np.array([1, 2, 3]), 4)|;|+|;|+        with pytest.raises(TypeError, match=r""Cannot cast ufunc '_slice' input .* from .* to dtype\('int(64|32)'\)""):|;|+            np.strings.slice(np.array(['foo', 'bar'], dtype=dt), np.array(['foo', 'bar'], dtype=dt))|;|+|;|+    @pytest.mark.parametrize(""int_dt"", [np.int8, np.int16, np.int32, np.int64,|;|+                                        np.uint8, np.uint16, np.uint32, np.uint64])|;|+    def test_slice_int_type_promotion(self, int_dt, dt):|;|+        buf = np.array([""hello"", ""world""], dtype=dt)|;|+|;|+        assert_array_equal(np.strings.slice(buf, int_dt(4)), np.array([""hell"", ""worl""], dtype=dt))|;|+        assert_array_equal(np.strings.slice(buf, np.array([4, 4], dtype=int_dt)), np.array([""hell"", ""worl""], dtype=dt))|;|+|;|+        assert_array_equal(np.strings.slice(buf, int_dt(2), int_dt(4)), np.array([""ll"", ""rl""], dtype=dt))|;|+        assert_array_equal(np.strings.slice(buf, np.array([2, 2], dtype=int_dt), np.array([4, 4], dtype=int_dt)), np.array([""ll"", ""rl""], dtype=dt))|;|+|;|+        assert_array_equal(np.strings.slice(buf, int_dt(0), int_dt(4), int_dt(2)), np.array([""hl"", ""wr""], dtype=dt))|;|+        assert_array_equal(np.strings.slice(buf, np.array([0, 0], dtype=int_dt), np.array([4, 4], dtype=int_dt), np.array([2, 2], dtype=int_dt)), np.array([""hl"", ""wr""], dtype=dt))|;| |;| @pytest.mark.parametrize(""dt"", [""U"", ""T""])|;| class TestMethodsWithUnicode:|;|@@ -1178,6 +1229,37 @@ def test_strip_functions_unicode(self, source, strip, method, dt):|;| |;|         assert_array_equal(actual, expected)|;| |;|+    @pytest.mark.parametrize(""args"", [|;|+        (None,),|;|+        (0,),|;|+        (1,),|;|+        (5,),|;|+        (15,),|;|+        (22,),|;|+        (-1,),|;|+        (-3,),|;|+        ([3, 4],),|;|+        ([-5, 5],),|;|+        ([0, -8],),|;|+        (1, 12),|;|+        (-12, 15),|;|+        (None, -1),|;|+        (0, [17, 6]),|;|+        ([1, 2], [-1, -2]),|;|+        (1, 11, 2),|;|+        (None, None, -1),|;|+        ([0, 10], [-1, 0], [2, -1]),|;|+    ])|;|+    def test_slice(self, args, dt):|;|+        buf = np.array([""Приве́т नमस्ते שָׁלוֹם"", ""😀😃😄😁😆😅🤣😂🙂🙃""],|;|+                       dtype=dt)|;|+        act = np.strings.slice(buf, *args)|;|+        bcast_args = tuple(np.broadcast_to(arg, buf.shape) for arg in args)|;|+        res = np.array([s[slice(*arg)]|;|+                        for s, arg in zip(buf, zip(*bcast_args))],|;|+                       dtype=dt)|;|+        assert_array_equal(act, res)|;|+|;| |;| class TestMixedTypeMethods:|;|     def test_center(self): || PR#27789 - numpy/_core/umath.py: @@ -20,7 +20,7 @@|;|     _replace, _strip_whitespace, _lstrip_whitespace, _rstrip_whitespace,|;|     _strip_chars, _lstrip_chars, _rstrip_chars, _expandtabs_length,|;|     _expandtabs, _center, _ljust, _rjust, _zfill, _partition, _partition_index,|;|-    _rpartition, _rpartition_index)|;|+    _rpartition, _rpartition_index, _slice)|;| |;| __all__ = [|;|     'absolute', 'add',","ENH: Implement np.strings.slice as a gufunc

This commit adds a `np.strings.slice` function which
vectorizes slicing of string arrays. For example
```
    >>> a = np.array(['hello', 'world'])
    >>> np.char.slice(a, 2)
    array(['he', 'wo'], dtype='<U5')
```

This supports fixed-length and variable-length string dtypes.
It also supports broadcasting the start, stop, step args:
```
    >>> b = np.array(['hello world', 'γεια σου κόσμε', '你好世界', '👋 🌍️'], dtype=np.dtypes.StringDType())
    >>> np.strings.slice(b, [3, 0, 2, 1], -1)
    array(['lo worl', 'γεια σου κόσμ', '世', ' 🌍'], dtype=StringDType())
```

Closes #8579 || Fix reference to numpy.char.slice"
numpy/numpy,jorenham,20099,BUG: `NDArray[Any]` methods ignore overload ambiguity,"### Describe the issue:

A operation between a `NDArray[Any]` array and an integer, as in the code example, makes Mypy infer the result as
`numpy.ndarray[Any, numpy.dtype[numpy.signedinteger[Any]]]`. This is an error, as the result could also be a floating point array, or even a complex one.

### Reproduce the code example:

```python
from numpy.typing import NDArray

def f(arr: NDArray[Any]) -> None:
    reveal_type(arr + 2)
```


### Error message:

_No response_

### NumPy/Python version information:

1.21.2 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0]","cc @nschloe

Turns out this issue is present in both mypy and pyright: https://github.com/numpy/numpy/issues/20265 || For Pyright I opened an issue at https://github.com/microsoft/pyright/issues/2521.

It seems that Pyright currently does not handle overload ambiguity at all, 
so I'm concerned this might be more difficult to fix compared to https://github.com/python/mypy/issues/11347.",closed,2021-10-11T18:20:19+00:00,2025-01-06T22:52:31+00:00,vnmabus,"00 - Bug, 41 - Static typing",2,"PR#28112 - environment.yml: @@ -25,7 +25,7 @@ dependencies:|;|   - hypothesis|;|   # For type annotations|;|   - typing_extensions>=4.2.0  # needed for python < 3.10|;|-  - mypy=1.13.0|;|+  - mypy=1.14.1|;|   - orjson  # makes mypy faster|;|   # For building docs|;|   - sphinx>=4.5.0 || PR#28112 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2617,111 +2623,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2731,20 +2818,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2754,20 +2855,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2777,22 +2892,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2801,156 +2930,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28112 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28112 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -87,17 +88,16 @@ def __array_function__(|;| )|;| |;| if sys.version_info >= (3, 12):|;|-    from collections.abc import Buffer|;|-|;|-    ArrayLike: TypeAlias = Buffer | _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    from collections.abc import Buffer as _Buffer|;| else:|;|-    ArrayLike: TypeAlias = _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    @runtime_checkable|;|+    class _Buffer(Protocol):|;|+        def __buffer__(self, flags: int, /) -> memoryview: ...|;|+|;|+ArrayLike: TypeAlias = _Buffer | _DualArrayLike[|;|+    dtype[Any],|;|+    bool | int | float | complex | str | bytes,|;|+]|;| |;| # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`|;| # given the casting rules `same_kind`|;|@@ -165,6 +165,11 @@ def __array_function__(|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28112 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28112 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28112 - numpy/typing/tests/data/reveal/index_tricks.pyi: @@ -58,13 +58,13 @@ assert_type(np.mgrid[1:1:2, None:10], npt.NDArray[Any])|;| assert_type(np.ogrid[1:1:2], tuple[npt.NDArray[Any], ...])|;| assert_type(np.ogrid[1:1:2, None:10], tuple[npt.NDArray[Any], ...])|;| |;|-assert_type(np.index_exp[0:1], tuple[slice])|;|-assert_type(np.index_exp[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.index_exp[0:1], tuple[slice[int, int, None]])|;|+assert_type(np.index_exp[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;|-assert_type(np.s_[0:1], slice)|;|-assert_type(np.s_[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.s_[0:1], slice[int, int, None])|;|+assert_type(np.s_[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;| assert_type(np.ix_(AR_LIKE_b), tuple[npt.NDArray[np.bool], ...])|;| assert_type(np.ix_(AR_LIKE_i, AR_LIKE_f), tuple[npt.NDArray[np.float64], ...]) || PR#28112 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28112 - requirements/test_requirements.txt: @@ -14,7 +14,7 @@ cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:|;| # - Mypy relies on C API features not present in PyPy|;| # NOTE: Keep mypy in sync with environment.yml|;|-mypy==1.13.0; platform_python_implementation != ""PyPy""|;|+mypy==1.14.1; platform_python_implementation != ""PyPy""|;| typing_extensions>=4.2.0|;| # for optional f2py encoding detection|;| charset-normalizer || PR#28108 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2613,111 +2619,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2727,20 +2814,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2750,20 +2851,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2773,22 +2888,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2797,156 +2926,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28108 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28108 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -164,6 +165,11 @@ def __buffer__(self, flags: int, /) -> memoryview: ...|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28108 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28108 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28108 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])","TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128`` || MAINT: bump ``mypy`` to ``1.14.1`` (#28089)

* MAINT: bump `mypy` to `1.14.1`

* TYP: fix new `mypy==1.14.1` type-test errors

* TYP: backport `collections.abc.Buffer` for `npt.ArrayLike` on `python<3.11` || TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128``"
numpy/numpy,jorenham,22631,numpy.typing uint8 becomes signedinteger on multiplication,"### Describe the issue:

When using numpy.typing, multiplying an array with dtype `uint8` by any integer converts the typing dtype to `signedinteger`

### Reproduce the code example:

```python
import numpy as np
from numpy.typing import NDArray


def get_uint8() -> NDArray[np.uint8]:
    return np.random.rand(3).astype(np.uint8)


a = get_uint8()  # a is correctly NDArray[np.uint8]
b = a * 1        # b is NDArray[signedinteger]
```


### Error message:

```shell
`b` in the code shows as `NDArray[signedinteger]`, instead of `NDArray[np.uint8]`
```


### NumPy/Python version information:

```
$ python -c 'import sys, numpy; print(numpy.__version__, sys.version)'
1.23.4 3.10.7 (main, Nov 14 2022, 18:57:04) [Clang 14.0.0 (clang-1400.0.29.202)]
```

### Context for the issue:

I'm using numpy.typing to differentiate between some arrays of type `uint8` and some arrays of type `float32`. However, I have to use a `cast` every time I multiply an array by a number, which compromises the effectiveness of type checking.","I believe this is due to numpy's type promotion rules to prevent data loss from mathematical operations. You can test this behavior with [`np.result_type`](https://numpy.org/doc/stable/reference/generated/numpy.result_type.html), and see the linked page for details.

```
>>> np.result_type(np.uint8, int)
dtype('int64')
```

I agree this is annoying for static type checking, and I understand numpy's rationales for doing type promotion. Certainly, static type annotations currently have no influence on the actual numpy data types at the moment. || How to work around it? Need to replace all constants with e.g. `np.array([1], np.uint8)`? || (Just checked, and this workaround does work) || Replacing constant with uint8 is dangerous if the other side may be a scalar with a small value currently.

From a runtime perspective, I guess you are effectively getting what you want (although you probably want NEP 50).  As I understand it, the problem with typing, although I am not sure if there can be a reasonable solution without NEP 50 (or similar) to remove the value-dependency of the current results. || awesome 🙌 ",closed,2022-11-20T15:01:17+00:00,2025-01-06T22:52:31+00:00,hughperkins,"00 - Bug, 41 - Static typing",2,"PR#28112 - environment.yml: @@ -25,7 +25,7 @@ dependencies:|;|   - hypothesis|;|   # For type annotations|;|   - typing_extensions>=4.2.0  # needed for python < 3.10|;|-  - mypy=1.13.0|;|+  - mypy=1.14.1|;|   - orjson  # makes mypy faster|;|   # For building docs|;|   - sphinx>=4.5.0 || PR#28112 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2617,111 +2623,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2731,20 +2818,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2754,20 +2855,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2777,22 +2892,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2801,156 +2930,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28112 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28112 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -87,17 +88,16 @@ def __array_function__(|;| )|;| |;| if sys.version_info >= (3, 12):|;|-    from collections.abc import Buffer|;|-|;|-    ArrayLike: TypeAlias = Buffer | _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    from collections.abc import Buffer as _Buffer|;| else:|;|-    ArrayLike: TypeAlias = _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    @runtime_checkable|;|+    class _Buffer(Protocol):|;|+        def __buffer__(self, flags: int, /) -> memoryview: ...|;|+|;|+ArrayLike: TypeAlias = _Buffer | _DualArrayLike[|;|+    dtype[Any],|;|+    bool | int | float | complex | str | bytes,|;|+]|;| |;| # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`|;| # given the casting rules `same_kind`|;|@@ -165,6 +165,11 @@ def __array_function__(|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28112 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28112 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28112 - numpy/typing/tests/data/reveal/index_tricks.pyi: @@ -58,13 +58,13 @@ assert_type(np.mgrid[1:1:2, None:10], npt.NDArray[Any])|;| assert_type(np.ogrid[1:1:2], tuple[npt.NDArray[Any], ...])|;| assert_type(np.ogrid[1:1:2, None:10], tuple[npt.NDArray[Any], ...])|;| |;|-assert_type(np.index_exp[0:1], tuple[slice])|;|-assert_type(np.index_exp[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.index_exp[0:1], tuple[slice[int, int, None]])|;|+assert_type(np.index_exp[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;|-assert_type(np.s_[0:1], slice)|;|-assert_type(np.s_[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.s_[0:1], slice[int, int, None])|;|+assert_type(np.s_[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;| assert_type(np.ix_(AR_LIKE_b), tuple[npt.NDArray[np.bool], ...])|;| assert_type(np.ix_(AR_LIKE_i, AR_LIKE_f), tuple[npt.NDArray[np.float64], ...]) || PR#28112 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28112 - requirements/test_requirements.txt: @@ -14,7 +14,7 @@ cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:|;| # - Mypy relies on C API features not present in PyPy|;| # NOTE: Keep mypy in sync with environment.yml|;|-mypy==1.13.0; platform_python_implementation != ""PyPy""|;|+mypy==1.14.1; platform_python_implementation != ""PyPy""|;| typing_extensions>=4.2.0|;| # for optional f2py encoding detection|;| charset-normalizer || PR#28108 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2613,111 +2619,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2727,20 +2814,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2750,20 +2851,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2773,22 +2888,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2797,156 +2926,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28108 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28108 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -164,6 +165,11 @@ def __buffer__(self, flags: int, /) -> memoryview: ...|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28108 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28108 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28108 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])","TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128`` || MAINT: bump ``mypy`` to ``1.14.1`` (#28089)

* MAINT: bump `mypy` to `1.14.1`

* TYP: fix new `mypy==1.14.1` type-test errors

* TYP: backport `collections.abc.Buffer` for `npt.ArrayLike` on `python<3.11` || TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128``"
numpy/numpy,jorenham,27957,TYP: regression between 2.1.3 and 2.2.0 (mypy only),"### Describe the issue:

The following code seems correct, and passes type checking under 2.1.3 but not 2.2.0:

```python
import numpy as np

rng = np.random.default_rng(27446968)
n_states = 5

P = rng.random(size=(n_states, n_states))
p = rng.random(n_states)

p = P.T @ p
```

I suppose mypy is flagging that the float width can increase, but since float64 is used by random, that won't happen in this scenario.

### Reproduce the code example:

```python
N/A
```


### Error message:

```shell
foo.py:10: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int, ...], dtype[float64]]"")  [assignment]
Found 1 error in 1 file (checked 1 source file)
```


### Python and NumPy Versions:

Python 3.13, mypy 1.13, numpy 2.2.0

### Runtime Environment:

_No response_

### Context for the issue:

_No response_","We're seeing these failures in http://github.com/google/jax/ as well. || Looks like this was introduced in #27767: we need `tuple[int, ...]` rather than `tuple[int]` in a number of places. cc/ @jorenham || Some cases where failures happen:

```python
import numpy as np


def case1_fail() -> np.ndarray:
    a = np.random.random((3, 10))
    return np.all(a, axis=1)


def case1_ok() -> np.ndarray:
    a = np.random.random((3, 10))
    b = np.all(a, axis=1)
    assert not isinstance(b, np.bool)
    return b


def case2_fail() -> int:
    a = np.arange(5)
    for i in a:
        return i

    return 0


def case2_ok() -> int:
    a = np.arange(5)
    return a[0]

``` || Much simpler reproducer:
```python
import numpy as np

x = np.zeros(1)
x = x / 1
```
results in:
```
test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[float64]]"")  [assignment]
```
If I try:
```python
import numpy as np

x = np.zeros(1, dtype=float)
x = x / 1
```
I get:
```
test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[Any]]"")  [assignment]
```
Trying:
```python
import numpy as np

x = np.zeros(1, dtype=np.float32)
x = x / 1
```
gives:
```
test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[floating[_32Bit]]]"")  [assignment]
```
Similarly, this:
```python
import numpy as np

x = np.zeros(1, dtype=np.float64)
x = x / 1
```
gives:
```
test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[float64]]"")  [assignment]
```
I have no idea how to annotate this in a way that will work. || > Looks like this was introduced in #27767: we need `tuple[int, ...]` rather than `tuple[int]` in a number of places. cc/ @jorenham

That's unrelated to this issue. Both the left- and the right-hand-side have `tuple[int, ...]` as shape type.

Since numpy 2.2.0, `numpy.float64` is a proper subtype of `numpy.floating` (and `builtins.float`). Before, it was simply a type alias, but that was invalid.
What you're seeing is a direct result of that, and it's correct behavior. To illustrate:

```pyi
from typing import Any
import numpy as np

f: np.floating[Any]
f8: np.float64

f = f8  # accepted
f8 = f  # rejected on >=2.2.0, accepted on <2.2.0
```

---

So 

> The following code seems correct, and passes type checking under 2.1.3 but not 2.2.0:
> 
> ```python
> import numpy as np
> 
> rng = np.random.default_rng(27446968)
> n_states = 5
> 
> P = rng.random(size=(n_states, n_states))
> p = rng.random(n_states)
> 
> p = P.T @ p
> ```
> 
> I suppose mypy is flagging that the float width can increase, but since float64 is used by random, that won't happen in this scenario.

Pyright gives a more helpful error message in this case:

```
Type ""floating[Any]"" is not assignable to declared type ""float64""
  ""floating[Any]"" is not assignable to ""float64""
```

So the result of `rng.random` is a `float64` array, which causes `p` to be inferred as a `npt.NDArray[np.float64]`. But `P.T @ p` isn't typed as narrowly as it could be (but technically it's valid), so it is inferred as `npt.NDArray[np.floating]`. And because `floating` is the supertype of `float64`, it cannot be assigned to it. And that is correct behavior.

To make this example work without typing errors, this is what you could do

```py
import numpy as np
import numpy.typing as npt

rng = np.random.default_rng(27446968)
n_states = 5

P = rng.random(size=(n_states, n_states))

p: npt.NDArray[np.floating]
p = rng.random(n_states)
p = P.T @ p
``` || @nabenabe0928 your examples are unrelated to the this issue.

> ```python
> def case1_fail() -> np.ndarray:
>     a = np.random.random((3, 10))
>     return np.all(a, axis=1)
> ```

I know this isn't related to what you're point is, but the return type is missing type arguments, and that's invalid (that's why `strict=True` should always be set).

The return type annotation of `np.all(a, axis=1)` is inferrred as `npt.NDArray[np.bool] | np.bool`. At first glance, that seems unnecessarily broad. But in practice, it's currently impossible to properly annotate this so that mypy understands it (with pyright it would be possible). This is because mypy (unlike pyright) can't understand `tuple[int, int, Unpack[tuple[int, ...]]`, or in words, ""a shape type that is at least 1-dimensional"".

So to make this valid, change the return type annotation to `npt.NDArray[np.bool] | np.bool`, or use `typing.cast(npt.NDArray[np.bool], np.all(a, axis=1)`

---

> ```py
> def case1_ok() -> np.ndarray:
>     a = np.random.random((3, 10))
>     b = np.all(a, axis=1)
>     assert not isinstance(b, np.bool)
>     return b
> ```

The return type should be `npt.NDArray[np.bool]` here.

You're trying to ""narrow"" `b` into `npt.NDArray[np.bool]`, here, which seems like a good idea to me. And the latest mypy actually does this correctly, and accepts this example. But for some reason pyright doesn't narrow `b` correctly in this case, which results in a false positive. So this is not related to numpy, but an issue with pyright.

---

> ```py
> def case2_fail() -> int:
>     a = np.arange(5)
>     for i in a:
>         return i
> 
>     return 0
> 
> def case2_ok() -> int:
>     a = np.arange(5)
>     return a[0]
> ```


Both these are invalid, and that's for a good reason: `numpy.integer` isn't assignable to `builtins.int`. 
To fix this, you could instead return `int(i)` and `int(a[0])`, or change the return-type annotations to match what you're actually returning, i.e. `np.integer | int` in the first case, and `np.integer` in the second case.
 || > Much simpler reproducer:
> 
> ```python
> import numpy as np
> 
> x = np.zeros(1)
> x = x / 1
> ```

This is yet another issue, and it has to do with shape-typing instead. While technically this isn't a bug, I'll admit that it's very annoying.

The `np.zeros(1)` returns an array with shape type `tuple[int]` and scalar type `float64`, and that actually the best possible way to annotate this.

But currently, the division operator doesn't take shape-typing into account, so `x / 1` will ignore the shape-type of the input, and returns the ""generic"" shape type `tuple[int, ...]`.
But since `x` already has a more-specific shape-type, it cannot be overwritten with one that is less specific.
It also isn't very precise when it comes to the scalar type, and returns `np.floating` instead of `float64`. Technically, that is correct, but I fully agree that it's sub-optimal.

Anyway, this is how you can fix it to work with both mypy and pyright:

```py
import numpy as np
import numpy.typing as npt

x: npt.NDArray[np.floating]
x = np.zeros(1)
x = x / 1
```

You're other examples, @adamjstewart, can also be fixed in the same way.

Feel free to open a separate issue about these ""suboptimally annotated arithmetic operator types"". || > We're seeing these failures in [http://github.com/google/jax/](https://github.com/google/jax/) as well.

Could you be more specific? || > > We're seeing these failures in [http://github.com/google/jax/](https://github.com/google/jax/) as well.
> 
> Could you be more specific?

I temporarily pinned NumPy 2.1 yesterday to fix the CI errors, but https://github.com/jax-ml/jax/pull/25381 shows the errors under NumPy 2.2. In particular, this one prompted me to go searching for this issue:
```
jax/_src/mesh_utils.py:600: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[Any]]"", variable has type ""ndarray[tuple[int], dtype[Any]]"")  [assignment]
```
I now see that this is probably the intended behavior: it's no longer safe to assume that an array is an array; every array annotation must now be specialized on its shape (as I said in the other thread, I suspect this will break a lot of valid code). || To be quite honest, we've been talking about giving up on mypy & static type checking in JAX, because the signal-to-noise ratio of type failures is far too low. This change in NumPy might be the final nail in the coffin for that. || > valid code

It will by definition only break code that type-checkers (mypy in this case) deems invalid. So in a way, these errors have always been there, but numpy 2.2.0 made it so they now come to light.

As my earlier answer showed, such cases are often easy to work around. And I agree that the mypy error messages are cryptic and difficult to read. 

And instead of giving up on python typing altogether, perhaps you could switching from mypy to pyright @jakevdp. At the very least, you'd get better error messages, but it also helps a lot if you don't have to deal with all of those mypy bugs anymore (see https://github.com/erictraut/mypy_issues). || I understand that the change is considered technically more accurate, but from the SP lecture notes' perspective (where I got my example), we'd like to write code that is simple and correct, but without using type annotations. This change makes that quite a bit harder to do. || > And instead of giving up on python typing altogether, perhaps you could switching from mypy to pyright @jakevdp

Is this a sign that the numerical computing community in Python is giving up on mypy as a standard type checker? Your responses here certainly could be read that way. Is that your intent? || > I understand that the change is considered technically more accurate

That's not necessarily the motivation behind these changes. There has been huge demand for shape-typing support (see e.g. https://github.com/numpy/numpy/issues/16544), and these changes are the steps we need to take towards realizing that goal.  || We should work toward implementing features that users are asking for. But if the cost of that is that simple & correct un-annotated code is now incorrectly flagged as a type error, I would contend that it's the implementation that is wrong, not the user code. || > Is this a sign that the numerical computing community in Python is giving up on mypy as a standard type checker?

There's no hidden agenda or something. It's just that I know first-hand how frustrating it can be to run into mypy bugs time and time again, especially in cases when mypy is the sole reason that I'm not able to implement a good idea. There are also many examples where mypy is preventing bugs from being fixed in typeshed stubs for the python standard library. 

So what I'm trying to say is that I'd hate to see people stop typing their code because of their frustrations with mypy. I'm convinced that typing could prevent many bugs, so getting rid of it could have serious consequences for libraries as popular as jax. So that's why I'm trying to show that there are alternatives that could make everyone's life a bit easier 🤷🏻  || > simple & correct un-annotated code

That's not quite right, because when you assign a 1-d array to a 2-d one in your example, you're doing something that's *type-unsafe*, i.e. something that can lead to bugs. In this case, the only way to prevent this, is using shape-typing. || Here's a reduction of one of the errors we're seeing in JAX:
```python
import numpy as np
x = np.zeros(1, dtype=object)
x[0] = slice(None)
```
```
tmp.py:3: error: No overload variant of ""__setitem__"" of ""ndarray"" matches argument types ""int"", ""slice""  [call-overload]
tmp.py:3: note: Possible overload variants:
tmp.py:3: note:     def __setitem__(self, str | list[str], Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
tmp.py:3: note:     def __setitem__(self, SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | tuple[SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | None, ...] | None, Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
Found 1 error in 1 file (checked 1 source file)
```
This looks to me like a bug. || > Here's a reduction of one of the errors we're seeing in JAX:
> 
> ```python
> import numpy as np
> x = np.zeros(1, dtype=object)
> x[0] = slice(None)
> ```
> 
> ```
> tmp.py:3: error: No overload variant of ""__setitem__"" of ""ndarray"" matches argument types ""int"", ""slice""  [call-overload]
> tmp.py:3: note: Possible overload variants:
> tmp.py:3: note:     def __setitem__(self, str | list[str], Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
> tmp.py:3: note:     def __setitem__(self, SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | tuple[SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | None, ...] | None, Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
> Found 1 error in 1 file (checked 1 source file)
> ```
> 
> This looks to me like a bug.

At first glance that indeed looks like a bug. Could you open a separate issue for this? || https://github.com/numpy/numpy/issues/27964 – thanks! || On Tue, Dec 10, 2024 at 10:53 AM Joren Hammudoglu ***@***.***>
wrote:

> Is this a sign that the numerical computing community in Python is giving
> up on mypy as a standard type checker?
>
> There's no hidden agenda or something. It's just that I know first-hand
> how frustrating it can be to run into mypy bugs time and time again,
> especially in cases when mypy is the sole reason that I'm not able to
> implement a good idea. There are also many examples where mypy is
> preventing bugs from being fixed in typeshed stubs for the python standard
> library.
>
> So what I'm trying to say is that I'd hate to see people stop typing their
> code because of their frustrations with mypy. I'm convinced that typing
> could prevent many bugs, so getting rid of it could have serious
> consequences for libraries as popular as jax. So that's why I'm trying to
> show that there are alternatives that could make everyone's life a bit
> easier 🤷🏻
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/numpy/numpy/issues/27957#issuecomment-2532461477>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAAS3WFLNQE4GQVET6KEG7D2E4TDPAVCNFSM6AAAAABTJ2FFKKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKMZSGQ3DCNBXG4>
> .
> You are receiving this because you are subscribed to this thread.
>

I think the question is, should we prefer pyright? If so, we might want to
change our own tests to use it and suggest it for users instead of mypy. If
mypy has as many problems as you say, it is hard to justify. Are there
problems with pyright? Platform support, dependencies, etc? It is under the
MIT license, so no problem there. I see that there is a pywrite wrapper up
on PyPI.

Chuck

> Message ID: ***@***.***>
>
 || Echoing https://github.com/numpy/numpy/issues/27957#issuecomment-2532362224, I'm going to propose a principle: un-annotated user code that executes correctly should not error when type-checked.

The main issue with the errors discussed above is that NumPy 2.2 violates this principle. Given that, I think the type annotation changes in NumPy 2.2 are problematic, and should be rolled back until they can be implemented more carefully. || > That's not quite right, because when you assign a 1-d array to a 2-d one in your example, you're doing something that's _type-unsafe_, i.e. something that can lead to bugs. In this case, the only way to prevent this, is using shape-typing.

I thought I am assigning a shape `(5,)` array to a shape `(5,)` array, but perhaps I missed some subtlety?

```
P.shape=(5, 5) p.shape=(5,)
(P.T @ p).shape=(5,)
```

From above, the error message:

```
foo.py:9: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int, ...], dtype[float64]]"")  [assignment]
```

The types seem identical, other than for the floating point types? || > I'm going to propose a principle: un-annotated user code that executes correctly should not error when type-checked.

This seems like a good guiding principle, but what do we do when the type-checking tool is buggy or problematic? In a recent triage meeting we discussed this and would like lower expectations. Typing is turning out to be very complicated and it may a few tries to get things working on all type checker. || I'll note that a number of the issues above are due to Mypy not being able to understand variables being reassigned. That is the case for both of these for example:
```python
P = rng.random(size=(n_states, n_states))
p = rng.random(n_states)
p = P.T @ p

x = np.zeros(1)
x = x / 1
```
Here the `p` and `x` variables' type should be inferred again when the type checker encounters a new `x =`/`p =`, but it doesn't . This is a very annoying and long-standing usability issue in Mypy. It also affects code patterns like this:
```python
def some_long_func():
    tmp = None
    # do something here that uses `tmp`, then further down use a fresh `tmp` variable:
    tmp = []
```
One fix that works in some cases, as @jorenham pointed out, is to explicitly type the variable with the looser of the two types (`p: npt.NDArray[np.floating]`), but the easier and more generic fix is just to rename the variable so it gets inferred correctly on first use.

Code patterns like that are common and there is nothing that can be done in NumPy to guard against new failures. For code like this:
```python
y = np.func1(...)
y = np.func2(...)
```
Mypy will choke as soon as `func1` gets more strict (and hence more accurate) type annotations and `func2` doesn't, if before their annotations were the same. Given that `func1` and `func2` can be any numpy functions, it follows that we cannot make any annotations more strict without causing these types of failures with Mypy. Pyright has no issues here.

> Is this a sign that the numerical computing community in Python is giving up on mypy as a standard type checker?

In addition to what @jorenham said in https://github.com/numpy/numpy/issues/27957#issuecomment-2532461477: AFAIK this has not been discussed before, but I don't think it's an outrageous suggestion. Mypy is very problematic and beta quality at best - and that is probably not going to improve quickly given the weight of development history and backlog.

 || Looking at [`mypy` issues](https://github.com/python/mypy/issues/9700#issuecomment-722398581), is it right that the work-around is that for NumPy + MyPy you are likely to need `--allow-redefinition` unless you want to rename things every line?
(Since NumPy arrays have such detailed type info, it is practically impossible to write two lines of code and not change the type... especially with necessarily incomplete stubs.)

Maybe that is not an outlandish fix and should be documented somewhere (possibly even by the MyPy error itself...)?

(And maybe it makes sense to bring it up with mypy again, even if in the end the ecosystem may just give up on it?)

---

The question is whether such a work-around is an acceptable fix to allow improving the NumPy stubs without just causing churn downstream?
(Or maybe the alternative of suggesting using `pyright`...  I don't have an opinion on this, but we need to balance churn and right now I don't know what that means.) || Good find @seberg! Following the cross-links from there, it looks like MyPy 2.0 will be the release that finally fixes this problem. Prominently documenting that `--allow-redefinition` should be used (e.g., in https://numpy.org/devdocs/reference/typing.html) seems reasonable as well.  || On Thu, Dec 12, 2024 at 2:44 AM Ralf Gommers ***@***.***>
wrote:

> I'll note that a number of the issues above are due to Mypy not being able
> to understand variables being reassigned. That is the case for both of
> these for example:
>
> P = rng.random(size=(n_states, n_states))p = rng.random(n_states)p = P.T @ p
> x = np.zeros(1)x = x / 1
>
> Here the p and x variables' type should be inferred again when the type
> checker encounters a new x =/p =, but it doesn't . This is a very
> annoying and long-standing usability issue in Mypy. It also affects code
> patterns like this:
>
> def some_long_func():
>     tmp = None
>     # do something here that uses `tmp`, then further down use a fresh `tmp` variable:
>     tmp = []
>
> One fix that works in some cases, as @jorenham
> <https://github.com/jorenham> pointed out, is to explicitly type the
> variable with the looser of the two types (p: npt.NDArray[np.floating]),
> but the easier and more generic fix is just to rename the variable so it
> gets inferred correctly on first use.
>
> Code patterns like that are common and there is nothing that can be done
> in NumPy to guard against new failures. For code like this:
>
> y = np.func1(...)y = np.func2(...)
>
> Mypy will choke as soon as func1 gets more strict (and hence more
> accurate) type annotations and func2 doesn't, if before their annotations
> were the same. Given that func1 and func2 can be any numpy functions, it
> follows that we cannot made any annotations more strict without causing
> these types of failures with Mypy. Pyright has no issues here.
>
> Is this a sign that the numerical computing community in Python is giving
> up on mypy as a standard type checker?
>
> In addition to what @jorenham <https://github.com/jorenham> said in #27957
> (comment)
> <https://github.com/numpy/numpy/issues/27957#issuecomment-2532461477>:
> AFAIK this has not been discussed before, but I don't think it's an
> outrageous suggestion. Mypy is very problematic and beta quality at best -
> and that is probably not going to improve quickly given the weight of
> development history and backlog.
>

What do the popular IDEs use?

Chuck
 || > so getting rid of it could have serious consequences for libraries as popular as jax

To be clear, we are not discussing removing type annotations altogether from the package. Rather we've discussed not type-checking our internal implementations, but rather just declaring types for users via interface files for the public API. We're often finding type check failures to be low signal-to-noise during the course of our own development (especially when trying to appease mypy, pytype, and pyright all in a single code-base), but we're happy to let API consumers use type checking if they wish.

There's still no decision here though – we would do a public RFC before making any such changes. || There's one unspoken assumption in this thread that I'd like to call out: namely, that rank is the right level of specificity for static typing of arrays. One could imagine alternatives: e.g. until now ""ndarray"" has been the supported level of specificity, with ""ndarray + dtype"" supported in some cases. With 2.2, ""ndarray + rank + dtype"" is the supported level of specificity. Perhaps in the future, ""ndarray + rank + shape + dtype"" will be supported. Or maybe ""ndarray + rank + shape + dtype + contents"" – I don't know.

But we should recognize that implementing more specificity is not free from tradeoffs: for every true error you flag, you'll also flag false positives, whether it's due to deficient tooling (e.g. the mypy bugs discussed above) or deficient type propagation in NumPy itself (e.g. @stefanv's error, where the arrays have identical shapes and dtypes at runtime, but NumPy's propagated static types are more specific for one than the other).

I'm not personally convinced that rank-specificity of static types—at least in its current implementation—is worth the tradeoffs it comes with. But reasonable people can disagree. || > We're often finding type check failures to be low signal-to-noise 

I'm beginning to think of annotations more as documentation than ""type checking"". || > I think the question is, should we prefer pyright? If so, we might want to change our own tests to use it and suggest it for users instead of mypy. If mypy has as many problems as you say, it is hard to justify.

I'm convinced that objectively speaking, Pyright is indeed the better choice. However, we shouldn't ignore the users that prefer mypy either. So for the type-tests it would be best if we *additionally* use pyright in our type-test, and minimize the number of times that they disagree with eachother.

Curently we're not doing any type-checking, only (manual type-testing). But we should. And once we start doing so, I think that we could start with pyright, and later add mypy in that mix (assuming it's still alive at that point). 

---


> Are there problems with pyright? Platform support, dependencies, etc? It is under the MIT license, so no problem there. I see that there is a pywrite wrapper up on PyPI.

It's significantly, faster, and has better IDE integration, especially in VSCode through the Pylance plugin, which is enabled by default. However, Pylance itself isn't open source. 

I personally use [basedpyright](https://github.com/detachhead/basedpyright/) for my projects. It's a fully backwards-compatible fork of pyright that has better defaults, and comes with its own open-source IDE plugins. The ""baseline"" it provides is especially interesting for numpy, which makes it significantly easier to adopt as a type-checker (we currently aren't type-checking our own stubs, we're only type-testing them by hand). Basedpyright is as far as I'm concerned better than pyright and mypy in all aspects. || > I thought I am assigning a shape `(5,)` array to a shape `(5,)` array, but perhaps I missed some subtlety?

Ah I see, you're right. I didn't notice the different capitalizations of `P` and `p`. || > > I'm going to propose a principle: un-annotated user code that executes correctly should not error when type-checked.
> 
> This seems like a good guiding principle, but what do we do when the type-checking tool is buggy or problematic? In a recent triage meeting we discussed this and would like lower expectations. Typing is turning out to be very complicated and it may a few tries to get things working on all type checker

We should let the official typing spec be leading in such cases: https://typing.readthedocs.io/en/latest/spec/index.html 

... as long as it's reasonable in that particular case || I am up in the air as to how much priority to give to these typing problems. If they are high priority, we should make sure they are fixed, or agreed not be fixed, before releasing 2.2.1. If they are seen as part of an ongoing development effort that will inevitably hit rough spots, then I can just add fixes as they come along. I am personally inclined towards the latter. Thoughts? || This issue is (originally) about an inevitable consequence of ongoing shape-typing development. 

I've been thinking quite a lot about how we could go about avoiding such situations like these in the future, and I came to the conclusion that it's impossible (at least, unless we somehow manage to perfectly type everything in the next release). 

To see why, consider functions `f` and `g` with identical signatures that return an array whose shape and dtype depends on the input. They both have annotations at the moment, but there's room for improvement, so we will do just that. But there's only enough time for us to improve *one* of the return type annotations, as the next release is very close, and you're also working on 6 other important open-source projects for some reason 😅.

Now here's the problem: if you choose `f`, then the return type will become *better*, so its return type will be more *narrow* than that of `g`. That means that any code that first does `x = f(*args)`  and then `x = g(*args)` (which before this change was allowed), isn't allowed anymore. There will always be users that use `f` and `g` in different orders like this. So improving either `f` or `g` will inevitably lead to new typechecker errors for some users.

🤷🏻 

---

> I am personally inclined towards the latter.

So in case it wasn't clear yet; so am I :) || > Looking at [`mypy` issues](https://github.com/python/mypy/issues/9700#issuecomment-722398581), is it right that the work-around is that for NumPy + MyPy you are likely to need `--allow-redefinition` unless you want to rename things every line?

This looked promising, but it's very strict. E.g., I simplified my example above. In the lecture notes it is:

```python
# Normalize p
p /= p.sum()

# Take steps
for k in range(n_steps):
    p = P.T @ p
```

That for-loop, because it is at a different block/nesting depth, still fails the check even with `--allow-redefinition`.
 || > This looked promising, but it's very strict.

Does `basedpyright` do any better? || > > This looked promising, but it's very strict.
> 
> Does `basedpyright` do any better?

Yes

```py
import numpy as np

rng = np.random.default_rng(27446968)
n_states = 5

P = rng.random(size=(n_states, n_states))
p = rng.random(n_states)

# Normalize p
p /= p.sum()

# Take steps
for k in range(10):
    p = P.T @ p
```

running `basedpyright` on this, configured with `strict = true`, reports

```bash
$ uv run basedpyright src/numpy_play/issues/issue_27957.py
0 errors, 0 warnings, 0 notes
```

and with `mypy`

```bash
$ uv run mypy src/numpy_play/issues/issue_27957.py
src/numpy_play/issues/issue_27957.py:14: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int, ...], dtype[float64]]"")  [assignment]
        p = P.T @ p
            ^~~~~~~
Found 1 error in 1 file (checked 1 source file)
```

See https://docs.basedpyright.com/latest/usage/mypy-comparison/ for the differences between the two || On the original lecture notes example, I needed to use the following configuration, and then basedpyright passes:

```json
{
  ""reportAny"": false,
  ""reportConstantRedefinition"": false
}
```

```python
import numpy as np

rng = np.random.default_rng(27446968)

n_states = 5
n_steps = 50
tolerance = 1e-5

# Random transition matrix and state vector
P = rng.random(size=(n_states, n_states))
p = rng.random(n_states)

# Normalize rows in P
P /= P.sum(axis=1)[:, np.newaxis]

# Normalize p
p /= p.sum()

# Take steps
for k in range(n_steps):
    p = P.T @ p

p_50 = p
print(p_50)

# Compute stationary state
w, v = np.linalg.eig(P.T)

j_stationary = np.argmin(abs(w - 1.0))
p_stationary = np.real(v[:, j_stationary])
p_stationary /= p_stationary.sum()
print(p_stationary)

# Compare
if all(abs(p_50 - p_stationary) < tolerance):
    print(""Tolerance satisfied in infty-norm"")

if np.linalg.norm(p_50 - p_stationary) < tolerance:
    print(""Tolerance satisfied in 2-norm"")
``` || @stefanv FYI, the `reportConstantRedefinition = false` is only needed here, because basedpyright (and legacy pyright too I believe) assumes that all-caps names are constants, and are therefore not allowed to change. || as someone that has been closely involved with mypy for many years, my only recommendation is that it should be avoided at all costs. the project is extremely poorly managed and poorly written, and that leads to the issues that everyone that uses it experiences 

ideally it will be deprecated and a new type checker will be pushed forward as the standard. mypy is beyond fixing (and I should know, I've been trying to fix it for a very long time) || The lack of a ""blessed"" tool to check typing annotations seems like a foundational problem with type checking and Python. I admit, I am not a heavy user of type checking, but I would have difficulty parsing a failure like 

> `test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[Any]]"")  [assignment]` 

Maybe we should make type checking shapes and dtypes opt-in via some import flag or environment variable (like we did with NEP50) until the tools to handle it seamlessly can catch up. || I ran into another fun anomaly, which is that `pyright` does not work with (meson-python) editable installs in their current form: https://github.com/microsoft/pyright/blob/main/docs/import-resolution.md#editable-installs (see also https://github.com/microsoft/pyright/issues/1473#issuecomment-1296286498) || It looks like `ArrayLike` also needs to be widened in other cases, or perhaps @jorenham can suggest a better mechanism to solve the following:

```python
from skimage import measure
import matplotlib.pyplot as plt
import numpy as np

all_labels = measure.label(np.arange(12).reshape((3,4)))

def foo(x: np.typing.ArrayLike):
    return x

foo(all_labels)
```

Which fails with the delightful:

```
$ basedpyright /home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py
/home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py
  /home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py:10:5 - error: Argument of type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]] | Unknown | tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Unknown] | ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64] | Literal[1, 0]"" cannot be assigned to parameter ""x"" of type ""ArrayLike"" in function ""foo""
    Type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]] | Unknown | tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Unknown] | ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64] | Literal[1, 0]"" is not assignable to type ""ArrayLike""
      Type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is not assignable to type ""ArrayLike""
        ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""Buffer""
          ""__buffer__"" is not present
        ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""_SupportsArray[dtype[Any]]""
          ""__array__"" is not present
        ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""_NestedSequence[_SupportsArray[dtype[Any]]]""
          ""__getitem__"" is an incompatible type
    ... (reportArgumentType)
```

Although, to be honest, in this case I am not sure whether it's a problem with NumPy's `ArrayLike`, or whether pyright is not able to infer the correct return type for this specific invocation of the code. We could, of course, make modifications to skimage to assist, if that's necessary. || > which is that `pyright` does not work with (meson-python) editable installs in their current form

I think there are issues with all type checkers. Mypy in addition also removed support for type-checking a regular installed package IIRC. Basically (a) editable installs are fundamentally limited in what they can do/support, and (b) typing tools are going to be limited here as long as they refuse to either run on installed packages in a useful way, or support editable installs with import hooks. The third option is blaming meson-python (and scikit-build-core when used with out-of-tree builds which are also recommended for CMake) for using out-of-tree builds, but that's not all that constructive since it's pretty well established that that's a good way of building with a number of important advantages over littering build artifacts all over the source tree.

 || > Although, to be honest, in this case I am not sure whether it's a problem with NumPy's `ArrayLike`, or whether pyright is not able to infer the correct return type for this specific invocation of the code. We could, of course, make modifications to skimage to assist, if that's necessary.

I think that code is not quite right, you shouldn't have a half-annotated signature, nor return a union. If you'd always return a `np.ndarray` (which you'd normally always do from code that accepts `ArrayLike`) things would work as expected.  || > The lack of a ""blessed"" tool to check typing annotations seems like a foundational problem with type checking and Python. I admit, I am not a heavy user of type checking, but I would have difficulty parsing a failure like
> 
> > `test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[Any]]"")  [assignment]`
> 
> Maybe we should make type checking shapes and dtypes opt-in via some import flag or environment variable (like we did with NEP50) until the tools to handle it seamlessly can catch up.

I don't think that's possible: Typing stubs cannot access any information about the platform apart from `sys.platform` and `sys.version_info`. || > It looks like `ArrayLike` also needs to be widened in other cases, or perhaps @jorenham can suggest a better mechanism to solve the following:
> 
> ```python
> from skimage import measure
> import matplotlib.pyplot as plt
> import numpy as np
> 
> all_labels = measure.label(np.arange(12).reshape((3,4)))
> 
> def foo(x: np.typing.ArrayLike):
>     return x
> 
> foo(all_labels)
> ```
> 
> Which fails with the delightful:
> 
> ```
> $ basedpyright /home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py
> /home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py
>   /home/stefan/p/scientific-python/lectures/packages/scikit-image/examples/plot_labels.py:10:5 - error: Argument of type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]] | Unknown | tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Unknown] | ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64] | Literal[1, 0]"" cannot be assigned to parameter ""x"" of type ""ArrayLike"" in function ""foo""
>     Type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]] | Unknown | tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Unknown] | ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64] | Literal[1, 0]"" is not assignable to type ""ArrayLike""
>       Type ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is not assignable to type ""ArrayLike""
>         ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""Buffer""
>           ""__buffer__"" is not present
>         ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""_SupportsArray[dtype[Any]]""
>           ""__array__"" is not present
>         ""tuple[ndarray[Unknown, Unknown] | _Array[_Shape, signedinteger[_NBitIntP] | signedinteger[_32Bit]] | _Array[_Shape, float64], Literal[1, 0]]"" is incompatible with protocol ""_NestedSequence[_SupportsArray[dtype[Any]]]""
>           ""__getitem__"" is an incompatible type
>     ... (reportArgumentType)
> ```
> 
> Although, to be honest, in this case I am not sure whether it's a problem with NumPy's `ArrayLike`, or whether pyright is not able to infer the correct return type for this specific invocation of the code. We could, of course, make modifications to skimage to assist, if that's necessary.

This seems unrelated to shape-typing, and is probably related to the fact that [`skimage.measure.label` is unannotated](https://github.com/scikit-image/scikit-image/blob/dd5d5b4d54aec2af0608ad39455c5a422d9da835/skimage/measure/_label.py). || > I ran into another fun anomaly, which is that `pyright` does not work with (meson-python) editable installs in their current form: https://github.com/microsoft/pyright/blob/main/docs/import-resolution.md#editable-installs (see also [microsoft/pyright#1473 (comment)](https://github.com/microsoft/pyright/issues/1473#issuecomment-1296286498))

That might be specific to [`pyright-python`](https://github.com/RobertCraigie/pyright-python), which relies on `nodeenv`. Perhaps you could try `basedpyright` instead, which uses `nodejs-wheel-binaries`. || > (a) editable installs are fundamentally limited in what they can do/support

Mypy not properly dealing with editable installs gave me a lot of trouble recently in `scipy-stubs`. There, I also use `basedpyright`, which didn't have these issues, and dealt with editable installs as expected. || > Perhaps you could try basedpyright instead, which uses nodejs-wheel-binaries.

basedpyright recently added support for a nodeless release to address edge case systems || > The lack of a ""blessed"" tool to check typing annotations

I think we will need to do the blessing. Dealing with mypy is making annotation difficult and taking up a lot of our time. It is like using a buggy compiler. I think it essential to use a working and maintained checker. || > The third option is blaming meson-python (and scikit-build-core when used with out-of-tree builds which are also recommended for CMake) for using out-of-tree builds, but that's not all that constructive since it's pretty well established that that's a good way of building with a number of important advantages over littering build artifacts all over the source tree.

Makes perfect sense, and just to be clear: I was only pointing out what the pyright author wrote. Their docs should at least mention the actual problem! || > That might be specific to [`pyright-python`](https://github.com/RobertCraigie/pyright-python), which relies on `nodeenv`. Perhaps you could try `basedpyright` instead, which uses `nodejs-wheel-binaries`.

I've been using `basedpyright`, FWIW, and still ran into the [issue](https://docs.basedpyright.com/latest/usage/import-resolution/#editable-installs). || > I think that code is not quite right, you shouldn't have a half-annotated signature, nor return a union.

I'd like to understand this better: are you saying that scikit-image has a half-annotated signature? As far as I can tell `skimage.measure.label` is fully un-annotated:

```python
def label(label_image, background=None, return_num=False, connectivity=None):
```

 || I was commenting on this signature in your example:
```python
def foo(x: np.typing.ArrayLike):
```
`x` is annotated, but it's missing `-> np.ndarray` or something like that. || > `x` is annotated, but it's missing `-> np.ndarray` or something like that.

Ah, gotcha. This was just a toy example, and adding an output type doesn't resolve the error. || > > I think that code is not quite right, you shouldn't have a half-annotated signature, nor return a union.
> 
> I'd like to understand this better: are you saying that scikit-image has a half-annotated signature? As far as I can tell `skimage.measure.label` is fully un-annotated:
> 
> ```python
> def label(label_image, background=None, return_num=False, connectivity=None):
> ```

This ""half-annotated signature"" is the result of this `basedpyright` environment option:

> `useLibraryCodeForTypes [boolean]`: Determines whether pyright reads, parses and analyzes library code to extract type information in the absence of type stub files. Type information will typically be incomplete. We recommend using type stubs where possible. The default value for this option is true.

https://docs.basedpyright.com/latest/configuration/config-files/#environment-options || After updating from numpy 2.1 to 2.2 in our codebase, I ran into similar errors.

Before discovering this Github issue, I've been able to isolate this example, where mypy would pass without any error with numpy==2.1.3:
```python
from typing import TypeAlias

import numpy as np

Mask: TypeAlias = np.ndarray[tuple[int, int], np.dtype[np.bool_]]

mask: Mask = np.random.rand(1080, 1920).astype(np.bool_)
```

With numpy 2.2.0 I get this error:
```
example_typing.py:7: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[numpy.bool[builtins.bool]]]"", variable has type ""ndarray[tuple[int, int], dtype[numpy.bool[builtins.bool]]]"")  [assignment]
Found 1 error in 1 file (checked 1 source file)
```

I'm not sure if this is the same issue as here above, or something else ? || > I'm not sure if this is the same issue as here above, or something else ?

It's indeed a similar issue @titouanc. The `ndarray.astype` currently does not take the shape-type into account:

https://github.com/numpy/numpy/blob/e7a123b2d3eca9897843791dd698c1803d9a39c2/numpy/__init__.pyi#L2444-L2461

The reason why it's only now rejected by type-checkers, is because since 2.2.0, the `npt.NDArray` type-alias will use `tuple[int, ...]` as its shape-type, instead of `Any`. 

The reason for this, is because if you have some `x: ndarray[Any, ...]`, its `x.shape` attribute will now also be `Any`, even though the associated type parameter is explicitly defined to have `bound=tuple[int, ...]`. This made it impossible to write `@overload`s for different shape-types, because `Any` would always match either the first or last overload (depending on the type-checker), which made it impossible to implement shape-typing in many (if not most) functions. This is one of the reasons why I've been calling `Any` ""evil"", and why e.g. `basedpyright` and `flake8-pyi` report an error when you use it. || What is the recommended approach in this scenario? It feels less than desirable to litter code with `cast`. || > What is the recommended approach in this scenario? It feels less than desirable to litter code with `cast`.

I mentioned this in https://github.com/numpy/numpy/issues/27957#issuecomment-2531480073:

```py
import numpy as np
import numpy.typing as npt

rng = np.random.default_rng(27446968)
n_states = 5

P = rng.random(size=(n_states, n_states))

p: npt.NDArray[np.floating]
p = rng.random(n_states)
p = P.T @ p
```

Note that this is only required for mypy; (`based`)`pyright` accepts the initial example as-is. || I just want to make sure I understand: the recommended solution here is to proactively annotate all your array variables with a very permissive shape annotation, so that outputs of NumPy APIs which do not propagate strict shapes can be assigned to them without error. Is that accurate? || > I just want to make sure I understand: the recommended solution here is to proactively annotate all your array variables with a very permissive shape annotation, so that outputs of NumPy APIs which do not propagate strict shapes can be assigned to them without error. Is that accurate?

This workaround is only needed if a) you're using mypy, and b) mypy reports a false positive in a case such as this one.  

For example 

```py
p = P.T @ rng.random(n_states)
```

is already accepted by mypy || > I mentioned this in [#27957 (comment)](https://github.com/numpy/numpy/issues/27957#issuecomment-2531480073):

Oh, I meant the recommended approach for [@titouanc's example](https://github.com/numpy/numpy/issues/27957#issuecomment-2551558171) || > > I mentioned this in [#27957 (comment)](https://github.com/numpy/numpy/issues/27957#issuecomment-2531480073):
> 
> Oh, I meant the recommended approach for [@titouanc's example](https://github.com/numpy/numpy/issues/27957#issuecomment-2551643556)

You could either `cast` it to `Mask`, broaden the shape-type of `Mask` to `tuple[int, ...]`, or don't use `Mask` at all. || OK, so I can imagine it would be difficult in the case of `rand`, which accepts N positional arguments. But for `default_rng().random`, we know the output shape matches the dimension of the provided shape:

```
rng = np.random.default_rng()
Mask: TypeAlias = np.ndarray[tuple[int, int], np.dtype[np.bool_]]
mask: Mask = rng.random((1080, 1920)).astype(np.bool_)
```

I don't think Python yet supports matching the `shape` argument to the output dimension, and so I'm starting to have doubts whether shape typing, in its current form, is helpful or a hindrance.

The above case seems to be like the kind of scenario where type hinting could potentially be useful, but again it is just making the user jump through unnecessary hoops to make already correct code pass. || > I don't think Python yet supports matching the `shape` argument to the output dimension, and so I'm starting to have doubts whether shape typing, in its current form, is helpful or a hindrance.

It does, we just haven't annotated all of numpy's functions in a way that they take that into account. So it can certainly be very helpful. 
And in this case, the only hindrance is the custom `Mask` type alias, which is an application of NumPy's *incomplete* shape-typing support (and therefore also undocumented).

It being accepted before 2.2.0 was accidental. || > It being accepted before 2.2.0 was accidental.

Ah, OK, that happens. Worth rolling back in a 2.2.1?

Could you point me to a resource on matching output shape to length of input parameter? I've searched quite a bit, and can't find it :see_no_evil: || > Worth rolling back in a 2.2.1?

no

> Could you point me to a resource on matching output shape to length of input parameter? 

I can't because we haven't documented shape-typing yet. But it's something that happens *a lot* in [`scipy-stubs`](https://github.com/jorenham/scipy-stubs), e.g. in [`scipy.sparse._coo._coo_base.__init__`](https://github.com/jorenham/scipy-stubs/blob/713ae0d7a1127425dd2d0057a3edab3f0727c700/scipy-stubs/sparse/_coo.pyi#L81-L300).

But as you can see there as well, it's far from ideal. And in the case of nested `Sequence` types, the best you can do is ""brute-force overload"" the first couple of `ndim`, followed by an an ""etc."" overload. 

There has been recent effort to write a PEP that could improve shape-typing, by introducing something called *refinement types*. But that's a very involved feature, and there's a good chance it won't make it, or otherwise take a very long time until it'll be accepted. || So let's imagine a situation in which NumPy is fully typed, to the available features available in Python: what are the benefits and the disadvantages of shape typing and, in that light, are they worth keeping around?

What I observe so far is that 2.2.1 introduced a certain amount of churn, without any shown benefit. But I realize I may just be experiencing a small sliver of it, so want to understand better why the decision was taken to continue along this path.

If the choice was optimistic (Python will fix annotation, eventually), then I think we ought to step back. If the decision was made because the concrete benefits are there now, then developers can reasonably be encouraged to take the hit. || Just a quick comment: there is clearly a large demand for shape typing, given the number of 👍🏼's on gh-16544. It was a very long journey to implement it and seems far from complete, but given all that interest and effort I kinda take it at a given that we want to support it. The linked feature request has a lot of context on the benefits of shape typing, including from other NumPy devs (e.g., https://github.com/numpy/numpy/issues/16544#issuecomment-351116822).  || Given the complexity of the topic, the level of detail of that discussion and the [existing write-up by @shoyer](https://docs.google.com/document/d/1vpMse4c6DrWH5rq2tQSx3qwP_m_0lyn-Ij4WHqQqRHY/edit?tab=t.0#heading=h.rkj7d39awayl), it could be helpful to summarize the arguments that went into the decision making, what we are aiming for, and what's missing in a short NEP.

The demand for typing is high, but there are still subtleties into how that typing should be implemented. And I think a lot of projects are looking to NumPy and SciPy to figure out how to proceed—this would help them too.
 || FWIW, I am not quite clear on how bad the inconvenience is.  There was at least one thing ""untyped code should not fail"" where mypy is problematic, but is that only mypy?

A NEP does not seem like a huge request right now since I understand at least @stefanv and @jakevdp are a bit skeptical about the new churn (or at least something that discusses possible problems or alternatives to get everyone on the same page... but that is basically a NEP).

The direction is clear, I think: more information in the types is better!  But while I would hate to revet things, right now I am not quite sure that the downstream churn may not warrent that?
(Possibly even if we most likely _will_ decide to go here in the next release.)

At the very least it seems that there needs to be docs that point to `(based)pyright` etc. because there are issues with mypy? || > There was at least one thing ""untyped code should not fail"" where mypy is problematic, but is that only mypy?

It at least isn't a problem with (based)pyright, which uses global analysis (i.e. non-greedy), whereas mypy only looks at the first declaration when inferring a type:

```py
a = True
a = a + 1
```

mypy ([playground](https://mypy-play.net/?mypy=latest&python=3.12&gist=ca21ad484702f4c30909ed72717f24b0)):

```
main.py:2: error: Incompatible types in assignment (expression has type ""int"", variable has type ""bool"")  [assignment]
Found 1 error in 1 file (checked 1 source file)
```

basedpyright ([playground](https://basedpyright.com/?typeCheckingMode=all&code=IYAgvCAqBOCuCmBYAUKCoDUICMKg)):

```
No problems have been detected.
```

So basedpyright (same as legacy pyright) accept this, because doesn't limit `a` to `bool` after seeing `a = True`, but also considers `a = a + 1`, and therefore concludes that `a: int | bool` , or equivalently, `a: int`.
 || > At the very least it seems that there needs to be docs that point to `(based)pyright` etc. because there are issues with mypy?

This is just one of the many situations where the limitations or bugs of mypy make it frustrating to use static typing (in numpy, but also in general). 

So I think it's indeed a good idea to recommend using `r'(based)?pyright'` over mypy (but not only because of this particular issue, but also because of its >1200 confirmed bugs, >100 missing features, and the deviations from the official typing spec, see https://github.com/erictraut/mypy_issues). || I think the reassignment issue and mypy-vs-pytype discussion is a distraction here: even setting that aside, the comments here bring up cases where the NumPy 2.0 implementation leads to false positives. Adapting the first example from this issue (https://github.com/numpy/numpy/issues/27957#issue-2728410765), consider this:
```python
import numpy as np
from typing import TypeAlias

rng = np.random.default_rng(27446968)

FloatVector: TypeAlias = np.ndarray[tuple[int], np.dtype[np.floating]]

def f(x: FloatVector) -> FloatVector:
    M = np.random.rand(len(x), len(x))
    return M @ x

x = np.ones(4)
f(x)
```
This is correctly-annotated code: both the input and output are one-dimensional floating-point arrays. However both mypy and pyright incorrectly flag this as an error under NumPy 2.2:
```
$ mypy --version
mypy 1.13.0 (compiled: yes)

$ mypy script.py
script.py:10: error: Incompatible return value type (got ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", expected ""ndarray[tuple[int], dtype[floating[Any]]]"")  [return-value]
Found 1 error in 1 file (checked 1 source file)

$ pyright --version
pyright 1.1.391

$ pyright script.py
/content/script.py
  /content/script.py:10:12 - error: Type ""NDArray[floating[Any]]"" is not assignable to return type ""FloatVector""
    ""ndarray[_Shape, dtype[floating[Any]]]"" is not assignable to ""ndarray[tuple[int], dtype[floating[Any]]]""
      Type parameter ""_ShapeT_co@ndarray"" is covariant, but ""_Shape"" is not a subtype of ""tuple[int]""
        ""tuple[int, ...]"" is not assignable to ""tuple[int]""
          Tuple size mismatch; expected 1 but received indeterminate (reportReturnType)
1 error, 0 warnings, 0 informations 
```
The problem is that the API annotations don't propagate specific shape information in this case.

I don't doubt that there is demand for shape-specific and dtype-specific annotations. But when the propagation of those annotations through public APIs leads to these kinds of false positives, I think it's evidence that we're not actually providing what those people are asking for. || > This is correctly-annotated code: both the input and output are one-dimensional floating-point arrays. However both mypy and pyright incorrectly flag this as an error under NumPy 2.2:

It is correctly annotated iff. you assume that numpy perfectly supports shape-typing, which isn't the case at all: it's a work in progress. || > It is correctly annotated if you assume that numpy perfectly supports shape-typing, which isn't the case at all: it's a work in progress.

OK, thanks – then my view is that a work-in-progress should not be part of a NumPy release. NumPy is too important a package to release partially-implemented APIs. || > NumPy is too important a package to release partially-implemented APIs.

I agree. That's why shape-typing hasn't been mentioned in the release notes. || > That's why shape-typing hasn't been mentioned in the release notes.

If the new behavior were strictly opt-in, that would be fine. But the reports here show that even when people are not explicitly using shape annotations, the false positives appear and break their CI. This incomplete typing implementation is part of the release and is affecting downstream packages. || > > That's why shape-typing hasn't been mentioned in the release notes.
> 
> If the new behavior were strictly opt-in, that would be fine. But the reports here show that even when people are not explicitly using shape annotations, the false positives appear and break their CI. This incomplete typing implementation is part of the release and is affecting downstream packages.

Yes, and as one of those downstream package maintainers that uses mypy, I find that very frustrating as well. But as I've explained several times now, this is an *inevitable* consequence of the ongoing development of numpy's typing support, and is in the majority of examples a direct consequence of the limitations or bugs of mypy that result in reported false positives. Other type-checkers ike pyright don't report these false positives, which shows that these are indeed mypy related issues. 
The remaining reported numpy 2.2.0 typing issues have alreaady been fixed, or have a an open PR containing the fix.

> I think the reassignment issue and mypy-vs-pytype discussion is a distraction here

This very issue is limited to mypy, and works as expected on e.g. pyright. If you encounter other new typing issues, please open a new issue for them. I always take issues seriously, but in cases, there just aren't any good solutions that we can implement here. In this case, I'm afraid that the only way this could be avoided, is for mypy to implement something similar to pyright's global analysis. But knowing mypy, I don't think that is likely to happen.

I've suggested a one-liner workaround, and pointed to mypy alternatives that are objectively better. 

So I'm not saying this to ""distract"" you, because I'm not trying to hide anything:
I'm showing you the source of the problem, as well as several ways on how it can be avoided. || Does factoring out type annotations to a separate stubs package give us some flexibility in how we handle the shape typing?

If not, I think we either need a complete implementation released ASAP, or roll back the changes and push back to the next major release.

Also, I just want to make clear @jorenham that I really appreciate your effort, and that my comments here are in no way meant to ignore all the work you've put in. But I want your work to be well received and in its current form I'm worried that we're encouraging projects to rather move away from using numpy stubs.  || @jorenham has definitely done a significant effort to make this complicated typing all work, thanks so much.

With that, I second the idea of reverting the problematic typing changes for the upcoming 2.2.1 bug release. || > Does factoring out type annotations to a separate stubs package give us some flexibility in how we handle the shape typing?

Yea I think it would; I've actually been thinking about this as well, but mostly for different reasons. Some of those are the decoupling from the release cycle, so you could have a versioning scheme like `numpy-stubs==2.2.0.0`, so that you could release `2.2.0.1` whenever necessary. It'd also help alot for DX, as there'd be no need to compile anything, which would significantly speed up local testing and CI. That way it'll be a lot easier to introduce additional tooling, like `basedpyright`, `stubtest` and `flake8-pyi`. 

> If not, I think we either need a complete implementation released ASAP, or roll back the changes and push back to the next major release.

I'm all for a complete shape-typing implementation, and I would even work full-time on that, but I'm afraid that I won't be able to afford that (as I've used up almost all of my savings while working on `scipy-stubs` and `numpy` itself before that). 

But I think that rolling back the 2.2.0 typing changes would cause more issues than it would solve, as it also includes many fixes and fully-backwards compatible improvements. It would also mean that after the rollback, we won't be able to make *any* improvements anymore, unless we manage to do it *everywhere* in the same way, and manage to do so within the scope of a single release. And that might only be possible for someone working full-time on it, given that they have a similar level of experience as I have typing in python.
Because even if you change a single annotation, e.g. make `np.sum()` return a slightly more specific scalar- or array-type, then there's always a valid scenario that would now be reported by mypy (and only mypy) as a (false positive) error, specifically anything of the form

```py
x = np.sum(...)  # improved
x = used_to_return_the_same_type_as_sum(x)  # did not change
```

will afterwards be rejected by mypy. So it's impossible to avoid such false positives for mypy users (pyright users won't notice), if we want to be able to *gradually* improve NumPy's stubs (regardless of whether the stubs are bundled or externally packaged).

Alternatively we could say to our users something like 

""Mypy users might experiencce new typing errors after upgrading to numpy 2.x.x. In some cases, this is caused by limitations in mypy's type-inference capabilities. Errors like these won't be reported by more advanced type-checkers such as `basedpyright`, and will result in more accurately inferred types in general.""

> But I want your work to be well received and in its current form I'm worried that we're encouraging projects to rather move away from using numpy stubs.

I'd like to prevent that as well. And I think that the best way to do that is to make them aware that many of the typing issues that they're experiencing, are specific to mypy, and that there are alternative type-checkers (that are objectively better) that could also be considered.

And I can see how it could sound like I'm trying to blame mypy for issues that I have caused or something, and that it's very odd that mypy would indeed be as bad as I describe it to be, given its amount of users, and intrinsic connection to python itself. But I've written *a lot* of annotations now, and I wouldn't be surprised if more than half of the time I have spent doing that went into debugging issues that turned out to be mypy-specific, often a bug or a unsupported or ""partially-supported"" python typing feature. 

So for instance, mypy doesn't support `@property` setters, a `__new__` that returns something other than `Self` (e.g. `np.object_` or `builtins.reversed`), class decorators, just to name a few. But this isn't documented, and they even actively try to make it *look like* it's supported, often by turning types into `Any`, which makes it extremely difficult to debug, and will often lead to unexpected outcomes for the user. 
So it's no wonder that this leads to frustrated users and maintainers. No one in their right mind will search through those >1200 mypy bugs, so it's a lot easier to blame the maintainers of the typing stubs, or to walk away from python as a whole. || > This very issue is limit to mypy, and works as expected on e.g. pyright. If you encounter other new typing issues, please open a new issue for them.

The context of my comment is https://github.com/numpy/numpy/issues/27957#issuecomment-2555286484, which shows that this is *not* just a mypy issue. It seems strange to open a new issue for this, becuase it's essentially the same as the code snippet reported in the original comment here.

Maybe we need a new issue to discuss recommending mypy vs pyright instead? I think that's distracting from the main topic here. || > a new issue to discuss recommending mypy vs pyright

I was already going to do that in the 2.2.1 release notes. I don't know why anyone would want to stick with mypy. Is there really anything to discuss? || > The context of my comment is [#27957 (comment)](https://github.com/numpy/numpy/issues/27957#issuecomment-2555286484), which shows that this is _not_ just a mypy issue. It seems strange to open a new issue for this, becuase it's essentially the same as the code snippet reported in the original comment here.

But as I've explained, https://github.com/numpy/numpy/issues/27957#issuecomment-2555286484 is about shape-typing, which is isn't supported yet, and not what this issue is about. || Let me break things down as I see them:

- We need to use the best checking tool we can justify. That is basic if we consider typing important enough to 
pursue. Which brings up the question:

- How important is typing? I am not the person to judge this, I don't do much coding in anger these days and don't use an IDE. That said, it seems to be important to some users, and for some projects. That leads to:

- There is not a lot of typing expertise. Often when problems like this turn up in other parts of the code there will be a fix submitted along with the report, or the problem clearly isolated. That isn't the case with typing, I think few have a sufficiently deep understanding of it. An additional problem is that at the same time we are trying to improve NumPy's typing, the typing standard itself is under development.

How to proceed? I think for a start we should settle on a provisional choice of (based)pyright as the checker to work with. Supplemented with a few standard options, that will allow us to agree on what are actual typing problems and what are checker problems.

As for the problems themselves, we should put together a short list, with examples, of specific problems that need fixing, and that can be fixed. That will give us something to discuss. If in that process there are some problems identified that cannot be fixed in isolation, and cannot be lived with, perhaps the typing can be loosened with a note for future work. At this point we don't need to be perfect, but neither should we be overly noisy.

 || My impression of the types of issues is that there are 3:

1. Issues specific to Mypy,
2. Actual regressions that were fixed already,
3. @jakevdp's last example which starts using shape typing before it's ready.

Perhaps the disconnect on (3) is connected to this question and the answer that was given to it:

> I just want to make sure I understand: the recommended solution here is to proactively annotate all your array variables with a very permissive shape annotation, so that outputs of NumPy APIs which do not propagate strict shapes can be assigned to them without error. Is that accurate?

The answer here should be: no, just do not use shape typing at all unless it is documented. And since it wasn't usable before 2.2.0 either, there are no regressions here.

> OK, thanks – then my view is that a work-in-progress should not be part of a NumPy release. NumPy is too important a package to release partially-implemented APIs.

I agree with @jorenham that this isn't feasible. gh-26081 alone took 5 months to land. Shape typing is a very large effect, and it has to be done incrementally for practical reasons. We've done that for other large efforts as well, like the new dtype infra, array API support, and further back `__array_function__`. In runtime code we had the ability to mark those as experimental. With static typing that can't be done, but ""we don't document it until it's ready"" seems like a very reasonable answer. || > and I would even work full-time on that, but I'm afraid that I won't be able to afford that (as I've used up almost all of my savings while working on `scipy-stubs` and `numpy` itself before that).

That seems like a potentially solvable problem. Thank you for making such a large personal investment in this topic to date. When we had no or much less $$ resources in the past, multiple other people have made such large investments. I'm optimistic that at this point we (NumPy, SciPy, and the wider community including a number of companies) now have resources to support the most active maintainers. I'll reach out to you to chat about this. || > The answer here should be: no, just do not use shape typing at all unless it is documented.

This is the important thing to spell out more clearly, and we should also spell out the two caveats that I think exist?  Or maybe they don't?
1. `mypy` users may not be able to avoid this (and other bugs) due to redefinition rules.  We, unfortunately, have to tell users to stop using `mypy` if they don't want to work around that.
2. The ""just avoid it"" part works but I think(?) it omits a point that:
   ```
   a: np.ndarray[tuple[int], np.dtype[np.float64]] = np.zeros((10, 10))
   ```
   (yes, this is silly since incorrect) used to succeed with mypy.
   
   That is, users who already added shapes diligently thinking it may be useful in the future, now have to remove them, I believe?
   It isn't quite clear if this is a real problem or not (i.e. any such type is known to be weird or almost nobody should be doing it).
   The other question I have (maybe moot?):  Would it be remotely possible to have `np.ndarray[Shape, dtype]` ignore the shape and set it to `Any` while a new `shaped_ndarray[]` enforces it (as well as possible) and is used internally for all returns?!

I am not very invested in this issue, but seems both of these may be acceptable, although we should amend the release notes with such guidance. || I've put up draft 2.2.1 release notes at #28047. Feel free to suggest changes or additions. || In https://github.com/numpy/numpy/issues/28054 I've proposed a way that could help us avoid, or at least anticipate, situations like these in the future || Hello! I help maintain mypy and several other projects in the Python typing ecosystem. Static type checking in Python is far from perfect, which is why I've volunteered a lot of my time to these projects.

There's a lot going on in this issue. As far as I can tell, the concrete issues here are:
- [comment 1](https://github.com/numpy/numpy/issues/27957#issuecomment-2530184016) jorenham 's numpy PR uses `tuple[int]` instead of `tuple[int, ...]`. The first annotation means a tuple containing exactly one int, the second means a tuple of unknown length containing ints. These are two very different types (but yes, this is e.g. a relatively common confusion for folks new to typing).
- [comment 2](https://github.com/numpy/numpy/issues/27957#issuecomment-2538543325) Discussion about whether mypy should default to `--allow-redefinition` (and some closely related behaviour)

mypy sees several orders of magnitude more usage than basedpyright. So it seems less than ideal for users of both mypy and numpy to run into issues.

Maybe folks could post concrete issues in https://github.com/python/mypy/issues/18343 ? Like many open source projects, mypy is entirely driven by volunteer effort, but at least this way folks can track what needs to be done, what configuration needs to be used, or identify cases where the meaning of type annotations is underspecified.

Regarding charris' comment about expertise in typing. If you post at https://github.com/python/typing/discussions or https://discuss.python.org/c/typing/32 you're likely to attract more eyeballs from folks who can bend typing to their will.

Another thing that could be good is type checking downstream projects that depend on numpy in numpy's CI. [I set up downstream regression checks](https://github.com/hauntsaninja/mypy_primer) for mypy, pyright, typeshed, basedpyright, etc and it's proven quite useful at avoiding regrettable regressions.

Also real quick — I'd also like to contend with KotlinIsland's description of themselves as [""closely involved"" with mypy](https://github.com/numpy/numpy/issues/27957#issuecomment-2547452942). Their primary involvement is maintaining a mypy fork, with [very few substantive upstream changes](https://github.com/python/mypy/pulls?q=is%3Amerged+is%3Apr+author%3Akotlinisland). Projects should of course stand on their merits — I just want to provide some context for the claims to authority in that comment.
(edit: apologies if this paragraph came across as dismissive. It's no easy feat to maintain a fork of mypy; it takes dedication and expertise and I should have been more explicit about that. Hopefully https://github.com/numpy/numpy/issues/27957#issuecomment-2563382985 better describes what I was trying to clarify) || > * jorenham 's numpy PR uses `tuple[int]` instead of `tuple[int, ...]`. The first annotation means a tuple containing exactly one int, the second means a tuple of unknown length containing ints. These are two very different types (but yes, this is e.g. a relatively common confusion for folks new to typing).

In #27767 I intentionally use `tuple[int]` to annotate a 1-dimensional array. Also, that PR, and shape-typing in general, is not what this issue is about.

---

> * Discussion about whether mypy should default to `--allow-redefinition` (and some closely related behaviour)

That's unrelated to this issue, and enabling `--allow-redefinition` does not result in different outcomes, see https://github.com/numpy/numpy/issues/27957#issuecomment-2547042651.

---

> mypy sees several orders of magnitude more usage than basedpyright

The results from a recent survey (https://discuss.python.org/t/python-typing-survey-results/71821) with 1677 participants showed that ~60% used mypy, and ~34% used pyright. 
To me, that looks like it's the same order of magnitude.

---
> Another thing that could be good is type checking downstream projects that depend on numpy in numpy's CI

See https://github.com/numpy/numpy/issues/28054 || > Also real quick — I'd also like to contend with KotlinIsland's description of themselves as [""closely involved"" with mypy](https://github.com/numpy/numpy/issues/27957#issuecomment-2547452942). Their primary involvement is maintaining a mypy fork, with [very few substantive upstream changes](https://github.com/python/mypy/pulls?q=is%3Amerged+is%3Apr+author%3Akotlinisland).

I count 21 merged PR's, 6 open PR's, 151 open issues, and 117 closed issues. Describing that as ""very few substantive upstream changes"" is not only disrespectful to @KotlinIsland, but to everyone that has invested a similar amount of their time into trying to improve mypy.

It should also be noted that the majority of @KotlinIsland's involvement with the mypy codebase is through the work he's done for [`basedmypy`](https://github.com/KotlinIsland/basedmypy). A quick glance at the readme should already make that obvious. || Wait, what is happening. If anything here is disrespectful to mypy contributors, it's statements like:

>  as someone that has been closely involved with mypy for many years, my only recommendation is that it should be avoided at all costs. the project is extremely poorly managed and poorly written, and that leads to the issues that everyone that uses it experiences.
ideally it will be deprecated and a new type checker will be pushed forward as the standard. mypy is beyond fixing 

My intention with briefly mentioning that KotlinIsland's primary involvement with mypy was their fork and linking to their upstream PRs was to make it clear that statements like ^ aren't the opinion of people who actually maintain upstream mypy.

(You're of course welcome to your opinion — like I said above, projects should stand on their merits. Just worth clarifying the source of that opinion's involvement with upstream, so people don't think it's the equivalent of say, rgommers saying that numpy is ""beyond fixing"". I wouldn't have said anything if they led with ""As someone who forked mypy / As a long time user of mypy / As someone who has contributed several CI improvements to mypy"" instead)

Someone shared this link with me, so I came here to see if there was something I could do to help. For worse or for better, mypy has 7x monthly downloads of pyright and 230x basedpyright on PyPI, so it would be good for the community if things just worked. Feel free to post in https://github.com/python/mypy/issues/18343 if there's something I could help with in my volunteer time. Unsubscribing from this issue. || I found this issue when running into the following problem and chatted with hauntsaninja about it:

```python
import numpy
from numpy.typing import NDArray

def f() -> NDArray[numpy.float64]:
    return numpy.zeros(2, dtype=numpy.float64) + numpy.float64(1.0)  # error: Incompatible return value type (got ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", expected ""ndarray[tuple[int, ...], dtype[float64]]"")  [return-value]
```

First, a general remark.  Statements like this

> So for instance, mypy doesn't support @property setters, ... But this isn't documented, and they even actively try to make it look like it's supported...

are not only wrong but insulting.  Wrong, because Mypy has supported property setters for ages.  It only does not support different getter and setter types (I guess this is what jorenham refers to).  Insulting (and also wrong), because it suggests that people who contributed to Mypy are trying to mislead the Python community.  In the case of different setter types, there was a change in the perception of the desired behaviour.  This change is now tricky to implement because Mypy's property support is not consistently programmed with its descriptor support for historical reasons.  I do not want to go into more details, but I want to clarify there is no *active* deception but only limited time.  And usually, one (or at least me) finds fixing problems in their free time more attractive than documenting them.

But now to the actual topic.  In my (and, I think, also hauntsaninja's) perception, this issue is about incomplete transitions in shape typing (`tuple[int]` vs `tuple[int, ...]`) and inheritance (e.g. `floating` vs `float64`) in Numpy and that Mypy reports the resulting inconsistencies more frequently than other type checkers, primarily because of `--allow-redefinition` is not enabled by default.  However, jorenham says in his second least comment that neither of these is the topic of this issue.  Could you please clarify what [defect](https://github.com/numpy/numpy/blob/feb3091b1135217ebcba9c01a1b939aa937038ce/doc/source/release/2.2.1-notes.rst?plain=1#L10-L15) you mean, then?

The only other hint pointing to another concrete topic I could find is this one:

> This is because mypy (unlike pyright) can't understand `tuple[int, int, Unpack[tuple[int, ...]]`, or in words, ""a shape type that is at least 1-dimensional"".

But, again, I have the feeling you might have encountered a bug but are overgeneralising.  Mypy supports `Unpack`:

```python
from typing import Unpack

x: tuple[int, int, Unpack[tuple[int, ...]]]

x = (1,)  #  error: Incompatible types in assignment (expression has type ""tuple[int]"", variable has type ""tuple[int, int, *tuple[int, ...]]"")  [assignment]
x = (1, 2, 3, 4)
reveal_type(x)  # note: Revealed type is ""tuple[builtins.int, builtins.int, builtins.int, builtins.int]""
```

I work with Numpy and Mypy (and sometimes try to improve the latter a little), so I want them to work well together.  I hope for a constructive discussion. || > I found this issue when running into the following problem and chatted with hauntsaninja about it:
> 
> ```python
> import numpy
> from numpy.typing import NDArray
> 
> def f() -> NDArray[numpy.float64]:
>     return numpy.zeros(2, dtype=numpy.float64) + numpy.float64(1.0)  # error: Incompatible return value type (got ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", expected ""ndarray[tuple[int, ...], dtype[float64]]"")  [return-value]
> ```

I can reproduce this on both pyright and mypy, and this indeed used to be accepted on `numpy==2.1.3`. So could you open a new issue for this? 

---

> Wrong, because Mypy has supported property setters for ages. It only does not support different getter and setter types (I guess this is what jorenham refers to).

When I say that mypy doesn't support something, I mean that within the context of typing, because that's what we're talking about here, and that's what mypy is meant to check.
So for mypy to support something, it should do what is expected of it, and prevent type-unsafe situations like these:

```py
class A:
    @property
    def thing(self) -> str:
        return ""thing""
    @thing.setter
    def thing(self, thing: int, /) -> None:
        assert isinstance(thing, int)

a = A()
a.thing = ""unsafe""  # mypy allows this
```

https://mypy-play.net/?mypy=latest&python=3.12&gist=c74a929091e366135306081ea0965098

Mypy explicitly allows this type-unsafe behaviour, but rejects e.g. `a.thing = 3.14`. And it also allows defining the `thing` setter with a different type, even though it is known to be unsupported. So this is why the only conclusion I can draw, is that mypy actively hides the fact that is doesn't (fully) support property setters. 

---

> because it suggests that people who contributed to Mypy are trying to mislead the Python community

I never mentioned individuals or a group of contributors. I'm purely talking about the software itself. So I don't see why you think that I suggesting this. 

I thought it would go without saying, but I applaud anyone who contributes to open source, and actively try to motivate people to do so. Mypy is of course no exception to it. 
All I'm trying to say is that, there are currently better alternatives to mypy. 
And of course doesn't mean that I think that there's some conspiracy going on or something 🤷🏻‍♂️.

---

> this issue is about incomplete transitions in shape typing (`tuple[int]` vs `tuple[int, ...]`)

No. I've explained this several times now. This issue isn't about shape-typing. And shape-typing isn't yet supported in numpy, so you shouldn't expect it to work.

---

> ... and inheritance (e.g. `floating` vs `float64`) in Numpy

This issue isn't about inheritance. It's about how `a = f(); a = g()` was accepted in mypy when `f: () -> int` and `g: () -> int`, but isn't anymore now that we've narrowed `f` to `() -> bool`, while keeping `g` the same. This is the same situations as when you'd do `a = True; a = 1`, which also gets rejected by mypy, and only mypy.

---

> Mypy reports the resulting inconsistencies more frequently than other type checkers, primarily because of `--allow-redefinition` is not enabled by default

So that's why `--allow-redefinition` has nothing do do with this.

---

> The only other hint pointing to another concrete topic I could find is this one:
> 
> > This is because mypy (unlike pyright) can't understand `tuple[int, int, Unpack[tuple[int, ...]]`, or in words, ""a shape type that is at least 1-dimensional"".

I just checked this again with the latest mypy, and it seems to work now. So it appears my knowledge was outdated, and it's supported now 👌🏻. || > I can reproduce this on both pyright and mypy, and this indeed used to be accepted on `numpy==2.1.3`. So could you open a new issue for this?

Yes, gladly,


> So this is why the only conclusion I can draw, is that mypy actively hides the fact that is doesn't (fully) support property setters.

`property` is very special and requires a lot of special casing.  Even Pyright, which, as far as I know, has better support for `property`, does not try to catch everything.  For example, neither Mypy nor Pyright will warn you about this obvious bug:

```python
from __future__ import annotations

def get(self: C) -> int:
    return 1

class C:
    g = property(get)

y = C().g + ""x""
```

There was a general attempt to improve the situation for all type checker maintainers and Python users (by turning `property` into a descriptor), but that led to nothing (so far) and was even rejected by the Pyright team because of the anticipated work (which I find unfortunate but it's understandable, of course).

As hauntsaninja mentioned, *Static type checking in Python is far from perfect* and things are complicated, so oversimplified ""by the way accusations"" are usually not helpful.

But coming back to the main point of this issue (which you seem to have the authority to decide).  From the perspective of all numpy users: What would be Mypy's preferred behaviour?  I still guess they would want `--allow-redefinition` enabled by default.  I do not know if the limitations of this option are for a good reason or just because the implementation is incomplete (but I could investigate).  Also, my preliminary impression is that there should be a way to handle explicitly typed code differently:

```python
x = True
x = 1  # maybe okay

y: bool = True
y = 1  # maybe not okay
```

What do you think? || > There was a general attempt to improve the situation for all type checker maintainers and Python users (by turning `property` into a descriptor), but that led to nothing (so far) and was even rejected by the Pyright team because of the anticipated work (which I find unfortunate but it's understandable, of course).

Yes, I agree that this would be the best way. IMO special casing should only be used in, well, special cases. But `@property` being nothing but a descriptor, so it's not special (sorry `@property`; but we still love you regardless).

---

> As hauntsaninja mentioned, _Static type checking in Python is far from perfect_ and things are complicated, so oversimplified ""by the way accusations"" are usually not helpful.

I completely agree that static type checking is very difficult, especially in a gradual type system like the one Python uses. 
That's why it matters so much that we use, and recommend, the best tool to help us with this. And the way to do this, is to lay out the pros and cons of the available tools. 

And it's no secret that mypy has a lot more issues than pyright has. See https://github.com/erictraut/mypy_issues for example, for a thorough analysis of this. So what 

So the way I see it, is that I'm not saying something new, and not accusing anyone of anything. 
I'm just trying to help the numpy developers and users choose the type-checker that's best suited for the job. 

Admittedly, I have my frustrations in dealing with mypy for five years or so, and we've seen here that I'm not the only one. But by no means did I intend to insult anyone; my frustrations are with the tool itself, and I having nothing but respect for those that try to make it better.

> But coming back to the main point of this issue (which you seem to have the authority to decide). From the perspective of all numpy users: What would be Mypy's preferred behaviour? I still guess they would want `--allow-redefinition` enabled by default. I do not know if the limitations of this option are for a good reason or just because the implementation is incomplete (but I could investigate). Also, my preliminary impression is that there should be a way to handle explicitly typed code differently:
> 
> ```python
> x = True
> x = 1  # maybe okay
> 
> y: bool = True
> y = 1  # maybe not okay
> ```
> 
> What do you think?

I agree that this would be the preferred behaviour in this case. 

The `x` type should be determined by looking at how it's used globally. But as far as I can tell, mypy currently decides on the type after looking at `x = True`, but doesn't consider the following `x = 1` after that for this.

The `y: bool` declaration is explicit, so there's no for the type-checker to infer `y`. That indeed makes it invalid to `y = 1`, since `1` isn't assignable to `bool`, just like `isinstance(1, bool) is False`.

Coincidentally, pyright already supports this: It accepts `x = 1`, and only rejects `y = 1`:

```
Type ""Literal[1]"" is not assignable to declared type ""bool""
  ""Literal[1]"" is not assignable to ""bool""  (reportAssignmentType)
```

https://basedpyright.com/?typeCheckingMode=all&code=B4AgvCAqBOCuCmBYAUKCBGEIDEIC2AhgJ4BG8IA9gNbEopEBcIJFFANuFHEskZ5jnzEyIAHYUALpRpEgA



 || > But coming back to the main point of this issue (which you seem to have the authority to decide)

That's not really the way things work here. I'm just ""the typing guy"", and most of what I do in open source is related to static typing in Python. And just like any other NumPy maintainer, I try to do what's best for numpy and its users. In the end, we all decide together. || with `allow-redefinition` mypy will allow any assignments, as long as the old value has been used at least once:
```py
a: bool = True
a = 1 # error

# but
b: bool = True
b = int(b)  # no error
```

where as pyright will never allow any redefinitions:
```py
a: bool = True  # error: declaration is obscured
a: int = 1
```

pyright will allow a variable without an annotation to have assignments that can change the type, as it's not considered:
```py
a = 1
a = """"  # no error
```

the minuta of the issues that mypy has with this can be demonstrated:
```py
a: str = ""a""
print(a)  # use `a` to allow mypy redefinition
a: int
reveal_type(a)  # mypy: int, runtime: ""a""
```

also, mypy doesn't support reassignments across branching logic:
```py
a = True
if bool():
    a = 1  # mypy: error expected bool
else:
    a = ""a""  # mypy: error expected bool
reveal_type(a)  # mypy: bool, pyright: Literal[1, ""a""]
```

additionally, I never intended to mislead anyone into thinking I was a mypy collaborator/maintainer. I didn't state as much but I can understand that it could be interpreted that way. I have spent many years developing (based)mypy every day, so I would consider my experience quite a bit more than ""has contributed several ci improvements""

additionally-additionally, when I said ""mypy is beyond saving"", I wasn't trying to personally insult anyone, what I meant was that the issues in mypy are so deep in the implementation that it would require rewriting it to resolve them

I have great respect for open source, Python, mypy and all of its collaborators and contributors. I detest the vitriolic, spiteful and downright nasty not niceness of certain maintainers that exist in this world, so I'm sorry if anything I said was taken personally || Thanks for the clarifying words.  I am very happy we left the stumblers behind us and seem to have started a closer collaboration.  Numpy and Mypy working well together would be fantastic, and I look forward to Numpy providing shape-typing support for arrays.  It's great that you are working on this!

> the minuta of the issues that mypy has with this can be demonstrated:
> 
> ```python
> a: bool = True
> print(a)  # use `a` to allow mypy redefinition
> a: int
> reveal_type(a)  # mypy: int, pyright: Literal[True]
> ```

I screened through the above comments again and have the impression that users are most bothered that Mypy reports not-so-relevant (from the user perspective) array inconsistencies for unannotated assignments.  We internally discussed ways to make Mypy less strict for such cases, even when different scopes are involved.  I am (cautiously) optimistic we can make some progress on this soon.

Regarding the given example, I don't see how it relates to this issue.  Could you please give an example? (Personally, I like narrowing but don't like and never use `allow-redefinition`, so I have never really thought it through.)
 || To reiterate what @jakevdp said, and what I agree with: ""un-annotated user code that executes correctly should not error when type-checked"". I care about that case in the context of teaching, and the Scientific Python lecture notes.  || @stefanv was avoiding `mypy` a viable solution here for you or not?  I am not sure if Scientific Python lectures is a typical use-case or not.
But if it isn't a very common use-case and/or `pyright` (or another work around yet to be discovered!) is feasible than that would be good to know.

EDIT: I suppose this PR answers the question: https://github.com/scipy-lectures/scientific-python-lectures/pull/813 (mostly works, but some other issues remaining). || > [scipy-lectures/scientific-python-lectures#813](https://github.com/scipy-lectures/scientific-python-lectures/pull/813) (mostly works, but some other issues remaining).

Anything I can help with? || > @stefanv was avoiding `mypy` a viable solution here for you or not? I am not sure if Scientific Python lectures is a typical use-case or not.
> But if it isn't a very common use-case and/or `pyright` (or another work around yet to be discovered!) is feasible than that would be good to know.

Concerning mypy vs pyright I have had similar experience to @jorenham while adding type annotations in SymPy. There are many situations where I can add what seem like the right annotations and everything works with pyright but then I run mypy and it doesn't work and I need to go change the code or the annotations in awkward ways to satisfy mypy.

I think it is worth remembering though that there are different consumers of the type checkers and that these different type checkers are typically used by different people. Downstream of NumPy there are lots of libraries that will for the most part use mypy if they do use a type checker. In this role mypy is a command line development tool that is used somewhat like a linter so the kind of people using it are also the kind of people who might run ruff or flake8 etc on their libraries in CI.

On the other hand there are many ""end users"" who use NumPy directly but probably do not run any type checker explicitly and certainly would not use mypy. However pyright is a popular editor plugin and is e.g. part of the default Python plugin for vscode. The kind of person who is doing a typical end user calculation with NumPy probably does not add type hints to their code but will often benefit from things like autocompletion provided by pyright based on the type annotations/stubs that are provided by NumPy.

I think that the typical person reading @stefanv's lecture notes does not run mypy. At most they have pyright running in their editor. If thinking about the ""end user"" experience it is more important to focus on pyright being able to infer the types correctly for users of NumPy's main public API. Importantly you want those users to have no type hints in their own code but for pyright to be able to infer the types of all the numpy objects. Then users can do things like hover their mouse over `x` and see something like `ndarray` or type `x.` and see suggestions for possible array methods and so on. These features are actually very useful in an editor and now that I have pyright running in my editor (vim) I use these a lot and would recommend others to try them out.

For downstream libraries that use type checkers it will be problematic as NumPy adds annotations because it will be a long process during which the annotations are incomplete and continuously changing. Whenever new annotations or stubs are added it will ""break"" some downstream library's type checking. In some cases that might be a genuine regression and it would be reasonable for NumPy to change/revert the annotations. Otherwise though downstream libraries will just need to adapt and fix their own type annotations. There isn't any way to do the ""gradual typing"" thing without going through a long process of churn so either NumPy gives up on typing altogether or this downstream library typing churn has to be accepted.

There will be many downstream libraries who are using mypy in combination with the NumPy stubs regardless of whether NumPy ""blesses"" any other type checker. If, like in the OP issue, someone has problems that are specific to mypy then I think it is perfectly reasonable for NumPy to point out that the problem is specific to mypy and that mypy has configuration options and also that they can use a different checker if they want.

The problematic behaviour that mypy is showing here is just that mypy disallows rebinding the type like this:
```
data = '123'
data = int(data) # mypy errors but fine with pyright
```
Personally I don't want to use a checker that behaves like that and I much prefer pyright's handling of this case.

If someone else is happy with this style of type checking then they can feel free to use mypy but as NumPy (and other libraries) add more annotations it is going to break their mypy CI jobs. This is unavoidable since fewer things will be inferred as `Any` and mypy will inevitably consider more assignments to be incompatible. There is a simple fix to make mypy happy:
```
data = '123'
data_int = int(data)
```
Or they can configure mypy or they can use a different checker.

If NumPy wants to use a type checker on its own *internal* code then it can choose whichever one it wants. If pyright seems best then just use pyright. It doesn't matter what anyone else thinks or what checker they use. I haven't used basedpyright but having a lot of experience of mypy and pyright I would recommend pyright over mypy.",closed,2024-12-09T22:21:59+00:00,2025-01-06T22:52:32+00:00,stefanv,"00 - Bug, 41 - Static typing",2,"PR#28112 - environment.yml: @@ -25,7 +25,7 @@ dependencies:|;|   - hypothesis|;|   # For type annotations|;|   - typing_extensions>=4.2.0  # needed for python < 3.10|;|-  - mypy=1.13.0|;|+  - mypy=1.14.1|;|   - orjson  # makes mypy faster|;|   # For building docs|;|   - sphinx>=4.5.0 || PR#28112 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2617,111 +2623,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2731,20 +2818,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2754,20 +2855,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2777,22 +2892,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2801,156 +2930,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28112 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28112 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -87,17 +88,16 @@ def __array_function__(|;| )|;| |;| if sys.version_info >= (3, 12):|;|-    from collections.abc import Buffer|;|-|;|-    ArrayLike: TypeAlias = Buffer | _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    from collections.abc import Buffer as _Buffer|;| else:|;|-    ArrayLike: TypeAlias = _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    @runtime_checkable|;|+    class _Buffer(Protocol):|;|+        def __buffer__(self, flags: int, /) -> memoryview: ...|;|+|;|+ArrayLike: TypeAlias = _Buffer | _DualArrayLike[|;|+    dtype[Any],|;|+    bool | int | float | complex | str | bytes,|;|+]|;| |;| # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`|;| # given the casting rules `same_kind`|;|@@ -165,6 +165,11 @@ def __array_function__(|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28112 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28112 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28112 - numpy/typing/tests/data/reveal/index_tricks.pyi: @@ -58,13 +58,13 @@ assert_type(np.mgrid[1:1:2, None:10], npt.NDArray[Any])|;| assert_type(np.ogrid[1:1:2], tuple[npt.NDArray[Any], ...])|;| assert_type(np.ogrid[1:1:2, None:10], tuple[npt.NDArray[Any], ...])|;| |;|-assert_type(np.index_exp[0:1], tuple[slice])|;|-assert_type(np.index_exp[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.index_exp[0:1], tuple[slice[int, int, None]])|;|+assert_type(np.index_exp[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;|-assert_type(np.s_[0:1], slice)|;|-assert_type(np.s_[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.s_[0:1], slice[int, int, None])|;|+assert_type(np.s_[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;| assert_type(np.ix_(AR_LIKE_b), tuple[npt.NDArray[np.bool], ...])|;| assert_type(np.ix_(AR_LIKE_i, AR_LIKE_f), tuple[npt.NDArray[np.float64], ...]) || PR#28112 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28112 - requirements/test_requirements.txt: @@ -14,7 +14,7 @@ cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:|;| # - Mypy relies on C API features not present in PyPy|;| # NOTE: Keep mypy in sync with environment.yml|;|-mypy==1.13.0; platform_python_implementation != ""PyPy""|;|+mypy==1.14.1; platform_python_implementation != ""PyPy""|;| typing_extensions>=4.2.0|;| # for optional f2py encoding detection|;| charset-normalizer || PR#28108 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2613,111 +2619,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2727,20 +2814,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2750,20 +2851,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2773,22 +2888,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2797,156 +2926,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28108 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28108 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -164,6 +165,11 @@ def __buffer__(self, flags: int, /) -> memoryview: ...|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28108 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28108 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28108 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])","TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128`` || MAINT: bump ``mypy`` to ``1.14.1`` (#28089)

* MAINT: bump `mypy` to `1.14.1`

* TYP: fix new `mypy==1.14.1` type-test errors

* TYP: backport `collections.abc.Buffer` for `npt.ArrayLike` on `python<3.11` || TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128``"
numpy/numpy,jorenham,27965,TYP: Suboptimally annotated arithmetic operator types,"### Describe the issue:

Arithmetic operators like division do not take shape typing into account, resulting in false-positive type hinting issues.

Originally reported here: https://github.com/numpy/numpy/issues/27957#issuecomment-2530265613
Some debugging work done by @jorenham at here: https://github.com/numpy/numpy/issues/27957#issuecomment-2531559754
Opening a separate bug report as requested

### Reproduce the code example:

```python
import numpy as np

x = np.zeros(1)
x = x / 1
```


### Error message:

```shell
test.py:4: error: Incompatible types in assignment (expression has type ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", variable has type ""ndarray[tuple[int], dtype[float64]]"")  [assignment]
```


### Python and NumPy Versions:

2.2.0
3.13.0 (main, Nov 21 2024, 10:46:46) [Clang 16.0.0 (clang-1600.0.26.4)]

### Type-checker version and settings:

mypy 1.11.2 (compiled: no)
mypy --strict

### Additional typing packages.

_No response_","this example shows why type-checkers reject the `x = x / 1` from your example""

```pyi
# issue_27965.pyi

import numpy as np

reveal_type(x := np.zeros(1))
reveal_type(x / 1)
```

relevant mypy output:

```
[...]/issue_27965.pyi:3: note: Revealed type is ""numpy.ndarray[tuple[builtins.int], numpy.dtype[numpy.float64]]""
[...]/issue_27965.pyi:4: note: Revealed type is ""numpy.ndarray[builtins.tuple[builtins.int, ...], numpy.dtype[numpy.floating[Any]]]""
```

relevant pyright output:

```
[...]/issue_27965.pyi:3:13 - information: Type of ""x := np.zeros(1)"" is ""ndarray[tuple[int], dtype[float64]]""
[...]/issue_27965.pyi:4:13 - information: Type of ""x / 1"" is ""ndarray[tuple[int, ...], dtype[floating[Any]]]""
```

The `np.zeros(1)` is inferred by both mypy and pyright as a *`ndarray` with 1-d shape and a dtype of `float64`*. This is correct in the most accurate way that's (reasonably) possible.

But `np.zeros(1) / 1` isn't as precisely typed, and is inferred as *`ndarray` with ?-d shape and a dtype of `floating`*. 

Now the problem emerges when we do `x = x / 1`, which means we're assigning `ndarray[tuple[int, ...], floating]` to `ndarray[(int), float64]`. But this is invalid, because

1. `tuple[int, ...]` isn't assignable to `tuple[int]`
2. `floating` isn't assignable to `float64` ()

This is because we can't assign something *less specific* to something *more specific*, just like you can't assign `int` to a `bool`. 

But if we flip the LHS and RHS, then it actually is allowed. So in the same way that `bool` is assignable to `int`, `tuple[int]` is assignable to `tuple[int, ...]` and `float64` is assignable to `floating`.

We can use this to create a very clean workaround to this issue:

```pyi
import numpy as np
import numpy.typing as npt

x: npt.NDArray[np.floating]  # ndarray[tuple[int, ...], dtype[floating]]
x = np.zeros(1)  # accepted
x = x / 1  # accepted
```

---

Note that this workaround is only required for mypy users: Pyright infers the type of `x` as `ndarray[tuple[int, ...], dtype[floating]]`, because it looks at more than one line of code at a time, and isn't ""greedy"" (algorithmically speaking) like mypy is.",closed,2024-12-10T18:57:06+00:00,2025-01-06T22:52:32+00:00,adamjstewart,41 - Static typing,2,"PR#28112 - environment.yml: @@ -25,7 +25,7 @@ dependencies:|;|   - hypothesis|;|   # For type annotations|;|   - typing_extensions>=4.2.0  # needed for python < 3.10|;|-  - mypy=1.13.0|;|+  - mypy=1.14.1|;|   - orjson  # makes mypy faster|;|   # For building docs|;|   - sphinx>=4.5.0 || PR#28112 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2617,111 +2623,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2731,20 +2818,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2754,20 +2855,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2777,22 +2892,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2801,156 +2930,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28112 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28112 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -87,17 +88,16 @@ def __array_function__(|;| )|;| |;| if sys.version_info >= (3, 12):|;|-    from collections.abc import Buffer|;|-|;|-    ArrayLike: TypeAlias = Buffer | _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    from collections.abc import Buffer as _Buffer|;| else:|;|-    ArrayLike: TypeAlias = _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    @runtime_checkable|;|+    class _Buffer(Protocol):|;|+        def __buffer__(self, flags: int, /) -> memoryview: ...|;|+|;|+ArrayLike: TypeAlias = _Buffer | _DualArrayLike[|;|+    dtype[Any],|;|+    bool | int | float | complex | str | bytes,|;|+]|;| |;| # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`|;| # given the casting rules `same_kind`|;|@@ -165,6 +165,11 @@ def __array_function__(|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28112 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28112 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28112 - numpy/typing/tests/data/reveal/index_tricks.pyi: @@ -58,13 +58,13 @@ assert_type(np.mgrid[1:1:2, None:10], npt.NDArray[Any])|;| assert_type(np.ogrid[1:1:2], tuple[npt.NDArray[Any], ...])|;| assert_type(np.ogrid[1:1:2, None:10], tuple[npt.NDArray[Any], ...])|;| |;|-assert_type(np.index_exp[0:1], tuple[slice])|;|-assert_type(np.index_exp[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.index_exp[0:1], tuple[slice[int, int, None]])|;|+assert_type(np.index_exp[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;|-assert_type(np.s_[0:1], slice)|;|-assert_type(np.s_[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.s_[0:1], slice[int, int, None])|;|+assert_type(np.s_[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;| assert_type(np.ix_(AR_LIKE_b), tuple[npt.NDArray[np.bool], ...])|;| assert_type(np.ix_(AR_LIKE_i, AR_LIKE_f), tuple[npt.NDArray[np.float64], ...]) || PR#28112 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28112 - requirements/test_requirements.txt: @@ -14,7 +14,7 @@ cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:|;| # - Mypy relies on C API features not present in PyPy|;| # NOTE: Keep mypy in sync with environment.yml|;|-mypy==1.13.0; platform_python_implementation != ""PyPy""|;|+mypy==1.14.1; platform_python_implementation != ""PyPy""|;| typing_extensions>=4.2.0|;| # for optional f2py encoding detection|;| charset-normalizer || PR#28108 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2613,111 +2619,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2727,20 +2814,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2750,20 +2851,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2773,22 +2888,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2797,156 +2926,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28108 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28108 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -164,6 +165,11 @@ def __buffer__(self, flags: int, /) -> memoryview: ...|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28108 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28108 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28108 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])","TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128`` || MAINT: bump ``mypy`` to ``1.14.1`` (#28089)

* MAINT: bump `mypy` to `1.14.1`

* TYP: fix new `mypy==1.14.1` type-test errors

* TYP: backport `collections.abc.Buffer` for `npt.ArrayLike` on `python<3.11` || TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128``"
numpy/numpy,jorenham,28071,TYP: inconsistent static typing of `float64` addition,"### Describe the issue:

This is a regression due to changes in Numpy 2.2.  The bug is correctly identified both by Mypy and Pyright.  The given error message is from Mypy.  I initially mentioned this problem in #27957 and was asked by @jorenham to report it separately.  See #27957 for more information.

### Reproduce the code example:

```python
import numpy
from numpy.typing import NDArray

def f() -> NDArray[numpy.float64]:
    return numpy.zeros(2, dtype=numpy.float64) + numpy.float64(1.0)
```


### Error message:

```shell
Incompatible return value type (got ""ndarray[tuple[int, ...], dtype[floating[Any]]]"", expected ""ndarray[tuple[int, ...], dtype[float64]]"")
```


### Python and NumPy Versions:

Python 3.13.1
Numpy 2.2.1

### Runtime Environment:

_No response_

### Context for the issue:

In one of our projects, this regression results in 30 (unhelpful) error messages.",,closed,2024-12-27T23:15:40+00:00,2025-01-06T22:52:33+00:00,tyralla,"00 - Bug, 41 - Static typing",2,"PR#28112 - environment.yml: @@ -25,7 +25,7 @@ dependencies:|;|   - hypothesis|;|   # For type annotations|;|   - typing_extensions>=4.2.0  # needed for python < 3.10|;|-  - mypy=1.13.0|;|+  - mypy=1.14.1|;|   - orjson  # makes mypy faster|;|   # For building docs|;|   - sphinx>=4.5.0 || PR#28112 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2617,111 +2623,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2731,20 +2818,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2754,20 +2855,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2777,22 +2892,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2801,156 +2930,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28112 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28112 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -87,17 +88,16 @@ def __array_function__(|;| )|;| |;| if sys.version_info >= (3, 12):|;|-    from collections.abc import Buffer|;|-|;|-    ArrayLike: TypeAlias = Buffer | _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    from collections.abc import Buffer as _Buffer|;| else:|;|-    ArrayLike: TypeAlias = _DualArrayLike[|;|-        dtype[Any],|;|-        bool | int | float | complex | str | bytes,|;|-    ]|;|+    @runtime_checkable|;|+    class _Buffer(Protocol):|;|+        def __buffer__(self, flags: int, /) -> memoryview: ...|;|+|;|+ArrayLike: TypeAlias = _Buffer | _DualArrayLike[|;|+    dtype[Any],|;|+    bool | int | float | complex | str | bytes,|;|+]|;| |;| # `ArrayLike<X>_co`: array-like objects that can be coerced into `X`|;| # given the casting rules `same_kind`|;|@@ -165,6 +165,11 @@ def __array_function__(|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28112 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28112 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28112 - numpy/typing/tests/data/reveal/index_tricks.pyi: @@ -58,13 +58,13 @@ assert_type(np.mgrid[1:1:2, None:10], npt.NDArray[Any])|;| assert_type(np.ogrid[1:1:2], tuple[npt.NDArray[Any], ...])|;| assert_type(np.ogrid[1:1:2, None:10], tuple[npt.NDArray[Any], ...])|;| |;|-assert_type(np.index_exp[0:1], tuple[slice])|;|-assert_type(np.index_exp[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.index_exp[0:1], tuple[slice[int, int, None]])|;|+assert_type(np.index_exp[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.index_exp[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;|-assert_type(np.s_[0:1], slice)|;|-assert_type(np.s_[0:1, None:3], tuple[slice, slice])|;|-assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice, EllipsisType, list[int]])|;|+assert_type(np.s_[0:1], slice[int, int, None])|;|+assert_type(np.s_[0:1, None:3], tuple[slice[int, int, None], slice[None, int, None]])|;|+assert_type(np.s_[0, 0:1, ..., [0, 1, 3]], tuple[Literal[0], slice[int, int, None], EllipsisType, list[int]])|;| |;| assert_type(np.ix_(AR_LIKE_b), tuple[npt.NDArray[np.bool], ...])|;| assert_type(np.ix_(AR_LIKE_i, AR_LIKE_f), tuple[npt.NDArray[np.float64], ...]) || PR#28112 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]]) || PR#28112 - requirements/test_requirements.txt: @@ -14,7 +14,7 @@ cffi; python_version < '3.10'|;| # For testing types. Notes on the restrictions:|;| # - Mypy relies on C API features not present in PyPy|;| # NOTE: Keep mypy in sync with environment.yml|;|-mypy==1.13.0; platform_python_implementation != ""PyPy""|;|+mypy==1.14.1; platform_python_implementation != ""PyPy""|;| typing_extensions>=4.2.0|;| # for optional f2py encoding detection|;| charset-normalizer || PR#28108 - numpy/__init__.pyi: @@ -23,11 +23,14 @@ from numpy._typing import (|;|     _SupportsArray,|;|     _NestedSequence,|;|     _FiniteNestedSequence,|;|+    _ArrayLike,|;|     _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co,|;|     _ArrayLikeInt,|;|     _ArrayLikeInt_co,|;|+    _ArrayLikeFloat64_co,|;|     _ArrayLikeFloat_co,|;|+    _ArrayLikeComplex128_co,|;|     _ArrayLikeComplex_co,|;|     _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co,|;|@@ -800,6 +803,7 @@ _1NShapeT = TypeVar(""_1NShapeT"", bound=tuple[L[1], Unpack[tuple[L[1], ...]]])  #|;| _SCT = TypeVar(""_SCT"", bound=generic)|;| _SCT_co = TypeVar(""_SCT_co"", bound=generic, covariant=True)|;| _NumberT = TypeVar(""_NumberT"", bound=number[Any])|;|+_RealNumberT = TypeVar(""_RealNumberT"", bound=floating | integer)|;| _FloatingT_co = TypeVar(""_FloatingT_co"", bound=floating[Any], default=floating[Any], covariant=True)|;| _IntegerT = TypeVar(""_IntegerT"", bound=integer)|;| _IntegerT_co = TypeVar(""_IntegerT_co"", bound=integer[Any], default=integer[Any], covariant=True)|;|@@ -833,14 +837,16 @@ _1D: TypeAlias = tuple[int]|;| _2D: TypeAlias = tuple[int, int]|;| _2Tuple: TypeAlias = tuple[_T, _T]|;| |;|-_ArrayUInt_co: TypeAlias = NDArray[np.bool | unsignedinteger[Any]]|;|-_ArrayInt_co: TypeAlias = NDArray[np.bool | integer[Any]]|;|-_ArrayFloat_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any]]|;|-_ArrayComplex_co: TypeAlias = NDArray[np.bool | integer[Any] | floating[Any] | complexfloating[Any, Any]]|;|-_ArrayNumber_co: TypeAlias = NDArray[np.bool | number[Any]]|;|-_ArrayTD64_co: TypeAlias = NDArray[np.bool | integer[Any] | timedelta64]|;|+_ArrayUInt_co: TypeAlias = NDArray[unsignedinteger | np.bool]|;|+_ArrayInt_co: TypeAlias = NDArray[integer | np.bool]|;|+_ArrayFloat64_co: TypeAlias = NDArray[floating[_64Bit] | float32 | float16 | integer | np.bool]|;|+_ArrayFloat_co: TypeAlias = NDArray[floating | integer | np.bool]|;|+_ArrayComplex128_co: TypeAlias = NDArray[number[_64Bit] | number[_32Bit] | float16 | integer | np.bool]|;|+_ArrayComplex_co: TypeAlias = NDArray[inexact | integer | np.bool]|;|+_ArrayNumber_co: TypeAlias = NDArray[number | np.bool]|;|+_ArrayTD64_co: TypeAlias = NDArray[timedelta64 | integer | np.bool]|;| |;|-_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[Any] | np.bool|;|+_Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer | np.bool|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|@@ -2613,111 +2619,192 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     ) -> ndarray[_ShapeT, dtype[floating[_AnyNBitInexact]]]: ...|;|     @overload|;|     def __abs__(self: _RealArrayT, /) -> _RealArrayT: ...|;|+|;|     def __invert__(self: _IntegralArrayT, /) -> _IntegralArrayT: ...  # noqa: PYI019|;|     def __neg__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;|     def __pos__(self: _NumericArrayT, /) -> _NumericArrayT: ...  # noqa: PYI019|;| |;|     # Binary ops|;|+|;|+    # TODO: Support the ""1d @ 1d -> scalar"" case|;|+    @overload|;|+    def __matmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __matmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __matmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __matmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __matmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __matmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __matmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|     @overload|;|     def __matmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __matmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __matmul__|;|+    def __rmatmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...|;|+    @overload|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmatmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rmatmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmatmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rmatmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|     @overload|;|-    def __rmatmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmatmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmatmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __mod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|+    @overload|;|+    def __mod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __mod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __mod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __mod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mod__|;|+    def __rmod__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmod__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[timedelta64]: ...|;|+    def __rmod__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __rmod__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmod__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmod__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __divmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|+    @overload|;|+    def __divmod__(self: NDArray[_RealNumberT], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[np.bool], rhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __divmod__(self: NDArray[floating[_64Bit]], rhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __divmod__(self: _ArrayFloat64_co, rhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayUInt_co, rhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayInt_co, rhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __divmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __divmod__(self: _ArrayFloat_co, rhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|     @overload|;|-    def __divmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __divmod__(self: NDArray[timedelta64], rhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|+    @overload  # signature equivalent to __divmod__|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: int | np.bool, /) -> _2Tuple[ndarray[_ShapeT_co, dtype[_RealNumberT]]]: ...|;|     @overload|;|-    def __rdivmod__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[_RealNumberT], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLikeBool_co, /) -> _2Tuple[NDArray[int8]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[np.bool], lhs: _ArrayLike[_RealNumberT], /) -> _2Tuple[NDArray[_RealNumberT]]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rdivmod__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating[Any]]]: ...  # type: ignore[misc]|;|+    def __rdivmod__(self: NDArray[floating[_64Bit]], lhs: _ArrayLikeFloat64_co, /) -> _2Tuple[NDArray[float64]]: ...|;|     @overload|;|-    def __rdivmod__(self: _ArrayTD64_co, other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;|+    def __rdivmod__(self: _ArrayFloat64_co, lhs: _ArrayLike[floating[_64Bit]], /) -> _2Tuple[NDArray[float64]]: ...|;|+    @overload|;|+    def __rdivmod__(self: _ArrayUInt_co, lhs: _ArrayLikeUInt_co, /) -> _2Tuple[NDArray[unsignedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayInt_co, lhs: _ArrayLikeInt_co, /) -> _2Tuple[NDArray[signedinteger]]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rdivmod__(self: _ArrayFloat_co, lhs: _ArrayLikeFloat_co, /) -> _2Tuple[NDArray[floating]]: ...|;|+    @overload|;|+    def __rdivmod__(self: NDArray[timedelta64], lhs: _ArrayLike[timedelta64], /) -> tuple[NDArray[int64], NDArray[timedelta64]]: ...|;| |;|     @overload|;|-    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __add__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __add__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __add__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __add__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __add__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2727,20 +2814,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __add__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __add__|;|+    def __radd__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __radd__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __radd__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __radd__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __radd__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __radd__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2750,20 +2851,34 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __radd__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __sub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __sub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __sub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __sub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __sub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __sub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __sub__(self: NDArray[datetime64], other: _ArrayLikeTD64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|@@ -2773,22 +2888,36 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __sub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|     def __rsub__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|     @overload|;|-    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rsub__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rsub__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rsub__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...  # type: ignore[misc]|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rsub__(self: _ArrayTD64_co, other: _ArrayLikeDT64_co, /) -> NDArray[datetime64]: ...|;|     @overload|;|     def __rsub__(self: NDArray[datetime64], other: _ArrayLikeDT64_co, /) -> NDArray[timedelta64]: ...|;|     @overload|;|@@ -2797,156 +2926,252 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     def __rsub__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __mul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __mul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __mul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __mul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __mul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __mul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __mul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __mul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|+    @overload  # signature equivalent to __mul__|;|+    def __rmul__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rmul__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[np.bool]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rmul__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayTD64_co, other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rmul__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rmul__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rmul__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rmul__(self: _ArrayFloat_co, other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|     @overload|;|     def __rmul__(self: NDArray[object_], other: Any, /) -> Any: ...|;|     @overload|;|     def __rmul__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __truediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __truediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __truediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __truediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __truediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __truediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayInt_co, other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayFloat64_co, other: _ArrayLikeInt_co | _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rtruediv__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[int64]: ...|;|+    def __rtruediv__(self: NDArray[floating], other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLike[floating], /) -> NDArray[floating]: ...|;|     @overload|;|-    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rtruediv__(self: NDArray[complexfloating], other: _ArrayLikeNumber_co, /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rtruediv__(self: _ArrayNumber_co, other: _ArrayLike[complexfloating], /) -> NDArray[complexfloating]: ...|;|     @overload|;|-    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rtruediv__(self: NDArray[inexact], other: _ArrayLikeNumber_co, /) -> NDArray[inexact]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[float64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[integer | floating], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __floordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __floordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __floordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __floordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __floordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __floordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_RealNumberT]]: ...|;|     @overload|;|-    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[_RealNumberT], other: _ArrayLikeBool_co, /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rfloordiv__(self: NDArray[np.bool], other: _ArrayLike[_RealNumberT], /) -> NDArray[_RealNumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...|;|+    def __rfloordiv__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rfloordiv__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rfloordiv__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[timedelta64], other: _ArrayLike[timedelta64], /) -> NDArray[int64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[floating | integer], other: _ArrayLike[timedelta64], /) -> NDArray[timedelta64]: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rfloordiv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __truediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __truediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __pow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __pow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeBool_co, /) -> NoReturn: ...|;|+    def __pow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[timedelta64], other: _ArrayLikeFloat_co, /) -> NDArray[timedelta64]: ...|;|+    def __pow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __pow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __truediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __pow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __pow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __pow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __pow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|-    def __rtruediv__(self: _ArrayInt_co, other: _ArrayInt_co, /) -> NDArray[float64]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: int | np.bool, /) -> ndarray[_ShapeT_co, dtype[_NumberT]]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating[Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[_NumberT], other: _ArrayLikeBool_co, /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating[Any, Any]]: ...  # type: ignore[misc]|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[number[Any]], other: _ArrayLikeNumber_co, /) -> NDArray[number[Any]]: ...|;|+    def __rpow__(self: NDArray[np.bool], other: _ArrayLike[_NumberT], /) -> NDArray[_NumberT]: ...  # type: ignore[overload-overlap]|;|     @overload|;|-    def __rtruediv__(self: NDArray[timedelta64], other: _SupportsArray[_dtype[timedelta64]] | _NestedSequence[_SupportsArray[_dtype[timedelta64]]], /) -> NDArray[float64]: ...|;|+    def __rpow__(self: NDArray[floating[_64Bit]], other: _ArrayLikeFloat64_co, /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[np.bool], other: _ArrayLikeTD64_co, /) -> NoReturn: ...|;|+    def __rpow__(self: _ArrayFloat64_co, other: _ArrayLike[floating[_64Bit]], /) -> NDArray[float64]: ...|;|     @overload|;|-    def __rtruediv__(self: _ArrayFloat_co, other: _ArrayLikeTD64_co, /) -> NDArray[timedelta64]: ...|;|+    def __rpow__(self: NDArray[complexfloating[_64Bit]], other: _ArrayLikeComplex128_co, /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    def __rpow__(self: _ArrayComplex128_co, other: _ArrayLike[complexfloating[_64Bit]], /) -> NDArray[complex128]: ...|;|     @overload|;|-    def __rtruediv__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;|+    def __rpow__(self: _ArrayUInt_co, other: _ArrayLikeUInt_co, /) -> NDArray[unsignedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayInt_co, other: _ArrayLikeInt_co, /) -> NDArray[signedinteger]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayFloat_co, other: _ArrayLikeFloat_co, /) -> NDArray[floating]: ...  # type: ignore[overload-overlap]|;|+    @overload|;|+    def __rpow__(self: _ArrayComplex_co, other: _ArrayLikeComplex_co, /) -> NDArray[complexfloating]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[number], other: _ArrayLikeNumber_co, /) -> NDArray[number]: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[object_], other: Any, /) -> Any: ...|;|+    @overload|;|+    def __rpow__(self: NDArray[Any], other: _ArrayLikeObject_co, /) -> Any: ...|;| |;|     @overload|;|     def __lshift__(self: NDArray[np.bool], other: _ArrayLikeBool_co, /) -> NDArray[int8]: ...  # type: ignore[misc] || PR#28108 - numpy/_typing/__init__.py: @@ -121,15 +121,14 @@|;|     NDArray as NDArray,|;|     ArrayLike as ArrayLike,|;|     _ArrayLike as _ArrayLike,|;|-    _FiniteNestedSequence as _FiniteNestedSequence,|;|-    _SupportsArray as _SupportsArray,|;|-    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _ArrayLikeInt as _ArrayLikeInt,|;|     _ArrayLikeBool_co as _ArrayLikeBool_co,|;|     _ArrayLikeUInt_co as _ArrayLikeUInt_co,|;|     _ArrayLikeInt_co as _ArrayLikeInt_co,|;|     _ArrayLikeFloat_co as _ArrayLikeFloat_co,|;|+    _ArrayLikeFloat64_co as _ArrayLikeFloat64_co,|;|     _ArrayLikeComplex_co as _ArrayLikeComplex_co,|;|+    _ArrayLikeComplex128_co as _ArrayLikeComplex128_co,|;|     _ArrayLikeNumber_co as _ArrayLikeNumber_co,|;|     _ArrayLikeTD64_co as _ArrayLikeTD64_co,|;|     _ArrayLikeDT64_co as _ArrayLikeDT64_co,|;|@@ -140,6 +139,9 @@|;|     _ArrayLikeString_co as _ArrayLikeString_co,|;|     _ArrayLikeAnyString_co as _ArrayLikeAnyString_co,|;|     _ArrayLikeUnknown as _ArrayLikeUnknown,|;|+    _FiniteNestedSequence as _FiniteNestedSequence,|;|+    _SupportsArray as _SupportsArray,|;|+    _SupportsArrayFunc as _SupportsArrayFunc,|;|     _UnknownType as _UnknownType,|;| )|;|  || PR#28108 - numpy/_typing/_array_like.py: @@ -21,6 +21,7 @@|;|     str_,|;|     bytes_,|;| )|;|+from ._nbit_base import _32Bit, _64Bit|;| from ._nested_sequence import _NestedSequence|;| from ._shape import _Shape|;| |;|@@ -164,6 +165,11 @@ def __buffer__(self, flags: int, /) -> memoryview: ...|;|     _ArrayLikeString_co|;| )|;| |;|+__Float64_co: TypeAlias = np.floating[_64Bit] | np.float32 | np.float16 | np.integer | np.bool|;|+__Complex128_co: TypeAlias = np.number[_64Bit] | np.number[_32Bit] | np.float16 | np.integer | np.bool|;|+_ArrayLikeFloat64_co: TypeAlias = _DualArrayLike[dtype[__Float64_co], float | int]|;|+_ArrayLikeComplex128_co: TypeAlias = _DualArrayLike[dtype[__Complex128_co], complex | float | int]|;|+|;| # NOTE: This includes `builtins.bool`, but not `numpy.bool`.|;| _ArrayLikeInt: TypeAlias = _DualArrayLike[|;|     dtype[integer[Any]], || PR#28108 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -51,6 +51,7 @@ AR_m: npt.NDArray[np.timedelta64]|;| AR_M: npt.NDArray[np.datetime64]|;| AR_O: npt.NDArray[np.object_]|;| AR_number: npt.NDArray[np.number[Any]]|;|+AR_Any: npt.NDArray[Any]|;| |;| AR_LIKE_b: list[bool]|;| AR_LIKE_u: list[np.uint32]|;|@@ -61,34 +62,35 @@ AR_LIKE_m: list[np.timedelta64]|;| AR_LIKE_M: list[np.datetime64]|;| AR_LIKE_O: list[np.object_]|;| |;|+|;| # Array subtraction|;| |;| assert_type(AR_number - AR_number, npt.NDArray[np.number[Any]])|;| |;|-assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b - AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_b - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_b - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u - AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i - AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_c - AR_b, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_m - AR_b, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_b, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_b, Any)|;| |;|-assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u - AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u - AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_u - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_u - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u - AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_u, npt.NDArray[np.floating[Any]])|;|@@ -97,15 +99,15 @@ assert_type(AR_LIKE_m - AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_u, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_u, Any)|;| |;|-assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i - AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i - AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_i - AR_LIKE_m, npt.NDArray[np.timedelta64])|;| assert_type(AR_i - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b - AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i - AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f - AR_i, npt.NDArray[np.floating[Any]])|;|@@ -114,32 +116,32 @@ assert_type(AR_LIKE_m - AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_M - AR_i, npt.NDArray[np.datetime64])|;| assert_type(AR_LIKE_O - AR_i, Any)|;| |;|-assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f - AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f - AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_f - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i - AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f - AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_c - AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(AR_LIKE_O - AR_f, Any)|;| |;|-assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_c - AR_LIKE_b, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_u, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_i, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_f, npt.NDArray[np.complex128])|;|+assert_type(AR_c - AR_LIKE_c, npt.NDArray[np.complex128])|;| assert_type(AR_c - AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|-assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_LIKE_b - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_u - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_i - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_f - AR_c, npt.NDArray[np.complex128])|;|+assert_type(AR_LIKE_c - AR_c, npt.NDArray[np.complex128])|;| assert_type(AR_LIKE_O - AR_c, Any)|;| |;| assert_type(AR_m - AR_LIKE_b, npt.NDArray[np.timedelta64])|;|@@ -186,53 +188,53 @@ assert_type(AR_LIKE_O - AR_O, Any)|;| # Array floor division|;| |;| assert_type(AR_b // AR_LIKE_b, npt.NDArray[np.int8])|;|-assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_b // AR_LIKE_u, npt.NDArray[np.uint32])|;| assert_type(AR_b // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_b // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_b // AR_LIKE_O, Any)|;| |;| assert_type(AR_LIKE_b // AR_b, npt.NDArray[np.int8])|;|-assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_u // AR_b, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_i // AR_b, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_b, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_O // AR_b, Any)|;| |;|-assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_u // AR_LIKE_b, npt.NDArray[np.uint32])|;| assert_type(AR_u // AR_LIKE_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_u // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_u // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_u, npt.NDArray[np.uint32])|;| assert_type(AR_LIKE_u // AR_u, npt.NDArray[np.unsignedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_u, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_u, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_u, Any)|;| |;|-assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_i // AR_LIKE_b, npt.NDArray[np.int64])|;| assert_type(AR_i // AR_LIKE_u, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_i // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;| assert_type(AR_i // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_LIKE_b // AR_i, npt.NDArray[np.int64])|;| assert_type(AR_LIKE_u // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_i // AR_i, npt.NDArray[np.signedinteger[Any]])|;| assert_type(AR_LIKE_f // AR_i, npt.NDArray[np.floating[Any]])|;| assert_type(AR_LIKE_m // AR_i, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_i, Any)|;| |;|-assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f // AR_LIKE_b, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_u, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_i, npt.NDArray[np.float64])|;|+assert_type(AR_f // AR_LIKE_f, npt.NDArray[np.float64])|;| assert_type(AR_f // AR_LIKE_O, Any)|;| |;|-assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.floating[Any]])|;|-assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_LIKE_b // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_u // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_i // AR_f, npt.NDArray[np.float64])|;|+assert_type(AR_LIKE_f // AR_f, npt.NDArray[np.float64])|;| assert_type(AR_LIKE_m // AR_f, npt.NDArray[np.timedelta64])|;| assert_type(AR_LIKE_O // AR_f, Any)|;| |;|@@ -407,7 +409,7 @@ assert_type(c16 + b_, np.complex128)|;| assert_type(c16 + b, np.complex128)|;| assert_type(c16 + c, np.complex128)|;| assert_type(c16 + f, np.complex128)|;|-assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c16 + AR_f, npt.NDArray[np.complex128])|;| |;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;|@@ -420,7 +422,7 @@ assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;| assert_type(f + c16, np.complex128)|;|-assert_type(AR_f + c16, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c16, npt.NDArray[np.complex128])|;| |;| assert_type(c8 + f16, np.complexfloating[_32Bit, _32Bit] | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c8 + c16, np.complex64 | np.complex128)|;|@@ -433,7 +435,7 @@ assert_type(c8 + b_, np.complex64)|;| assert_type(c8 + b, np.complex64)|;| assert_type(c8 + c, np.complex64 | np.complex128)|;| assert_type(c8 + f, np.complex64 | np.complex128)|;|-assert_type(c8 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(c8 + AR_f, npt.NDArray[np.complexfloating])|;| |;| assert_type(f16 + c8, np.complexfloating[_128Bit, _128Bit] | np.complex64)|;| assert_type(c16 + c8, np.complex128)|;|@@ -446,7 +448,7 @@ assert_type(b_ + c8, np.complex64)|;| assert_type(b + c8, np.complex64)|;| assert_type(c + c8, np.complex64 | np.complex128)|;| assert_type(f + c8, np.complex64 | np.complex128)|;|-assert_type(AR_f + c8, npt.NDArray[np.complexfloating[Any, Any]])|;|+assert_type(AR_f + c8, npt.NDArray[np.complexfloating])|;| |;| # Float|;| |;|@@ -459,18 +461,18 @@ assert_type(f8 + b_, np.float64)|;| assert_type(f8 + b, np.float64)|;| assert_type(f8 + c, np.float64 | np.complex128)|;| assert_type(f8 + f, np.float64)|;|-assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;| assert_type(i8 + f8, np.float64)|;|-assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(f4 + f8, np.float32 | np.float64)|;| assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;| assert_type(f + f8, np.float64)|;|-assert_type(AR_f + f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f8, npt.NDArray[np.float64])|;| |;| assert_type(f4 + f16, np.float32 | np.floating[_128Bit])|;| assert_type(f4 + f8, np.float32 | np.float64)|;|@@ -481,7 +483,7 @@ assert_type(f4 + b_, np.float32)|;| assert_type(f4 + b, np.float32)|;| assert_type(f4 + c, np.complex64 | np.complex128)|;| assert_type(f4 + f, np.float32 | np.float64)|;|-assert_type(f4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(f4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(f16 + f4, np.floating[_128Bit] | np.float32)|;| assert_type(f8 + f4, np.float64)|;|@@ -492,7 +494,7 @@ assert_type(b_ + f4, np.float32)|;| assert_type(b + f4, np.float32)|;| assert_type(c + f4, np.complex64 | np.complex128)|;| assert_type(f + f4, np.float64 | np.float32)|;|-assert_type(AR_f + f4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + f4, npt.NDArray[np.float64])|;| |;| # Int|;| |;|@@ -504,7 +506,7 @@ assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;| assert_type(i8 + c, np.complex128)|;| assert_type(i8 + f, np.float64)|;|-assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;|@@ -513,7 +515,7 @@ assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;| assert_type(u8 + c, np.complex128)|;| assert_type(u8 + f, np.float64)|;|-assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u8 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i8, np.int64)|;| assert_type(u8 + i8, Any)|;|@@ -523,7 +525,7 @@ assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;| assert_type(c + i8, np.complex128)|;| assert_type(f + i8, np.float64)|;|-assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i8, npt.NDArray[np.float64])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;|@@ -532,32 +534,36 @@ assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;| assert_type(c + u8, np.complex128)|;| assert_type(f + u8, np.float64)|;|-assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u8, npt.NDArray[np.float64])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(i4 + b_, np.int32)|;| assert_type(i4 + b, np.int32)|;|-assert_type(i4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(i4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(u4 + i8, Any)|;| assert_type(u4 + i4, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(u4 + b_, np.uint32)|;| assert_type(u4 + b, np.uint32)|;|-assert_type(u4 + AR_f, npt.NDArray[np.floating[Any]])|;|+assert_type(u4 + AR_f, npt.NDArray[np.float64])|;| |;| assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i4 + i4, np.int32)|;| assert_type(b_ + i4, np.int32)|;| assert_type(b + i4, np.int32)|;|-assert_type(AR_f + i4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + i4, npt.NDArray[np.float64])|;| |;| assert_type(i8 + u4, Any)|;| assert_type(i4 + u4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u4 + u4, np.uint32)|;| assert_type(b_ + u4, np.uint32)|;| assert_type(b + u4, np.uint32)|;|-assert_type(AR_f + u4, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_f + u4, npt.NDArray[np.float64])|;|+|;|+# Any|;|+|;|+assert_type(AR_Any + 2, npt.NDArray[Any]) || PR#28108 - numpy/typing/tests/data/reveal/false_positives.pyi: @@ -1,14 +0,0 @@|;|-from typing import Any|;|-|;|-import numpy as np|;|-import numpy.typing as npt|;|-|;|-from typing_extensions import assert_type|;|-|;|-AR_Any: npt.NDArray[Any]|;|-|;|-# Mypy bug where overload ambiguity is ignored for `Any`-parametrized types|;|;-# xref numpy/numpy#20099 and python/mypy#11347|;|-#|;|-# The expected output would be something akin to `npt.NDArray[Any]`|;|-assert_type(AR_Any + 2, npt.NDArray[np.signedinteger[Any]]) || PR#28108 - numpy/typing/tests/data/reveal/mod.pyi: @@ -83,7 +83,7 @@ assert_type(i4 % i8, np.int64 | np.int32)|;| assert_type(i4 % f8, np.float64 | np.float32)|;| assert_type(i4 % i4, np.int32)|;| assert_type(i4 % f4, np.float32)|;|-assert_type(i8 % AR_b, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(i8 % AR_b, npt.NDArray[np.int64])|;| |;| assert_type(divmod(i8, b), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(i8, f), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -93,7 +93,7 @@ assert_type(divmod(i8, i4), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(i8, f4), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(i4, f4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(i8, AR_b), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| assert_type(b % i8, np.signedinteger[_64Bit])|;| assert_type(f % i8, np.floating[_64Bit])|;|@@ -103,7 +103,7 @@ assert_type(i8 % i4, np.int64 | np.int32)|;| assert_type(f8 % i4, np.float64)|;| assert_type(i4 % i4, np.int32)|;| assert_type(f4 % i4, np.float32)|;|-assert_type(AR_b % i8, npt.NDArray[np.signedinteger[Any]])|;|+assert_type(AR_b % i8, npt.NDArray[np.int64])|;| |;| assert_type(divmod(b, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64Bit]])|;| assert_type(divmod(f, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]])|;|@@ -113,33 +113,33 @@ assert_type(divmod(i4, i8), tuple[np.signedinteger[_64Bit], np.signedinteger[_64|;| assert_type(divmod(f4, i8), tuple[np.floating[_64Bit], np.floating[_64Bit]] | tuple[np.floating[_32Bit], np.floating[_32Bit]])|;| assert_type(divmod(i4, i4), tuple[np.signedinteger[_32Bit], np.signedinteger[_32Bit]])|;| assert_type(divmod(f4, i4), tuple[np.floating[_32Bit], np.floating[_32Bit]])|;|-assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.signedinteger[Any]], npt.NDArray[np.signedinteger[Any]]])|;|+assert_type(divmod(AR_b, i8), tuple[npt.NDArray[np.int64], npt.NDArray[np.int64]])|;| |;| # float|;| |;| assert_type(f8 % b, np.float64)|;| assert_type(f8 % f, np.float64)|;| assert_type(i8 % f4, np.floating[_64Bit] | np.floating[_32Bit])|;| assert_type(f4 % f4, np.float32)|;|-assert_type(f8 % AR_b, npt.NDArray[np.floating[Any]])|;|+assert_type(f8 % AR_b, npt.NDArray[np.float64])|;| |;| assert_type(divmod(f8, b), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f4), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(f8, AR_b), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])|;| |;| assert_type(b % f8, np.float64)|;| assert_type(f % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f8 % f8, np.float64)|;| assert_type(f4 % f4, np.float32)|;|-assert_type(AR_b % f8, npt.NDArray[np.floating[Any]])|;|+assert_type(AR_b % f8, npt.NDArray[np.float64])|;| |;| assert_type(divmod(b, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f8, f8), tuple[np.float64, np.float64])|;| assert_type(divmod(f4, f8), tuple[np.float64, np.float64] | tuple[np.float32, np.float32])|;| assert_type(divmod(f4, f4), tuple[np.float32, np.float32])|;|-assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.floating[Any]], npt.NDArray[np.floating[Any]]])|;|+assert_type(divmod(AR_b, f8), tuple[npt.NDArray[np.float64], npt.NDArray[np.float64]])","TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128`` || MAINT: bump ``mypy`` to ``1.14.1`` (#28089)

* MAINT: bump `mypy` to `1.14.1`

* TYP: fix new `mypy==1.14.1` type-test errors

* TYP: backport `collections.abc.Buffer` for `npt.ArrayLike` on `python<3.11` || TYP: Better ``ndarray`` binop return types for ``float64`` & ``complex128``"
numpy/numpy,Uvi-12,28093,DOC: numpy.ma.masked example doesn't resolve,"### Issue with current documentation:

[Example from documentation](https://numpy.org/doc/stable/reference/maskedarray.baseclass.html#numpy.ma.masked) about `numpy.ma.masked` seems to contain a little mistake.

Example starts with:

```python
import numpy as np

x = ma.array([1, 2, 3], mask=[0, 1, 0])
```

As it is, `ma` doesn't resolve, and `np` isn't referenced. I believe it should be:

```python
x = np.ma.array([1, 2, 3], mask=[0, 1, 0])
```

Same for the two following lines:

```python
x[1] is ma.masked
```

```python
x[-1] = ma.masked
```

Should be replaced with

```python
x[1] is np.ma.masked
```

```python
x[-1] = np.ma.masked
```

### Idea or request for content:

_No response_",,closed,2025-01-03T10:12:53+00:00,2025-01-06T19:27:46+00:00,MoonZ,"04 - Documentation, component: numpy.ma",1,"PR#28094 - doc/source/reference/maskedarray.baseclass.rst: @@ -1,8 +1,5 @@|;| .. currentmodule:: numpy.ma|;| |;|-.. for doctests|;|-   >>> from numpy import ma|;|-|;| .. _numpy.ma.constants:|;| |;| Constants of the :mod:`numpy.ma` module|;|@@ -20,10 +17,10 @@ defines several constants.|;| |;|       >>> import numpy as np|;| |;|-      >>> x = ma.array([1, 2, 3], mask=[0, 1, 0])|;|-      >>> x[1] is ma.masked|;|+      >>> x = np.ma.array([1, 2, 3], mask=[0, 1, 0])|;|+      >>> x[1] is np.ma.masked|;|       True|;|-      >>> x[-1] = ma.masked|;|+      >>> x[-1] = np.ma.masked|;|       >>> x|;|       masked_array(data=[1, --, --],|;|                    mask=[False,  True,  True],",Fix documentation example for numpy.ma.masked || Updated maskedarray.baseclass.rst as per review
numpy/numpy,that-ar-guy,28061,DOC: linalg.outer appears in wrong section in docs,"### Issue with current documentation:

`numpy.linalg.outer` is documented under ""Decompositions"" however it seems much more natural for it to be under ""Matrix and vector products"" as it is a product not a decomposition.

### Idea or request for content:

Move under ""Matrix and vector products"" in toc tree","hey can i take this up
 || Please assign this to me || We don't assign issues generally, but feel free to open a pull request mentioning this issue! || I believe the solution would be to remove `numpy.linalg.outer` from the ""Decompositions"" section, as it is a product, not a decomposition. Since `numpy.outer` is already listed under ""Matrix and vector products"" and both functions are identical, there's no need to add `numpy.linalg.outer` there. We could optionally include a note clarifying that `numpy.linalg.outer` is equivalent to `numpy.outer` for compatibility.",closed,2024-12-24T05:14:55+00:00,2025-01-06T04:03:51+00:00,j-bowhay,04 - Documentation,1,"PR#28100 - doc/source/reference/routines.linalg.rst: @@ -60,6 +60,7 @@ Matrix and vector products|;|    linalg.vecdot|;|    inner|;|    outer|;|+   linalg.outer|;|    matmul|;|    linalg.matmul (Array API compatible location)|;|    matvec|;|@@ -71,14 +72,14 @@ Matrix and vector products|;|    linalg.matrix_power|;|    kron|;|    linalg.cross|;|+   |;| |;| Decompositions|;| --------------|;| .. autosummary::|;|    :toctree: generated/|;| |;|    linalg.cholesky|;|-   linalg.outer|;|    linalg.qr|;|    linalg.svd|;|    linalg.svdvals",DOC: Move linalg.outer from Decompositions to Matrix and vector products || DOC: fix linting [skip actions][ skip azp][skip cirrus] || DOC: Update TOC to group `numpy.outer` and `numpy.linalg.outer` together
numpy/numpy,mattip,28061,DOC: linalg.outer appears in wrong section in docs,"### Issue with current documentation:

`numpy.linalg.outer` is documented under ""Decompositions"" however it seems much more natural for it to be under ""Matrix and vector products"" as it is a product not a decomposition.

### Idea or request for content:

Move under ""Matrix and vector products"" in toc tree","hey can i take this up
 || Please assign this to me || We don't assign issues generally, but feel free to open a pull request mentioning this issue! || I believe the solution would be to remove `numpy.linalg.outer` from the ""Decompositions"" section, as it is a product, not a decomposition. Since `numpy.outer` is already listed under ""Matrix and vector products"" and both functions are identical, there's no need to add `numpy.linalg.outer` there. We could optionally include a note clarifying that `numpy.linalg.outer` is equivalent to `numpy.outer` for compatibility.",closed,2024-12-24T05:14:55+00:00,2025-01-06T04:03:51+00:00,j-bowhay,04 - Documentation,1,"PR#28100 - doc/source/reference/routines.linalg.rst: @@ -60,6 +60,7 @@ Matrix and vector products|;|    linalg.vecdot|;|    inner|;|    outer|;|+   linalg.outer|;|    matmul|;|    linalg.matmul (Array API compatible location)|;|    matvec|;|@@ -71,14 +72,14 @@ Matrix and vector products|;|    linalg.matrix_power|;|    kron|;|    linalg.cross|;|+   |;| |;| Decompositions|;| --------------|;| .. autosummary::|;|    :toctree: generated/|;| |;|    linalg.cholesky|;|-   linalg.outer|;|    linalg.qr|;|    linalg.svd|;|    linalg.svdvals",DOC: Move linalg.outer from Decompositions to Matrix and vector products || DOC: fix linting [skip actions][ skip azp][skip cirrus] || DOC: Update TOC to group `numpy.outer` and `numpy.linalg.outer` together
numpy/numpy,ngoldbaum,28087,BUG: Cannot build with clang thread sanitizer,"When I try to build NumPy using the Clang-19 thread sanitizer, I get the following compiler error:

<details>

```
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:15:5: error: no function template matches function template specialization 'QSort_ASIMD'
     15 |     DISPATCH_VQSORT(int32_t)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:23:1: note: expanded from here
     23 | QSort_ASIMD
        | ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:16:5: error: no function template matches function template specialization 'QSort_ASIMD'
     16 |     DISPATCH_VQSORT(uint32_t)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:25:1: note: expanded from here
     25 | QSort_ASIMD
        | ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:17:5: error: no function template matches function template specialization 'QSort_ASIMD'
     17 |     DISPATCH_VQSORT(int64_t)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:27:1: note: expanded from here
     27 | QSort_ASIMD
        | ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:18:5: error: no function template matches function template specialization 'QSort_ASIMD'
     18 |     DISPATCH_VQSORT(uint64_t)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:29:1: note: expanded from here
     29 | QSort_ASIMD
        | ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:19:5: error: no function template matches function template specialization 'QSort_ASIMD'
     19 |     DISPATCH_VQSORT(double)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:31:1: note: expanded from here
     31 | QSort_ASIMD
        | ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:20:5: error: no function template matches function template specialization 'QSort_ASIMD'
     20 |     DISPATCH_VQSORT(float)
        |     ^
  ../numpy/_core/src/npysort/highway_qsort.dispatch.cpp:8:17: note: expanded from macro 'DISPATCH_VQSORT'
      8 | template<> void NPY_CPU_DISPATCH_CURFX(QSort)(TYPE *arr, intptr_t size) \
        |                 ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:155:42: note: expanded from macro 'NPY_CPU_DISPATCH_CURFX'
    155 |     #define NPY_CPU_DISPATCH_CURFX(NAME) NPY__CPU_CAT(NPY__CPU_CAT(NAME, _), NPY_MTARGETS_CURRENT)
        |                                          ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:42:28: note: expanded from macro 'NPY__CPU_CAT'
     42 | #define NPY__CPU_CAT(a, b) NPY__CPU_CAT_(a, b)
        |                            ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:41:29: note: expanded from macro 'NPY__CPU_CAT_'
     41 | #define NPY__CPU_CAT_(a, b) NPY__CPU_CAT__(a, b)
        |                             ^
  /Users/goldbaum/Documents/numpy/build/meson_cpu/npy_cpu_dispatch_config.h:40:30: note: expanded from macro 'NPY__CPU_CAT__'
     40 | #define NPY__CPU_CAT__(a, b) a ## b
        |                              ^
  <scratch space>:33:1: note: expanded from here
     33 | QSort_ASIMD
        | ^
  6 errors generated.
```

</details>

This seems similar to other issues we've seen where highway didn't play nicely with address sanitizer. If I manually disable highway by defining `NPY_DISABLE_HIGHWAY_SORT` at compile time I get different errors about missing function template specializations.

ping @Mousius, not sure why I'm getting past the `HWY_IS_TSAN` check. I'm building numpy on my Mac with clang-19 installed via homebrew:

```bash
$ CC=/opt/homebrew/opt/llvm/bin/clang CXX=/opt/homebrew/opt/llvm/bin/clang++ spin build --clean -- -Dbuildtype=debug -Db_sanitize=thread
```","@ngoldbaum looks like we've gotten out of sync with Highway's `shared-inl.h` again. I've raised https://github.com/google/highway/pull/2421 to split the constant so we can check `VQSORT_COMPILER_COMPATIBLE` instead.

Can you try using the value of that macro in place of `NPY_DISABLE_HIGHWAY_SORT` for now? || > Can you try using the value of that macro in place of NPY_DISABLE_HIGHWAY_SORT for now?

Feeling a little dense - can you spell out a little more what I need to do? || >  can you spell out a little more what I need to do?

Figured it out, I'll send in a PR.",closed,2025-01-02T17:16:48+00:00,2025-01-02T19:04:31+00:00,ngoldbaum,,1,"PR#28088 - numpy/_core/src/npysort/highway_qsort.hpp: @@ -10,9 +10,7 @@|;| // dispatched sources.|;| #if (HWY_COMPILER_MSVC && !HWY_IS_DEBUG_BUILD) ||                   \|;|     (HWY_ARCH_ARM_V7 && HWY_IS_DEBUG_BUILD) ||                      \|;|-    (HWY_ARCH_ARM_A64 && HWY_COMPILER_GCC_ACTUAL && HWY_IS_ASAN) || \|;|-    (HWY_ARCH_ARM_A64 && HWY_COMPILER_CLANG &&                      \|;|-    (HWY_IS_HWASAN || HWY_IS_MSAN || HWY_IS_TSAN || HWY_IS_ASAN))|;|+    (HWY_ARCH_ARM_A64 && HWY_COMPILER_GCC_ACTUAL && HWY_IS_ASAN)|;| #define NPY_DISABLE_HIGHWAY_SORT|;| #endif|;| ",BUG: update check for highway compiler support
numpy/numpy,Shashwatpandey4,27995,"DOC: np.gradient, how many varargs when axis is provided","### Issue with current documentation:

[np.gradient](https://numpy.org/devdocs/reference/generated/numpy.gradient.html) documentation says:
`numpy.gradient(f, *varargs, axis=None, edge_order=1)`
_If axis is given, the number of varargs must equal the number of axes._ 
It does not specify, whether the number of axes of the array, or the number of axes the user specified in axis. Unexpectedly the latter is the case.
```
import numpy as np
res1=np.gradient(np.random.random((5, 6, 7)),.1,.2,axis=(0,1))
res2=np.gradient(np.random.random((5, 6, 7)),.1,.2,.3,axis=(0,1))
```
The last line raises  `TypeError: invalid number of arguments`, in versions 1.18.1 & 1.19.1.

### Idea or request for content:

I propose to amend the documentation, e.g. by amending the italic sentence above by:
_If axis is given, the number of varargs must equal the number of axes **provided in the axis keyword**._
or by changing numpy's code, such that the number of `varargs` can be either the number of dimensions of the array `f`, or the number of axes provided in the axis keyword. 
Should the behavior I describe be a bug instead of unclear documentation, feel free to shift this to the BUG category.",,closed,2024-12-13T15:47:18+00:00,2024-12-29T06:41:35+00:00,schmassmann-m,04 - Documentation,1,"PR#28074 - numpy/lib/_function_base_impl.py: @@ -999,7 +999,7 @@ def gradient(f, *varargs, axis=None, edge_order=1):|;|            the corresponding dimension|;|         4. Any combination of N scalars/arrays with the meaning of 2. and 3.|;| |;|-        If `axis` is given, the number of varargs must equal the number of axes.|;|+        If `axis` is given, the number of varargs must equal the number of axes specified in the axis parameter.|;|         Default: 1. (see Examples below).|;| |;|     edge_order : {1, 2}, optional","DOC: clarify np.gradient varargs requirement for axis parameter

The documentation was ambiguous about whether the number of varargs
should match the total number of array axes or the number of axes
specified in the axis parameter. This change clarifies that it must
match the number of axes specified in the axis parameter."
numpy/numpy,jorenham,28057,TYP: Mixed scalar/int binary operations have incorrect type annotation,"### Describe the issue:

The type annotations used for scalar/int binary operations like `np.float32(1) * 2` imply that the scalar types are not closed under e.g. multiplication with `int`:
```python
reveal_type(np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * 1) # signedinteger[_8Bit] | signedinteger[_32Bit | _64Bit]
```
As far as I can tell mixed operations with `int` don't actually promote the type:
```python
>>> np.int8(1) * 128
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
OverflowError: Python integer 128 out of bounds for int8
```
It comes from here:
https://github.com/numpy/numpy/blob/a7eda47eee93618a5cf7a21fd37c2f3c56134710/numpy/__init__.pyi#L3768-L3776
And that uses:
https://github.com/numpy/numpy/blob/a7eda47eee93618a5cf7a21fd37c2f3c56134710/numpy/_typing/_callable.pyi#L207-L222
I think that the problematic overload is:
```python
def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...
```
Is there a reason that `| int_` is needed there?

### Reproduce the code example:

```python
from __future__ import annotations
import numpy as np
from typing import Protocol, Self, reveal_type

class MultiplyWithInt(Protocol):
    def __mul__(self, other: int, /) -> Self:
        ...

a: MultiplyWithInt = 1
b: MultiplyWithInt = 1.0
c: MultiplyWithInt = 1j
d: MultiplyWithInt = np.uint8(1)
e: MultiplyWithInt = np.uint16(1)
f: MultiplyWithInt = np.uint32(1)
g: MultiplyWithInt = np.uint64(1)
h: MultiplyWithInt = np.int8(1) # type check error
i: MultiplyWithInt = np.int16(1) # type check error
j: MultiplyWithInt = np.int32(1) # type check error
k: MultiplyWithInt = np.int64(1)
l: MultiplyWithInt = np.float32(1.0) # type check error
m: MultiplyWithInt = np.float64(1.0)
n: MultiplyWithInt = np.complex64(1) # type check error
o: MultiplyWithInt = np.complex128(1)

reveal_type(np.uint8(1)) # unsignedinteger[_8Bit]
reveal_type(np.uint8(1) * 1) # Any
reveal_type(np.uint8(1) * np.uint8(1)) # unsignedinteger[_8Bit]

reveal_type(np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * 1) # signedinteger[_8Bit] | signedinteger[_32Bit | _64Bit]
reveal_type(np.int8(1) * np.int8(1)) # signedinteger[_8Bit]
```


### Error message:

_No response_

### Python and NumPy Versions:

Python 3.12
NumPy 2.2.1

### Runtime Environment:

_No response_

### Context for the issue:

I'm trying to write generically typed code with rings like:
```python
from typing import Protocol, Self, Literal

type _PositiveInteger = Literal[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

class RingElement(Protocol):
    """"""Elements supporting ring operations.""""""

    def __pos__(self) -> Self: ...
    def __neg__(self) -> Self: ...
    def __add__(self, other: Self, /) -> Self: ...
    def __mul__(self, other: Self | int, /) -> Self: ...
    def __rmul__(self, other: int, /) -> Self: ...
    def __pow__(self, other: _PositiveInteger, /) -> Self: ...
```
The allowance for multiplication with `int` is so that with this protocol you can have code like `2*x + y*2`. Both mypy and pyright think that some of numpy's scalar types are incompatible with this protocol because they are not closed under multiplication with `int`.","Thanks for reporting this!

Technically speaking, the return type annotation for `integer.__add__` isn't *incorrect* here; it's just unnecessarily broad. But as you demonstrated, this can lead to unexpected behavior, which can be especially annoying in the case of structural typing (i.e. a `Protocol`).

So to answer your question:

> Is there a reason that `| int_` is needed there?

No. It should be removed. And I will.

But I suppose that it isn't far-fetched to (incorrectly) assume that `np.array(1, np.int8) + np.array(2)` would have the same scalar type as `np.int8(1) + 2` would -- especially if you also take the fact that `np.int(8) + 1.0` is `np.float64(3.0)` into account.

 || For (mostly my own) reference, I tabulated the resulting dtypes of `y = xi.__add__(xj)` (i the rows, j the columns), with `xi` and `xj` `numpy` or `builtin` scalars, displayed as `y.dtype.str[1:]`, (on my 64bit linux machine with `numpy==2.2.1`, i.e. `f16` is the 
`longdouble` and `c32` the `clongdouble`). 
A `_` is used in case the result type is the same as that of `xi`. A cell is empty if `__add__` returned `NotImplemented` (so `+` would delegate to `xj.__radd__`).

| `_`   | `bool`   | `int`   | `float`   | `complex`   |
|:------|:---------|:--------|:----------|:------------|
| `b1`  | `_`      | `i8`    | `f8`      | `c16`       |
| `u1`  | `_`      | `_`     | `f8`      | `c16`       |
| `u2`  | `_`      | `_`     | `f8`      | `c16`       |
| `u4`  | `_`      | `_`     | `f8`      | `c16`       |
| `u8`  | `_`      | `_`     | `f8`      | `c16`       |
| `i1`  | `_`      | `_`     | `f8`      | `c16`       |
| `i2`  | `_`      | `_`     | `f8`      | `c16`       |
| `i4`  | `_`      | `_`     | `f8`      | `c16`       |
| `i8`  | `_`      | `_`     | `f8`      | `c16`       |
| `f2`  | `_`      | `_`     | `_`       | `c8`        |
| `f4`  | `_`      | `_`     | `_`       | `c8`        |
| `f8`  | `_`      | `_`     | `_`       | `c16`       |
| `f16` | `_`      | `_`     | `_`       | `c32`       |
| `c8`  | `_`      | `_`     | `_`       | `_`         |
| `c16` | `_`      | `_`     | `_`       | `_`         |
| `c32` | `_`      | `_`     | `_`       | `_`         |


(note that `np.float64() + complex()` is a `complex128`, but `complex() + np.float64()` is *just* a `builtins.complex`)


| `_`   | `u1`   | `u2`   | `u4`   | `u8`   | `i1`   | `i2`   | `i4`   | `i8`   |
|:------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|
| `b1`  | `u1`   | `u2`   | `u4`   | `u8`   | `i1`   | `i2`   | `i4`   | `i8`   |
| `u1`  | `_`    |        |        |        | `i2`   |        |        |        |
| `u2`  | `_`    | `_`    |        |        | `i4`   | `i4`   |        |        |
| `u4`  | `_`    | `_`    | `_`    |        | `i8`   | `i8`   | `i8`   |        |
| `u8`  | `_`    | `_`    | `_`    | `_`    | `f8`   | `f8`   | `f8`   | `f8`   |
| `i1`  | `i2`   | `i4`   | `i8`   | `f8`   | `_`    |        |        |        |
| `i2`  | `_`    | `i4`   | `i8`   | `f8`   | `_`    | `_`    |        |        |
| `i4`  | `_`    | `_`    | `i8`   | `f8`   | `_`    | `_`    | `_`    |        |
| `i8`  | `_`    | `_`    | `_`    | `f8`   | `_`    | `_`    | `_`    | `_`    |
| `f2`  | `_`    | `f4`   | `f8`   | `f8`   | `_`    | `f4`   | `f8`   | `f8`   |
| `f4`  | `_`    | `_`    | `f8`   | `f8`   | `_`    | `_`    | `f8`   | `f8`   |
| `f8`  | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `f16` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `c8`  | `_`    | `_`    | `c16`  | `c16`  | `_`    | `_`    | `c16`  | `c16`  |
| `c16` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `c32` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |


| `_`   | `f2`   | `f4`   | `f8`   | `f16`   | `c8`   | `c16`   | `c32`   |
|:------|:-------|:-------|:-------|:--------|:-------|:--------|:--------|
| `b1`  | `f2`   | `f4`   | `f8`   | `f16`   | `c8`   | `c16`   | `c32`   |
| `u1`  |        |        |        |         |        |         |         |
| `u2`  | `f4`   |        |        |         |        |         |         |
| `u4`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `u8`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `i1`  |        |        |        |         |        |         |         |
| `i2`  | `f4`   |        |        |         |        |         |         |
| `i4`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `i8`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `f2`  | `_`    |        |        |         |        |         |         |
| `f4`  | `_`    | `_`    |        |         |        |         |         |
| `f8`  | `_`    | `_`    | `_`    |         | `c16`  |         |         |
| `f16` | `_`    | `_`    | `_`    | `_`     | `c32`  | `c32`   |         |
| `c8`  | `_`    | `_`    | `c16`  | `c32`   | `_`    |         |         |
| `c16` | `_`    | `_`    | `_`    | `c32`   | `_`    | `_`     |         |
| `c32` | `_`    | `_`    | `_`    | `_`     | `_`    | `_`     | `_`     |


 || Thanks both.

I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
```python
from __future__ import annotations
import numpy as np
from typing import Protocol, Self, reveal_type, Literal

class MultiplyWithInt(Protocol):
    def __mul__(self, other: int, /) -> Self:
        ...

a: MultiplyWithInt = 1
b: MultiplyWithInt = 1.0
c: MultiplyWithInt = 1j
d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
h: MultiplyWithInt = np.array([1], dtype=np.int8)
i: MultiplyWithInt = np.array([1], dtype=np.int16)
j: MultiplyWithInt = np.array([1], dtype=np.int32)
k: MultiplyWithInt = np.array([1], dtype=np.int64)
l: MultiplyWithInt = np.array([1], dtype=np.float32)
m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
n: MultiplyWithInt = np.array([1], dtype=np.complex64)
o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error

reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]

reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
```
Should I open that as a new issue? || > Thanks both.
> 
> I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
> 
> ```python
> from __future__ import annotations
> import numpy as np
> from typing import Protocol, Self, reveal_type, Literal
> 
> class MultiplyWithInt(Protocol):
>     def __mul__(self, other: int, /) -> Self:
>         ...
> 
> a: MultiplyWithInt = 1
> b: MultiplyWithInt = 1.0
> c: MultiplyWithInt = 1j
> d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
> e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
> f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
> g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
> h: MultiplyWithInt = np.array([1], dtype=np.int8)
> i: MultiplyWithInt = np.array([1], dtype=np.int16)
> j: MultiplyWithInt = np.array([1], dtype=np.int32)
> k: MultiplyWithInt = np.array([1], dtype=np.int64)
> l: MultiplyWithInt = np.array([1], dtype=np.float32)
> m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
> n: MultiplyWithInt = np.array([1], dtype=np.complex64)
> o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error
> 
> reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]
> 
> reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
> ```
> 
> Should I open that as a new issue?

Good catch! That indeed sounds like a different issue, and I'll have a look at what's going on there. You're of course also free to try and take a shot at fixing it yourself :) || > Thanks both.
> 
> I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
> 
> ```python
> from __future__ import annotations
> import numpy as np
> from typing import Protocol, Self, reveal_type, Literal
> 
> class MultiplyWithInt(Protocol):
>     def __mul__(self, other: int, /) -> Self:
>         ...
> 
> a: MultiplyWithInt = 1
> b: MultiplyWithInt = 1.0
> c: MultiplyWithInt = 1j
> d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
> e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
> f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
> g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
> h: MultiplyWithInt = np.array([1], dtype=np.int8)
> i: MultiplyWithInt = np.array([1], dtype=np.int16)
> j: MultiplyWithInt = np.array([1], dtype=np.int32)
> k: MultiplyWithInt = np.array([1], dtype=np.int64)
> l: MultiplyWithInt = np.array([1], dtype=np.float32)
> m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
> n: MultiplyWithInt = np.array([1], dtype=np.complex64)
> o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error
> 
> reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]
> 
> reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
> ```
> 
> Should I open that as a new issue?

This should be fixed by https://github.com/numpy/numpy/pull/28108",closed,2024-12-23T14:39:56+00:00,2024-12-25T17:04:00+00:00,oscarbenjamin,"00 - Bug, 41 - Static typing",2,"PR#28065 - numpy/_typing/_callable.pyi: @@ -151,19 +151,15 @@ class _IntTrueDiv(Protocol[_NBit1]):|;| class _UnsignedIntOp(Protocol[_NBit1]):|;|     # NOTE: `uint64 + signedinteger -> float64`|;|     @overload|;|-    def __call__(self, other: bool, /) -> unsignedinteger[_NBit1]: ...|;|+    def __call__(self, other: int, /) -> unsignedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: int | signedinteger[Any], /) -> Any: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: unsignedinteger[_NBit2], /) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|     @overload|;|-    def __call__(|;|-        self, other: unsignedinteger[_NBit2], /|;|-    ) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger, /) -> Any: ...|;| |;| @type_check_only|;| class _UnsignedIntBitOp(Protocol[_NBit1]):|;|@@ -207,19 +203,13 @@ class _UnsignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _SignedIntOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> signedinteger[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...|;|+    def __call__(self, other: int, /) -> signedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: signedinteger[_NBit2], /|;|-    ) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger[_NBit2], /) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;| |;| @type_check_only|;| class _SignedIntBitOp(Protocol[_NBit1]):|;|@@ -261,9 +251,7 @@ class _SignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _FloatOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> floating[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> floating[_NBit1] | floating[_NBitInt]: ...|;|+    def __call__(self, other: int, /) -> floating[_NBit1]: ...|;|     @overload|;|     def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|     @overload || PR#28065 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -412,10 +412,10 @@ assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;| assert_type(f8 + c16, np.complex128)|;|-assert_type(i8 + c16, np.complexfloating[_64Bit, _64Bit])|;|+assert_type(i8 + c16, np.complex128)|;| assert_type(c8 + c16, np.complex128 | np.complex64)|;| assert_type(f4 + c16, np.complex128 | np.complex64)|;|-assert_type(i4 + c16, np.complex128 | np.complex64)|;|+assert_type(i4 + c16, np.complex128)|;| assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;|@@ -463,9 +463,9 @@ assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;|-assert_type(i8 + f8, np.floating[_64Bit])|;|+assert_type(i8 + f8, np.float64)|;| assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|-assert_type(i4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;|@@ -502,17 +502,17 @@ assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i8 + u4, Any)|;| assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;|-assert_type(i8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(i8 + f, np.floating[_64Bit])|;|+assert_type(i8 + c, np.complex128)|;|+assert_type(i8 + f, np.float64)|;| assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;|-assert_type(u8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(u8 + f, np.floating[_64Bit])|;|+assert_type(u8 + c, np.complex128)|;|+assert_type(u8 + f, np.float64)|;| assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i8 + i8, np.int64)|;|@@ -521,17 +521,17 @@ assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(u4 + i8, Any)|;| assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;|-assert_type(c + i8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + i8, np.floating[_64Bit])|;|+assert_type(c + i8, np.complex128)|;|+assert_type(f + i8, np.float64)|;| assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;|-assert_type(c + u8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + u8, np.floating[_64Bit])|;|+assert_type(c + u8, np.complex128)|;|+assert_type(f + u8, np.float64)|;| assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit]) || PR#28066 - numpy/_typing/_callable.pyi: @@ -151,19 +151,15 @@ class _IntTrueDiv(Protocol[_NBit1]):|;| class _UnsignedIntOp(Protocol[_NBit1]):|;|     # NOTE: `uint64 + signedinteger -> float64`|;|     @overload|;|-    def __call__(self, other: bool, /) -> unsignedinteger[_NBit1]: ...|;|+    def __call__(self, other: int, /) -> unsignedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: int | signedinteger[Any], /) -> Any: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: unsignedinteger[_NBit2], /) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|     @overload|;|-    def __call__(|;|-        self, other: unsignedinteger[_NBit2], /|;|-    ) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger, /) -> Any: ...|;| |;| @type_check_only|;| class _UnsignedIntBitOp(Protocol[_NBit1]):|;|@@ -207,19 +203,13 @@ class _UnsignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _SignedIntOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> signedinteger[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...|;|+    def __call__(self, other: int, /) -> signedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: signedinteger[_NBit2], /|;|-    ) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger[_NBit2], /) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;| |;| @type_check_only|;| class _SignedIntBitOp(Protocol[_NBit1]):|;|@@ -261,9 +251,7 @@ class _SignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _FloatOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> floating[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> floating[_NBit1] | floating[_NBitInt]: ...|;|+    def __call__(self, other: int, /) -> floating[_NBit1]: ...|;|     @overload|;|     def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|     @overload || PR#28066 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -412,10 +412,10 @@ assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;| assert_type(f8 + c16, np.complex128)|;|-assert_type(i8 + c16, np.complexfloating[_64Bit, _64Bit])|;|+assert_type(i8 + c16, np.complex128)|;| assert_type(c8 + c16, np.complex128 | np.complex64)|;| assert_type(f4 + c16, np.complex128 | np.complex64)|;|-assert_type(i4 + c16, np.complex128 | np.complex64)|;|+assert_type(i4 + c16, np.complex128)|;| assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;|@@ -463,9 +463,9 @@ assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;|-assert_type(i8 + f8, np.floating[_64Bit])|;|+assert_type(i8 + f8, np.float64)|;| assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|-assert_type(i4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;|@@ -502,17 +502,17 @@ assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i8 + u4, Any)|;| assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;|-assert_type(i8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(i8 + f, np.floating[_64Bit])|;|+assert_type(i8 + c, np.complex128)|;|+assert_type(i8 + f, np.float64)|;| assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;|-assert_type(u8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(u8 + f, np.floating[_64Bit])|;|+assert_type(u8 + c, np.complex128)|;|+assert_type(u8 + f, np.float64)|;| assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i8 + i8, np.int64)|;|@@ -521,17 +521,17 @@ assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(u4 + i8, Any)|;| assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;|-assert_type(c + i8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + i8, np.floating[_64Bit])|;|+assert_type(c + i8, np.complex128)|;|+assert_type(f + i8, np.float64)|;| assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;|-assert_type(c + u8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + u8, np.floating[_64Bit])|;|+assert_type(c + u8, np.complex128)|;|+assert_type(f + u8, np.float64)|;| assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])","TYP: fix unnecessarily broad `integer` binop return types || MAINT: Fix linter complaint. || TYP: fix unnecessarily broad `integer` binop return types (#28065)

* TYP: fix unnecessarily broad `integer` binop return types

* MAINT: Fix linter complaint.

---------

Co-authored-by: Charles Harris <charlesr.harris@gmail.com>"
numpy/numpy,charris,28057,TYP: Mixed scalar/int binary operations have incorrect type annotation,"### Describe the issue:

The type annotations used for scalar/int binary operations like `np.float32(1) * 2` imply that the scalar types are not closed under e.g. multiplication with `int`:
```python
reveal_type(np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * 1) # signedinteger[_8Bit] | signedinteger[_32Bit | _64Bit]
```
As far as I can tell mixed operations with `int` don't actually promote the type:
```python
>>> np.int8(1) * 128
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
OverflowError: Python integer 128 out of bounds for int8
```
It comes from here:
https://github.com/numpy/numpy/blob/a7eda47eee93618a5cf7a21fd37c2f3c56134710/numpy/__init__.pyi#L3768-L3776
And that uses:
https://github.com/numpy/numpy/blob/a7eda47eee93618a5cf7a21fd37c2f3c56134710/numpy/_typing/_callable.pyi#L207-L222
I think that the problematic overload is:
```python
def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...
```
Is there a reason that `| int_` is needed there?

### Reproduce the code example:

```python
from __future__ import annotations
import numpy as np
from typing import Protocol, Self, reveal_type

class MultiplyWithInt(Protocol):
    def __mul__(self, other: int, /) -> Self:
        ...

a: MultiplyWithInt = 1
b: MultiplyWithInt = 1.0
c: MultiplyWithInt = 1j
d: MultiplyWithInt = np.uint8(1)
e: MultiplyWithInt = np.uint16(1)
f: MultiplyWithInt = np.uint32(1)
g: MultiplyWithInt = np.uint64(1)
h: MultiplyWithInt = np.int8(1) # type check error
i: MultiplyWithInt = np.int16(1) # type check error
j: MultiplyWithInt = np.int32(1) # type check error
k: MultiplyWithInt = np.int64(1)
l: MultiplyWithInt = np.float32(1.0) # type check error
m: MultiplyWithInt = np.float64(1.0)
n: MultiplyWithInt = np.complex64(1) # type check error
o: MultiplyWithInt = np.complex128(1)

reveal_type(np.uint8(1)) # unsignedinteger[_8Bit]
reveal_type(np.uint8(1) * 1) # Any
reveal_type(np.uint8(1) * np.uint8(1)) # unsignedinteger[_8Bit]

reveal_type(np.int8(1)) # signedinteger[_8Bit]
reveal_type(np.int8(1) * 1) # signedinteger[_8Bit] | signedinteger[_32Bit | _64Bit]
reveal_type(np.int8(1) * np.int8(1)) # signedinteger[_8Bit]
```


### Error message:

_No response_

### Python and NumPy Versions:

Python 3.12
NumPy 2.2.1

### Runtime Environment:

_No response_

### Context for the issue:

I'm trying to write generically typed code with rings like:
```python
from typing import Protocol, Self, Literal

type _PositiveInteger = Literal[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

class RingElement(Protocol):
    """"""Elements supporting ring operations.""""""

    def __pos__(self) -> Self: ...
    def __neg__(self) -> Self: ...
    def __add__(self, other: Self, /) -> Self: ...
    def __mul__(self, other: Self | int, /) -> Self: ...
    def __rmul__(self, other: int, /) -> Self: ...
    def __pow__(self, other: _PositiveInteger, /) -> Self: ...
```
The allowance for multiplication with `int` is so that with this protocol you can have code like `2*x + y*2`. Both mypy and pyright think that some of numpy's scalar types are incompatible with this protocol because they are not closed under multiplication with `int`.","Thanks for reporting this!

Technically speaking, the return type annotation for `integer.__add__` isn't *incorrect* here; it's just unnecessarily broad. But as you demonstrated, this can lead to unexpected behavior, which can be especially annoying in the case of structural typing (i.e. a `Protocol`).

So to answer your question:

> Is there a reason that `| int_` is needed there?

No. It should be removed. And I will.

But I suppose that it isn't far-fetched to (incorrectly) assume that `np.array(1, np.int8) + np.array(2)` would have the same scalar type as `np.int8(1) + 2` would -- especially if you also take the fact that `np.int(8) + 1.0` is `np.float64(3.0)` into account.

 || For (mostly my own) reference, I tabulated the resulting dtypes of `y = xi.__add__(xj)` (i the rows, j the columns), with `xi` and `xj` `numpy` or `builtin` scalars, displayed as `y.dtype.str[1:]`, (on my 64bit linux machine with `numpy==2.2.1`, i.e. `f16` is the 
`longdouble` and `c32` the `clongdouble`). 
A `_` is used in case the result type is the same as that of `xi`. A cell is empty if `__add__` returned `NotImplemented` (so `+` would delegate to `xj.__radd__`).

| `_`   | `bool`   | `int`   | `float`   | `complex`   |
|:------|:---------|:--------|:----------|:------------|
| `b1`  | `_`      | `i8`    | `f8`      | `c16`       |
| `u1`  | `_`      | `_`     | `f8`      | `c16`       |
| `u2`  | `_`      | `_`     | `f8`      | `c16`       |
| `u4`  | `_`      | `_`     | `f8`      | `c16`       |
| `u8`  | `_`      | `_`     | `f8`      | `c16`       |
| `i1`  | `_`      | `_`     | `f8`      | `c16`       |
| `i2`  | `_`      | `_`     | `f8`      | `c16`       |
| `i4`  | `_`      | `_`     | `f8`      | `c16`       |
| `i8`  | `_`      | `_`     | `f8`      | `c16`       |
| `f2`  | `_`      | `_`     | `_`       | `c8`        |
| `f4`  | `_`      | `_`     | `_`       | `c8`        |
| `f8`  | `_`      | `_`     | `_`       | `c16`       |
| `f16` | `_`      | `_`     | `_`       | `c32`       |
| `c8`  | `_`      | `_`     | `_`       | `_`         |
| `c16` | `_`      | `_`     | `_`       | `_`         |
| `c32` | `_`      | `_`     | `_`       | `_`         |


(note that `np.float64() + complex()` is a `complex128`, but `complex() + np.float64()` is *just* a `builtins.complex`)


| `_`   | `u1`   | `u2`   | `u4`   | `u8`   | `i1`   | `i2`   | `i4`   | `i8`   |
|:------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|
| `b1`  | `u1`   | `u2`   | `u4`   | `u8`   | `i1`   | `i2`   | `i4`   | `i8`   |
| `u1`  | `_`    |        |        |        | `i2`   |        |        |        |
| `u2`  | `_`    | `_`    |        |        | `i4`   | `i4`   |        |        |
| `u4`  | `_`    | `_`    | `_`    |        | `i8`   | `i8`   | `i8`   |        |
| `u8`  | `_`    | `_`    | `_`    | `_`    | `f8`   | `f8`   | `f8`   | `f8`   |
| `i1`  | `i2`   | `i4`   | `i8`   | `f8`   | `_`    |        |        |        |
| `i2`  | `_`    | `i4`   | `i8`   | `f8`   | `_`    | `_`    |        |        |
| `i4`  | `_`    | `_`    | `i8`   | `f8`   | `_`    | `_`    | `_`    |        |
| `i8`  | `_`    | `_`    | `_`    | `f8`   | `_`    | `_`    | `_`    | `_`    |
| `f2`  | `_`    | `f4`   | `f8`   | `f8`   | `_`    | `f4`   | `f8`   | `f8`   |
| `f4`  | `_`    | `_`    | `f8`   | `f8`   | `_`    | `_`    | `f8`   | `f8`   |
| `f8`  | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `f16` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `c8`  | `_`    | `_`    | `c16`  | `c16`  | `_`    | `_`    | `c16`  | `c16`  |
| `c16` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |
| `c32` | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    | `_`    |


| `_`   | `f2`   | `f4`   | `f8`   | `f16`   | `c8`   | `c16`   | `c32`   |
|:------|:-------|:-------|:-------|:--------|:-------|:--------|:--------|
| `b1`  | `f2`   | `f4`   | `f8`   | `f16`   | `c8`   | `c16`   | `c32`   |
| `u1`  |        |        |        |         |        |         |         |
| `u2`  | `f4`   |        |        |         |        |         |         |
| `u4`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `u8`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `i1`  |        |        |        |         |        |         |         |
| `i2`  | `f4`   |        |        |         |        |         |         |
| `i4`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `i8`  | `f8`   | `f8`   |        |         | `c16`  |         |         |
| `f2`  | `_`    |        |        |         |        |         |         |
| `f4`  | `_`    | `_`    |        |         |        |         |         |
| `f8`  | `_`    | `_`    | `_`    |         | `c16`  |         |         |
| `f16` | `_`    | `_`    | `_`    | `_`     | `c32`  | `c32`   |         |
| `c8`  | `_`    | `_`    | `c16`  | `c32`   | `_`    |         |         |
| `c16` | `_`    | `_`    | `_`    | `c32`   | `_`    | `_`     |         |
| `c32` | `_`    | `_`    | `_`    | `_`     | `_`    | `_`     | `_`     |


 || Thanks both.

I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
```python
from __future__ import annotations
import numpy as np
from typing import Protocol, Self, reveal_type, Literal

class MultiplyWithInt(Protocol):
    def __mul__(self, other: int, /) -> Self:
        ...

a: MultiplyWithInt = 1
b: MultiplyWithInt = 1.0
c: MultiplyWithInt = 1j
d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
h: MultiplyWithInt = np.array([1], dtype=np.int8)
i: MultiplyWithInt = np.array([1], dtype=np.int16)
j: MultiplyWithInt = np.array([1], dtype=np.int32)
k: MultiplyWithInt = np.array([1], dtype=np.int64)
l: MultiplyWithInt = np.array([1], dtype=np.float32)
m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
n: MultiplyWithInt = np.array([1], dtype=np.complex64)
o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error

reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]

reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
```
Should I open that as a new issue? || > Thanks both.
> 
> I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
> 
> ```python
> from __future__ import annotations
> import numpy as np
> from typing import Protocol, Self, reveal_type, Literal
> 
> class MultiplyWithInt(Protocol):
>     def __mul__(self, other: int, /) -> Self:
>         ...
> 
> a: MultiplyWithInt = 1
> b: MultiplyWithInt = 1.0
> c: MultiplyWithInt = 1j
> d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
> e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
> f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
> g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
> h: MultiplyWithInt = np.array([1], dtype=np.int8)
> i: MultiplyWithInt = np.array([1], dtype=np.int16)
> j: MultiplyWithInt = np.array([1], dtype=np.int32)
> k: MultiplyWithInt = np.array([1], dtype=np.int64)
> l: MultiplyWithInt = np.array([1], dtype=np.float32)
> m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
> n: MultiplyWithInt = np.array([1], dtype=np.complex64)
> o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error
> 
> reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]
> 
> reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
> ```
> 
> Should I open that as a new issue?

Good catch! That indeed sounds like a different issue, and I'll have a look at what's going on there. You're of course also free to try and take a shot at fixing it yourself :) || > Thanks both.
> 
> I also found similar problems with arrays rather than scalars although this time the type check errors are almost for the opposite set of dtypes:
> 
> ```python
> from __future__ import annotations
> import numpy as np
> from typing import Protocol, Self, reveal_type, Literal
> 
> class MultiplyWithInt(Protocol):
>     def __mul__(self, other: int, /) -> Self:
>         ...
> 
> a: MultiplyWithInt = 1
> b: MultiplyWithInt = 1.0
> c: MultiplyWithInt = 1j
> d: MultiplyWithInt = np.array([1], dtype=np.uint8) # type check error
> e: MultiplyWithInt = np.array([1], dtype=np.uint16) # type check error
> f: MultiplyWithInt = np.array([1], dtype=np.uint32) # type check error
> g: MultiplyWithInt = np.array([1], dtype=np.uint64) # type check error
> h: MultiplyWithInt = np.array([1], dtype=np.int8)
> i: MultiplyWithInt = np.array([1], dtype=np.int16)
> j: MultiplyWithInt = np.array([1], dtype=np.int32)
> k: MultiplyWithInt = np.array([1], dtype=np.int64)
> l: MultiplyWithInt = np.array([1], dtype=np.float32)
> m: MultiplyWithInt = np.array([1], dtype=np.float64) # type check error
> n: MultiplyWithInt = np.array([1], dtype=np.complex64)
> o: MultiplyWithInt = np.array([1], dtype=np.complex128) # type check error
> 
> reveal_type(np.array([1], dtype=np.uint8)) # dtype[unsignedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.uint8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.uint8) * np.uint8(1)) # dtype[unsignedinteger[Any]]
> 
> reveal_type(np.array([1], dtype=np.int8)) # dtype[signedinteger[_8bit]]
> reveal_type(np.array([1], dtype=np.int8) * 1) # dtype[signedinteger[Any]]
> reveal_type(np.array([1], dtype=np.int8) * np.int8(1)) # dtype[signedinteger[Any]]
> ```
> 
> Should I open that as a new issue?

This should be fixed by https://github.com/numpy/numpy/pull/28108",closed,2024-12-23T14:39:56+00:00,2024-12-25T17:04:00+00:00,oscarbenjamin,"00 - Bug, 41 - Static typing",2,"PR#28065 - numpy/_typing/_callable.pyi: @@ -151,19 +151,15 @@ class _IntTrueDiv(Protocol[_NBit1]):|;| class _UnsignedIntOp(Protocol[_NBit1]):|;|     # NOTE: `uint64 + signedinteger -> float64`|;|     @overload|;|-    def __call__(self, other: bool, /) -> unsignedinteger[_NBit1]: ...|;|+    def __call__(self, other: int, /) -> unsignedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: int | signedinteger[Any], /) -> Any: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: unsignedinteger[_NBit2], /) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|     @overload|;|-    def __call__(|;|-        self, other: unsignedinteger[_NBit2], /|;|-    ) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger, /) -> Any: ...|;| |;| @type_check_only|;| class _UnsignedIntBitOp(Protocol[_NBit1]):|;|@@ -207,19 +203,13 @@ class _UnsignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _SignedIntOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> signedinteger[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...|;|+    def __call__(self, other: int, /) -> signedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: signedinteger[_NBit2], /|;|-    ) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger[_NBit2], /) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;| |;| @type_check_only|;| class _SignedIntBitOp(Protocol[_NBit1]):|;|@@ -261,9 +251,7 @@ class _SignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _FloatOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> floating[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> floating[_NBit1] | floating[_NBitInt]: ...|;|+    def __call__(self, other: int, /) -> floating[_NBit1]: ...|;|     @overload|;|     def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|     @overload || PR#28065 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -412,10 +412,10 @@ assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;| assert_type(f8 + c16, np.complex128)|;|-assert_type(i8 + c16, np.complexfloating[_64Bit, _64Bit])|;|+assert_type(i8 + c16, np.complex128)|;| assert_type(c8 + c16, np.complex128 | np.complex64)|;| assert_type(f4 + c16, np.complex128 | np.complex64)|;|-assert_type(i4 + c16, np.complex128 | np.complex64)|;|+assert_type(i4 + c16, np.complex128)|;| assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;|@@ -463,9 +463,9 @@ assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;|-assert_type(i8 + f8, np.floating[_64Bit])|;|+assert_type(i8 + f8, np.float64)|;| assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|-assert_type(i4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;|@@ -502,17 +502,17 @@ assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i8 + u4, Any)|;| assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;|-assert_type(i8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(i8 + f, np.floating[_64Bit])|;|+assert_type(i8 + c, np.complex128)|;|+assert_type(i8 + f, np.float64)|;| assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;|-assert_type(u8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(u8 + f, np.floating[_64Bit])|;|+assert_type(u8 + c, np.complex128)|;|+assert_type(u8 + f, np.float64)|;| assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i8 + i8, np.int64)|;|@@ -521,17 +521,17 @@ assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(u4 + i8, Any)|;| assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;|-assert_type(c + i8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + i8, np.floating[_64Bit])|;|+assert_type(c + i8, np.complex128)|;|+assert_type(f + i8, np.float64)|;| assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;|-assert_type(c + u8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + u8, np.floating[_64Bit])|;|+assert_type(c + u8, np.complex128)|;|+assert_type(f + u8, np.float64)|;| assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit]) || PR#28066 - numpy/_typing/_callable.pyi: @@ -151,19 +151,15 @@ class _IntTrueDiv(Protocol[_NBit1]):|;| class _UnsignedIntOp(Protocol[_NBit1]):|;|     # NOTE: `uint64 + signedinteger -> float64`|;|     @overload|;|-    def __call__(self, other: bool, /) -> unsignedinteger[_NBit1]: ...|;|+    def __call__(self, other: int, /) -> unsignedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: int | signedinteger[Any], /) -> Any: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: unsignedinteger[_NBit2], /) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|     @overload|;|-    def __call__(|;|-        self, other: unsignedinteger[_NBit2], /|;|-    ) -> unsignedinteger[_NBit1] | unsignedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger, /) -> Any: ...|;| |;| @type_check_only|;| class _UnsignedIntBitOp(Protocol[_NBit1]):|;|@@ -207,19 +203,13 @@ class _UnsignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _SignedIntOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> signedinteger[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> signedinteger[_NBit1] | int_: ...|;|+    def __call__(self, other: int, /) -> signedinteger[_NBit1]: ...|;|     @overload|;|-    def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|+    def __call__(self, other: float, /) -> float64: ...|;|     @overload|;|-    def __call__(|;|-        self, other: complex, /|;|-    ) -> complexfloating[_NBit1, _NBit1] | complex128: ...|;|+    def __call__(self, other: complex, /) -> complex128: ...|;|     @overload|;|-    def __call__(|;|-        self, other: signedinteger[_NBit2], /|;|-    ) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;|+    def __call__(self, other: signedinteger[_NBit2], /) -> signedinteger[_NBit1] | signedinteger[_NBit2]: ...|;| |;| @type_check_only|;| class _SignedIntBitOp(Protocol[_NBit1]):|;|@@ -261,9 +251,7 @@ class _SignedIntDivMod(Protocol[_NBit1]):|;| @type_check_only|;| class _FloatOp(Protocol[_NBit1]):|;|     @overload|;|-    def __call__(self, other: bool, /) -> floating[_NBit1]: ...|;|-    @overload|;|-    def __call__(self, other: int, /) -> floating[_NBit1] | floating[_NBitInt]: ...|;|+    def __call__(self, other: int, /) -> floating[_NBit1]: ...|;|     @overload|;|     def __call__(self, other: float, /) -> floating[_NBit1] | float64: ...|;|     @overload || PR#28066 - numpy/typing/tests/data/reveal/arithmetic.pyi: @@ -412,10 +412,10 @@ assert_type(c16 + AR_f, npt.NDArray[np.complexfloating[Any, Any]])|;| assert_type(f16 + c16, np.complex128 | np.complexfloating[_128Bit, _128Bit])|;| assert_type(c16 + c16, np.complex128)|;| assert_type(f8 + c16, np.complex128)|;|-assert_type(i8 + c16, np.complexfloating[_64Bit, _64Bit])|;|+assert_type(i8 + c16, np.complex128)|;| assert_type(c8 + c16, np.complex128 | np.complex64)|;| assert_type(f4 + c16, np.complex128 | np.complex64)|;|-assert_type(i4 + c16, np.complex128 | np.complex64)|;|+assert_type(i4 + c16, np.complex128)|;| assert_type(b_ + c16, np.complex128)|;| assert_type(b + c16, np.complex128)|;| assert_type(c + c16, np.complex128)|;|@@ -463,9 +463,9 @@ assert_type(f8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(f16 + f8, np.floating[_128Bit] | np.float64)|;| assert_type(f8 + f8, np.float64)|;|-assert_type(i8 + f8, np.floating[_64Bit])|;|+assert_type(i8 + f8, np.float64)|;| assert_type(f4 + f8, np.floating[_32Bit] | np.float64)|;|-assert_type(i4 + f8, np.floating[_32Bit] | np.float64)|;|+assert_type(i4 + f8,np.float64)|;| assert_type(b_ + f8, np.float64)|;| assert_type(b + f8, np.float64)|;| assert_type(c + f8, np.complex128 | np.float64)|;|@@ -502,17 +502,17 @@ assert_type(i8 + i4, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(i8 + u4, Any)|;| assert_type(i8 + b_, np.int64)|;| assert_type(i8 + b, np.int64)|;|-assert_type(i8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(i8 + f, np.floating[_64Bit])|;|+assert_type(i8 + c, np.complex128)|;|+assert_type(i8 + f, np.float64)|;| assert_type(i8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(u8 + i4, Any)|;| assert_type(u8 + u4, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(u8 + b_, np.uint64)|;| assert_type(u8 + b, np.uint64)|;|-assert_type(u8 + c, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(u8 + f, np.floating[_64Bit])|;|+assert_type(u8 + c, np.complex128)|;|+assert_type(u8 + f, np.float64)|;| assert_type(u8 + AR_f, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i8 + i8, np.int64)|;|@@ -521,17 +521,17 @@ assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])|;| assert_type(u4 + i8, Any)|;| assert_type(b_ + i8, np.int64)|;| assert_type(b + i8, np.int64)|;|-assert_type(c + i8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + i8, np.floating[_64Bit])|;|+assert_type(c + i8, np.complex128)|;|+assert_type(f + i8, np.float64)|;| assert_type(AR_f + i8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(u8 + u8, np.uint64)|;| assert_type(i4 + u8, Any)|;| assert_type(u4 + u8, np.unsignedinteger[_32Bit] | np.unsignedinteger[_64Bit])|;| assert_type(b_ + u8, np.uint64)|;| assert_type(b + u8, np.uint64)|;|-assert_type(c + u8, np.complexfloating[_64Bit, _64Bit])|;|-assert_type(f + u8, np.floating[_64Bit])|;|+assert_type(c + u8, np.complex128)|;|+assert_type(f + u8, np.float64)|;| assert_type(AR_f + u8, npt.NDArray[np.floating[Any]])|;| |;| assert_type(i4 + i8, np.signedinteger[_32Bit] | np.signedinteger[_64Bit])","TYP: fix unnecessarily broad `integer` binop return types || MAINT: Fix linter complaint. || TYP: fix unnecessarily broad `integer` binop return types (#28065)

* TYP: fix unnecessarily broad `integer` binop return types

* MAINT: Fix linter complaint.

---------

Co-authored-by: Charles Harris <charlesr.harris@gmail.com>"
numpy/numpy,simonaltrogge,28038,TYP: `nditer` does not allow `None`-valued elements in operand sequence,"### Describe the issue:

Passing `None`-valued elements next to array_like-valued elements in a sequence as operands to `nditer` is part of the documented idiom of [iterator-allocated output arrays](https://numpy.org/doc/stable/reference/arrays.nditer.html#iterator-allocated-output-arrays). Mentions of this can also be found in the [documentation of `nditer`](https://numpy.org/doc/stable/reference/generated/numpy.nditer.html) directly. The type-hints do not reflect this, however, and lead to an error instead when using this intended way of calling `nditer`.

### Reproduce the code example:

```python
import numpy as np
import numpy.typing as npt

def square(a: npt.NDArray):
    with np.nditer([a, None]) as it:
        for x, y in it:
            y[...] = x*x
        return it.operands[1]
```


### Error message:

```shell
Argument of type ""list[NDArray[Unknown] | None]"" cannot be assigned to parameter ""op"" of type ""ArrayLike | Sequence[ArrayLike]"" in function ""__new__""
  Type ""None"" is not assignable to type ""ArrayLike""
    ""None"" is incompatible with protocol ""Buffer""
      ""__buffer__"" is not present
    ""None"" is incompatible with protocol ""_SupportsArray[dtype[Any]]""
      ""__array__"" is not present
    ""None"" is incompatible with protocol ""_NestedSequence[_SupportsArray[dtype[Any]]]""
      ""__len__"" is not present
      ""__getitem__"" is not present Pylance (reportArgumentType)
```


### Python and NumPy Versions:

2.2.0
3.13.1 | packaged by conda-forge | (main, Dec  5 2024, 21:23:54) [GCC 13.3.0]

### Type-checker version and settings:

Pylance 2024.12.1 used in Visual Studio Code 1.96.0

### Additional typing packages.

_No response_","Thanks for the report! This is indeed seems to be a valid use-case that currently is falsely rejected, and is reproducible.


---

> Mentions of this can also be found in the [documentation of `nditer`](https://numpy.org/doc/stable/reference/generated/numpy.nditer.html) directly.

Where exactly? I can't seem to find it.

## Minimal repro

```pycon
>>> import numpy as np
>>> np.__version__
'2.2.0'
>>> list(np.nditer([np.ones(3), None]))
[(array(1.), array(6.31480055e-310)), (array(1.), array(6.31480055e-310)), (array(1.), array(1.6e-322))]
```

This `[...]/issue_28038.pyi` example is rejected by both mypy and pyright:

```pyi
import numpy as np
import numpy.typing as npt

a: npt.NDArray[np.float32]
np.nditer([a, None])
```

mypy output:

```
Argument 1 to ""nditer"" has incompatible type ""list[ndarray[tuple[int, ...], dtype[floating[_32Bit]]] | None]""; expected ""Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes] | Sequence[Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes]]""
```

pyright output:

```
Argument of type ""list[NDArray[float32] | None]"" cannot be assigned to parameter ""op"" of type ""ArrayLike | Sequence[ArrayLike]"" in function ""__new__""
  Type ""None"" is not assignable to type ""ArrayLike""
    ""None"" is incompatible with protocol ""Buffer""
      ""__buffer__"" is not present
    ""None"" is incompatible with protocol ""_SupportsArray[dtype[Any]]""
      ""__array__"" is not present
    ""None"" is incompatible with protocol ""_NestedSequence[_SupportsArray[dtype[Any]]]""
      ""__len__"" is not present
      ""__getitem__"" is not present
```

## The cause

`np.nditer.__new__` only accepts array-likes or sequences of array-likes for its first `op` parameter:
https://github.com/numpy/numpy/blob/e7a123b2d3eca9897843791dd698c1803d9a39c2/numpy/__init__.pyi#L4703-L4715

After seeing this, you can probably already see how this could be fixed. Do you want to give it a try, and submit a PR for this @simonaltrogge ?

 || Admittedly, it is more indirectly than directly: “`allocate` causes the array to be allocated if it is None in the `op` parameter.”

Regarding the PR, that’s already done, see #28039. :)",closed,2024-12-19T15:08:57+00:00,2024-12-20T14:09:02+00:00,simonaltrogge,41 - Static typing,2,"PR#28044 - numpy/__init__.pyi: @@ -4746,7 +4746,7 @@ class iinfo(Generic[_IntegerT_co]):|;| class nditer:|;|     def __new__(|;|         cls,|;|-        op: ArrayLike | Sequence[ArrayLike],|;|+        op: ArrayLike | Sequence[ArrayLike | None],|;|         flags: None | Sequence[_NDIterFlagsKind] = ...,|;|         op_flags: None | Sequence[Sequence[_NDIterFlagsOp]] = ...,|;|         op_dtypes: DTypeLike | Sequence[DTypeLike] = ..., || PR#28044 - numpy/typing/tests/data/pass/nditer.py: @@ -0,0 +1,4 @@|;|+import numpy as np|;|+|;|+arr = np.array([1])|;|+np.nditer([arr, None]) || PR#28039 - numpy/__init__.pyi: @@ -4740,7 +4740,7 @@ class iinfo(Generic[_IntegerT_co]):|;| class nditer:|;|     def __new__(|;|         cls,|;|-        op: ArrayLike | Sequence[ArrayLike],|;|+        op: ArrayLike | Sequence[ArrayLike | None],|;|         flags: None | Sequence[_NDIterFlagsKind] = ...,|;|         op_flags: None | Sequence[Sequence[_NDIterFlagsOp]] = ...,|;|         op_dtypes: DTypeLike | Sequence[DTypeLike] = ..., || PR#28039 - numpy/typing/tests/data/pass/nditer.py: @@ -0,0 +1,4 @@|;|+import numpy as np|;|+|;|+arr = np.array([1])|;|+np.nditer([arr, None])","TYP: allow `None` in operand sequence of nditer

Prevent type-hint errors when using `nditer` in an intended way (see https://numpy.org/doc/stable/reference/arrays.nditer.html#iterator-allocated-output-arrays).

Fix #28038 || TST: Add test for allowing `None` in operand sequence passed to `nditer` || TYP: allow `None` in operand sequence of nditer

Prevent type-hint errors when using `nditer` in an intended way (see https://numpy.org/doc/stable/reference/arrays.nditer.html#iterator-allocated-output-arrays).

Fix #28038 || TST: Add test for allowing `None` in operand sequence passed to `nditer`"
numpy/numpy,seberg,28019,"TST,DOC: Bump `scipy_doctest` (or remove pin) and fix new failures","@ev-br ping FYI,  since the new scipy-doctest release (less than an hour ago) the refcheck has universal failures.

I suspect, this is all just bad documentation that needs fixing, but not sure yet.  In either case, until fixed both CircleCI and the ""benchmark"" tests which also still run the refcheck are expected to fail.

(Currently, also the linter just started failing...)","We should pin tools to a specific version, and update in a controlled fasion. || I see we do not pin matplotlib, scipy, pytz, pandas. Should we? || > I see we do not pin matplotlib, scipy, pytz, pandas. Should we?

Seems fine not to, since I don't think we ever ran into an issue and it seems simple enough to add when we do?
But yes, in this case unless someone wants to sprint on fixing everything, it probably makes sense to add a lower pin and remove after that is OK. || Here's  failing job: https://app.circleci.com/pipelines/github/numpy/numpy/30210/workflows/1d8f4112-60a7-42f9-ae82-3ff7ed57b6b5/jobs/44299

Two kinds of issues:
- the fix for https://github.com/numpy/numpy/issues/28002 : dtype methods were never tested and now they are, with predictable results :-). 
- we discovered in https://github.com/scipy/scipy/pull/22027#issuecomment-2536212386 that the doctester was missing inherited methods. I suspect the polynomial failures are of this variety.
 
The issues at `.strides`, `.shape` and `.fields` (duplicated many times over across dtype classes) are certainly bad/non-ideal examples. || Reopening, we really should fix the new failures (and bump the version) soon! || Should have been closed when merging gh-28023",closed,2024-12-17T11:59:12+00:00,2024-12-19T08:19:00+00:00,seberg,,2,"PR#28021 - .github/workflows/linux.yml: @@ -188,7 +188,7 @@ jobs:|;|     - name: Check docstests|;|       shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|       run: ||;|-        pip install scipy-doctest hypothesis matplotlib scipy pytz pandas|;|+        pip install scipy-doctest==1.5.1 hypothesis==6.104.1 matplotlib scipy pytz pandas|;|         spin check-docs -v|;|         spin check-tutorials -v|;|  || PR#28021 - requirements/doc_requirements.txt: @@ -18,4 +18,4 @@ towncrier|;| toml|;| |;| # for doctests, also needs pytz which is in test_requirements|;|-scipy-doctest|;|+scipy-doctest==1.5.1 || PR#28020 - .github/workflows/linux.yml: @@ -197,7 +197,7 @@ jobs:|;|     - name: Check docstests|;|       shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|       run: ||;|-        pip install scipy-doctest hypothesis matplotlib scipy pytz pandas|;|+        pip install scipy-doctest==1.5.1 hypothesis==6.104.1 matplotlib scipy pytz pandas|;|         spin check-docs -v|;|         spin check-tutorials -v|;|  || PR#28020 - requirements/doc_requirements.txt: @@ -18,4 +18,4 @@ towncrier|;| toml|;| |;| # for doctests, also needs pytz which is in test_requirements|;|-scipy-doctest|;|+scipy-doctest==1.5.1","CI: pin scipy-doctest to 1.5.1 (#28020)

Pin scipy-doctest to 1.5.1 until new errors in previously uncovered tests are fixed. || pin scipy-doctest to 1.5.1 || Update requirements/doc_requirements.txt"
numpy/numpy,mattip,28019,"TST,DOC: Bump `scipy_doctest` (or remove pin) and fix new failures","@ev-br ping FYI,  since the new scipy-doctest release (less than an hour ago) the refcheck has universal failures.

I suspect, this is all just bad documentation that needs fixing, but not sure yet.  In either case, until fixed both CircleCI and the ""benchmark"" tests which also still run the refcheck are expected to fail.

(Currently, also the linter just started failing...)","We should pin tools to a specific version, and update in a controlled fasion. || I see we do not pin matplotlib, scipy, pytz, pandas. Should we? || > I see we do not pin matplotlib, scipy, pytz, pandas. Should we?

Seems fine not to, since I don't think we ever ran into an issue and it seems simple enough to add when we do?
But yes, in this case unless someone wants to sprint on fixing everything, it probably makes sense to add a lower pin and remove after that is OK. || Here's  failing job: https://app.circleci.com/pipelines/github/numpy/numpy/30210/workflows/1d8f4112-60a7-42f9-ae82-3ff7ed57b6b5/jobs/44299

Two kinds of issues:
- the fix for https://github.com/numpy/numpy/issues/28002 : dtype methods were never tested and now they are, with predictable results :-). 
- we discovered in https://github.com/scipy/scipy/pull/22027#issuecomment-2536212386 that the doctester was missing inherited methods. I suspect the polynomial failures are of this variety.
 
The issues at `.strides`, `.shape` and `.fields` (duplicated many times over across dtype classes) are certainly bad/non-ideal examples. || Reopening, we really should fix the new failures (and bump the version) soon! || Should have been closed when merging gh-28023",closed,2024-12-17T11:59:12+00:00,2024-12-19T08:19:00+00:00,seberg,,2,"PR#28021 - .github/workflows/linux.yml: @@ -188,7 +188,7 @@ jobs:|;|     - name: Check docstests|;|       shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|       run: ||;|-        pip install scipy-doctest hypothesis matplotlib scipy pytz pandas|;|+        pip install scipy-doctest==1.5.1 hypothesis==6.104.1 matplotlib scipy pytz pandas|;|         spin check-docs -v|;|         spin check-tutorials -v|;|  || PR#28021 - requirements/doc_requirements.txt: @@ -18,4 +18,4 @@ towncrier|;| toml|;| |;| # for doctests, also needs pytz which is in test_requirements|;|-scipy-doctest|;|+scipy-doctest==1.5.1 || PR#28020 - .github/workflows/linux.yml: @@ -197,7 +197,7 @@ jobs:|;|     - name: Check docstests|;|       shell: 'script -q -e -c ""bash --noprofile --norc -eo pipefail {0}""'|;|       run: ||;|-        pip install scipy-doctest hypothesis matplotlib scipy pytz pandas|;|+        pip install scipy-doctest==1.5.1 hypothesis==6.104.1 matplotlib scipy pytz pandas|;|         spin check-docs -v|;|         spin check-tutorials -v|;|  || PR#28020 - requirements/doc_requirements.txt: @@ -18,4 +18,4 @@ towncrier|;| toml|;| |;| # for doctests, also needs pytz which is in test_requirements|;|-scipy-doctest|;|+scipy-doctest==1.5.1","CI: pin scipy-doctest to 1.5.1 (#28020)

Pin scipy-doctest to 1.5.1 until new errors in previously uncovered tests are fixed. || pin scipy-doctest to 1.5.1 || Update requirements/doc_requirements.txt"
numpy/numpy,ngoldbaum,27953,BUG: Python (debug mode+free threading) segfaults at exit since Numpy 2.2.0,"### Describe the issue:

Numpy 2.1.3 works fine but with 2.2.0 the interpreter segfaults at exit.

Both Python 3.13.0t and 3.13.1t segfault at exit, both 3.13.0 and 3.13.1 do not.

I can reproduce this on macOS (amd64), Debian 11 (amd64) and Debian 12 (arm64). However also other combinations might be affected.

All the interpreters are built in debug mode with pyenv, ex. `pyenv install -g 3.13.1t`. ~Did not check if non-debug builds are affected as well.~ Python 3.13.1t non-debug (`pyenv install 3.13.1t`), at least on macOS, does not exhibit the segfault.

The discriminating Python build options seem to be:
1. debug mode
2. free threading

### Reproduce the code example:

```python
import numpy
```


### Error message (from gdb on Debian 12 arm64):

```shell
Thread 1 ""python3"" received signal SIGSEGV, Segmentation fault.
__GI___libc_free (mem=<optimized out>) at ./malloc/malloc.c:3362
3362	./malloc/malloc.c: No such file or directory.
(gdb) bt
#0  __GI___libc_free (mem=<optimized out>) at ./malloc/malloc.c:3362
#1  0x0000fffff447e5ac in ufunc_dealloc ()
   from /home/cavok/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/numpy/_core/_multiarray_umath.cpython-313t-aarch64-linux-gnu.so
#2  0x0000fffff799daf8 in _Py_Dealloc (op=0x2000f4d1a50) at Objects/object.c:2918
#3  0x0000fffff7999794 in _Py_MergeZeroLocalRefcount (op=0x2000f4d1a50) at Objects/object.c:423
#4  0x0000fffff7972ea0 in Py_DECREF (filename=0xfffff7c918f8 ""./Include/object.h"", lineno=1042, op=0x2000f4d1a50) at ./Include/object.h:892
#5  0x0000fffff7972f1c in Py_XDECREF (op=0x2000f4d1a50) at ./Include/object.h:1042
#6  0x0000fffff79753dc in dictkeys_decref (interp=0xfffff7f10280 <_PyRuntime+128704>, dk=0x2000f858c10, use_qsbr=false) at Objects/dictobject.c:496
#7  0x0000fffff797c284 in dict_dealloc (self=0x2000f78fcd0) at Objects/dictobject.c:3179
#8  0x0000fffff799daf8 in _Py_Dealloc (op=0x2000f78fcd0) at Objects/object.c:2918
#9  0x0000fffff7999794 in _Py_MergeZeroLocalRefcount (op=0x2000f78fcd0) at Objects/object.c:423
#10 0x0000fffff7b38344 in Py_DECREF (filename=0xfffff7d023d8 ""./Include/object.h"", lineno=1042, op=0x2000f78fcd0) at ./Include/object.h:892
#11 0x0000fffff7b383c0 in Py_XDECREF (op=0x2000f78fcd0) at ./Include/object.h:1042
#12 0x0000fffff7b3adb8 in del_cached_m_dict (value=0xaaaaaab10780) at Python/import.c:1119
#13 0x0000fffff7b3aeac in del_extensions_cache_value (value=0xaaaaaab10780) at Python/import.c:1149
#14 0x0000fffff7b37d00 in _Py_hashtable_destroy_entry (ht=0xaaaaaaad7e50, entry=0xaaaaaab107e0) at Python/hashtable.c:385
#15 0x0000fffff7b37e1c in _Py_hashtable_destroy (ht=0xaaaaaaad7e50) at Python/hashtable.c:417
#16 0x0000fffff7b3b7f0 in _extensions_cache_clear_all () at Python/import.c:1452
#17 0x0000fffff7b40d98 in _PyImport_Fini () at Python/import.c:4014
#18 0x0000fffff7b754f8 in _Py_Finalize (runtime=0xfffff7ef0bc0 <_PyRuntime>) at Python/pylifecycle.c:2129
#19 0x0000fffff7b7557c in Py_FinalizeEx () at Python/pylifecycle.c:2215
#20 0x0000fffff7bb98a0 in Py_RunMain () at Modules/main.c:777
#21 0x0000fffff7bb9938 in pymain_main (args=0xfffffffff2c0) at Modules/main.c:805
#22 0x0000fffff7bb99ac in Py_BytesMain (argc=6, argv=0xfffffffff478) at Modules/main.c:829
#23 0x0000aaaaaaaa0970 in main (argc=6, argv=0xfffffffff478) at ./Programs/python.c:15
```


### Python and NumPy Versions:

3.13.1 experimental free-threading build (main, Dec  9 2024, 11:53:27) [Clang 16.0.0 (clang-1600.0.26.4)]
2.2.0


### Context for the issue:

This affects the Pygolo Project CI pipeline ([logs](https://gitlab.com/pygolo/py/-/jobs/8585360957)) which has a minimal interoperability extension test based on Numpy. I will pin the release of Numpy so to use 2.1.3 but I'll be happy to revert that as soon as this bug is fixed.","I'm not able to reproduce this on a fresh build debug build of python 3.13.1t and numpy built from source from main or with the numpy 2.2.0 wheel on pypi on my ARM macbook Pro:

```
goldbaum at Nathans-MBP in ~/Documents/numpy on wheel-build-timeouts
± python -m pip install -v . --no-build-isolation -Cbuilddir=build -C'compile-args=-v' -C'setup-args=-Dbuildtype=debug'
(lots of output elided)
goldbaum at Nathans-MBP in ~/Documents
○  python
imPython 3.13.1 experimental free-threading build (main, Dec  9 2024, 10:24:44) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy as np
>>> import sys; print(sys.version_info)
sys.version_info(major=3, minor=13, micro=1, releaselevel='final', serial=0)
>>> import sysconfig
>>> sysconfig.get_config_var(""CFLAGS"")
'-fno-strict-overflow -Wsign-compare -g -Og -Wall -I/opt/homebrew/opt/zlib  -O0 -I/opt/homebrew/opt/zlib'
>>> sys.gettotalrefcount()
105532
>>> quit()

goldbaum at Nathans-MBP in ~/Documents
○  pip uninstall numpy
Found existing installation: numpy 2.3.0.dev0
Uninstalling numpy-2.3.0.dev0:
  Would remove:
    /Users/goldbaum/.pyenv/versions/3.13.1t-debug/bin/f2py
    /Users/goldbaum/.pyenv/versions/3.13.1t-debug/bin/numpy-config
    /Users/goldbaum/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/numpy-2.3.0.dev0.dist-info/*
    /Users/goldbaum/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/numpy/*
Proceed (Y/n)? y
  Successfully uninstalled numpy-2.3.0.dev0

goldbaum at Nathans-MBP in ~/Documents
○  pip install numpy
Collecting numpy
  Downloading numpy-2.2.0-cp313-cp313t-macosx_14_0_arm64.whl.metadata (62 kB)
Downloading numpy-2.2.0-cp313-cp313t-macosx_14_0_arm64.whl (5.2 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 18.4 MB/s eta 0:00:00
/Users/goldbaum/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/pip/_internal/metadata/importlib/_dists.py:77: DeprecationWarning: Unimplemented abstract methods {'locate_file'}
  return cls(files, info_location)
Installing collected packages: numpy
Successfully installed numpy-2.2.0

goldbaum at Nathans-MBP in ~/Documents
○  python
Python 3.13.1 experimental free-threading build (main, Dec  9 2024, 10:24:44) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
im>>> import numpy as np
>>>
```

Trying on Linux next... || I later updated the issue, it seems you also need the debug mode enabled. || I built Python with debug mode. || It would help me if you could give more information about how you're installing numpy after building python. || I can't reproduce this on an amd64 Ubuntu 22.04 system either, using either a from-source numpy build or the 2.2.0 wheel. || 2.2.0:
```
$ pip install numpy
Collecting numpy
  Using cached numpy-2.2.0-cp313-cp313t-macosx_14_0_x86_64.whl.metadata (62 kB)
Using cached numpy-2.2.0-cp313-cp313t-macosx_14_0_x86_64.whl (6.7 MB)
/Users/cavok/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/pip/_internal/metadata/importlib/_dists.py:77: DeprecationWarning: Unimplemented abstract methods {'locate_file'}
  return cls(files, info_location)
Installing collected packages: numpy
Successfully installed numpy-2.2.0
$ python3
Python 3.13.1 experimental free-threading build (main, Dec  9 2024, 11:53:27) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy
>>> quit()
zsh: segmentation fault  python
```

2.1.3:
```
$ pip install numpy==2.1.3
Collecting numpy==2.1.3
  Using cached numpy-2.1.3-cp313-cp313t-macosx_14_0_x86_64.whl.metadata (62 kB)
Using cached numpy-2.1.3-cp313-cp313t-macosx_14_0_x86_64.whl (6.6 MB)
/Users/cavok/.pyenv/versions/3.13.1t-debug/lib/python3.13t/site-packages/pip/_internal/metadata/importlib/_dists.py:77: DeprecationWarning: Unimplemented abstract methods {'locate_file'}
  return cls(files, info_location)
Installing collected packages: numpy
  Attempting uninstall: numpy
    Found existing installation: numpy 2.2.0
    Uninstalling numpy-2.2.0:
      Successfully uninstalled numpy-2.2.0
Successfully installed numpy-2.1.3
$ python3
Python 3.13.1 experimental free-threading build (main, Dec  9 2024, 11:53:27) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy
>>> quit()
``` || Oh interesting, it looks like I do get a seg fault when Python exits:

```
goldbaum at Nathans-MBP in ~/Documents
○  python
Python 3.13.1 experimental free-threading build (main, Dec  9 2024, 10:24:44) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import sys
>>> # this function is only available on debug builds
>>> sys.gettotalrefcount()
54380
>>> import numpy as np
>>> np.__version__
'2.2.0'
>>> quit()
[1]    89726 segmentation fault  python
``` || What changed on your side, `np.__version__`? I don't need that to get the segfault, which BTW is 100% reproducible for me. || > `>>> # this function is only available on debug builds`

Thanks for this tip! || > What changed on your side, np.__version__? I don't need that to get the segfault, which BTW is 100% reproducible for me.

I was trying to prove that I don't hit the segfault on my machine, and I've only hit it doing exactly what I copy/pasted. || > > What changed on your side, np.**version**? I don't need that to get the segfault, which BTW is 100% reproducible for me.
> 
> I was trying to prove that I don't hit the segfault on my machine, and I've only hit it doing exactly what I copy/pasted.

Is it 100% reproducible or just once in a while? || I was able to trigger it on NumPy 2.2.0 but not on NumPy main, so I suspect a broken backport is the cause. Ping @charris.

Here's the traceback in a debug build of NumPy 2.2.0:

```
    frame #0: 0x0000000183b6411c libsystem_pthread.dylib`pthread_cond_destroy + 32
    frame #1: 0x0000000183a8bcc4 libc++.1.dylib`std::__1::condition_variable::~condition_variable() + 24
    frame #2: 0x0000000101870850 _multiarray_umath.cpython-313td-darwin.so`::PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *) [inlined] std::__1::__shared_mutex_base::~__shared_mutex_base[abi:sn180100](this=0xdddddddddddddddd) at shared_mutex:167:56 [opt]
  * frame #3: 0x0000000101870848 _multiarray_umath.cpython-313td-darwin.so`::PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *) [inlined] std::__1::__shared_mutex_base::~__shared_mutex_base[abi:sn180100](this=0xdddddddddddddddd) at shared_mutex:167:56 [opt]
    frame #4: 0x0000000101870848 _multiarray_umath.cpython-313td-darwin.so`::PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *) [inlined] std::__1::shared_mutex::~shared_mutex[abi:sn180100](this=0xdddddddddddddddd) at shared_mutex:192:49 [opt]
    frame #5: 0x0000000101870848 _multiarray_umath.cpython-313td-darwin.so`::PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *) [inlined] std::__1::shared_mutex::~shared_mutex[abi:sn180100](this=0xdddddddddddddddd) at shared_mutex:192:49 [opt]
    frame #6: 0x0000000101870848 _multiarray_umath.cpython-313td-darwin.so`PyArrayIdentityHash_Dealloc(tb=<unavailable>) at npy_hashtable.cpp:131:5 [opt]
    frame #7: 0x0000000101884f04 _multiarray_umath.cpython-313td-darwin.so`ufunc_dealloc(ufunc=0x0000020000a30650) at ufunc_object.c:5196:9 [opt]
    frame #8: 0x0000000100f09408 libpython3.13td.dylib`_Py_Dealloc(op='0x16fdfe7e8') at object.c:2918:5
``` || Is there anything I can do to help? I'll later try with a numpy built from source. || No I think this should be sorted out quickly and we'll do a 2.2.1 release with a fix. || Thank you for the lightning support! || I edited some of my comments above, there *is* a `dispatching.cpp` in the 2.2.0 release, that's not the issue... || ping @seberg do you have any idea why we'd seg fault in the destructor of a `std::shared_mutex`, but only under the debug python build? || Oh I see, this is a very dumb use-after-free error:

https://github.com/numpy/numpy/blob/ba9205f26a5640d8be4b05de3e0db2cbc00bbd0a/numpy/_core/src/common/npy_hashtable.cpp#L129-L132

Those two operations should be switched. Oops! 

PR incoming...",closed,2024-12-09T17:02:56+00:00,2024-12-09T19:26:20+00:00,cavokz,"00 - Bug, 39 - free-threading",1,"PR#27955 - numpy/_core/src/common/npy_hashtable.cpp: @@ -126,10 +126,10 @@ NPY_NO_EXPORT void|;| PyArrayIdentityHash_Dealloc(PyArrayIdentityHash *tb)|;| {|;|     PyMem_Free(tb->buckets)|;|;-    PyMem_Free(tb)|;|; #ifdef Py_GIL_DISABLED|;|     delete (std::shared_mutex *)tb->mutex|;|; #endif|;|+    PyMem_Free(tb)|;|; }|;| |;| ",BUG: fix use-after-free error in npy_hashtable.cpp
numpy/numpy,Uvi-12,27948,DOC: dtype kind 'T' is not documented,"### Issue with current documentation:

This page https://numpy.org/doc/stable/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind explicitly lists all possible returns from `np.dtype.kind` as 
> one of 'biufcmMOSUV'

However, the character associated with `StringDType` (`T`) isn't listed
```python
>>> import numpy as np
>>> np.dtypes.StringDType().kind
'T'
```

### Idea or request for content:

_No response_",,closed,2024-12-09T11:53:36+00:00,2024-12-15T13:58:21+00:00,neutrinoceros,04 - Documentation,1,"PR#28001 - numpy/_core/_add_newdocs.py: @@ -6066,7 +6066,7 @@|;| |;| add_newdoc('numpy._core.multiarray', 'dtype', ('kind',|;|     """"""|;|-    A character code (one of 'biufcmMOSUV') identifying the general kind of data.|;|+    A character code (one of 'biufcmMOSTUV') identifying the general kind of data.|;| |;|     =  ======================|;|     b  boolean|;|@@ -6078,6 +6078,7 @@|;|     M  datetime|;|     O  object|;|     S  (byte-)string|;|+    T  string (StringDType)|;|     U  Unicode|;|     V  void|;|     =  ======================",DOC: Fix documentation for np.dtype.kind to include 'T' for StringDType || changes made as per review
numpy/numpy,Uvi-12,28012,DOC: Typos in development_advanced_debugging.rst,"### Issue with current documentation:

There is a typo in the development_advanced_debugging.rst file where the word ""bases"" is incorrectly used, the correct word should be ""basis"". And ""PYTHOMMALLOC"" should be ""PYTHONMALLOC"".
",,closed,2024-12-16T12:55:09+00:00,2024-12-16T13:51:16+00:00,Uvi-12,04 - Documentation,1,"PR#28013 - doc/source/dev/development_advanced_debugging.rst: @@ -10,7 +10,7 @@ day-to-day development.|;| These are used more rarely, for example close to a new NumPy release,|;| or when a large or particular complex change was made.|;| |;|-Since not all of these tools are used on a regular bases and only available|;|+Since not all of these tools are used on a regular basis and only available|;| on some systems, please expect differences, issues, or quirks|;|; we will be happy to help if you get stuck and appreciate any improvements|;| or suggestions to these workflows.|;|@@ -188,7 +188,7 @@ Use together with ``pytest``|;| You can run the test suite with valgrind which may be sufficient|;| when you are only interested in a few tests::|;| |;|-    PYTHOMMALLOC=malloc valgrind python runtests.py \|;|+    PYTHONMALLOC=malloc valgrind python runtests.py \|;|      -t numpy/_core/tests/test_multiarray.py -- --continue-on-collection-errors|;| |;| Note the ``--continue-on-collection-errors``, which is currently necessary due to",DOC: Fixed typos in development_advanced_debugging.rst
numpy/numpy,ngoldbaum,27984,BUG: lexsort segfaults on StringDType,"### Describe the issue:

Hi! I've been switching some code to the new `StringDType` and I came across a segfault when feeding `StringDType` arrays to lexsort. The example below is the same as in the documentation for lexsort: https://numpy.org/doc/stable/reference/generated/numpy.lexsort.html

### Reproduce the code example:

```python
#!/usr/bin/env python3

import numpy as np
from numpy.dtypes import StringDType

# Works
surnames =    ('Hertz',    'Galilei', 'Hertz')
first_names = ('Heinrich', 'Galileo', 'Gustav')
ind = np.lexsort((first_names, surnames))
print(ind)

# Works
surnames2 = np.array(surnames, str)
first_names2 = np.array(first_names, str)
ind = np.lexsort((first_names2, surnames2))
print(ind)

# Segfaults
surnames2 = np.array(surnames, StringDType())
first_names2 = np.array(first_names, StringDType())
ind = np.lexsort((first_names2, surnames2))
print(ind)
```


### Error message:

_No response_

### Python and NumPy Versions:

```
2.2.0
3.12.8 (main, Dec  4 2024, 12:15:27) [GCC 14.2.0]
```

### Runtime Environment:

```
[{'numpy_version': '2.2.0',
  'python': '3.12.8 (main, Dec  4 2024, 12:15:27) [GCC 14.2.0]',
  'uname': uname_result(system='Linux', node='thalatta', release='6.11.10-amd64', version='#1 SMP PREEMPT_DYNAMIC Debian 6.11.10-1 (2024-11-23)', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Haswell',
  'filepath': '.../venv/lib/python3.12/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 8,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]
```

### Context for the issue:

_No response_","Reproduces on Python 3.13.0 (main, Oct  7 2024, 05:02:14) [Clang 16.0.0 (clang-1600.0.26.4)] on darwin, Numpy 2.2.0

<details><summary>Crash log</summary>
<pre>
-------------------------------------
Translated Report (Full Report Below)
-------------------------------------

Process:               Python [69601]
Path:                  /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python
Identifier:            org.python.python
Version:               3.13.0 (3.13.0)
Code Type:             X86-64 (Translated)
Parent Process:        zsh [69583]
Responsible:           kitty [1231]
User ID:               503

Date/Time:             2024-12-12 10:06:41.9720 +0700
OS Version:            macOS 14.6.1 (23G93)
Report Version:        12
Anonymous UUID:        66111A0E-A8EE-8FA5-8BA0-50DD5D0F521A

Sleep/Wake UUID:       19CEACD9-F374-45F1-8E7A-C409CDF51582

Time Awake Since Boot: 280000 seconds
Time Since Wake:       1892 seconds

System Integrity Protection: enabled

Notes:
PC register does not match crashing frame (0x0 vs 0x10B2E746D)

Crashed Thread:        0  Dispatch queue: com.apple.main-thread

Exception Type:        EXC_BAD_ACCESS (SIGSEGV)
Exception Codes:       KERN_INVALID_ADDRESS at 0x0000000000000070
Exception Codes:       0x0000000000000001, 0x0000000000000070

Termination Reason:    Namespace SIGNAL, Code 11 Segmentation fault: 11
Terminating Process:   exc handler [69601]

VM Region Info: 0x70 is not in any region.  Bytes before following region: 4331028368
      REGION TYPE                    START - END         [ VSIZE] PRT/MAX SHRMOD  REGION DETAIL
      UNUSED SPACE AT START
--->  
      __TEXT                      102264000-102266000    [    8K] r-x/r-x SM=COW  /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python

Error Formulating Crash Report:
PC register does not match crashing frame (0x0 vs 0x10B2E746D)

Thread 0 Crashed::  Dispatch queue: com.apple.main-thread
0   Python                        	       0x10b2e746d PyErr_Occurred + 16
1   _multiarray_umath.cpython-313-darwin.so	       0x10c335b06 PyArray_LexSort + 2454
2   _multiarray_umath.cpython-313-darwin.so	       0x10c352a6a array_lexsort + 138
3   Python                        	       0x10b1de187 cfunction_vectorcall_FASTCALL_KEYWORDS + 94
4   Python                        	       0x10b181d6d PyObject_Vectorcall + 75
5   _multiarray_umath.cpython-313-darwin.so	       0x10c2f1c78 dispatcher_vectorcall + 376
6   Python                        	       0x10b181d6d PyObject_Vectorcall + 75
7   Python                        	       0x10b2b5411 _PyEval_EvalFrameDefault + 10898
8   Python                        	       0x10b2b27d6 PyEval_EvalCode + 207
9   Python                        	       0x10b3284b5 run_eval_code_obj + 97
10  Python                        	       0x10b327e26 run_mod + 157
11  Python                        	       0x10b32673e pyrun_file + 141
12  Python                        	       0x10b325b58 _PyRun_SimpleFileObject + 272
13  Python                        	       0x10b325818 _PyRun_AnyFileObject + 66
14  Python                        	       0x10b34e6cf pymain_run_file_obj + 187
15  Python                        	       0x10b34e3b9 pymain_run_file + 94
16  Python                        	       0x10b34d513 Py_RunMain + 1263
17  Python                        	       0x10b34dbdb pymain_main + 371
18  Python                        	       0x10b34dc8e Py_BytesMain + 42
19  dyld                          	       0x20245b345 start + 1909

Thread 1:: com.apple.rosetta.exceptionserver
0   runtime                       	    0x7ff7ffe21414 0x7ff7ffe1d000 + 17428


Thread 0 crashed with X86 Thread State (64-bit):
  rax: 0x0000000000000000  rbx: 0x00006000017080e0  rcx: 0x0000000000000003  rdx: 0x0000000000000003
  rdi: 0x000000010b589160  rsi: 0x0000000000000003  rbp: 0x00000003057a3230  rsp: 0x00000003057a3230
   r8: 0x0000000000000061   r9: 0x0000000000000000  r10: 0x0000000000000000  r11: 0x0000000000000002
  r12: 0x0000000000000000  r13: 0x000000010b100b10  r14: 0x00006000017080b0  r15: 0x000000010c39c170
  rip: <unavailable>       rfl: 0x0000000000000202
 tmp0: 0x000000010b2e746a tmp1: 0x000000010b2e746a tmp2: 0x000000010b938ec4


Binary Images:
       0x202455000 -        0x2024e5fff dyld (*) <18f658dd-20f3-324d-b7ac-8a9c60b574b3> /usr/lib/dyld
       0x10bbd7000 -        0x10bbfefff _umath_linalg.cpython-313-darwin.so (*) <dcc445c8-85f9-3c6f-a59c-4497162058ce> /Users/USER/*/_umath_linalg.cpython-313-darwin.so
       0x10afc4000 -        0x10afd6fff _ctypes.cpython-313-darwin.so (*) <79240ca2-cd41-316b-84b6-a123952aea42> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/_ctypes.cpython-313-darwin.so
       0x10ae65000 -        0x10ae79fff _pickle.cpython-313-darwin.so (*) <1496c3bb-1414-3179-9d27-90b14adf49de> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/_pickle.cpython-313-darwin.so
       0x10aad1000 -        0x10aad6fff _struct.cpython-313-darwin.so (*) <2410714c-7f19-3e0b-8a49-c07fb4a9c14d> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/_struct.cpython-313-darwin.so
       0x10aa32000 -        0x10aa32fff _contextvars.cpython-313-darwin.so (*) <5db42a44-316d-38e6-bffb-8e581a78a873> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/_contextvars.cpython-313-darwin.so
       0x10aa80000 -        0x10aa8afff math.cpython-313-darwin.so (*) <8c61d294-3b26-384a-81bb-6225c430d0ef> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/math.cpython-313-darwin.so
       0x10aa46000 -        0x10aa54fff _datetime.cpython-313-darwin.so (*) <5d125419-982e-324a-943f-074978c8fdcf> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload/_datetime.cpython-313-darwin.so
       0x10c1e7000 -        0x10c79efff _multiarray_umath.cpython-313-darwin.so (*) <e594e1d4-839b-3adf-b603-9d9cfbb305a1> /Users/USER/*/_multiarray_umath.cpython-313-darwin.so
       0x10b11f000 -        0x10b4befff org.python.python (3.13.0, (c) 2001-2024 Python Software Foundation.) <f1af652e-465e-3c90-99b4-9308a3aef0e5> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/Python
    0x7ff7ffe1d000 -     0x7ff7ffe4cfff runtime (*) <785a360c-c838-3095-94d4-2cc4faf5d5de> /usr/libexec/rosetta/runtime
       0x10a27d000 -        0x10a2d0fff libRosettaRuntime (*) <3e6996b2-eddb-3269-b841-bb2b3c546f07> /Library/Apple/*/libRosettaRuntime
       0x102264000 -        0x102265fff org.python.python (3.13.0) <bb2ba445-920c-3799-9bbf-4841bd266f0a> /usr/local/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/Resources/Python.app/Contents/MacOS/Python
               0x0 - 0xffffffffffffffff ??? (*) <00000000-0000-0000-0000-000000000000> ???

External Modification Summary:
  Calls made by other processes targeting this process:
    task_for_pid: 0
    thread_create: 0
    thread_set_state: 0
  Calls made by this process:
    task_for_pid: 0
    thread_create: 0
    thread_set_state: 0
  Calls made by all processes on this machine:
    task_for_pid: 0
    thread_create: 0
    thread_set_state: 0

VM Region Summary:
ReadOnly portion of Libraries: Total=320.6M resident=0K(0%) swapped_out_or_unallocated=320.6M(100%)
Writable regions: Total=1.1G written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=1.1G(100%)

                                VIRTUAL   REGION 
REGION TYPE                        SIZE    COUNT (non-coalesced) 
===========                     =======  ======= 
Kernel Alloc Once                    8K        1 
MALLOC                           923.2M       18 
MALLOC guard page                   96K        6 
Rosetta Arena                     4096K        2 
Rosetta Generic                    968K      239 
Rosetta IndirectBranch             224K        3 
Rosetta JIT                      128.0M        1 
Rosetta Return Stack                20K        2 
Rosetta Thread Context              20K        2 
Stack                             16.0M        1 
Stack Guard                         16K        1 
VM_ALLOCATE                       7512K       19 
VM_ALLOCATE (reserved)               4K        1         reserved VM address space (unallocated)
__DATA                            4499K      159 
__DATA_CONST                      6622K      113 
__DATA_DIRTY                       348K       60 
__LINKEDIT                       177.4M       18 
__OBJC_RO                         71.8M        1 
__OBJC_RW                         2198K        2 
__TEXT                           143.2M      169 
mapped file                       14.4M       34 
shared memory                       32K        2 
===========                     =======  ======= 
TOTAL                              1.5G      854 
TOTAL, minus reserved VM space     1.5G      854 



-----------
Full Report
-----------

{""app_name"":""Python"",""timestamp"":""2024-12-12 10:06:42.00 +0700"",""app_version"":""3.13.0"",""slice_uuid"":""bb2ba445-920c-3799-9bbf-4841bd266f0a"",""build_version"":""3.13.0"",""platform"":1,""bundleID"":""org.python.python"",""share_with_app_devs"":0,""is_first_party"":0,""bug_type"":""309"",""os_version"":""macOS 14.6.1 (23G93)"",""roots_installed"":0,""name"":""Python"",""incident_id"":""E39E3FB3-E173-45B6-B240-B310B190B32F""}
{
  ""uptime"" : 280000,
  ""procRole"" : ""Unspecified"",
  ""version"" : 2,
  ""userID"" : 503,
  ""deployVersion"" : 210,
  ""modelCode"" : ""Mac15,9"",
  ""coalitionID"" : 1485,
  ""osVersion"" : {
    ""train"" : ""macOS 14.6.1"",
    ""build"" : ""23G93"",
    ""releaseType"" : ""User""
  },
  ""captureTime"" : ""2024-12-12 10:06:41.9720 +0700"",
  ""codeSigningMonitor"" : 1,
  ""incident"" : ""E39E3FB3-E173-45B6-B240-B310B190B32F"",
  ""pid"" : 69601,
  ""translated"" : true,
  ""cpuType"" : ""X86-64"",
  ""roots_installed"" : 0,
  ""bug_type"" : ""309"",
  ""procLaunch"" : ""2024-12-12 10:06:40.7481 +0700"",
  ""procStartAbsTime"" : 6922039843878,
  ""procExitAbsTime"" : 6922069209904,
  ""procName"" : ""Python"",
  ""procPath"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/Resources\/Python.app\/Contents\/MacOS\/Python"",
  ""bundleInfo"" : {""CFBundleShortVersionString"":""3.13.0"",""CFBundleVersion"":""3.13.0"",""CFBundleIdentifier"":""org.python.python""},
  ""storeInfo"" : {""deviceIdentifierForVendor"":""787583A1-DAB6-52EB-BF2B-DBD30F05219A"",""thirdParty"":true},
  ""parentProc"" : ""zsh"",
  ""parentPid"" : 69583,
  ""coalitionName"" : ""net.kovidgoyal.kitty"",
  ""crashReporterKey"" : ""66111A0E-A8EE-8FA5-8BA0-50DD5D0F521A"",
  ""responsiblePid"" : 1231,
  ""responsibleProc"" : ""kitty"",
  ""codeSigningID"" : """",
  ""codeSigningTeamID"" : """",
  ""codeSigningValidationCategory"" : 0,
  ""codeSigningTrustLevel"" : 4294967295,
  ""wakeTime"" : 1892,
  ""sleepWakeUUID"" : ""19CEACD9-F374-45F1-8E7A-C409CDF51582"",
  ""sip"" : ""enabled"",
  ""vmRegionInfo"" : ""0x70 is not in any region.  Bytes before following region: 4331028368\n      REGION TYPE                    START - END         [ VSIZE] PRT\/MAX SHRMOD  REGION DETAIL\n      UNUSED SPACE AT START\n--->  \n      __TEXT                      102264000-102266000    [    8K] r-x\/r-x SM=COW  \/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/Resources\/Python.app\/Contents\/MacOS\/Python"",
  ""exception"" : {""codes"":""0x0000000000000001, 0x0000000000000070"",""rawCodes"":[1,112],""type"":""EXC_BAD_ACCESS"",""signal"":""SIGSEGV"",""subtype"":""KERN_INVALID_ADDRESS at 0x0000000000000070""},
  ""termination"" : {""flags"":0,""code"":11,""namespace"":""SIGNAL"",""indicator"":""Segmentation fault: 11"",""byProc"":""exc handler"",""byPid"":69601},
  ""vmregioninfo"" : ""0x70 is not in any region.  Bytes before following region: 4331028368\n      REGION TYPE                    START - END         [ VSIZE] PRT\/MAX SHRMOD  REGION DETAIL\n      UNUSED SPACE AT START\n--->  \n      __TEXT                      102264000-102266000    [    8K] r-x\/r-x SM=COW  \/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/Resources\/Python.app\/Contents\/MacOS\/Python"",
  ""extMods"" : {""caller"":{""thread_create"":0,""thread_set_state"":0,""task_for_pid"":0},""system"":{""thread_create"":0,""thread_set_state"":0,""task_for_pid"":0},""targeted"":{""thread_create"":0,""thread_set_state"":0,""task_for_pid"":0},""warnings"":0},
  ""faultingThread"" : 0,
  ""threads"" : [{""triggered"":true,""id"":2950989,""threadState"":{""flavor"":""x86_THREAD_STATE"",""rbp"":{""value"":12976796208},""r12"":{""value"":0},""rosetta"":{""tmp2"":{""value"":4489187012},""tmp1"":{""value"":4482561130},""tmp0"":{""value"":4482561130}},""rbx"":{""value"":105553140416736},""r8"":{""value"":97},""r15"":{""value"":4500078960,""symbolLocation"":0,""symbol"":""npy_atimsort""},""r10"":{""value"":0},""rdx"":{""value"":3},""rdi"":{""value"":4485321056,""symbolLocation"":0,""symbol"":""_Py_tss_tstate""},""r9"":{""value"":0},""r13"":{""value"":4480568080},""rflags"":{""value"":514},""rax"":{""value"":0},""rsp"":{""value"":12976796208},""r11"":{""value"":2},""rcx"":{""value"":3},""r14"":{""value"":105553140416688},""rsi"":{""value"":3}},""queue"":""com.apple.main-thread"",""frames"":[{""imageOffset"":1868909,""symbol"":""PyErr_Occurred"",""symbolLocation"":16,""imageIndex"":9},{""imageOffset"":1370886,""symbol"":""PyArray_LexSort"",""symbolLocation"":2454,""imageIndex"":8},{""imageOffset"":1489514,""symbol"":""array_lexsort"",""symbolLocation"":138,""imageIndex"":8},{""imageOffset"":782727,""symbol"":""cfunction_vectorcall_FASTCALL_KEYWORDS"",""symbolLocation"":94,""imageIndex"":9},{""imageOffset"":404845,""symbol"":""PyObject_Vectorcall"",""symbolLocation"":75,""imageIndex"":9},{""imageOffset"":1092728,""symbol"":""dispatcher_vectorcall"",""symbolLocation"":376,""imageIndex"":8},{""imageOffset"":404845,""symbol"":""PyObject_Vectorcall"",""symbolLocation"":75,""imageIndex"":9},{""imageOffset"":1664017,""symbol"":""_PyEval_EvalFrameDefault"",""symbolLocation"":10898,""imageIndex"":9},{""imageOffset"":1652694,""symbol"":""PyEval_EvalCode"",""symbolLocation"":207,""imageIndex"":9},{""imageOffset"":2135221,""symbol"":""run_eval_code_obj"",""symbolLocation"":97,""imageIndex"":9},{""imageOffset"":2133542,""symbol"":""run_mod"",""symbolLocation"":157,""imageIndex"":9},{""imageOffset"":2127678,""symbol"":""pyrun_file"",""symbolLocation"":141,""imageIndex"":9},{""imageOffset"":2124632,""symbol"":""_PyRun_SimpleFileObject"",""symbolLocation"":272,""imageIndex"":9},{""imageOffset"":2123800,""symbol"":""_PyRun_AnyFileObject"",""symbolLocation"":66,""imageIndex"":9},{""imageOffset"":2291407,""symbol"":""pymain_run_file_obj"",""symbolLocation"":187,""imageIndex"":9},{""imageOffset"":2290617,""symbol"":""pymain_run_file"",""symbolLocation"":94,""imageIndex"":9},{""imageOffset"":2286867,""symbol"":""Py_RunMain"",""symbolLocation"":1263,""imageIndex"":9},{""imageOffset"":2288603,""symbol"":""pymain_main"",""symbolLocation"":371,""imageIndex"":9},{""imageOffset"":2288782,""symbol"":""Py_BytesMain"",""symbolLocation"":42,""imageIndex"":9},{""imageOffset"":25413,""symbol"":""start"",""symbolLocation"":1909,""imageIndex"":0}]},{""id"":2950990,""name"":""com.apple.rosetta.exceptionserver"",""threadState"":{""flavor"":""x86_THREAD_STATE"",""rbp"":{""value"":34097745362944},""r12"":{""value"":140705915693264},""rosetta"":{""tmp2"":{""value"":0},""tmp1"":{""value"":4496830765379},""tmp0"":{""value"":10337986281472}},""rbx"":{""value"":4496830765379},""r8"":{""value"":7939},""r15"":{""value"":4831842304},""r10"":{""value"":15586436317184},""rdx"":{""value"":0},""rdi"":{""value"":0},""r9"":{""value"":0},""r13"":{""value"":4465765232},""rflags"":{""value"":582},""rax"":{""value"":268451845},""rsp"":{""value"":10337986281472},""r11"":{""value"":112},""rcx"":{""value"":17314086914},""r14"":{""value"":4489187016},""rsi"":{""value"":2616}},""frames"":[{""imageOffset"":17428,""imageIndex"":10}]}],
  ""usedImages"" : [
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 8628031488,
    ""size"" : 593920,
    ""uuid"" : ""18f658dd-20f3-324d-b7ac-8a9c60b574b3"",
    ""path"" : ""\/usr\/lib\/dyld"",
    ""name"" : ""dyld""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4491931648,
    ""size"" : 163840,
    ""uuid"" : ""dcc445c8-85f9-3c6f-a59c-4497162058ce"",
    ""path"" : ""\/Users\/USER\/*\/_umath_linalg.cpython-313-darwin.so"",
    ""name"" : ""_umath_linalg.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4479270912,
    ""size"" : 77824,
    ""uuid"" : ""79240ca2-cd41-316b-84b6-a123952aea42"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/_ctypes.cpython-313-darwin.so"",
    ""name"" : ""_ctypes.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4477833216,
    ""size"" : 86016,
    ""uuid"" : ""1496c3bb-1414-3179-9d27-90b14adf49de"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/_pickle.cpython-313-darwin.so"",
    ""name"" : ""_pickle.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4474081280,
    ""size"" : 24576,
    ""uuid"" : ""2410714c-7f19-3e0b-8a49-c07fb4a9c14d"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/_struct.cpython-313-darwin.so"",
    ""name"" : ""_struct.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4473430016,
    ""size"" : 4096,
    ""uuid"" : ""5db42a44-316d-38e6-bffb-8e581a78a873"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/_contextvars.cpython-313-darwin.so"",
    ""name"" : ""_contextvars.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4473749504,
    ""size"" : 45056,
    ""uuid"" : ""8c61d294-3b26-384a-81bb-6225c430d0ef"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/math.cpython-313-darwin.so"",
    ""name"" : ""math.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4473511936,
    ""size"" : 61440,
    ""uuid"" : ""5d125419-982e-324a-943f-074978c8fdcf"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/lib\/python3.13\/lib-dynload\/_datetime.cpython-313-darwin.so"",
    ""name"" : ""_datetime.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4498288640,
    ""size"" : 5996544,
    ""uuid"" : ""e594e1d4-839b-3adf-b603-9d9cfbb305a1"",
    ""path"" : ""\/Users\/USER\/*\/_multiarray_umath.cpython-313-darwin.so"",
    ""name"" : ""_multiarray_umath.cpython-313-darwin.so""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4480692224,
    ""CFBundleShortVersionString"" : ""3.13.0, (c) 2001-2024 Python Software Foundation."",
    ""CFBundleIdentifier"" : ""org.python.python"",
    ""size"" : 3801088,
    ""uuid"" : ""f1af652e-465e-3c90-99b4-9308a3aef0e5"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/Python"",
    ""name"" : ""Python"",
    ""CFBundleVersion"" : ""3.13.0""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""arm64"",
    ""base"" : 140703126638592,
    ""size"" : 196608,
    ""uuid"" : ""785a360c-c838-3095-94d4-2cc4faf5d5de"",
    ""path"" : ""\/usr\/libexec\/rosetta\/runtime"",
    ""name"" : ""runtime""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""arm64"",
    ""base"" : 4465348608,
    ""size"" : 344064,
    ""uuid"" : ""3e6996b2-eddb-3269-b841-bb2b3c546f07"",
    ""path"" : ""\/Library\/Apple\/*\/libRosettaRuntime"",
    ""name"" : ""libRosettaRuntime""
  },
  {
    ""source"" : ""P"",
    ""arch"" : ""x86_64"",
    ""base"" : 4331028480,
    ""CFBundleShortVersionString"" : ""3.13.0"",
    ""CFBundleIdentifier"" : ""org.python.python"",
    ""size"" : 8192,
    ""uuid"" : ""bb2ba445-920c-3799-9bbf-4841bd266f0a"",
    ""path"" : ""\/usr\/local\/Cellar\/python@3.13\/3.13.0_1\/Frameworks\/Python.framework\/Versions\/3.13\/Resources\/Python.app\/Contents\/MacOS\/Python"",
    ""name"" : ""Python"",
    ""CFBundleVersion"" : ""3.13.0""
  },
  {
    ""size"" : 0,
    ""source"" : ""A"",
    ""base"" : 0,
    ""uuid"" : ""00000000-0000-0000-0000-000000000000""
  }
],
  ""sharedCache"" : {
  ""base"" : 140703487148032,
  ""size"" : 25769803776,
  ""uuid"" : ""4fbce036-4b8b-3f24-954d-e2c0e9f9cc90""
},
  ""vmSummary"" : ""ReadOnly portion of Libraries: Total=320.6M resident=0K(0%) swapped_out_or_unallocated=320.6M(100%)\nWritable regions: Total=1.1G written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=1.1G(100%)\n\n                                VIRTUAL   REGION \nREGION TYPE                        SIZE    COUNT (non-coalesced) \n===========                     =======  ======= \nKernel Alloc Once                    8K        1 \nMALLOC                           923.2M       18 \nMALLOC guard page                   96K        6 \nRosetta Arena                     4096K        2 \nRosetta Generic                    968K      239 \nRosetta IndirectBranch             224K        3 \nRosetta JIT                      128.0M        1 \nRosetta Return Stack                20K        2 \nRosetta Thread Context              20K        2 \nStack                             16.0M        1 \nStack Guard                         16K        1 \nVM_ALLOCATE                       7512K       19 \nVM_ALLOCATE (reserved)               4K        1         reserved VM address space (unallocated)\n__DATA                            4499K      159 \n__DATA_CONST                      6622K      113 \n__DATA_DIRTY                       348K       60 \n__LINKEDIT                       177.4M       18 \n__OBJC_RO                         71.8M        1 \n__OBJC_RW                         2198K        2 \n__TEXT                           143.2M      169 \nmapped file                       14.4M       34 \nshared memory                       32K        2 \n===========                     =======  ======= \nTOTAL                              1.5G      854 \nTOTAL, minus reserved VM space     1.5G      854 \n"",
  ""legacyInfo"" : {
  ""threadTriggered"" : {
    ""queue"" : ""com.apple.main-thread""
  }
},
  ""logWritingSignature"" : ""4a2832827f8dd6135730b6dc39bdb5bf283f0566"",
  ""trialInfo"" : {
  ""rollouts"" : [
    {
      ""rolloutId"" : ""60356660bbe37970735c5624"",
      ""factorPackIds"" : {

      },
      ""deploymentId"" : 240000027
    },
    {
      ""rolloutId"" : ""645eb1d0417dab722a215927"",
      ""factorPackIds"" : {

      },
      ""deploymentId"" : 240000005
    }
  ],
  ""experiments"" : [
    {
      ""treatmentId"" : ""45f4e2a5-551b-4bc2-a2dc-19c244dda8f8"",
      ""experimentId"" : ""6643969b3099cf28e049862f"",
      ""deploymentId"" : 400000007
    }
  ]
},
  ""reportNotes"" : [
  ""PC register does not match crashing frame (0x0 vs 0x10B2E746D)""
]
}

Model: Mac15,9, BootROM 10151.140.19, proc 16:12:4 processors, 48 GB, SMC 
Graphics: Apple M3 Max, Apple M3 Max, Built-In
Display: Color LCD, 3456 x 2234 Retina, Main, MirrorOff, Online
Memory Module: LPDDR5, Micron
AirPort: spairport_wireless_card_type_wifi (0x14E4, 0x4388), wl0: Apr  4 2024 20:57:11 version 23.30.58.0.41.51.138 FWID 01-baea9d27
AirPort: 
Bluetooth: Version (null), 0 services, 0 devices, 0 incoming serial ports
Network Service: Wi-Fi, AirPort, en0
USB Device: USB31Bus
USB Device: USB31Bus
USB Device: USB31Bus
Thunderbolt Bus: MacBook Pro, Apple Inc.
Thunderbolt Bus: MacBook Pro, Apple Inc.
Thunderbolt Bus: MacBook Pro, Apple Inc.

</pre>
</details> || Thanks! I can reproduce this. || see https://github.com/numpy/numpy/pull/27992",closed,2024-12-11T21:38:36+00:00,2024-12-13T00:22:07+00:00,otsaloma,"00 - Bug, component: numpy.strings",1,"PR#27992 - numpy/_core/src/multiarray/item_selection.c: @@ -2014,8 +2014,7 @@ PyArray_LexSort(PyObject *sort_keys, int axis)|;|                 }|;|                 rcode = argsort(its[j]->dataptr,|;|                         (npy_intp *)rit->dataptr, N, mps[j])|;|;-                if (rcode < 0 || (PyDataType_REFCHK(PyArray_DESCR(mps[j]))|;|-                            && PyErr_Occurred())) {|;|+                if (rcode < 0 || (object && PyErr_Occurred())) {|;|                     goto fail|;|;                 }|;|                 PyArray_ITER_NEXT(its[j]); || PR#27992 - numpy/_core/tests/test_multiarray.py: @@ -5374,6 +5374,13 @@ def test_object(self):  # gh-6312|;|             u, v = np.array(u, dtype='object'), np.array(v, dtype='object')|;|             assert_array_equal(idx, np.lexsort((u, v)))|;| |;|+    def test_strings(self):  # gh-27984|;|+        for dtype in ""TU"":|;|+            surnames = np.array(['Hertz',    'Galilei', 'Hertz'], dtype=dtype)|;|+            first_names = np.array(['Heinrich', 'Galileo', 'Gustav'], dtype=dtype)|;|+            assert_array_equal(np.lexsort((first_names, surnames)), [1, 2, 0])|;|+|;|+|;|     def test_invalid_axis(self): # gh-7528|;|         x = np.linspace(0., 1., 42*3).reshape(42, 3)|;|         assert_raises(AxisError, np.lexsort, x, axis=2) || PR#27992 - numpy/_core/tests/test_stringdtype.py: @@ -415,8 +415,19 @@ def test_sort(dtype, strings):|;| |;|     def test_sort(strings, arr_sorted):|;|         arr = np.array(strings, dtype=dtype)|;|-        np.random.default_rng().shuffle(arr)|;|         na_object = getattr(arr.dtype, ""na_object"", """")|;|+        if na_object is None and None in strings:|;|+            with pytest.raises(|;|+                ValueError,|;|+                match=""Cannot compare null that is not a nan-like value"",|;|+            ):|;|+                np.argsort(arr)|;|+            argsorted = None|;|+        elif na_object is pd_NA or na_object != '':|;|+            argsorted = None|;|+        else:|;|+            argsorted = np.argsort(arr)|;|+        np.random.default_rng().shuffle(arr)|;|         if na_object is None and None in strings:|;|             with pytest.raises(|;|                 ValueError,|;|@@ -426,6 +437,9 @@ def test_sort(strings, arr_sorted):|;|         else:|;|             arr.sort()|;|             assert np.array_equal(arr, arr_sorted, equal_nan=True)|;|+        if argsorted is not None:|;|+            assert np.array_equal(argsorted, np.argsort(strings))|;|+|;| |;|     # make a copy so we don't mutate the lists in the fixture|;|     strings = strings.copy()",BUG: do not assume REFCHK is the same as object in lexsort || TST: add tests for stringdtype argsort || TST: add tests for string lexsort
numpy/numpy,jorenham,27964,TYP: False positives in ``ndarray.__setitem__`` with ``object_`` dtype in NumPy 2.2,"### Describe the issue:

Under NumPy 2.2, assignment of a slice to an object array results in a type check failure

### Reproduce the code example:

```python
import numpy as np
x = np.zeros(1, dtype=object)
x[0] = slice(None)
```


### Error message:

```shell
tmp.py:3: error: No overload variant of ""__setitem__"" of ""ndarray"" matches argument types ""int"", ""slice""  [call-overload]
tmp.py:3: note: Possible overload variants:
tmp.py:3: note:     def __setitem__(self, str | list[str], Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
tmp.py:3: note:     def __setitem__(self, SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | tuple[SupportsIndex | slice | EllipsisType | _SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]] | _NestedSequence[_SupportsArray[dtype[numpy.bool[builtins.bool]] | dtype[integer[Any]]]] | builtins.bool | int | _NestedSequence[builtins.bool | int] | None, ...] | None, Buffer | _SupportsArray[dtype[Any]] | _NestedSequence[_SupportsArray[dtype[Any]]] | bool | int | float | complex | str | bytes | _NestedSequence[bool | int | float | complex | str | bytes], /) -> None
Found 1 error in 1 file (checked 1 source file)
```


### Python and NumPy Versions:

```
>>> import sys, numpy; print(numpy.__version__); print(sys.version)
2.2.0
3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 (clang-1300.0.29.30)]
```

### Runtime Environment:

```python
>>> import numpy; numpy.show_runtime()
[{'numpy_version': '2.2.0',
  'python': '3.12.3 (v3.12.3:f6650f9ad7, Apr  9 2024, 08:18:47) [Clang 13.0.0 '
            '(clang-1300.0.29.30)]',
  'uname': uname_result(system='Darwin', node='jmdg-macbookpro.roam.internal', release='23.6.0', version='Darwin Kernel Version 23.6.0: Thu Sep 12 23:35:29 PDT 2024; root:xnu-10063.141.1.701.1~1/RELEASE_ARM64_T6000', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}}]
```

### Context for the issue:

Related to #27957; this is a reduction of an error we're seeing in the JAX CI under NumPy 2.2","caused by https://github.com/numpy/numpy/pull/27755 || The problem is that `ndarray.__setitem__` currently only accepts `numpy.typing.ArrayLike` values, causing it to reject valid values like `None` for `np.inexact` dtypes, and `object()` in `np.object_` dtypes.",closed,2024-12-10T18:02:09+00:00,2024-12-12T20:08:21+00:00,jakevdp,"00 - Bug, 41 - Static typing",1,"PR#27990 - numpy/__init__.pyi: @@ -844,7 +844,8 @@ _Float64_co: TypeAlias = float | floating[_64Bit] | float32 | float16 | integer[|;| _Complex64_co: TypeAlias = number[_32Bit] | number[_16Bit] | number[_8Bit] | builtins.bool | np.bool|;| _Complex128_co: TypeAlias = complex | number[_64Bit] | _Complex64_co|;| |;|-_ArrayIndexLike: TypeAlias = SupportsIndex | slice | EllipsisType | _ArrayLikeInt_co | None|;|+_ToIndex: TypeAlias = SupportsIndex | slice | EllipsisType | _ArrayLikeInt_co | None|;|+_ToIndices: TypeAlias = _ToIndex | tuple[_ToIndex, ...]|;| |;| _UnsignedIntegerCType: TypeAlias = type[|;|     ct.c_uint8 | ct.c_uint16 | ct.c_uint32 | ct.c_uint64|;|@@ -982,6 +983,8 @@ if sys.version_info >= (3, 11):|;|     _ConvertibleToComplex: TypeAlias = SupportsComplex | SupportsFloat | SupportsIndex | _CharLike_co|;| else:|;|     _ConvertibleToComplex: TypeAlias = complex | SupportsComplex | SupportsFloat | SupportsIndex | _CharLike_co|;|+_ConvertibleToTD64: TypeAlias = dt.timedelta | int | _CharLike_co | character | number | timedelta64 | np.bool | None|;|+_ConvertibleToDT64: TypeAlias = dt.date | int | _CharLike_co | character | number | datetime64 | np.bool | None|;| |;| _NDIterFlagsKind: TypeAlias = L[|;|     ""buffered"",|;|@@ -1070,7 +1073,7 @@ class _HasShapeAndSupportsItem(_HasShape[_ShapeT_co], _SupportsItem[_T_co], Prot|;| |;| # matches any `x` on `x.type.item() -> _T_co`, e.g. `dtype[np.int8]` gives `_T_co: int`|;| @type_check_only|;|-class _HashTypeWithItem(Protocol[_T_co]):|;|+class _HasTypeWithItem(Protocol[_T_co]):|;|     @property|;|     def type(self, /) -> type[_SupportsItem[_T_co]]: ...|;| |;|@@ -1082,7 +1085,7 @@ class _HasShapeAndDTypeWithItem(Protocol[_ShapeT_co, _T_co]):|;|     @property|;|     def shape(self, /) -> _ShapeT_co: ...|;|     @property|;|-    def dtype(self, /) -> _HashTypeWithItem[_T_co]: ...|;|+    def dtype(self, /) -> _HasTypeWithItem[_T_co]: ...|;| |;| @type_check_only|;| class _HasRealAndImag(Protocol[_RealT_co, _ImagT_co]):|;|@@ -1112,6 +1115,7 @@ class _HasDateAttributes(Protocol):|;|     @property|;|     def year(self) -> int: ...|;| |;|+|;| ### Mixins (for internal use only)|;| |;| @type_check_only|;|@@ -2006,7 +2010,6 @@ class _ArrayOrScalarCommon:|;|         correction: float = ...,|;|     ) -> _ArrayT: ...|;| |;|-|;| class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     __hash__: ClassVar[None]  # type: ignore[assignment]  # pyright: ignore[reportIncompatibleMethodOverride]|;|     @property|;|@@ -2082,16 +2085,56 @@ class ndarray(_ArrayOrScalarCommon, Generic[_ShapeT_co, _DType_co]):|;|     @overload|;|     def __getitem__(self, key: SupportsIndex | tuple[SupportsIndex, ...], /) -> Any: ...|;|     @overload|;|-    def __getitem__(self, key: _ArrayIndexLike | tuple[_ArrayIndexLike, ...], /) -> ndarray[_Shape, _DType_co]: ...|;|+    def __getitem__(self, key: _ToIndices, /) -> ndarray[_Shape, _DType_co]: ...|;|     @overload|;|     def __getitem__(self: NDArray[void], key: str, /) -> ndarray[_ShapeT_co, np.dtype[Any]]: ...|;|     @overload|;|     def __getitem__(self: NDArray[void], key: list[str], /) -> ndarray[_ShapeT_co, _dtype[void]]: ...|;| |;|-    @overload|;|-    def __setitem__(self: NDArray[void], key: str | list[str], value: ArrayLike, /) -> None: ...|;|-    @overload|;|-    def __setitem__(self, key: _ArrayIndexLike | tuple[_ArrayIndexLike, ...], value: ArrayLike, /) -> None: ...|;|+    @overload  # flexible | object_ | bool|;|+    def __setitem__(|;|+        self: ndarray[Any, dtype[flexible | object_ | np.bool] | dtypes.StringDType],|;|+        key: _ToIndices,|;|+        value: object,|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # integer|;|+    def __setitem__(|;|+        self: NDArray[integer],|;|+        key: _ToIndices,|;|+        value: _ConvertibleToInt | _NestedSequence[_ConvertibleToInt] | _ArrayLikeInt_co,|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # floating|;|+    def __setitem__(|;|+        self: NDArray[floating],|;|+        key: _ToIndices,|;|+        value: _ConvertibleToFloat | _NestedSequence[_ConvertibleToFloat | None] | _ArrayLikeFloat_co | None,|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # complexfloating|;|+    def __setitem__(|;|+        self: NDArray[complexfloating],|;|+        key: _ToIndices,|;|+        value: _ConvertibleToComplex | _NestedSequence[_ConvertibleToComplex | None] | _ArrayLikeNumber_co | None,|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # timedelta64|;|+    def __setitem__(|;|+        self: NDArray[timedelta64],|;|+        key: _ToIndices,|;|+        value: _ConvertibleToTD64 | _NestedSequence[_ConvertibleToTD64],|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # datetime64|;|+    def __setitem__(|;|+        self: NDArray[datetime64],|;|+        key: _ToIndices,|;|+        value: _ConvertibleToDT64 | _NestedSequence[_ConvertibleToDT64],|;|+        /,|;|+    ) -> None: ...|;|+    @overload  # catch-all|;|+    def __setitem__(self, key: _ToIndices, value: ArrayLike, /) -> None: ...|;| |;|     @property|;|     def ctypes(self) -> _ctypes[int]: ...|;|@@ -4122,16 +4165,16 @@ class timedelta64(_IntegralMixin, generic[_TD64ItemT_co], Generic[_TD64ItemT_co]|;|     @overload|;|     def __init__(self: timedelta64[int], value: dt.timedelta, format: _TimeUnitSpec[_IntTimeUnit], /) -> None: ...|;|     @overload|;|-    def __init__(self: timedelta64[int], value: int, format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|+    def __init__(self: timedelta64[int], value: _IntLike_co, format: _TimeUnitSpec[_IntTD64Unit] = ..., /) -> None: ...|;|     @overload|;|     def __init__(|;|         self: timedelta64[dt.timedelta],|;|-        value: dt.timedelta | int,|;|+        value: dt.timedelta | _IntLike_co,|;|         format: _TimeUnitSpec[_NativeTD64Unit] = ...,|;|         /,|;|     ) -> None: ...|;|     @overload|;|-    def __init__(self, value: int | bytes | str | dt.timedelta | None, format: _TimeUnitSpec = ..., /) -> None: ...|;|+    def __init__(self, value: _ConvertibleToTD64, format: _TimeUnitSpec = ..., /) -> None: ...|;| |;|     # NOTE: Only a limited number of units support conversion|;|     # to builtin scalar types: `Y`, `M`, `ns`, `ps`, `fs`, `as` || PR#27990 - numpy/typing/tests/data/pass/simple.py: @@ -71,17 +71,21 @@ def iterable_func(x: Iterable[object]) -> Iterable[object]:|;| |;| array_2d = np.ones((3, 3))|;| array_2d[:2, :2]|;|-array_2d[..., 0]|;| array_2d[:2, :2] = 0|;|+array_2d[..., 0]|;|+array_2d[..., 0] = 2|;|+array_2d[-1, -1] = None|;|+|;|+array_obj = np.zeros(1, dtype=np.object_)|;|+array_obj[0] = slice(None)|;| |;| # Other special methods|;| len(array)|;| str(array)|;| array_scalar = np.array(1)|;| int(array_scalar)|;| float(array_scalar)|;|-# currently does not work due to https://github.com/python/typeshed/issues/1904|;|-# complex(array_scalar)|;|+complex(array_scalar)|;| bytes(array_scalar)|;| operator.index(array_scalar)|;| bool(array_scalar)",TYP: Fix falsely rejected value types in ``ndarray.__setitem__``
numpy/numpy,john-science,26727,DOC: Add missing package names in API documentation page,"In [the API documentation page](https://numpy.org/doc/stable/reference/index.html#reference), there are some packages shown in parentheses (`numpy.exceptions`, `numpy.linalg`, etc.)  It might be nice to fill in the missing ones:
* [`numpy.strings`](https://numpy.org/doc/stable/reference/routines.strings.html)
* [`numpy.emath`](https://numpy.org/doc/stable/reference/routines.emath.html#module-numpy.emath)
* [`numpy.ma`](https://numpy.org/doc/stable/reference/routines.ma.html)
* [`numpy.polynomial`](https://numpy.org/doc/stable/reference/routines.polynomials.html)","Thanks for pointing out the inconsistency @NeilGirdhar.

I'd be more inclined to remove other names in brackets. That page is by topic rather than by module, and is much less messy than it was but still not 100% ideal. The ""by module"" docs are at https://numpy.org/doc/stable/reference/module_structure.html || I like that idea!

What do you think of reorganizing the ""element-wise functions"" in [the Array API's index](https://data-apis.org/array-api/latest/API_specification/index.html#) to match NumPy's index?  I think NumPy's organization is more logical and useful.  What do you think? || The PR probably didn't do all the changes, you liked.  So feel free to open a new issue or PR about it.",closed,2024-06-17T17:04:01+00:00,2024-12-12T12:07:21+00:00,NeilGirdhar,04 - Documentation,1,"PR#27324 - doc/source/reference/distutils.rst: @@ -1,8 +1,8 @@|;| .. _numpy-distutils-refguide:|;| |;|-**********************************|;|-Packaging (:mod:`numpy.distutils`)|;|-**********************************|;|+*********|;|+Packaging|;|+*********|;| |;| .. module:: numpy.distutils|;|  || PR#27324 - doc/source/reference/random/index.rst: @@ -4,8 +4,8 @@|;| |;| .. currentmodule:: numpy.random|;| |;|-Random sampling (:mod:`numpy.random`)|;|-=====================================|;|+Random sampling|;|+===============|;| |;| .. _random-quick-start:|;|  || PR#27324 - doc/source/reference/routines.linalg.rst: @@ -2,8 +2,8 @@|;| |;| .. module:: numpy.linalg|;| |;|-Linear algebra (:mod:`numpy.linalg`)|;|-====================================|;|+Linear algebra|;|+==============|;| |;| The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient|;| low level implementations of standard linear algebra algorithms. Those || PR#27324 - doc/source/reference/routines.testing.rst: @@ -1,8 +1,8 @@|;| .. _routines.testing:|;| .. module:: numpy.testing|;| |;|-Test support (:mod:`numpy.testing`)|;|-===================================|;|+Test support|;|+============|;| |;| .. currentmodule:: numpy.testing|;|  || PR#27324 - numpy/exceptions.py: @@ -1,6 +1,6 @@|;| """"""|;|-Exceptions and Warnings (:mod:`numpy.exceptions`)|;|-=================================================|;|+Exceptions and Warnings|;|+=======================|;| |;| General exceptions used by NumPy.  Note that some exceptions may be module|;| specific, such as linear algebra errors. || PR#27324 - numpy/fft/__init__.py: @@ -1,6 +1,6 @@|;| """"""|;|-Discrete Fourier Transform (:mod:`numpy.fft`)|;|-=============================================|;|+Discrete Fourier Transform|;|+==========================|;| |;| .. currentmodule:: numpy.fft|;| ",DOC: Removing module name from by-topic docs || I don't understand the typing problem
numpy/numpy,larsoner,27979,DOC: Explicitly spell out abi3 (in)compatibility,"### Issue with current documentation:

I have built a number of packages against NumPy and looked at things like the [depending on NumPy](https://numpy.org/devdocs/dev/depending_on_numpy.html#understanding-numpy-s-versioning-and-api-abi-stability) docs. However, I don't see it mentioned anywhere under what circumstances you can safely build `abi3` wheels, if any (and I actually don't know the answer :facepalm: !). So it would be great to add a note about this explicitly to the docs.

### Idea or request for content:

:point_up: ","We do test building a C extension with the Python 3.6 and latest limited API, using both C and Cython:

https://github.com/numpy/numpy/blob/main/numpy/_core/tests/test_limited_api.py

So I'd say ""it's supported"" and we'd like to hear bug reports if you run into any issues.

Doc updates to the C API docs indicating our support for building third-party extensions that use the numpy C API and the limited API are welcome. || There are at most two notes:
1. There are some niche APIs that cannot be public in the stable API.
2. There were issues/bugs in the header before NumPy 2 (and also one later on newer Python versions due to a Python header change).
   But that isn't much of a limitation in practice anymore, since you can just pin to a newer version if you run into it.

Basically, there is nothing in NumPy that would have a problem with the stable API, unless the API exposes Python internals that are not exposed. || @seberg do you want to push those tweaks directly as you see fit? Not sure I could do those two points justice, other than a hacky copy-paste of what you wrote :sweat_smile: 

*EDIT: I mean: push to https://github.com/numpy/numpy/pull/27981*",closed,2024-12-11T16:36:38+00:00,2024-12-11T19:49:01+00:00,larsoner,04 - Documentation,1,"PR#27981 - doc/source/dev/depending_on_numpy.rst: @@ -33,6 +33,13 @@ forward but not backward compatible. This means: binaries compiled against a|;| given target version of NumPy's C API will still run correctly with newer NumPy|;| versions, but not with older versions.|;| |;|+Modules can also be safely built against NumPy 2.0 or later in|;|+:ref:`CPython's abi3 mode <python:stable-abi>`, which allows|;|+building against a single (minimum-supported) version of Python but be|;|+forward compatible higher versions in the same series (e.g., ``3.x``).|;|+This can greatly reduce the number of wheels that need to be built and|;|+distributed. For more information and examples, see the|;|+`cibuildwheel docs <https://cibuildwheel.pypa.io/en/stable/faq/#abi3>`__.|;| |;| .. _testing-prereleases:|;| |;|@@ -82,7 +89,7 @@ Build-time dependency|;| |;| If a package either uses the NumPy C API directly or it uses some other tool|;| that depends on it like Cython or Pythran, NumPy is a *build-time* dependency|;|-of the package. |;|+of the package.|;| |;| By default, NumPy will expose an API that is backwards compatible with the|;| oldest NumPy version that supports the currently oldest compatible Python",DOC: Document abi3 compat || FIX: 2.0 || FIX: Link
numpy/numpy,mhvk,27461,ENH: Add `shape` control parameter to `set_printoptions`,"### Proposed new feature or change:

I want to be able to print large arrays and display the shape of the array at the same time.

Like this, I don't know what the shape of `x`, shape == (2, ???).

```python
> print(x)
array([[       0,        1,        2, ..., 49999997, 49999998, 49999999],
       [50000000, 50000001, 50000002, ..., 99999997, 99999998, 99999999]])
```","What is wrong with this? I don't think we are going to change something so basic to NumPy at this stage.
```
print(f""{x=}"")
print(f""{x.shape=}"")
``` || > What is wrong with this? I don't think we are going to change something so basic to NumPy at this stage.
> 
> ```
> print(f""{x=}"")
> print(f""{x.shape=}"")
> ```

I'm using jupyter notebook.

If you want to look at a complex statement like:
`x[x > 0].sum(...).otherFunc1(...).otherFunc2(...)`

Your need to do either:
```python
tmp = x[x > 0].sum(...).otherFunc1(...).otherFunc2(...)
print(tmp)
print(tmp.shape)
```
or:
```python
print(x[x > 0].sum(...).otherFunc1(...).otherFunc2(...))
print(x[x > 0].sum(...).otherFunc1(...).otherFunc2(...).shape)
```

I want to look at a large array summary and its shape in one line code. || Maybe good to try to be concrete, since while writing this I completely changed my mind, to thinking this should be done without even an option to turn it on or off.

In a jupyter notebook, what you get from `print(x)` is not directly relevant, since that uses `__str__` while you would normally see `__repr__`, like,
```
In [3]: np.ones((2, 100000), dtype='f4')
Out[3]: 
array([[1., 1., 1., ..., 1., 1., 1.],
       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)
```
I chose this example with `'f4'` since that shows that we do put in extra information already when it cannot be inferred directly from the data as shown. But here it is also really logical to do so in that it is an argument that can actually be passed on to `np.array`. This is not the case for `shape`, making that less logical to show. However, it is in fact already shown for zero-sized arrays with shape not simply `(0,)`:
```
In [4]: np.ones((2, 0), dtype='f4')
Out[4]: array([], shape=(2, 0), dtype=float32)
```
For this case, the shape cannot be guessed from the data values (`[]` in this case), and perhaps that was the reason to show it, just like `dtype` is shown for the case that it cannot be guessed from the data.

To me, the above makes it seem reasonable to show the shape more generally when it cannot be directly inferred, i.e., also when data has been summarized. I think it would not be particularly hard to do: just an extra bit of logic in `_array_repr_implementation` in `numpy/_core/arrayprint.py`.

p.s. An alternative I thought of would be to allow customization of `summary_insert`, so that one could replace `...` with, e.g., `...[10 items]...`. But I think for adding extra options we have to be way more careful - we already have rather many and really it is not that useful to allow control at the level of which people should just write their own function. || @mhvk This is what I want to say, sometime you are hard to know the shape.

![image](https://github.com/user-attachments/assets/ffb63a79-c23d-4676-9bcb-ea56af5c835d)

I had written myself version for printing, but I had to write it every new notebook.

```python
def summary(self: NDArray, include_dtype: bool = False, include_shape: bool = True):
    summ = cp.array_repr(self) if hasattr(self, 'device') else np.array_repr(self)
    summ_parts = [summ[:-1]]
    if include_dtype:
        summ_parts.append(f', dtype={self.dtype}')
    if include_shape:
        summ_parts.append(f', shape={self.shape}')
    summ_parts.append(')')
    print(''.join(summ_parts))
``` || The actual implementation does something fairly similar - except that it also checks the result still fits on the last line. I think it would make sense to adjust it... See https://github.com/numpy/numpy/blob/9c5162192639937c53fbbbba74391d9e80df485b/numpy/_core/arrayprint.py#L1564-L1613 || > I'm using jupyter notebook.

I think this is common.  I think it may make sense to focus attention on creating an html representation for arrays, which could probably much more naturally fit the shape somewhere.  I realize that is a bigger job, but it would be a pretty major improvement! || I found a solution to my needs, which is `np.set_string_function`:

```python
def summary(self: NDArray, include_dtype: bool = False, include_shape: bool = True):
    summ = cp.array_repr(self) if hasattr(self, 'device') else np.array_repr(self)
    summ_parts = [summ[:-1]]
    if include_dtype:
        summ_parts.append(f', dtype={self.dtype}')
    if include_shape:
        summ_parts.append(f', shape={self.shape}')
    summ_parts.append(')')
    return ''.join(summ_parts)


np.set_string_function(summary)
```

```python
> np.arange(1000000).reshape(2000, -1)
array([[     0,      1,      2, ...,    497,    498,    499],
       [   500,    501,    502, ...,    997,    998,    999],
       [  1000,   1001,   1002, ...,   1497,   1498,   1499],
       ...,
       [998500, 998501, 998502, ..., 998997, 998998, 998999],
       [999000, 999001, 999002, ..., 999497, 999498, 999499],
       [999500, 999501, 999502, ..., 999997, 999998, 999999]], shape=(2000, 500))
``` || That work-around is great! But it still irritated me that the code doesn't ""do the right thing"" by default, so I made a quick PR that changes the behaviour - see #27482",closed,2024-09-25T09:27:32+00:00,2024-11-07T09:34:34+00:00,GF-Huang,,1,"PR#27482 - doc/release/upcoming_changes/27482.change.rst: @@ -0,0 +1,8 @@|;|+* The ``repr`` of arrays large enough to be summarized (i.e., where elements|;|+  are replaced with ``...``) now includes the ``shape`` of the array, similar|;|+  to what already was the case for arrays with zero size and non-obvious|;|+  shape. With this change, the shape is always given when it cannot be|;|+  inferred from the values.  Note that while written as ``shape=...``, this|;|+  argument cannot actually be passed in to the ``np.array`` constructor. If|;|+  you encounter problems, e.g., due to failing doctests, you can use the print|;|+  option ``legacy=2.1`` to get the old behaviour. || PR#27482 - numpy/_core/arrayprint.py: @@ -83,12 +83,14 @@ def _make_options_dict(precision=None, threshold=None, edgeitems=None,|;|         options['legacy'] = 121|;|     elif legacy == '1.25':|;|         options['legacy'] = 125|;|+    elif legacy == '2.1':|;|+        options['legacy'] = 201|;|     elif legacy is None:|;|         pass  # OK, do nothing.|;|     else:|;|         warnings.warn(|;|             ""legacy printing option can currently only be '1.13', '1.21', ""|;|-            ""'1.25', or `False`"", stacklevel=3)|;|+            ""'1.25', '2.1, or `False`"", stacklevel=3)|;| |;|     if threshold is not None:|;|         # forbid the bad threshold arg suggested by stack overflow, gh-12351|;|@@ -214,13 +216,16 @@ def set_printoptions(precision=None, threshold=None, edgeitems=None,|;|         that numeric scalars are printed without their type information, e.g.|;|         as ``3.0`` rather than ``np.float64(3.0)``.|;| |;|+        If set to ``'2.1'``, shape information is not given when arrays are|;|+        summarized (i.e., multiple elements replaced with ``...``).|;|+|;|         If set to `False`, disables legacy mode.|;| |;|         Unrecognized strings will be ignored with a warning for forward|;|         compatibility.|;| |;|         .. versionchanged:: 1.22.0|;|-        .. versionchanged:: 2.0|;|+        .. versionchanged:: 2.2|;| |;|     override_repr: callable, optional|;|         If set a passed function will be used for generating arrays' repr.|;|@@ -249,7 +254,7 @@ def set_printoptions(precision=None, threshold=None, edgeitems=None,|;| |;|     >>> np.set_printoptions(threshold=5)|;|     >>> np.arange(10)|;|-    array([0, 1, 2, ..., 7, 8, 9])|;|+    array([0, 1, 2, ..., 7, 8, 9], shape=(10,))|;| |;|     Small results can be suppressed:|;| |;|@@ -282,7 +287,7 @@ def set_printoptions(precision=None, threshold=None, edgeitems=None,|;| |;|     >>> with np.printoptions(precision=2, suppress=True, threshold=5):|;|     ...     np.linspace(0, 10, 10)|;|-    array([ 0.  ,  1.11,  2.22, ...,  7.78,  8.89, 10.  ])|;|+    array([ 0.  ,  1.11,  2.22, ...,  7.78,  8.89, 10.  ], shape=(10,))|;| |;|     """"""|;|     _set_printoptions(precision, threshold, edgeitems, linewidth, suppress,|;|@@ -1578,39 +1583,41 @@ def _array_repr_implementation(|;|     else:|;|         class_name = ""array""|;| |;|-    skipdtype = dtype_is_implied(arr.dtype) and arr.size > 0|;|-|;|     prefix = class_name + ""(""|;|-    suffix = "")"" if skipdtype else "",""|;|-|;|     if (current_options['legacy'] <= 113 and|;|             arr.shape == () and not arr.dtype.names):|;|         lst = repr(arr.item())|;|-    elif arr.size > 0 or arr.shape == (0,):|;|+    else:|;|         lst = array2string(arr, max_line_width, precision, suppress_small,|;|-                           ', ', prefix, suffix=suffix)|;|-    else:  # show zero-length shape unless it is (0,)|;|-        lst = ""[], shape=%s"" % (repr(arr.shape),)|;|-|;|-    arr_str = prefix + lst + suffix|;|-|;|-    if skipdtype:|;|-        return arr_str|;|-|;|-    dtype_str = ""dtype={})"".format(dtype_short_repr(arr.dtype))|;|-|;|-    # compute whether we should put dtype on a new line: Do so if adding the|;|-    # dtype would extend the last line past max_line_width.|;|+                           ', ', prefix, suffix="")"")|;|+|;|+    # Add dtype and shape information if these cannot be inferred from|;|+    # the array string.|;|+    extras = []|;|+    if (arr.size == 0 and arr.shape != (0,)|;|+            or current_options['legacy'] > 210|;|+            and arr.size > current_options['threshold']):|;|+        extras.append(f""shape={arr.shape}"")|;|+    if not dtype_is_implied(arr.dtype) or arr.size == 0:|;|+        extras.append(f""dtype={dtype_short_repr(arr.dtype)}"")|;|+|;|+    if not extras:|;|+        return prefix + lst + "")""|;|+|;|+    arr_str = prefix + lst + "",""|;|+    extra_str = "", "".join(extras) + "")""|;|+    # compute whether we should put extras on a new line: Do so if adding the|;|+    # extras would extend the last line past max_line_width.|;|     # Note: This line gives the correct result even when rfind returns -1.|;|     last_line_len = len(arr_str) - (arr_str.rfind('\n') + 1)|;|     spacer = "" ""|;|     if current_options['legacy'] <= 113:|;|         if issubclass(arr.dtype.type, flexible):|;|-            spacer = '\n' + ' '*len(class_name + ""("")|;|-    elif last_line_len + len(dtype_str) + 1 > max_line_width:|;|-        spacer = '\n' + ' '*len(class_name + ""("")|;|+            spacer = '\n' + ' '*len(prefix)|;|+    elif last_line_len + len(extra_str) + 1 > max_line_width:|;|+        spacer = '\n' + ' '*len(prefix)|;| |;|-    return arr_str + spacer + dtype_str|;|+    return arr_str + spacer + extra_str|;| |;| |;| def _array_repr_dispatcher( || PR#27482 - numpy/_core/tests/test_arrayprint.py: @@ -346,7 +346,13 @@ def test_summarize_1d(self):|;|         assert_equal(str(A), strA)|;| |;|         reprA = 'array([   0,    1,    2, ...,  998,  999, 1000])'|;|-        assert_equal(repr(A), reprA)|;|+        try:|;|+            np.set_printoptions(legacy='2.1')|;|+            assert_equal(repr(A), reprA)|;|+        finally:|;|+            np.set_printoptions(legacy=False)|;|+|;|+        assert_equal(repr(A), reprA.replace(')', ', shape=(1001,))'))|;| |;|     def test_summarize_2d(self):|;|         A = np.arange(1002).reshape(2, 501)|;|@@ -356,6 +362,23 @@ def test_summarize_2d(self):|;| |;|         reprA = 'array([[   0,    1,    2, ...,  498,  499,  500],\n' \|;|                 '       [ 501,  502,  503, ...,  999, 1000, 1001]])'|;|+        try:|;|+            np.set_printoptions(legacy='2.1')|;|+            assert_equal(repr(A), reprA)|;|+        finally:|;|+            np.set_printoptions(legacy=False)|;|+|;|+        assert_equal(repr(A), reprA.replace(')', ', shape=(2, 501))'))|;|+|;|+    def test_summarize_2d_dtype(self):|;|+        A = np.arange(1002, dtype='i2').reshape(2, 501)|;|+        strA = '[[   0    1    2 ...  498  499  500]\n' \|;|+               ' [ 501  502  503 ...  999 1000 1001]]'|;|+        assert_equal(str(A), strA)|;|+|;|+        reprA = ('array([[   0,    1,    2, ...,  498,  499,  500],\n'|;|+                 '       [ 501,  502,  503, ...,  999, 1000, 1001]],\n'|;|+                 '      shape=(2, 501), dtype=int16)')|;|         assert_equal(repr(A), reprA)|;| |;|     def test_summarize_structure(self):|;|@@ -1040,7 +1063,7 @@ def test_edgeitems(self):|;| |;|                    [[18, ..., 20],|;|                     ...,|;|-                    [24, ..., 26]]])"""""")|;|+                    [24, ..., 26]]], shape=(3, 3, 3))"""""")|;|         )|;| |;|         b = np.zeros((3, 3, 1, 1))|;|@@ -1061,40 +1084,37 @@ def test_edgeitems(self):|;| |;|                     ...,|;| |;|-                    [[0.]]]])"""""")|;|+                    [[0.]]]], shape=(3, 3, 1, 1))"""""")|;|         )|;| |;|         # 1.13 had extra trailing spaces, and was missing newlines|;|-        np.set_printoptions(legacy='1.13')|;|-|;|-        assert_equal(|;|-            repr(a),|;|-            textwrap.dedent(""""""\|;|-            array([[[ 0, ...,  2],|;|-                    ..., |;|-                    [ 6, ...,  8]],|;|-|;|-                   ..., |;|-                   [[18, ..., 20],|;|-                    ..., |;|-                    [24, ..., 26]]])"""""")|;|-        )|;|-|;|-        assert_equal(|;|-            repr(b),|;|-            textwrap.dedent(""""""\|;|-            array([[[[ 0.]],|;|-|;|-                    ..., |;|-                    [[ 0.]]],|;|-|;|-|;|-                   ..., |;|-                   [[[ 0.]],|;|-|;|-                    ..., |;|-                    [[ 0.]]]])"""""")|;|-        )|;|+        try:|;|+            np.set_printoptions(legacy='1.13')|;|+            assert_equal(repr(a), (|;|+                ""array([[[ 0, ...,  2],\n""|;|+                ""        ..., \n""|;|+                ""        [ 6, ...,  8]],\n""|;|+                ""\n""|;|+                ""       ..., \n""|;|+                ""       [[18, ..., 20],\n""|;|+                ""        ..., \n""|;|+                ""        [24, ..., 26]]])"")|;|+            )|;|+            assert_equal(repr(b), (|;|+                ""array([[[[ 0.]],\n""|;|+                ""\n""|;|+                ""        ..., \n""|;|+                ""        [[ 0.]]],\n""|;|+                ""\n""|;|+                ""\n""|;|+                ""       ..., \n""|;|+                ""       [[[ 0.]],\n""|;|+                ""\n""|;|+                ""        ..., \n""|;|+                ""        [[ 0.]]]])"")|;|+            )|;|+        finally:|;|+            np.set_printoptions(legacy=False)|;| |;|     def test_edgeitems_structured(self):|;|         np.set_printoptions(edgeitems=1, threshold=1)","MAINT: refactor array_repr to treat shape and dtype similary

To help set oneself up for using shape for different reasons. || ENH: include shape in repr also for summarized arrays

So that it is always there when the shape cannot be inferred from list"
numpy/numpy,ngoldbaum,27637,BUG: Operation spuriously returns a legacy string,"After applying the changes from #27636:

```
>>> print(repr(np.strings.replace(
            np.array([""hello planet""], dtype=""U""),
            np.array(""planet"", dtype=""T""),
            np.array(""world"", dtype=""T""))))
array(['hello world'], dtype='<U11')
```

We get a unicode array back, despite the fact that StringDType explicitly installs a promoter for this case.

I thought this had something to do with the fact that the legacy string unicode promoters work by constructing a promoter DType tuple that's filled with `None` entries. But that's fine, since `None` has less priority than a specific DType.

Instead something else is going on. I got as far as tracing through the call to `resolve_descriptors`, which does correctly set the output DType to StringDType, so something else fishy is going on later when the actual output array is created.","Nice, tracking, but the error is just in the Python code.  It thinks we are taking the code path designed for old strings, and if it does that it has to pass the `out=` array.

So the ufunc does the right thing:  It operates with the new strings, but happily casts to the `U11` output that the Python code forces it to cast to.
(Which, is a same-kind cast, so not an error.)

EDIT:

The easiest solution is probably just to promote ahead of time.  You could do that with `_replace.resolve_dtypes`, but not sure it is worth it compared to just using `np.result_type` here. || Thanks! I should have probably noticed that `out` was set even though I didn't pass it in...

> The easiest solution is probably just to promote ahead of time. You could do that with _replace.resolve_dtypes, but not sure it is worth it compared to just using np.result_type here.

I implemented this using `np.result_type` for `replace` and this works. I'll apply the same refactoring to the other string ufunc wrappers and update #27636  to close this. || > and this works

Oh actually one wrinkle is that `np.result_type` assumes a string argument is a dtype, but then strings are also array-likes 🙃 

I can get it to work by first converting to array and then calling `result_type`, but it is a little annoying for this use case where the arguments are very likely to be string scalars. || Yeah, I was starting to wonder if we should have `result_type(*args, objs=, dtypes=)`, because it's quite messy that there is ""is this a dtype"" guessing logic.  And then, we could potentially avoid converting to an array fully.
OTOH, the ufunc will convert to an array anyway, so... You can use the new `_array_converter` helper, it may be convenient here, but probably doens't really change anything.",closed,2024-10-24T23:06:34+00:00,2024-10-30T14:37:12+00:00,ngoldbaum,00 - Bug,1,"PR#27636 - doc/release/upcoming_changes/27636.improvement.rst: @@ -0,0 +1,3 @@|;|+* Fixed a number of issues around promotion for string ufuncs with StringDType|;|+  arguments. Mixing StringDType and the fixed-width DTypes using the string|;|+  ufuncs should now generate much more uniform results. || PR#27636 - numpy/_core/src/umath/stringdtype_ufuncs.cpp: @@ -1598,6 +1598,20 @@ string_expandtabs_strided_loop(PyArrayMethod_Context *context,|;|     return -1|;|; }|;| |;|+static int|;|+string_center_ljust_rjust_promoter(|;|+        PyObject *NPY_UNUSED(ufunc),|;|+        PyArray_DTypeMeta *const op_dtypes[],|;|+        PyArray_DTypeMeta *const signature[],|;|+        PyArray_DTypeMeta *new_op_dtypes[])|;|+{|;|+    new_op_dtypes[0] = NPY_DT_NewRef(&PyArray_StringDType)|;|;+    new_op_dtypes[1] = NPY_DT_NewRef(&PyArray_Int64DType)|;|;+    new_op_dtypes[2] = NPY_DT_NewRef(&PyArray_StringDType)|;|;+    new_op_dtypes[3] = NPY_DT_NewRef(&PyArray_StringDType)|;|;+    return 0|;|;+}|;|+|;| static NPY_CASTING|;| center_ljust_rjust_resolve_descriptors(|;|         struct PyArrayMethodObject_tag *NPY_UNUSED(method),|;|@@ -2595,10 +2609,17 @@ init_stringdtype_ufuncs(PyObject *umath)|;|         ""find"", ""rfind"", ""index"", ""rindex"", ""count"",|;|     }|;|; |;|-    PyArray_DTypeMeta *findlike_promoter_dtypes[] = {|;|-        &PyArray_StringDType, &PyArray_UnicodeDType,|;|-        &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|-        &PyArray_DefaultIntDType,|;|+    PyArray_DTypeMeta *findlike_promoter_dtypes[2][5] = {|;|+        {|;|+            &PyArray_StringDType, &PyArray_UnicodeDType,|;|+            &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|+            &PyArray_IntAbstractDType,|;|+        },|;|+        {|;|+            &PyArray_UnicodeDType, &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|+            &PyArray_IntAbstractDType,|;|+        },|;|     }|;|; |;|     find_like_function *findlike_functions[] = {|;|@@ -2618,11 +2639,12 @@ init_stringdtype_ufuncs(PyObject *umath)|;|             return -1|;|;         }|;| |;|-|;|-        if (add_promoter(umath, findlike_names[i],|;|-                         findlike_promoter_dtypes,|;|-                         5, string_findlike_promoter) < 0) {|;|-            return -1|;|;+        for (int j=0; j<2; j++) {|;|+            if (add_promoter(umath, findlike_names[i],|;|+                             findlike_promoter_dtypes[j],|;|+                             5, string_findlike_promoter) < 0) {|;|+                return -1|;|;+            }|;|         }|;|     }|;| |;|@@ -2636,10 +2658,17 @@ init_stringdtype_ufuncs(PyObject *umath)|;|         ""startswith"", ""endswith"",|;|     }|;|; |;|-    PyArray_DTypeMeta *startswith_endswith_promoter_dtypes[] = {|;|-        &PyArray_StringDType, &PyArray_UnicodeDType,|;|-        &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|-        &PyArray_BoolDType,|;|+    PyArray_DTypeMeta *startswith_endswith_promoter_dtypes[2][5] = {|;|+        {|;|+            &PyArray_StringDType, &PyArray_UnicodeDType,|;|+            &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|+            &PyArray_BoolDType,|;|+        },|;|+        {|;|+            &PyArray_UnicodeDType, &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType, &PyArray_IntAbstractDType,|;|+            &PyArray_BoolDType,|;|+        },|;|     }|;|; |;|     static STARTPOSITION startswith_endswith_startposition[] = {|;|@@ -2656,11 +2685,12 @@ init_stringdtype_ufuncs(PyObject *umath)|;|             return -1|;|;         }|;| |;|-|;|-        if (add_promoter(umath, startswith_endswith_names[i],|;|-                         startswith_endswith_promoter_dtypes,|;|-                         5, string_startswith_endswith_promoter) < 0) {|;|-            return -1|;|;+        for (int j=0; j<2; j++) {|;|+            if (add_promoter(umath, startswith_endswith_names[i],|;|+                             startswith_endswith_promoter_dtypes[j],|;|+                             5, string_startswith_endswith_promoter) < 0) {|;|+                return -1|;|;+            }|;|         }|;|     }|;| |;|@@ -2732,24 +2762,38 @@ init_stringdtype_ufuncs(PyObject *umath)|;|         return -1|;|;     }|;| |;|-    PyArray_DTypeMeta *replace_promoter_pyint_dtypes[] = {|;|-        &PyArray_StringDType, &PyArray_UnicodeDType, &PyArray_UnicodeDType,|;|-        &PyArray_IntAbstractDType, &PyArray_StringDType,|;|-    }|;|;-|;|-    if (add_promoter(umath, ""_replace"", replace_promoter_pyint_dtypes, 5,|;|-                     string_replace_promoter) < 0) {|;|-        return -1|;|;-    }|;|-|;|-    PyArray_DTypeMeta *replace_promoter_int64_dtypes[] = {|;|-        &PyArray_StringDType, &PyArray_UnicodeDType, &PyArray_UnicodeDType,|;|-        &PyArray_Int64DType, &PyArray_StringDType,|;|+    PyArray_DTypeMeta *replace_promoter_unicode_dtypes[6][5] = {|;|+        {|;|+            &PyArray_StringDType, &PyArray_UnicodeDType, &PyArray_UnicodeDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|+        {|;|+            &PyArray_UnicodeDType, &PyArray_StringDType, &PyArray_UnicodeDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|+        {|;|+            &PyArray_UnicodeDType, &PyArray_UnicodeDType, &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|+        {|;|+            &PyArray_StringDType, &PyArray_StringDType, &PyArray_UnicodeDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|+        {|;|+            &PyArray_StringDType, &PyArray_UnicodeDType, &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|+        {|;|+            &PyArray_UnicodeDType, &PyArray_StringDType, &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType, &PyArray_StringDType,|;|+        },|;|     }|;|; |;|-    if (add_promoter(umath, ""_replace"", replace_promoter_int64_dtypes, 5,|;|-                     string_replace_promoter) < 0) {|;|-        return -1|;|;+    for (int j=0; j<6; j++) {|;|+        if (add_promoter(umath, ""_replace"", replace_promoter_unicode_dtypes[j], 5,|;|+                         string_replace_promoter) < 0) {|;|+            return -1|;|;+        }|;|     }|;| |;|     PyArray_DTypeMeta *expandtabs_dtypes[] = {|;|@@ -2767,9 +2811,9 @@ init_stringdtype_ufuncs(PyObject *umath)|;|     }|;| |;|     PyArray_DTypeMeta *expandtabs_promoter_dtypes[] = {|;|-        &PyArray_StringDType,|;|-        (PyArray_DTypeMeta *)Py_None,|;|-        &PyArray_StringDType|;|+            &PyArray_StringDType,|;|+            &PyArray_IntAbstractDType,|;|+            &PyArray_StringDType|;|     }|;|; |;|     if (add_promoter(umath, ""_expandtabs"", expandtabs_promoter_dtypes,|;|@@ -2801,30 +2845,33 @@ init_stringdtype_ufuncs(PyObject *umath)|;|             return -1|;|;         }|;| |;|-        PyArray_DTypeMeta *int_promoter_dtypes[] = {|;|-            &PyArray_StringDType,|;|-            (PyArray_DTypeMeta *)Py_None,|;|-            &PyArray_StringDType,|;|-            &PyArray_StringDType,|;|-        }|;|;-|;|-        if (add_promoter(umath, center_ljust_rjust_names[i],|;|-                         int_promoter_dtypes, 4,|;|-                         string_multiply_promoter) < 0) {|;|-            return -1|;|;-        }|;|-|;|-        PyArray_DTypeMeta *unicode_promoter_dtypes[] = {|;|-            &PyArray_StringDType,|;|-            (PyArray_DTypeMeta *)Py_None,|;|-            &PyArray_UnicodeDType,|;|-            &PyArray_StringDType,|;|+        PyArray_DTypeMeta *promoter_dtypes[3][4] = {|;|+            {|;|+                &PyArray_StringDType,|;|+                &PyArray_IntAbstractDType,|;|+                &PyArray_StringDType,|;|+                &PyArray_StringDType,|;|+            },|;|+            {|;|+                &PyArray_StringDType,|;|+                &PyArray_IntAbstractDType,|;|+                &PyArray_UnicodeDType,|;|+                &PyArray_StringDType,|;|+            },|;|+            {|;|+                &PyArray_UnicodeDType,|;|+                &PyArray_IntAbstractDType,|;|+                &PyArray_StringDType,|;|+                &PyArray_StringDType,|;|+            },|;|         }|;|; |;|-        if (add_promoter(umath, center_ljust_rjust_names[i],|;|-                         unicode_promoter_dtypes, 4,|;|-                         string_multiply_promoter) < 0) {|;|-            return -1|;|;+        for (int j=0; j<3; j++) {|;|+            if (add_promoter(umath, center_ljust_rjust_names[i],|;|+                             promoter_dtypes[j], 4,|;|+                             string_center_ljust_rjust_promoter) < 0) {|;|+                return -1|;|;+            }|;|         }|;|     }|;| |;|@@ -2840,13 +2887,13 @@ init_stringdtype_ufuncs(PyObject *umath)|;|         return -1|;|;     }|;| |;|-    PyArray_DTypeMeta *int_promoter_dtypes[] = {|;|+    PyArray_DTypeMeta *zfill_promoter_dtypes[] = {|;|             &PyArray_StringDType,|;|-            (PyArray_DTypeMeta *)Py_None,|;|+            &PyArray_IntAbstractDType,|;|             &PyArray_StringDType,|;|     }|;|; |;|-    if (add_promoter(umath, ""_zfill"", int_promoter_dtypes, 3,|;|+    if (add_promoter(umath, ""_zfill"", zfill_promoter_dtypes, 3,|;|                      string_multiply_promoter) < 0) {|;|         return -1|;|;     } || PR#27636 - numpy/_core/strings.py: @@ -669,20 +669,27 @@ def center(a, width, fillchar=' '):|;|     array(['a1b2', '1b2a', 'b2a1', '2a1b'], dtype='<U4')|;| |;|     """"""|;|+    width = np.asanyarray(width)|;|+|;|+    if not np.issubdtype(width.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {width.dtype} for operand 'width'"")|;|+|;|     a = np.asanyarray(a)|;|-    fillchar = np.asanyarray(fillchar, dtype=a.dtype)|;|+    fillchar = np.asanyarray(fillchar)|;| |;|     if np.any(str_len(fillchar) != 1):|;|         raise TypeError(|;|             ""The fill character must be exactly one character long"")|;| |;|-    if a.dtype.char == ""T"":|;|+    if np.result_type(a, fillchar).char == ""T"":|;|         return _center(a, width, fillchar)|;| |;|+    fillchar = fillchar.astype(a.dtype, copy=False)|;|     width = np.maximum(str_len(a), width)|;|     out_dtype = f""{a.dtype.char}{width.max()}""|;|     shape = np.broadcast_shapes(a.shape, width.shape, fillchar.shape)|;|     out = np.empty_like(a, shape=shape, dtype=out_dtype)|;|+|;|     return _center(a, width, fillchar, out=out)|;| |;| |;|@@ -726,20 +733,26 @@ def ljust(a, width, fillchar=' '):|;|     array(['aAaAaA   ', '  aA     ', 'abBABba  '], dtype='<U9')|;| |;|     """"""|;|+    width = np.asanyarray(width)|;|+    if not np.issubdtype(width.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {width.dtype} for operand 'width'"")|;|+|;|     a = np.asanyarray(a)|;|-    fillchar = np.asanyarray(fillchar, dtype=a.dtype)|;|+    fillchar = np.asanyarray(fillchar)|;| |;|     if np.any(str_len(fillchar) != 1):|;|         raise TypeError(|;|             ""The fill character must be exactly one character long"")|;| |;|-    if a.dtype.char == ""T"":|;|+    if np.result_type(a, fillchar).char == ""T"":|;|         return _ljust(a, width, fillchar)|;| |;|+    fillchar = fillchar.astype(a.dtype, copy=False)|;|     width = np.maximum(str_len(a), width)|;|     shape = np.broadcast_shapes(a.shape, width.shape, fillchar.shape)|;|     out_dtype = f""{a.dtype.char}{width.max()}""|;|     out = np.empty_like(a, shape=shape, dtype=out_dtype)|;|+|;|     return _ljust(a, width, fillchar, out=out)|;| |;| |;|@@ -783,20 +796,26 @@ def rjust(a, width, fillchar=' '):|;|     array(['   aAaAaA', '     aA  ', '  abBABba'], dtype='<U9')|;| |;|     """"""|;|+    width = np.asanyarray(width)|;|+    if not np.issubdtype(width.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {width.dtype} for operand 'width'"")|;|+|;|     a = np.asanyarray(a)|;|-    fillchar = np.asanyarray(fillchar, dtype=a.dtype)|;|+    fillchar = np.asanyarray(fillchar)|;| |;|     if np.any(str_len(fillchar) != 1):|;|         raise TypeError(|;|             ""The fill character must be exactly one character long"")|;| |;|-    if a.dtype.char == ""T"":|;|+    if np.result_type(a, fillchar).char == ""T"":|;|         return _rjust(a, width, fillchar)|;| |;|+    fillchar = fillchar.astype(a.dtype, copy=False)|;|     width = np.maximum(str_len(a), width)|;|     shape = np.broadcast_shapes(a.shape, width.shape, fillchar.shape)|;|     out_dtype = f""{a.dtype.char}{width.max()}""|;|     out = np.empty_like(a, shape=shape, dtype=out_dtype)|;|+|;|     return _rjust(a, width, fillchar, out=out)|;| |;| |;|@@ -830,6 +849,10 @@ def zfill(a, width):|;|     array(['001', '-01', '+01'], dtype='<U3')|;| |;|     """"""|;|+    width = np.asanyarray(width)|;|+    if not np.issubdtype(width.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {width.dtype} for operand 'width'"")|;|+|;|     a = np.asanyarray(a)|;| |;|     if a.dtype.char == ""T"":|;|@@ -1205,22 +1228,29 @@ def replace(a, old, new, count=-1):|;|     array(['The dwash was fresh', 'Thwas was it'], dtype='<U19')|;| |;|     """"""|;|-    arr = np.asanyarray(a)|;|-    a_dt = arr.dtype|;|-    old = np.asanyarray(old, dtype=getattr(old, 'dtype', a_dt))|;|-    new = np.asanyarray(new, dtype=getattr(new, 'dtype', a_dt))|;|     count = np.asanyarray(count)|;|+    if not np.issubdtype(count.dtype, np.integer):|;|+        raise TypeError(f""unsupported type {count.dtype} for operand 'count'"")|;|+|;|+    arr = np.asanyarray(a)|;|+    old_dtype = getattr(old, 'dtype', None)|;|+    old = np.asanyarray(old)|;|+    new_dtype = getattr(new, 'dtype', None)|;|+    new = np.asanyarray(new)|;| |;|-    if arr.dtype.char == ""T"":|;|+    if np.result_type(arr, old, new).char == ""T"":|;|         return _replace(arr, old, new, count)|;| |;|+    a_dt = arr.dtype|;|+    old = old.astype(old_dtype if old_dtype else a_dt, copy=False)|;|+    new = new.astype(new_dtype if new_dtype else a_dt, copy=False)|;|     max_int64 = np.iinfo(np.int64).max|;|     counts = _count_ufunc(arr, old, 0, max_int64)|;|     counts = np.where(count < 0, counts, np.minimum(counts, count))|;|-|;|     buffersizes = str_len(arr) + counts * (str_len(new) - str_len(old))|;|     out_dtype = f""{arr.dtype.char}{buffersizes.max()}""|;|     out = np.empty_like(arr, shape=buffersizes.shape, dtype=out_dtype)|;|+|;|     return _replace(arr, old, new, counts, out=out)|;| |;| |;|@@ -1429,11 +1459,12 @@ def partition(a, sep):|;| |;|     """"""|;|     a = np.asanyarray(a)|;|-    # TODO switch to copy=False when issues around views are fixed|;|-    sep = np.array(sep, dtype=a.dtype, copy=True, subok=True)|;|-    if a.dtype.char == ""T"":|;|+    sep = np.asanyarray(sep)|;|+|;|+    if np.result_type(a, sep).char == ""T"":|;|         return _partition(a, sep)|;| |;|+    sep = sep.astype(a.dtype, copy=False)|;|     pos = _find_ufunc(a, sep, 0, MAX)|;|     a_len = str_len(a)|;|     sep_len = str_len(sep)|;|@@ -1495,11 +1526,12 @@ def rpartition(a, sep):|;| |;|     """"""|;|     a = np.asanyarray(a)|;|-    # TODO switch to copy=False when issues around views are fixed|;|-    sep = np.array(sep, dtype=a.dtype, copy=True, subok=True)|;|-    if a.dtype.char == ""T"":|;|+    sep = np.asanyarray(sep)|;|+|;|+    if np.result_type(a, sep).char == ""T"":|;|         return _rpartition(a, sep)|;| |;|+    sep = sep.astype(a.dtype, copy=False)|;|     pos = _rfind_ufunc(a, sep, 0, MAX)|;|     a_len = str_len(a)|;|     sep_len = str_len(sep) || PR#27636 - numpy/_core/tests/test_stringdtype.py: @@ -996,6 +996,62 @@ def test_ufunc_multiply(dtype, string_list, other, other_dtype, use_out):|;|             other * arr|;| |;| |;|+def test_findlike_promoters():|;|+    r = ""Wally""|;|+    l = ""Where's Wally?""|;|+    s = np.int32(3)|;|+    e = np.int8(13)|;|+    for dtypes in [(""T"", ""U""), (""U"", ""T"")]:|;|+        for function, answer in [|;|+            (np.strings.index, 8),|;|+            (np.strings.endswith, True),|;|+        ]:|;|+            assert answer == function(|;|+                np.array(l, dtype=dtypes[0]), np.array(r, dtype=dtypes[1]), s, e|;|+            )|;|+|;|+|;|+def test_strip_promoter():|;|+    arg = [""Hello!!!!"", ""Hello??!!""]|;|+    strip_char = ""!""|;|+    answer = [""Hello"", ""Hello??""]|;|+    for dtypes in [(""T"", ""U""), (""U"", ""T"")]:|;|+        result = np.strings.strip(|;|+            np.array(arg, dtype=dtypes[0]),|;|+            np.array(strip_char, dtype=dtypes[1])|;|+        )|;|+        assert_array_equal(result, answer)|;|+        assert result.dtype.char == ""T""|;|+|;|+|;|+def test_replace_promoter():|;|+    arg = [""Hello, planet!"", ""planet, Hello!""]|;|+    old = ""planet""|;|+    new = ""world""|;|+    answer = [""Hello, world!"", ""world, Hello!""]|;|+    for dtypes in itertools.product(""TU"", repeat=3):|;|+        if dtypes == (""U"", ""U"", ""U""):|;|+            continue|;|+        answer_arr = np.strings.replace(|;|+            np.array(arg, dtype=dtypes[0]),|;|+            np.array(old, dtype=dtypes[1]),|;|+            np.array(new, dtype=dtypes[2]),|;|+        )|;|+        assert_array_equal(answer_arr, answer)|;|+        assert answer_arr.dtype.char == ""T""|;|+|;|+|;|+def test_center_promoter():|;|+    arg = [""Hello"", ""planet!""]|;|+    fillchar = ""/""|;|+    for dtypes in [(""T"", ""U""), (""U"", ""T"")]:|;|+        answer = np.strings.center(|;|+            np.array(arg, dtype=dtypes[0]), 9, np.array(fillchar, dtype=dtypes[1])|;|+        )|;|+        assert_array_equal(answer, [""//Hello//"", ""/planet!/""])|;|+        assert answer.dtype.char == ""T""|;|+|;|+|;| DATETIME_INPUT = [|;|     np.datetime64(""1923-04-14T12:43:12""),|;|     np.datetime64(""1994-06-21T14:43:15""),",BUG: fixes for StringDType/unicode promoters || BUG: fix more issues with string ufunc promotion || BUG: substantially simplify and fix issue with justification promoter || DOC: add release note
numpy/numpy,mattip,27941,Latest release of vulture (Dec 8) finds error in ``numpy/f2py/tests/util.py``,"See https://github.com/numpy/numpy/actions/runs/12226281360/job/34101383557.  I think it is due to an indentation error:
```
        except subprocess.CalledProcessError:
            pytest.skip(""meson not present, skipping compiler dependent test"", allow_module_level=True)
        return runmeson.returncode == 0
    finally:
        shutil.rmtree(tmpdir)
    return False
```
~Perhaps `return runmeson.returncode == 0` should be indented?~

The last line should probably just be removed.","@HaoZeke Thoughts? || Agreed, it can be removed. It crept in from #25111.",closed,2024-12-09T02:51:34+00:00,2024-12-09T09:46:14+00:00,charris,,1,"PR#27943 - numpy/f2py/tests/util.py: @@ -57,7 +57,6 @@ def check_language(lang, code_snippet=None):|;|         return runmeson.returncode == 0|;|     finally:|;|         shutil.rmtree(tmpdir)|;|-    return False|;| |;| |;| fortran77_code = ''' || PR#27943 - numpy/ma/tests/test_core.py: @@ -23,7 +23,7 @@|;| import numpy._core.umath as umath|;| from numpy.exceptions import AxisError|;| from numpy.testing import (|;|-    assert_raises, assert_warns, suppress_warnings, IS_WASM|;|+    assert_raises, assert_warns, suppress_warnings, IS_WASM, temppath|;|     )|;| from numpy.testing._private.utils import requires_memory|;| from numpy import ndarray|;|@@ -1019,8 +1019,9 @@ def test_maskedarray_tofile_raises_notimplementederror(self):|;|         xm = masked_array([1, 2, 3], mask=[False, True, False])|;|         # Test case to check the NotImplementedError. |;|         # It is not implemented at this point of time. We can change this in future |;|-        with pytest.raises(NotImplementedError):|;|-            np.save('xm.np', xm)|;|+        with temppath(suffix='.npy') as path:|;|+            with pytest.raises(NotImplementedError):|;|+                np.save(path, xm)|;| |;| |;| class TestMaskedArrayArithmetic:",TEST: cleanups [skip cirrus][skip azp]
numpy/numpy,mattip,27942,BUG: test_maskedarray_tofile_raises_notimplementederror leaves a leftover `xm.np.npy` in cwd,"### Describe the issue:

The test `numpy.ma.tests.test_core::TestMaskedArray::test_maskedarray_tofile_raises_notimplementederror` seems to be writing a `xm.np.npy` file into the current directory (even though it passes — i.e. raises `NotImplementedError` as expected). Given that numpy tests can be run from pretty much any directory, it may result in cruft being left around unnoticed. I've noticed because we're running tests from inside site-packages directory when building the Gentoo package, and our QA checks noticed a stray file.

### Reproduce the code example:

```python
pip install hypothesis numpy pytest
python -m pytest --pyargs numpy.ma.tests.test_core::TestMaskedArray::test_maskedarray_tofile_raises_notimplementederror
```


### Error message:

_No response_

### Python and NumPy Versions:

2.2.0
3.12.7 (main, Oct 19 2024, 06:58:55) [GCC 14.2.1 20240921]


### Runtime Environment:

```
[{'numpy_version': '2.2.0',
  'python': '3.12.7 (main, Oct 19 2024, 06:58:55) [GCC 14.2.1 20240921]',
  'uname': uname_result(system='Linux', node='pomiot', release='6.12.3-gentoo-dist', version='#1 SMP PREEMPT_DYNAMIC Fri Dec  6 13:30:20 -00 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'Haswell',
  'filepath': '/home/mgorny/git/numpy/.venv/lib/python3.12/site-packages/numpy.libs/libscipy_openblas64_-6bb31eeb.so',
  'internal_api': 'openblas',
  'num_threads': 12,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.28'}]
```

### Context for the issue:

_No response_",Thank you!,closed,2024-12-09T05:14:41+00:00,2024-12-09T09:46:14+00:00,mgorny,00 - Bug,1,"PR#27943 - numpy/f2py/tests/util.py: @@ -57,7 +57,6 @@ def check_language(lang, code_snippet=None):|;|         return runmeson.returncode == 0|;|     finally:|;|         shutil.rmtree(tmpdir)|;|-    return False|;| |;| |;| fortran77_code = ''' || PR#27943 - numpy/ma/tests/test_core.py: @@ -23,7 +23,7 @@|;| import numpy._core.umath as umath|;| from numpy.exceptions import AxisError|;| from numpy.testing import (|;|-    assert_raises, assert_warns, suppress_warnings, IS_WASM|;|+    assert_raises, assert_warns, suppress_warnings, IS_WASM, temppath|;|     )|;| from numpy.testing._private.utils import requires_memory|;| from numpy import ndarray|;|@@ -1019,8 +1019,9 @@ def test_maskedarray_tofile_raises_notimplementederror(self):|;|         xm = masked_array([1, 2, 3], mask=[False, True, False])|;|         # Test case to check the NotImplementedError. |;|         # It is not implemented at this point of time. We can change this in future |;|-        with pytest.raises(NotImplementedError):|;|-            np.save('xm.np', xm)|;|+        with temppath(suffix='.npy') as path:|;|+            with pytest.raises(NotImplementedError):|;|+                np.save(path, xm)|;| |;| |;| class TestMaskedArrayArithmetic:",TEST: cleanups [skip cirrus][skip azp]
numpy/numpy,setbit123,27919,DOC: Exist an invalid URL in doc/neps/index.rst.,"### Issue with current documentation:

The URL for ""Nep 0"" in https://github.com/numpy/numpy/blob/main/doc/neps/index.rst is invalid.

### Idea or request for content:

It should be changed to https://github.com/numpy/numpy/blob/main/doc/neps/nep-0000.rst. I plan to submit a PR to fix this issue. If there is a better way to address it, please let me know.",,closed,2024-12-06T15:49:19+00:00,2024-12-08T16:14:22+00:00,setbit123,04 - Documentation,1,"PR#27920 - doc/neps/index.rst: @@ -5,8 +5,9 @@ Roadmap & NumPy enhancement proposals|;| This page provides an overview of development priorities for NumPy.|;| Specifically, it contains a roadmap with a higher-level overview, as|;| well as NumPy Enhancement Proposals (NEPs)—suggested changes|;|-to the library—in various stages of discussion or completion (see `NEP|;|-0 <nep-0000>`__).|;|+to the library—in various stages of discussion or completion.|;|+See `NEP 0 <https://github.com/numpy/numpy/blob/main/doc/neps/nep-0000.rst>`__|;|+for more informations about NEPs.|;| |;| Roadmap|;| -------",Modify the invalid URL in the index.rst file. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || MAINT: Rephrase a bit.
numpy/numpy,charris,27919,DOC: Exist an invalid URL in doc/neps/index.rst.,"### Issue with current documentation:

The URL for ""Nep 0"" in https://github.com/numpy/numpy/blob/main/doc/neps/index.rst is invalid.

### Idea or request for content:

It should be changed to https://github.com/numpy/numpy/blob/main/doc/neps/nep-0000.rst. I plan to submit a PR to fix this issue. If there is a better way to address it, please let me know.",,closed,2024-12-06T15:49:19+00:00,2024-12-08T16:14:22+00:00,setbit123,04 - Documentation,1,"PR#27920 - doc/neps/index.rst: @@ -5,8 +5,9 @@ Roadmap & NumPy enhancement proposals|;| This page provides an overview of development priorities for NumPy.|;| Specifically, it contains a roadmap with a higher-level overview, as|;| well as NumPy Enhancement Proposals (NEPs)—suggested changes|;|-to the library—in various stages of discussion or completion (see `NEP|;|-0 <nep-0000>`__).|;|+to the library—in various stages of discussion or completion.|;|+See `NEP 0 <https://github.com/numpy/numpy/blob/main/doc/neps/nep-0000.rst>`__|;|+for more informations about NEPs.|;| |;| Roadmap|;| -------",Modify the invalid URL in the index.rst file. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || Modify the index.rst format to enhance readability. || MAINT: Rephrase a bit.
numpy/numpy,charris,27861,Dropping Python 3.10 support.,"We are scheduled to drop Python 3.10 support in NumPy 2.3. I will make a PR to get started on that, but
have noticed a few issues I have questions about:

@ngoldbaum `numpy/_core/src/multiarray/stringdtype/static_string.c` has a 3.10 workaround.
@seberg `numpy/_core/include/numpy/numpyconfig.h`  NPY_FEATURE_VERSION needs update.
@r-devulap `linux_simd.yml` could probably use an update/rework.
@mattip can PyPy support 3.11 yet?

","I think the comment in `static_string.C` is referring to the note about Python3.9 here: https://docs.python.org/3.12/c-api/arg.html#strings-and-buffers

But looking [at the same docs for 3.13](https://docs.python.org/3/c-api/arg.html#strings-and-buffers), it looks like I might have misunderstood, and we can actually remove all the `Py_SSIZE_T_CLEAN` macros after we remove support for Python 3.12. || @ngoldbaum Feel free to push a comment update to #27862. || > [rdevulap](https://github.com/r-devulap) linux_simd.yml could probably use an update/rework.

Is 3.12 the new recommended version?  || Never mind, I just saw your PR :)",closed,2024-11-26T19:59:16+00:00,2024-12-04T23:52:45+00:00,charris,17 - Task,1,"PR#27862 - .github/workflows/linux.yml: @@ -39,7 +39,7 @@ jobs:|;|         fetch-depth: 0|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install linter requirements|;|       run:|;|         python -m pip install -r requirements/linter_requirements.txt|;|@@ -55,7 +55,7 @@ jobs:|;|       MESON_ARGS: ""-Dallow-noblas=true -Dcpu-baseline=none -Dcpu-dispatch=none""|;|     strategy:|;|       matrix:|;|-        version: [""3.10"", ""3.11"", ""3.12"", ""3.13"", ""3.13t""]|;|+        version: [""3.11"", ""3.12"", ""3.13"", ""3.13t""]|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|       with:|;|@@ -71,27 +71,28 @@ jobs:|;|         pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython|;|     - uses: ./.github/meson_actions|;| |;|-  pypy:|;|-    needs: [smoke_test]|;|-    runs-on: ubuntu-latest|;|-    if: github.event_name != 'push'|;|-    steps:|;|-    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|-      with:|;|-        submodules: recursive|;|-        fetch-tags: true|;|-    - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|-      with:|;|-        python-version: 'pypy3.10-v7.3.17'|;|-    - name: Setup using scipy-openblas|;|-      run: ||;|-        python -m pip install -r requirements/ci_requirements.txt|;|-        spin config-openblas --with-scipy-openblas=32|;|-    - uses: ./.github/meson_actions|;|+  # TODO pypy: uncomment when pypy3.11 becomes available    |;|+  #pypy:|;|+    #needs: [smoke_test]|;|+    #runs-on: ubuntu-latest|;|+    #if: github.event_name != 'push'|;|+    #steps:|;|+    #- uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|+      #with:|;|+        #submodules: recursive|;|+        #fetch-tags: true|;|+    #- uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|+      #with:|;|+        #python-version: 'pypy3.10-v7.3.17'|;|+    #- name: Setup using scipy-openblas|;|+      #run: ||;|+        #python -m pip install -r requirements/ci_requirements.txt|;|+        #spin config-openblas --with-scipy-openblas=32|;|+    #- uses: ./.github/meson_actions|;| |;|   debug:|;|     needs: [smoke_test]|;|-    runs-on: ubuntu-latest|;|+    runs-on: ubuntu-24.04|;|     if: github.event_name != 'push'|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|@@ -129,7 +130,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install build and test dependencies from PyPI|;|       run: ||;|         pip install -r requirements/build_requirements.txt|;|@@ -164,7 +165,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install build and benchmarking dependencies|;|       run: ||;|         sudo apt-get update || PR#27862 - .github/workflows/linux_musl.yml: @@ -47,7 +47,7 @@ jobs:|;|         fi|;|         git submodule update --init|;| |;|-        ln -s /usr/local/bin/python3.10 /usr/local/bin/python|;|+        ln -s /usr/local/bin/python3.11 /usr/local/bin/python|;| |;|     - name: test-musllinux_x86_64|;|       env: || PR#27862 - .github/workflows/linux_simd.yml: @@ -64,7 +64,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - uses: ./.github/meson_actions|;|       name: Build/Test|;| |;|@@ -81,7 +81,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;| |;|     - name: Install GCC/8/9|;|       run: ||;|@@ -127,12 +127,12 @@ jobs:|;|           - [|;|             ""without avx512"",|;|             ""-Dallow-noblas=true -Dcpu-dispatch=SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,AVX2,FMA3"",|;|-            ""3.10""|;|+            ""3.11""|;|           ]|;|           - [|;|             ""without avx512/avx2/fma3"",|;|             ""-Dallow-noblas=true -Dcpu-dispatch=SSSE3,SSE41,POPCNT,SSE42,AVX,F16C"",|;|-            ""3.10""|;|+            ""3.11""|;|           ]|;| |;|     env: || PR#27862 - .github/workflows/macos.yml: @@ -113,7 +113,7 @@ jobs:|;|         build_runner:|;|           - [ macos-13, ""macos_x86_64"" ]|;|           - [ macos-14, ""macos_arm64"" ]|;|-        version: [""3.10"", ""3.13t""]|;|+        version: [""3.11"", ""3.13t""]|;| |;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1 || PR#27862 - .github/workflows/mypy.yml: @@ -48,7 +48,7 @@ jobs:|;|         os_python:|;|           - [ubuntu-latest, '3.12']|;|           - [windows-latest, '3.11']|;|-          - [macos-latest, '3.10']|;|+          - [macos-latest, '3.11']|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|       with: || PR#27862 - .github/workflows/wheels.yml: @@ -85,7 +85,8 @@ jobs:|;|           - [macos-14, macosx_arm64, accelerate]  # always use accelerate|;|           - [windows-2019, win_amd64, """"]|;|           - [windows-2019, win32, """"]|;|-        python: [""cp310"", ""cp311"", ""cp312"", ""pp310"", ""cp313"", ""cp313t""]|;|+        # TODO pypy: Add pp311 to this list when it comes out (pp310 removed)  |;|+        python: [""cp311"", ""cp312"", ""cp313"", ""cp313t""]|;|         exclude:|;|           # Don't build PyPy 32-bit windows|;|           - buildplat: [windows-2019, win32, """"]|;|@@ -231,7 +232,7 @@ jobs:|;|       - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|         with:|;|           # Build sdist on lowest supported Python|;|-          python-version: ""3.10""|;|+          python-version: ""3.11""|;|       - name: Build sdist|;|         run: ||;|           python -m pip install -U pip build|;|@@ -263,7 +264,7 @@ jobs:|;|           # Note that this step is *after* specific pythons have been used to|;|           # build and test|;|           auto-update-conda: true|;|-          python-version: ""3.10""|;|+          python-version: ""3.11""|;| |;|       - name: Upload sdist|;|         if: success() || PR#27862 - .github/workflows/windows.yml: @@ -105,7 +105,7 @@ jobs:|;|       - name: Setup Python (32-bit)|;|         uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|         with:|;|-          python-version: '3.10'|;|+          python-version: '3.11'|;|           architecture: 'x86'|;| |;|       - name: Setup MSVC (32-bit) || PR#27862 - INSTALL.rst: @@ -14,7 +14,7 @@ Prerequisites|;| |;| Building NumPy requires the following installed software:|;| |;|-1) Python__ 3.10.x or newer.|;|+1) Python__ 3.11.x or newer.|;| |;|    Please note that the Python development headers also need to be installed,|;|    e.g., on Debian/Ubuntu one needs to install both `python3` and || PR#27862 - azure-pipelines.yml: @@ -44,7 +44,7 @@ stages:|;|     steps:|;|     - task: UsePythonVersion@0|;|       inputs:|;|-        versionSpec: '3.10'|;|+        versionSpec: '3.11'|;|         addToPath: true|;|         architecture: 'x64'|;|     - script: >-|;|@@ -57,7 +57,7 @@ stages:|;|       displayName: 'Run Lint Checks'|;|       failOnStderr: true|;| |;|-  - job: Linux_Python_310_32bit_full_with_asserts|;|+  - job: Linux_Python_311_32bit_full_with_asserts|;|     pool:|;|       vmImage: 'ubuntu-20.04'|;|     steps:|;|@@ -78,23 +78,24 @@ stages:|;|     strategy:|;|       maxParallel: 3|;|       matrix:|;|-          Python310-64bit-fast:|;|-            PYTHON_VERSION: '3.10'|;|+          Python311-64bit-fast:|;|+            PYTHON_VERSION: '3.11'|;|             PYTHON_ARCH: 'x64'|;|             TEST_MODE: fast|;|             BITS: 64|;|-          Python311-64bit-full:|;|-            PYTHON_VERSION: '3.11'|;|+          Python312-64bit-full:|;|+            PYTHON_VERSION: '3.12'|;|             PYTHON_ARCH: 'x64'|;|             TEST_MODE: full|;|             BITS: 64|;|             _USE_BLAS_ILP64: '1'|;|-          PyPy310-64bit-fast:|;|-            PYTHON_VERSION: 'pypy3.10'|;|-            PYTHON_ARCH: 'x64'|;|-            TEST_MODE: fast|;|-            BITS: 64|;|-            _USE_BLAS_ILP64: '1'|;|+# TODO pypy: uncomment when pypy3.11 comes out|;|+#          PyPy310-64bit-fast:|;|+#            PYTHON_VERSION: 'pypy3.10'|;|+#            PYTHON_ARCH: 'x64'|;|+#            TEST_MODE: fast|;|+#            BITS: 64|;|+#            _USE_BLAS_ILP64: '1'|;| |;|     steps:|;|     - template: azure-steps-windows.yml || PR#27862 - numpy/_core/src/multiarray/stringdtype/static_string.c: @@ -17,9 +17,6 @@|;| #define NPY_NO_DEPRECATED_API NPY_API_VERSION|;| #define _MULTIARRAYMODULE|;| |;|-// work around Python 3.10 and earlier issue, see|;|-// the commit message of 82fd2b8 for more details|;|-// also needed for the allocator mutex|;| #define PY_SSIZE_T_CLEAN|;| #include <Python.h>|;|  || PR#27862 - pyproject.toml: @@ -16,7 +16,7 @@ authors = [{name = ""Travis E. Oliphant et al.""}]|;| maintainers = [|;|     {name = ""NumPy Developers"", email=""numpy-discussion@python.org""},|;| ]|;|-requires-python = "">=3.10""|;|+requires-python = "">=3.11""|;| readme = ""README.md""|;| classifiers = [|;|     'Development Status :: 5 - Production/Stable',|;|@@ -26,7 +26,6 @@ classifiers = [|;|     'Programming Language :: C',|;|     'Programming Language :: Python',|;|     'Programming Language :: Python :: 3',|;|-    'Programming Language :: Python :: 3.10',|;|     'Programming Language :: Python :: 3.11',|;|     'Programming Language :: Python :: 3.12',|;|     'Programming Language :: Python :: 3.13', || PR#27862 - tools/ci/cirrus_arm.yml: @@ -42,10 +42,10 @@ linux_aarch64_test_task:|;|   prepare_env_script: ||;|     apt-get update|;|     apt-get install -y --no-install-recommends software-properties-common gcc g++ gfortran pkg-config ccache|;|-    apt-get install -y --no-install-recommends python3.10 python3.10-venv libopenblas-dev libatlas-base-dev liblapack-dev|;|+    apt-get install -y --no-install-recommends python3.11 python3.11-venv libopenblas-dev libatlas-base-dev liblapack-dev|;| |;|-    # python3.10 -m ensurepip --default-pip --user|;|-    ln -s $(which python3.10) python|;|+    # python3.11 -m ensurepip --default-pip --user|;|+    ln -s $(which python3.11) python|;| |;|     # put ccache and python on PATH|;|     export PATH=/usr/lib/ccache:$PWD:$PATH || PR#27862 - tools/ci/cirrus_wheels.yml: @@ -25,8 +25,6 @@ linux_aarch64_task:|;|     # build in a matrix because building and testing all four wheels in a|;|     # single task takes longer than 60 mins (the default time limit for a|;|     # cirrus-ci task).|;|-    - env:|;|-        CIBW_BUILD: cp310-*|;|     - env:|;|         CIBW_BUILD: cp311-*|;|     - env:|;|@@ -65,9 +63,9 @@ macosx_arm64_task:|;| |;|   matrix:|;|     - env:|;|-        CIBW_BUILD: cp310-* cp311-*|;|+        CIBW_BUILD: cp311-* cp312*|;|     - env:|;|-        CIBW_BUILD: cp312-* cp313-*|;|+        CIBW_BUILD: cp313-*|;|     - env:|;|         CIBW_BUILD: cp313t-*|;|         CIBW_FREE_THREADED_SUPPORT: 1 || PR#27862 - tools/ci/run_32_bit_linux_docker.sh: @@ -2,7 +2,7 @@ set -xe|;| |;| git config --global --add safe.directory /numpy|;| cd /numpy|;|-/opt/python/cp310-cp310/bin/python -mvenv venv|;|+/opt/python/cp311-cp311/bin/python -mvenv venv|;| source venv/bin/activate|;| pip install -r requirements/ci32_requirements.txt|;| python3 -m pip install -r requirements/test_requirements.txt","MAINT: Drop Python 3.10 support.

Dropping support is in line with SPEC 0, NumPy 2.3 is due sometime
in March 2025. || MAINT: remove incorrect comment in ""static_string.c"" || MAINT: Don't test/build for PyPy 3.10 [wheel build]

These changes should be reverted when PyPy 3.11 comes out."
numpy/numpy,ngoldbaum,27861,Dropping Python 3.10 support.,"We are scheduled to drop Python 3.10 support in NumPy 2.3. I will make a PR to get started on that, but
have noticed a few issues I have questions about:

@ngoldbaum `numpy/_core/src/multiarray/stringdtype/static_string.c` has a 3.10 workaround.
@seberg `numpy/_core/include/numpy/numpyconfig.h`  NPY_FEATURE_VERSION needs update.
@r-devulap `linux_simd.yml` could probably use an update/rework.
@mattip can PyPy support 3.11 yet?

","I think the comment in `static_string.C` is referring to the note about Python3.9 here: https://docs.python.org/3.12/c-api/arg.html#strings-and-buffers

But looking [at the same docs for 3.13](https://docs.python.org/3/c-api/arg.html#strings-and-buffers), it looks like I might have misunderstood, and we can actually remove all the `Py_SSIZE_T_CLEAN` macros after we remove support for Python 3.12. || @ngoldbaum Feel free to push a comment update to #27862. || > [rdevulap](https://github.com/r-devulap) linux_simd.yml could probably use an update/rework.

Is 3.12 the new recommended version?  || Never mind, I just saw your PR :)",closed,2024-11-26T19:59:16+00:00,2024-12-04T23:52:45+00:00,charris,17 - Task,1,"PR#27862 - .github/workflows/linux.yml: @@ -39,7 +39,7 @@ jobs:|;|         fetch-depth: 0|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install linter requirements|;|       run:|;|         python -m pip install -r requirements/linter_requirements.txt|;|@@ -55,7 +55,7 @@ jobs:|;|       MESON_ARGS: ""-Dallow-noblas=true -Dcpu-baseline=none -Dcpu-dispatch=none""|;|     strategy:|;|       matrix:|;|-        version: [""3.10"", ""3.11"", ""3.12"", ""3.13"", ""3.13t""]|;|+        version: [""3.11"", ""3.12"", ""3.13"", ""3.13t""]|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|       with:|;|@@ -71,27 +71,28 @@ jobs:|;|         pip install -i https://pypi.anaconda.org/scientific-python-nightly-wheels/simple cython|;|     - uses: ./.github/meson_actions|;| |;|-  pypy:|;|-    needs: [smoke_test]|;|-    runs-on: ubuntu-latest|;|-    if: github.event_name != 'push'|;|-    steps:|;|-    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|-      with:|;|-        submodules: recursive|;|-        fetch-tags: true|;|-    - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|-      with:|;|-        python-version: 'pypy3.10-v7.3.17'|;|-    - name: Setup using scipy-openblas|;|-      run: ||;|-        python -m pip install -r requirements/ci_requirements.txt|;|-        spin config-openblas --with-scipy-openblas=32|;|-    - uses: ./.github/meson_actions|;|+  # TODO pypy: uncomment when pypy3.11 becomes available    |;|+  #pypy:|;|+    #needs: [smoke_test]|;|+    #runs-on: ubuntu-latest|;|+    #if: github.event_name != 'push'|;|+    #steps:|;|+    #- uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|+      #with:|;|+        #submodules: recursive|;|+        #fetch-tags: true|;|+    #- uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|+      #with:|;|+        #python-version: 'pypy3.10-v7.3.17'|;|+    #- name: Setup using scipy-openblas|;|+      #run: ||;|+        #python -m pip install -r requirements/ci_requirements.txt|;|+        #spin config-openblas --with-scipy-openblas=32|;|+    #- uses: ./.github/meson_actions|;| |;|   debug:|;|     needs: [smoke_test]|;|-    runs-on: ubuntu-latest|;|+    runs-on: ubuntu-24.04|;|     if: github.event_name != 'push'|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|@@ -129,7 +130,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install build and test dependencies from PyPI|;|       run: ||;|         pip install -r requirements/build_requirements.txt|;|@@ -164,7 +165,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - name: Install build and benchmarking dependencies|;|       run: ||;|         sudo apt-get update || PR#27862 - .github/workflows/linux_musl.yml: @@ -47,7 +47,7 @@ jobs:|;|         fi|;|         git submodule update --init|;| |;|-        ln -s /usr/local/bin/python3.10 /usr/local/bin/python|;|+        ln -s /usr/local/bin/python3.11 /usr/local/bin/python|;| |;|     - name: test-musllinux_x86_64|;|       env: || PR#27862 - .github/workflows/linux_simd.yml: @@ -64,7 +64,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;|     - uses: ./.github/meson_actions|;|       name: Build/Test|;| |;|@@ -81,7 +81,7 @@ jobs:|;|         fetch-tags: true|;|     - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|       with:|;|-        python-version: '3.10'|;|+        python-version: '3.11'|;| |;|     - name: Install GCC/8/9|;|       run: ||;|@@ -127,12 +127,12 @@ jobs:|;|           - [|;|             ""without avx512"",|;|             ""-Dallow-noblas=true -Dcpu-dispatch=SSSE3,SSE41,POPCNT,SSE42,AVX,F16C,AVX2,FMA3"",|;|-            ""3.10""|;|+            ""3.11""|;|           ]|;|           - [|;|             ""without avx512/avx2/fma3"",|;|             ""-Dallow-noblas=true -Dcpu-dispatch=SSSE3,SSE41,POPCNT,SSE42,AVX,F16C"",|;|-            ""3.10""|;|+            ""3.11""|;|           ]|;| |;|     env: || PR#27862 - .github/workflows/macos.yml: @@ -113,7 +113,7 @@ jobs:|;|         build_runner:|;|           - [ macos-13, ""macos_x86_64"" ]|;|           - [ macos-14, ""macos_arm64"" ]|;|-        version: [""3.10"", ""3.13t""]|;|+        version: [""3.11"", ""3.13t""]|;| |;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1 || PR#27862 - .github/workflows/mypy.yml: @@ -48,7 +48,7 @@ jobs:|;|         os_python:|;|           - [ubuntu-latest, '3.12']|;|           - [windows-latest, '3.11']|;|-          - [macos-latest, '3.10']|;|+          - [macos-latest, '3.11']|;|     steps:|;|     - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11 # v4.1.1|;|       with: || PR#27862 - .github/workflows/wheels.yml: @@ -85,7 +85,8 @@ jobs:|;|           - [macos-14, macosx_arm64, accelerate]  # always use accelerate|;|           - [windows-2019, win_amd64, """"]|;|           - [windows-2019, win32, """"]|;|-        python: [""cp310"", ""cp311"", ""cp312"", ""pp310"", ""cp313"", ""cp313t""]|;|+        # TODO pypy: Add pp311 to this list when it comes out (pp310 removed)  |;|+        python: [""cp311"", ""cp312"", ""cp313"", ""cp313t""]|;|         exclude:|;|           # Don't build PyPy 32-bit windows|;|           - buildplat: [windows-2019, win32, """"]|;|@@ -231,7 +232,7 @@ jobs:|;|       - uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|         with:|;|           # Build sdist on lowest supported Python|;|-          python-version: ""3.10""|;|+          python-version: ""3.11""|;|       - name: Build sdist|;|         run: ||;|           python -m pip install -U pip build|;|@@ -263,7 +264,7 @@ jobs:|;|           # Note that this step is *after* specific pythons have been used to|;|           # build and test|;|           auto-update-conda: true|;|-          python-version: ""3.10""|;|+          python-version: ""3.11""|;| |;|       - name: Upload sdist|;|         if: success() || PR#27862 - .github/workflows/windows.yml: @@ -105,7 +105,7 @@ jobs:|;|       - name: Setup Python (32-bit)|;|         uses: actions/setup-python@0b93645e9fea7318ecaed2b359559ac225c90a2b # v5.3.0|;|         with:|;|-          python-version: '3.10'|;|+          python-version: '3.11'|;|           architecture: 'x86'|;| |;|       - name: Setup MSVC (32-bit) || PR#27862 - INSTALL.rst: @@ -14,7 +14,7 @@ Prerequisites|;| |;| Building NumPy requires the following installed software:|;| |;|-1) Python__ 3.10.x or newer.|;|+1) Python__ 3.11.x or newer.|;| |;|    Please note that the Python development headers also need to be installed,|;|    e.g., on Debian/Ubuntu one needs to install both `python3` and || PR#27862 - azure-pipelines.yml: @@ -44,7 +44,7 @@ stages:|;|     steps:|;|     - task: UsePythonVersion@0|;|       inputs:|;|-        versionSpec: '3.10'|;|+        versionSpec: '3.11'|;|         addToPath: true|;|         architecture: 'x64'|;|     - script: >-|;|@@ -57,7 +57,7 @@ stages:|;|       displayName: 'Run Lint Checks'|;|       failOnStderr: true|;| |;|-  - job: Linux_Python_310_32bit_full_with_asserts|;|+  - job: Linux_Python_311_32bit_full_with_asserts|;|     pool:|;|       vmImage: 'ubuntu-20.04'|;|     steps:|;|@@ -78,23 +78,24 @@ stages:|;|     strategy:|;|       maxParallel: 3|;|       matrix:|;|-          Python310-64bit-fast:|;|-            PYTHON_VERSION: '3.10'|;|+          Python311-64bit-fast:|;|+            PYTHON_VERSION: '3.11'|;|             PYTHON_ARCH: 'x64'|;|             TEST_MODE: fast|;|             BITS: 64|;|-          Python311-64bit-full:|;|-            PYTHON_VERSION: '3.11'|;|+          Python312-64bit-full:|;|+            PYTHON_VERSION: '3.12'|;|             PYTHON_ARCH: 'x64'|;|             TEST_MODE: full|;|             BITS: 64|;|             _USE_BLAS_ILP64: '1'|;|-          PyPy310-64bit-fast:|;|-            PYTHON_VERSION: 'pypy3.10'|;|-            PYTHON_ARCH: 'x64'|;|-            TEST_MODE: fast|;|-            BITS: 64|;|-            _USE_BLAS_ILP64: '1'|;|+# TODO pypy: uncomment when pypy3.11 comes out|;|+#          PyPy310-64bit-fast:|;|+#            PYTHON_VERSION: 'pypy3.10'|;|+#            PYTHON_ARCH: 'x64'|;|+#            TEST_MODE: fast|;|+#            BITS: 64|;|+#            _USE_BLAS_ILP64: '1'|;| |;|     steps:|;|     - template: azure-steps-windows.yml || PR#27862 - numpy/_core/src/multiarray/stringdtype/static_string.c: @@ -17,9 +17,6 @@|;| #define NPY_NO_DEPRECATED_API NPY_API_VERSION|;| #define _MULTIARRAYMODULE|;| |;|-// work around Python 3.10 and earlier issue, see|;|-// the commit message of 82fd2b8 for more details|;|-// also needed for the allocator mutex|;| #define PY_SSIZE_T_CLEAN|;| #include <Python.h>|;|  || PR#27862 - pyproject.toml: @@ -16,7 +16,7 @@ authors = [{name = ""Travis E. Oliphant et al.""}]|;| maintainers = [|;|     {name = ""NumPy Developers"", email=""numpy-discussion@python.org""},|;| ]|;|-requires-python = "">=3.10""|;|+requires-python = "">=3.11""|;| readme = ""README.md""|;| classifiers = [|;|     'Development Status :: 5 - Production/Stable',|;|@@ -26,7 +26,6 @@ classifiers = [|;|     'Programming Language :: C',|;|     'Programming Language :: Python',|;|     'Programming Language :: Python :: 3',|;|-    'Programming Language :: Python :: 3.10',|;|     'Programming Language :: Python :: 3.11',|;|     'Programming Language :: Python :: 3.12',|;|     'Programming Language :: Python :: 3.13', || PR#27862 - tools/ci/cirrus_arm.yml: @@ -42,10 +42,10 @@ linux_aarch64_test_task:|;|   prepare_env_script: ||;|     apt-get update|;|     apt-get install -y --no-install-recommends software-properties-common gcc g++ gfortran pkg-config ccache|;|-    apt-get install -y --no-install-recommends python3.10 python3.10-venv libopenblas-dev libatlas-base-dev liblapack-dev|;|+    apt-get install -y --no-install-recommends python3.11 python3.11-venv libopenblas-dev libatlas-base-dev liblapack-dev|;| |;|-    # python3.10 -m ensurepip --default-pip --user|;|-    ln -s $(which python3.10) python|;|+    # python3.11 -m ensurepip --default-pip --user|;|+    ln -s $(which python3.11) python|;| |;|     # put ccache and python on PATH|;|     export PATH=/usr/lib/ccache:$PWD:$PATH || PR#27862 - tools/ci/cirrus_wheels.yml: @@ -25,8 +25,6 @@ linux_aarch64_task:|;|     # build in a matrix because building and testing all four wheels in a|;|     # single task takes longer than 60 mins (the default time limit for a|;|     # cirrus-ci task).|;|-    - env:|;|-        CIBW_BUILD: cp310-*|;|     - env:|;|         CIBW_BUILD: cp311-*|;|     - env:|;|@@ -65,9 +63,9 @@ macosx_arm64_task:|;| |;|   matrix:|;|     - env:|;|-        CIBW_BUILD: cp310-* cp311-*|;|+        CIBW_BUILD: cp311-* cp312*|;|     - env:|;|-        CIBW_BUILD: cp312-* cp313-*|;|+        CIBW_BUILD: cp313-*|;|     - env:|;|         CIBW_BUILD: cp313t-*|;|         CIBW_FREE_THREADED_SUPPORT: 1 || PR#27862 - tools/ci/run_32_bit_linux_docker.sh: @@ -2,7 +2,7 @@ set -xe|;| |;| git config --global --add safe.directory /numpy|;| cd /numpy|;|-/opt/python/cp310-cp310/bin/python -mvenv venv|;|+/opt/python/cp311-cp311/bin/python -mvenv venv|;| source venv/bin/activate|;| pip install -r requirements/ci32_requirements.txt|;| python3 -m pip install -r requirements/test_requirements.txt","MAINT: Drop Python 3.10 support.

Dropping support is in line with SPEC 0, NumPy 2.3 is due sometime
in March 2025. || MAINT: remove incorrect comment in ""static_string.c"" || MAINT: Don't test/build for PyPy 3.10 [wheel build]

These changes should be reverted when PyPy 3.11 comes out."
numpy/numpy,StanFromIreland,27834,DOC: numpy imported twice in default_rng example docs,"https://github.com/numpy/numpy/blob/b1e6ccd14b173b922f5d6a11bb252f4141dc42cd/doc/source/reference/random/index.rst?plain=1#L66C1-L68C25

Noticed this. A minor doc bug? Or some reason to import again after secrets?","No good reason. That came in as part of a PR to add `import numpy as np` in all the examples, and slipped under the review process.",closed,2024-11-25T01:56:38+00:00,2024-11-29T19:44:27+00:00,jonpovey,"04 - Documentation, sprintable",1,"PR#27878 - doc/source/reference/random/index.rst: @@ -65,7 +65,6 @@ arbitrary 128-bit integer.|;| |;|   >>> import numpy as np|;|   >>> import secrets|;|-  >>> import numpy as np|;|   >>> secrets.randbits(128)  #doctest: +SKIP|;|   122807528840384100672342137672332424406  # may vary|;|   >>> rng1 = np.random.default_rng(122807528840384100672342137672332424406)",Update index.rst
numpy/numpy,mhvk,12348,"ENH: expose matmat, matvec, vecmat ufuncs","@charris [commented](https://github.com/numpy/numpy/pull/12219#issuecomment-436412360) on PR #12219 wishing to expose the vector-matrix matrix-vector loops function from the matmul ufunc. 

We would need two ufuncs with signature `(1,n),(n,p?)->(1,p?)` and `(m?,n),(n,1)->(m?,1)`, and could reuse the `@TYPE@_matmul` loops","I'm not sure I understand those signatures - why the frozen 1 dimension? || gh-25675 adds possible `matvec` and `vecmat` functions, though `vecmat` is not identical to what `matmul` does, since it conjugates complex vectors (which seems more logical, probably best to discuss in gh-25675 or on the relevant mailing list discussion: https://mail.python.org/archives/list/numpy-discussion@python.org/thread/LX36TEAENIDSSFAKS6YLXXLWVOBABSEC/",closed,2018-11-07T17:07:39+00:00,2024-11-25T16:50:00+00:00,mattip,"01 - Enhancement, 23 - Wish List, component: numpy.ufunc",2,"PR#25675 - benchmarks/benchmarks/bench_ufunc.py: @@ -16,12 +16,12 @@|;|           'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'left_shift', 'less',|;|           'less_equal', 'log', 'log10', 'log1p', 'log2', 'logaddexp',|;|           'logaddexp2', 'logical_and', 'logical_not', 'logical_or',|;|-          'logical_xor', 'matmul', 'maximum', 'minimum', 'mod', 'modf',|;|-          'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|+          'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'mod',|;|+          'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|           'power', 'rad2deg', 'radians', 'reciprocal', 'remainder',|;|           'right_shift', 'rint', 'sign', 'signbit', 'sin',|;|           'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|-          'true_divide', 'trunc', 'vecdot']|;|+          'true_divide', 'trunc', 'vecdot', 'vecmat']|;| arrayfuncdisp = ['real', 'round']|;| |;| for name in ufuncs: || PR#25675 - doc/release/upcoming_changes/25675.new_feature.rst: @@ -0,0 +1,20 @@|;|+New functions for matrix-vector and vector-matrix products|;|+----------------------------------------------------------|;|+|;|+Two new generalized ufuncs were defined:|;|+|;|+* `numpy.matvec` - matrix-vector product, treating the arguments as|;|+  stacks of matrices and column vectors, respectively.|;|+|;|+* `numpy.vecmat` - vector-matrix product, treating the arguments as|;|+  stacks of column vectors and matrices, respectively. For complex|;|+  vectors, the conjugate is taken.|;|+|;|+These add to the existing `numpy.matmul` as well as to `numpy.vecdot`,|;|+which was added in numpy 2.0.|;|+|;|+Note that `numpy.matmul` never takes a complex conjugate, also not|;|+when its left input is a vector, while both `numpy.vecdot` and|;|+`numpy.vecmat` do take the conjugate for complex vectors on the|;|+left-hand side (which are taken to be the ones that are transposed,|;|+following the physics convention). || PR#25675 - doc/source/reference/routines.linalg.rst: @@ -62,6 +62,8 @@ Matrix and vector products|;|    outer|;|    matmul|;|    linalg.matmul (Array API compatible location)|;|+   matvec|;|+   vecmat|;|    tensordot|;|    linalg.tensordot (Array API compatible location)|;|    einsum || PR#25675 - numpy/__init__.py: @@ -151,10 +151,10 @@|;|         left_shift, less, less_equal, lexsort, linspace, little_endian, log,|;|         log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not,|;|         logical_or, logical_xor, logspace, long, longdouble, longlong, matmul,|;|-        matrix_transpose, max, maximum, may_share_memory, mean, memmap, min,|;|-        min_scalar_type, minimum, mod, modf, moveaxis, multiply, nan, ndarray,|;|-        ndim, nditer, negative, nested_iters, newaxis, nextafter, nonzero,|;|-        not_equal, number, object_, ones, ones_like, outer, partition,|;|+        matvec, matrix_transpose, max, maximum, may_share_memory, mean, memmap,|;|+        min, min_scalar_type, minimum, mod, modf, moveaxis, multiply, nan,|;|+        ndarray, ndim, nditer, negative, nested_iters, newaxis, nextafter,|;|+        nonzero, not_equal, number, object_, ones, ones_like, outer, partition,|;|         permute_dims, pi, positive, pow, power, printoptions, prod,|;|         promote_types, ptp, put, putmask, rad2deg, radians, ravel, recarray,|;|         reciprocal, record, remainder, repeat, require, reshape, resize,|;|@@ -165,8 +165,8 @@|;|         str_, subtract, sum, swapaxes, take, tan, tanh, tensordot,|;|         timedelta64, trace, transpose, true_divide, trunc, typecodes, ubyte,|;|         ufunc, uint, uint16, uint32, uint64, uint8, uintc, uintp, ulong,|;|-        ulonglong, unsignedinteger, unstack, ushort, var, vdot, vecdot, void,|;|-        vstack, where, zeros, zeros_like|;|+        ulonglong, unsignedinteger, unstack, ushort, var, vdot, vecdot,|;|+        vecmat, void, vstack, where, zeros, zeros_like|;|     )|;| |;|     # NOTE: It's still under discussion whether these aliases || PR#25675 - numpy/__init__.pyi: @@ -4490,6 +4490,7 @@ logical_not: _UFunc_Nin1_Nout1[L['logical_not'], L[20], None]|;| logical_or: _UFunc_Nin2_Nout1[L['logical_or'], L[20], L[False]]|;| logical_xor: _UFunc_Nin2_Nout1[L['logical_xor'], L[19], L[False]]|;| matmul: _GUFunc_Nin2_Nout1[L['matmul'], L[19], None, L[""(n?,k),(k,m?)->(n?,m?)""]]|;|+matvec: _GUFunc_Nin2_Nout1[L['matvec'], L[19], None, L[""(m,n),(n)->(m)""]]|;| maximum: _UFunc_Nin2_Nout1[L['maximum'], L[21], None]|;| minimum: _UFunc_Nin2_Nout1[L['minimum'], L[21], None]|;| mod: _UFunc_Nin2_Nout1[L['remainder'], L[16], None]|;|@@ -4519,6 +4520,7 @@ tanh: _UFunc_Nin1_Nout1[L['tanh'], L[8], None]|;| true_divide: _UFunc_Nin2_Nout1[L['true_divide'], L[11], None]|;| trunc: _UFunc_Nin1_Nout1[L['trunc'], L[7], None]|;| vecdot: _GUFunc_Nin2_Nout1[L['vecdot'], L[19], None, L[""(n),(n)->()""]]|;|+vecmat: _GUFunc_Nin2_Nout1[L['vecmat'], L[19], None, L[""(n),(n,m)->(m)""]]|;| |;| abs = absolute|;| acos = arccos || PR#25675 - numpy/_core/code_generators/generate_umath.py: @@ -1152,6 +1152,22 @@ def english_upper(s):|;|           TD(O),|;|           signature='(n),(n)->()',|;|           ),|;|+'matvec':|;|+    Ufunc(2, 1, None,|;|+          docstrings.get('numpy._core.umath.matvec'),|;|+          ""PyUFunc_SimpleUniformOperationTypeResolver"",|;|+          TD(notimes_or_obj),|;|+          TD(O),|;|+          signature='(m,n),(n)->(m)',|;|+          ),|;|+'vecmat':|;|+    Ufunc(2, 1, None,|;|+          docstrings.get('numpy._core.umath.vecmat'),|;|+          ""PyUFunc_SimpleUniformOperationTypeResolver"",|;|+          TD(notimes_or_obj),|;|+          TD(O),|;|+          signature='(n),(n,m)->(m)',|;|+          ),|;| 'str_len':|;|     Ufunc(1, 1, Zero,|;|           docstrings.get('numpy._core.umath.str_len'), || PR#25675 - numpy/_core/code_generators/ufunc_docstrings.py: @@ -44,7 +44,7 @@ def add_newdoc(place, name, doc):|;| |;|     skip = (|;|         # gufuncs do not use the OUT_SCALAR replacement strings|;|-        'matmul', 'vecdot',|;|+        'matmul', 'vecdot', 'matvec', 'vecmat',|;|         # clip has 3 inputs, which is not handled by this|;|         'clip',|;|     )|;|@@ -2793,7 +2793,9 @@ def add_newdoc(place, name, doc):|;| |;|     See Also|;|     --------|;|-    vdot : Complex-conjugating dot product.|;|+    vecdot : Complex-conjugating dot product for stacks of vectors.|;|+    matvec : Matrix-vector product for stacks of matrices and vectors.|;|+    vecmat : Vector-matrix product for stacks of vectors and matrices.|;|     tensordot : Sum products over arbitrary axes.|;|     einsum : Einstein summation convention.|;|     dot : alternative matrix product with different broadcasting rules.|;|@@ -2808,10 +2810,10 @@ def add_newdoc(place, name, doc):|;|       matrices residing in the last two indexes and broadcast accordingly.|;|     - If the first argument is 1-D, it is promoted to a matrix by|;|       prepending a 1 to its dimensions. After matrix multiplication|;|-      the prepended 1 is removed.|;|+      the prepended 1 is removed. (For stacks of vectors, use ``vecmat``.)|;|     - If the second argument is 1-D, it is promoted to a matrix by|;|       appending a 1 to its dimensions. After matrix multiplication|;|-      the appended 1 is removed.|;|+      the appended 1 is removed. (For stacks of vectors, use ``matvec``.)|;| |;|     ``matmul`` differs from ``dot`` in two important ways:|;| |;|@@ -2910,8 +2912,8 @@ def add_newdoc(place, name, doc):|;|         Input arrays, scalars not allowed.|;|     out : ndarray, optional|;|         A location into which the result is stored. If provided, it must have|;|-        a shape that the broadcasted shape of `x1` and `x2` with the last axis|;|-        removed. If not provided or None, a freshly-allocated array is used.|;|+        the broadcasted shape of `x1` and `x2` with the last axis removed.|;|+        If not provided or None, a freshly-allocated array is used.|;|     **kwargs|;|         For other keyword-only arguments, see the|;|         :ref:`ufunc docs <ufuncs.kwargs>`.|;|@@ -2933,6 +2935,9 @@ def add_newdoc(place, name, doc):|;|     See Also|;|     --------|;|     vdot : same but flattens arguments first|;|+    matmul : Matrix-matrix product.|;|+    vecmat : Vector-matrix product.|;|+    matvec : Matrix-vector product.|;|     einsum : Einstein summation convention.|;| |;|     Examples|;|@@ -2949,6 +2954,135 @@ def add_newdoc(place, name, doc):|;|     .. versionadded:: 2.0.0|;|     """""")|;| |;|+add_newdoc('numpy._core.umath', 'matvec',|;|+    """"""|;|+    Matrix-vector dot product of two arrays.|;|+|;|+    Given a matrix (or stack of matrices) :math:`\\mathbf{A}` in ``x1`` and|;|+    a vector (or stack of vectors) :math:`\\mathbf{v}` in ``x2``, the|;|+    matrix-vector product is defined as:|;|+|;|+    .. math::|;|+       \\mathbf{A} \\cdot \\mathbf{b} = \\sum_{j=0}^{n-1} A_{ij} v_j|;|+|;|+    where the sum is over the last dimensions in ``x1`` and ``x2``|;|+    (unless ``axes`` is specified).  (For a matrix-vector product with the|;|+    vector conjugated, use ``np.vecmat(x2, x1.mT)``.)|;|+|;|+    Parameters|;|+    ----------|;|+    x1, x2 : array_like|;|+        Input arrays, scalars not allowed.|;|+    out : ndarray, optional|;|+        A location into which the result is stored. If provided, it must have|;|+        the broadcasted shape of ``x1`` and ``x2`` with the summation axis|;|+        removed. If not provided or None, a freshly-allocated array is used.|;|+    **kwargs|;|+        For other keyword-only arguments, see the|;|+        :ref:`ufunc docs <ufuncs.kwargs>`.|;|+|;|+    Returns|;|+    -------|;|+    y : ndarray|;|+        The matrix-vector product of the inputs.|;|+|;|+    Raises|;|+    ------|;|+    ValueError|;|+        If the last dimensions of ``x1`` and ``x2`` are not the same size.|;|+|;|+        If a scalar value is passed in.|;|+|;|+    See Also|;|+    --------|;|+    vecdot : Vector-vector product.|;|+    vecmat : Vector-matrix product.|;|+    matmul : Matrix-matrix product.|;|+    einsum : Einstein summation convention.|;|+|;|+    Examples|;|+    --------|;|+    Rotate a set of vectors from Y to X along Z.|;|+|;|+    >>> a = np.array([[0., 1., 0.],|;|+    ...               [-1., 0., 0.],|;|+    ...               [0., 0., 1.]])|;|+    >>> v = np.array([[1., 0., 0.],|;|+    ...               [0., 1., 0.],|;|+    ...               [0., 0., 1.],|;|+    ...               [0., 6., 8.]])|;|+    >>> np.matvec(a, v)|;|+    array([[ 0., -1.,  0.],|;|+           [ 1.,  0.,  0.],|;|+           [ 0.,  0.,  1.],|;|+           [ 6.,  0.,  8.]])|;|+|;|+    .. versionadded:: 2.1.0|;|+    """""")|;|+|;|+add_newdoc('numpy._core.umath', 'vecmat',|;|+    """"""|;|+    Vector-matrix dot product of two arrays.|;|+|;|+    Given a vector (or stack of vector) :math:`\\mathbf{v}` in ``x1`` and|;|+    a matrix (or stack of matrices) :math:`\\mathbf{A}` in ``x2``, the|;|+    vector-matrix product is defined as:|;|+|;|+    .. math::|;|+       \\mathbf{b} \\cdot \\mathbf{A} = \\sum_{i=0}^{n-1} \\overline{v_i}A_{ij}|;|+|;|+    where the sum is over the last dimension of ``x1`` and the one-but-last|;|+    dimensions in ``x2`` (unless `axes` is specified) and where|;|+    :math:`\\overline{v_i}` denotes the complex conjugate if :math:`v`|;|+    is complex and the identity otherwise. (For a non-conjugated vector-matrix|;|+    product, use ``np.matvec(x2.mT, x1)``.)|;|+|;|+    Parameters|;|+    ----------|;|+    x1, x2 : array_like|;|+        Input arrays, scalars not allowed.|;|+    out : ndarray, optional|;|+        A location into which the result is stored. If provided, it must have|;|+        the broadcasted shape of ``x1`` and ``x2`` with the summation axis|;|+        removed. If not provided or None, a freshly-allocated array is used.|;|+    **kwargs|;|+        For other keyword-only arguments, see the|;|+        :ref:`ufunc docs <ufuncs.kwargs>`.|;|+|;|+    Returns|;|+    -------|;|+    y : ndarray|;|+        The vector-matrix product of the inputs.|;|+|;|+    Raises|;|+    ------|;|+    ValueError|;|+        If the last dimensions of ``x1`` and the one-but-last dimension of|;|+        ``x2`` are not the same size.|;|+|;|+        If a scalar value is passed in.|;|+|;|+    See Also|;|+    --------|;|+    vecdot : Vector-vector product.|;|+    matvec : Matrix-vector product.|;|+    matmul : Matrix-matrix product.|;|+    einsum : Einstein summation convention.|;|+|;|+    Examples|;|+    --------|;|+    Project a vector along X and Y.|;|+|;|+    >>> v = np.array([0., 4., 2.])|;|+    >>> a = np.array([[1., 0., 0.],|;|+    ...               [0., 1., 0.],|;|+    ...               [0., 0., 0.]])|;|+    >>> np.vecmat(v, a)|;|+    array([ 0.,  4., 0.])|;|+|;|+    .. versionadded:: 2.1.0|;|+    """""")|;|+|;| add_newdoc('numpy._core.umath', 'modf',|;|     """"""|;|     Return the fractional and integral parts of an array, element-wise. || PR#25675 - numpy/_core/multiarray.py: @@ -83,11 +83,11 @@ def _override___module__():|;|         'isfinite', 'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'less',|;|         'less_equal', 'log', 'log10', 'log1p', 'log2', 'logaddexp',|;|         'logaddexp2', 'logical_and', 'logical_not', 'logical_or',|;|-        'logical_xor', 'matmul', 'maximum', 'minimum', 'remainder', 'modf',|;|-        'multiply', 'negative', 'nextafter', 'not_equal', 'positive', 'power',|;|-        'rad2deg', 'radians', 'reciprocal', 'rint', 'sign', 'signbit', 'sin',|;|-        'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|-        'trunc', 'vecdot',|;|+        'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'remainder',|;|+        'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|+        'power', 'rad2deg', 'radians', 'reciprocal', 'rint', 'sign', 'signbit',|;|+        'sin', 'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|+        'trunc', 'vecdot', 'vecmat',|;|     ]:|;|         ufunc = namespace_names[ufunc_name]|;|         ufunc.__module__ = ""numpy"" || PR#25675 - numpy/_core/src/umath/matmul.c.src: @@ -81,9 +81,9 @@ static const npy_cfloat oneF = 1.0f, zeroF = 0.0f|;|;  */|;| NPY_NO_EXPORT void|;| @name@_gemv(void *ip1, npy_intp is1_m, npy_intp is1_n,|;|-            void *ip2, npy_intp is2_n, npy_intp NPY_UNUSED(is2_p),|;|-            void *op, npy_intp op_m, npy_intp NPY_UNUSED(op_p),|;|-            npy_intp m, npy_intp n, npy_intp NPY_UNUSED(p))|;|+            void *ip2, npy_intp is2_n,|;|+            void *op, npy_intp op_m,|;|+            npy_intp m, npy_intp n)|;| {|;|     /*|;|      * Vector matrix multiplication -- Level 2 BLAS|;|@@ -465,13 +465,12 @@ NPY_NO_EXPORT void|;|                                            op, os_m, os_p, dm, dn, dp)|;|;             } else if (vector_matrix) {|;|                 /* vector @ matrix, switch ip1, ip2, p and m */|;|-                @TYPE@_gemv(ip2, is2_p, is2_n, ip1, is1_n, is1_m,|;|-                            op, os_p, os_m, dp, dn, dm)|;|;+                @TYPE@_gemv(ip2, is2_p, is2_n, ip1, is1_n,|;|+                            op, os_p, dp, dn)|;|;             } else if  (matrix_vector) {|;|                 /* matrix @ vector */|;|-                @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n, is2_p,|;|-|;|-                            op, os_m, os_p, dm, dn, dp)|;|;+                @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n,|;|+                            op, os_m, dm, dn)|;|;             } else {|;|                 /* column @ row, 2d output, no blas needed or non-blas-able input */|;|                 @TYPE@_matmul_inner_noblas(ip1, is1_m, is1_n,|;|@@ -655,3 +654,174 @@ NPY_NO_EXPORT void|;|     }|;| }|;| /**end repeat**/|;|+|;|+#if defined(HAVE_CBLAS)|;|+/*|;|+ * Blas complex vector-matrix product via gemm (gemv cannot conjugate the vector).|;|+ */|;|+/**begin repeat|;|+ *|;|+ * #name = CFLOAT, CDOUBLE#|;|+ * #typ = npy_cfloat, npy_cdouble#|;|+ * #prefix = c, z#|;|+ * #step1 = &oneF, &oneD#|;|+ * #step0 = &zeroF, &zeroD#|;|+ */|;|+NPY_NO_EXPORT void|;|+@name@_vecmat_via_gemm(void *ip1, npy_intp is1_n,|;|+                       void *ip2, npy_intp is2_n, npy_intp is2_m,|;|+                       void *op, npy_intp os_m,|;|+                       npy_intp n, npy_intp m)|;|+{|;|+    enum CBLAS_ORDER order = CblasRowMajor|;|;+    enum CBLAS_TRANSPOSE trans1, trans2|;|;+    CBLAS_INT N, M, lda, ldb, ldc|;|;+    assert(n <= BLAS_MAXSIZE && m <= BLAS_MAXSIZE)|;|;+    N = (CBLAS_INT)n|;|;+    M = (CBLAS_INT)m|;|;+|;|+    assert(os_m == sizeof(@typ@))|;|;+    ldc = (CBLAS_INT)m|;|;+|;|+    assert(is_blasable2d(is1_n, sizeof(@typ@), n, 1, sizeof(@typ@)))|;|;+    trans1 = CblasConjTrans|;|;+    lda = (CBLAS_INT)(is1_n / sizeof(@typ@))|;|;+|;|+    if (is_blasable2d(is2_n, is2_m, n, m, sizeof(@typ@))) {|;|+        trans2 = CblasNoTrans|;|;+        ldb = (CBLAS_INT)(is2_n / sizeof(@typ@))|;|;+    }|;|+    else {|;|+        assert(is_blasable2d(is2_m, is2_n, m, n, sizeof(@typ@)))|;|;+        trans2 = CblasTrans|;|;+        ldb = (CBLAS_INT)(is2_m / sizeof(@typ@))|;|;+    }|;|+    CBLAS_FUNC(cblas_@prefix@gemm)(|;|+        order, trans1, trans2, 1, M, N, @step1@, ip1, lda,|;|+        ip2, ldb, @step0@, op, ldc)|;|;+}|;|+/**end repeat**/|;|+#endif|;|+|;|+/*|;|+ * matvec loops, using blas gemv if possible, and TYPE_dot implementations otherwise.|;|+ * signature is (m,n),(n)->(m)|;|+ */|;|+/**begin repeat|;|+ *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|+ *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|+ *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|+ *          BYTE, SHORT, INT, LONG, LONGLONG,|;|+ *          BOOL, OBJECT#|;|+ *  #typ = npy_float,npy_double,npy_longdouble, npy_half,|;|+ *         npy_cfloat, npy_cdouble, npy_clongdouble,|;|+ *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,|;|+ *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,|;|+ *         npy_bool, npy_object#|;|+ * #USEBLAS = 1, 1, 0, 0, 1, 1, 0*13#|;|+ * #CHECK_PYERR = 0*18, 1#|;|+ */|;|+NPY_NO_EXPORT void|;|+@TYPE@_matvec(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|+{|;|+    npy_intp n_outer = dimensions[0]|;|;+    npy_intp s0=steps[0], s1=steps[1], s2=steps[2]|;|;+    npy_intp dm = dimensions[1], dn = dimensions[2]|;|;+    npy_intp is1_m=steps[3], is1_n=steps[4], is2_n=steps[5], os_m=steps[6]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+    npy_bool too_big_for_blas = (dm > BLAS_MAXSIZE || dn > BLAS_MAXSIZE)|;|;+    npy_bool i1_c_blasable = is_blasable2d(is1_m, is1_n, dm, dn, sizeof(@typ@))|;|;+    npy_bool i1_f_blasable = is_blasable2d(is1_n, is1_m, dn, dm, sizeof(@typ@))|;|;+    npy_bool i2_blasable = is_blasable2d(is2_n, sizeof(@typ@), dn, 1, sizeof(@typ@))|;|;+    npy_bool blasable = ((i1_c_blasable || i1_f_blasable) && i2_blasable|;|+                         && !too_big_for_blas && dn > 1 && dm > 1)|;|;+#endif|;|+    for (npy_intp i = 0; i < n_outer; i++,|;|+             args[0] += s0, args[1] += s1, args[2] += s2) {|;|+        char *ip1=args[0], *ip2=args[1], *op=args[2]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+        if (blasable) {|;|+            @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n, op, os_m, dm, dn)|;|;+            continue|;|;+        }|;|+#endif|;|+        /*|;|+         * Dot the different matrix rows with the vector to get output elements.|;|+         * (no conjugation for complex, unlike vecdot and vecmat)|;|+         */|;|+        for (npy_intp j = 0; j < dm; j++, ip1 += is1_m, op += os_m) {|;|+            @TYPE@_dot(ip1, is1_n, ip2, is2_n, op, dn, NULL)|;|;+#if @CHECK_PYERR@|;|+            if (PyErr_Occurred()) {|;|+                return|;|;+            }|;|+#endif|;|+        }|;|+    }|;|+}|;|+/**end repeat**/|;|+|;|+/*|;|+ * vecmat loops, using blas gemv for float and gemm for complex if possible,|;|+ * and TYPE_dot[c] implementations otherwise.|;|+ * Note that we cannot use gemv for complex, since we need to conjugate the vector.|;|+ * signature is (n),(n,m)->(m)|;|+ */|;|+/**begin repeat|;|+ *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|+ *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|+ *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|+ *          BYTE, SHORT, INT, LONG, LONGLONG,|;|+ *          BOOL, OBJECT#|;|+ *  #typ = npy_float,npy_double,npy_longdouble, npy_half,|;|+ *         npy_cfloat, npy_cdouble, npy_clongdouble,|;|+ *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,|;|+ *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,|;|+ *         npy_bool, npy_object#|;|+ * #USEBLAS = 1, 1, 0, 0, 1, 1, 0*13#|;|+ * #COMPLEX = 0*4, 1*3, 0*11, 1#|;|+ * #DOT = dot*4, dotc*3, dot*11, dotc#|;|+ * #CHECK_PYERR = 0*18, 1#|;|+ */|;|+NPY_NO_EXPORT void|;|+@TYPE@_vecmat(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|+{|;|+    npy_intp n_outer = dimensions[0]|;|;+    npy_intp s0=steps[0], s1=steps[1], s2=steps[2]|;|;+    npy_intp dn = dimensions[1], dm = dimensions[2]|;|;+    npy_intp is1_n=steps[3], is2_n=steps[4], is2_m=steps[5], os_m=steps[6]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+    npy_bool too_big_for_blas = (dm > BLAS_MAXSIZE || dn > BLAS_MAXSIZE)|;|;+    npy_bool i1_blasable = is_blasable2d(is1_n, sizeof(@typ@), dn, 1, sizeof(@typ@))|;|;+    npy_bool i2_c_blasable = is_blasable2d(is2_n, is2_m, dn, dm, sizeof(@typ@))|;|;+    npy_bool i2_f_blasable = is_blasable2d(is2_m, is2_n, dm, dn, sizeof(@typ@))|;|;+    npy_bool blasable = (i1_blasable && (i2_c_blasable || i2_f_blasable)|;|+                         && !too_big_for_blas && dn > 1 && dm > 1)|;|;+#endif|;|+    for (npy_intp i = 0; i < n_outer; i++,|;|+             args[0] += s0, args[1] += s1, args[2] += s2) {|;|+        char *ip1=args[0], *ip2=args[1], *op=args[2]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+        if (blasable) {|;|+#if @COMPLEX@|;|+            /* For complex, use gemm so we can conjugate the vector */|;|+            @TYPE@_vecmat_via_gemm(ip1, is1_n, ip2, is2_n, is2_m, op, os_m, dn, dm)|;|;+#else|;|+            /* For float, use gemv (hence flipped order) */|;|+            @TYPE@_gemv(ip2, is2_m, is2_n, ip1, is1_n, op, os_m, dm, dn)|;|;+#endif|;|+            continue|;|;+        }|;|+#endif|;|+        /* Dot the vector with different matrix columns to get output elements. */|;|+        for (npy_intp j = 0; j < dm; j++, ip2 += is2_m, op += os_m) {|;|+            @TYPE@_@DOT@(ip1, is1_n, ip2, is2_n, op, dn, NULL)|;|;+#if @CHECK_PYERR@|;|+            if (PyErr_Occurred()) {|;|+                return|;|;+            }|;|+#endif|;|+        }|;|+    }|;|+}|;|+/**end repeat**/ || PR#25675 - numpy/_core/src/umath/matmul.h.src: @@ -7,15 +7,10 @@|;|  **/|;| NPY_NO_EXPORT void|;| @TYPE@_matmul(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;-/**end repeat**/|;|-|;|-/**begin repeat|;|- *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|- *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|- *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|- *          BYTE, SHORT, INT, LONG, LONGLONG,|;|- *          BOOL, OBJECT#|;|- */|;| NPY_NO_EXPORT void|;| @TYPE@_vecdot(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;+NPY_NO_EXPORT void|;|+@TYPE@_matvec(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;+NPY_NO_EXPORT void|;|+@TYPE@_vecmat(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|; /**end repeat**/ || PR#25675 - numpy/_core/tests/test_ufunc.py: @@ -824,20 +824,77 @@ def test_vecdot(self):|;|         actual3 = np.vecdot(arr1.astype(""object""), arr2)|;|         assert_array_equal(actual3, expected.astype(""object""))|;| |;|-    def test_vecdot_complex(self):|;|-        arr1 = np.array([1, 2j, 3])|;|-        arr2 = np.array([1, 2, 3])|;|+    def test_matvec(self):|;|+        arr1 = np.arange(6).reshape((2, 3))|;|+        arr2 = np.arange(3).reshape((1, 3))|;|+|;|+        actual = np.matvec(arr1, arr2)|;|+        expected = np.array([[5, 14]])|;| |;|-        actual = np.vecdot(arr1, arr2)|;|-        expected = np.array([10-4j])|;|         assert_array_equal(actual, expected)|;| |;|-        actual2 = np.vecdot(arr2, arr1)|;|-        assert_array_equal(actual2, expected.conj())|;|+        actual2 = np.matvec(arr1.T, arr2.T, axes=[(-1, -2), -2, -1])|;|+        assert_array_equal(actual2, expected)|;| |;|-        actual3 = np.vecdot(arr1.astype(""object""), arr2.astype(""object""))|;|+        actual3 = np.matvec(arr1.astype(""object""), arr2)|;|         assert_array_equal(actual3, expected.astype(""object""))|;| |;|+    @pytest.mark.parametrize(""vec"", [|;|+        np.array([[1., 2., 3.], [4., 5., 6.]]),|;|+        np.array([[1., 2j, 3.], [4., 5., 6j]]),|;|+        np.array([[1., 2., 3.], [4., 5., 6.]], dtype=object),|;|+        np.array([[1., 2j, 3.], [4., 5., 6j]], dtype=object)])|;|+    @pytest.mark.parametrize(""matrix"", [|;|+        None,|;|+        np.array([[1.+1j, 0.5, -0.5j],|;|+                  [0.25, 2j, 0.],|;|+                  [4., 0., -1j]])])|;|+    def test_vecmatvec_identity(self, matrix, vec):|;|+        """"""Check that (x†A)x equals x†(Ax).""""""|;|+        mat = matrix if matrix is not None else np.eye(3)|;|+        matvec = np.matvec(mat, vec)  # Ax|;|+        vecmat = np.vecmat(vec, mat)  # x†A|;|+        if matrix is None:|;|+            assert_array_equal(matvec, vec)|;|+            assert_array_equal(vecmat.conj(), vec)|;|+        assert_array_equal(matvec, (mat @ vec[..., np.newaxis]).squeeze(-1))|;|+        assert_array_equal(vecmat, (vec[..., np.newaxis].mT.conj()|;|+                                    @ mat).squeeze(-2))|;|+        expected = np.einsum('...i,ij,...j', vec.conj(), mat, vec)|;|+        vec_matvec = (vec.conj() * matvec).sum(-1)|;|+        vecmat_vec = (vecmat * vec).sum(-1)|;|+        assert_array_equal(vec_matvec, expected)|;|+        assert_array_equal(vecmat_vec, expected)|;|+|;|+    @pytest.mark.parametrize(""ufunc, shape1, shape2, conj"", [|;|+        (np.vecdot, (3,), (3,), True),|;|+        (np.vecmat, (3,), (3, 1), True),|;|+        (np.matvec, (1, 3), (3,), False),|;|+        (np.matmul, (1, 3), (3, 1), False),|;|+    ])|;|+    def test_vecdot_matvec_vecmat_complex(self, ufunc, shape1, shape2, conj):|;|+        arr1 = np.array([1, 2j, 3])|;|+        arr2 = np.array([1, 2, 3])|;|+|;|+        actual1 = ufunc(arr1.reshape(shape1), arr2.reshape(shape2))|;|+        expected1 = np.array(((arr1.conj() if conj else arr1) * arr2).sum(),|;|+                             ndmin=min(len(shape1), len(shape2)))|;|+        assert_array_equal(actual1, expected1)|;|+        # This would fail for conj=True, since matmul omits the conjugate.|;|+        if not conj:|;|+            assert_array_equal(arr1.reshape(shape1) @ arr2.reshape(shape2),|;|+                               expected1)|;|+|;|+        actual2 = ufunc(arr2.reshape(shape1), arr1.reshape(shape2))|;|+        expected2 = np.array(((arr2.conj() if conj else arr2) * arr1).sum(),|;|+                             ndmin=min(len(shape1), len(shape2)))|;|+        assert_array_equal(actual2, expected2)|;|+|;|+        actual3 = ufunc(arr1.reshape(shape1).astype(""object""),|;|+                        arr2.reshape(shape2).astype(""object""))|;|+        expected3 = expected1.astype(object)|;|+        assert_array_equal(actual3, expected3)|;|+|;|     def test_vecdot_subclass(self):|;|         class MySubclass(np.ndarray):|;|             pass|;|@@ -2757,20 +2814,19 @@ def test_ufunc_noncontiguous(ufunc):|;|             # bool, object, datetime are too irregular for this simple test|;|             continue|;|         inp, out = typ.split('->')|;|-        args_c = [np.empty(6, t) for t in inp]|;|-        # non contiguous (3 step)|;|-        args_n = [np.empty(18, t)[::3] for t in inp]|;|+        args_c = [np.empty((6, 6), t) for t in inp]|;|+        # non contiguous (2, 3 step on the two dimensions)|;|+        args_n = [np.empty((12, 18), t)[::2, ::3] for t in inp]|;|         # alignment != itemsize is possible.  So create an array with such|;|         # an odd step manually.|;|         args_o = []|;|         for t in inp:|;|             orig_dt = np.dtype(t)|;|             off_dt = f""S{orig_dt.alignment}""  # offset by alignment|;|             dtype = np.dtype([(""_"", off_dt), (""t"", orig_dt)], align=False)|;|-            args_o.append(np.empty(6, dtype=dtype)[""t""])|;|-|;|+            args_o.append(np.empty((6, 6), dtype=dtype)[""t""])|;|         for a in args_c + args_n + args_o:|;|-            a.flat = range(1,7)|;|+            a.flat = range(1, 37)|;| |;|         with warnings.catch_warnings(record=True):|;|             warnings.filterwarnings(""always"")|;|@@ -2788,7 +2844,7 @@ def test_ufunc_noncontiguous(ufunc):|;|                 # since different algorithms (libm vs. intrinsics) can be used|;|                 # for different input strides|;|                 res_eps = np.finfo(dt).eps|;|-                tol = 2*res_eps|;|+                tol = 3*res_eps|;|                 assert_allclose(res_c, res_n, atol=tol, rtol=tol)|;|                 assert_allclose(res_c, res_o, atol=tol, rtol=tol)|;|             else: || PR#25675 - numpy/_core/umath.py: @@ -33,8 +33,8 @@|;|     'heaviside', 'hypot', 'invert', 'isfinite', 'isinf', 'isnan', 'isnat',|;|     'lcm', 'ldexp', 'left_shift', 'less', 'less_equal', 'log', 'log10',|;|     'log1p', 'log2', 'logaddexp', 'logaddexp2', 'logical_and', 'logical_not',|;|-    'logical_or', 'logical_xor', 'maximum', 'minimum', 'mod', 'modf',|;|+    'logical_or', 'logical_xor', 'matvec', 'maximum', 'minimum', 'mod', 'modf',|;|     'multiply', 'negative', 'nextafter', 'not_equal', 'pi', 'positive',|;|     'power', 'rad2deg', 'radians', 'reciprocal', 'remainder', 'right_shift',|;|     'rint', 'sign', 'signbit', 'sin', 'sinh', 'spacing', 'sqrt', 'square',|;|-    'subtract', 'tan', 'tanh', 'true_divide', 'trunc']|;|+    'subtract', 'tan', 'tanh', 'true_divide', 'trunc', 'vecdot', 'vecmat'] || PR#27846 - benchmarks/benchmarks/bench_ufunc.py: @@ -16,12 +16,12 @@|;|           'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'left_shift', 'less',|;|           'less_equal', 'log', 'log10', 'log1p', 'log2', 'logaddexp',|;|           'logaddexp2', 'logical_and', 'logical_not', 'logical_or',|;|-          'logical_xor', 'matmul', 'maximum', 'minimum', 'mod', 'modf',|;|-          'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|+          'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'mod',|;|+          'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|           'power', 'rad2deg', 'radians', 'reciprocal', 'remainder',|;|           'right_shift', 'rint', 'sign', 'signbit', 'sin',|;|           'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|-          'true_divide', 'trunc', 'vecdot']|;|+          'true_divide', 'trunc', 'vecdot', 'vecmat']|;| arrayfuncdisp = ['real', 'round']|;| |;| for name in ufuncs: || PR#27846 - doc/release/upcoming_changes/25675.new_feature.rst: @@ -0,0 +1,20 @@|;|+New functions for matrix-vector and vector-matrix products|;|+----------------------------------------------------------|;|+|;|+Two new generalized ufuncs were defined:|;|+|;|+* `numpy.matvec` - matrix-vector product, treating the arguments as|;|+  stacks of matrices and column vectors, respectively.|;|+|;|+* `numpy.vecmat` - vector-matrix product, treating the arguments as|;|+  stacks of column vectors and matrices, respectively. For complex|;|+  vectors, the conjugate is taken.|;|+|;|+These add to the existing `numpy.matmul` as well as to `numpy.vecdot`,|;|+which was added in numpy 2.0.|;|+|;|+Note that `numpy.matmul` never takes a complex conjugate, also not|;|+when its left input is a vector, while both `numpy.vecdot` and|;|+`numpy.vecmat` do take the conjugate for complex vectors on the|;|+left-hand side (which are taken to be the ones that are transposed,|;|+following the physics convention). || PR#27846 - doc/source/reference/routines.linalg.rst: @@ -62,6 +62,8 @@ Matrix and vector products|;|    outer|;|    matmul|;|    linalg.matmul (Array API compatible location)|;|+   matvec|;|+   vecmat|;|    tensordot|;|    linalg.tensordot (Array API compatible location)|;|    einsum || PR#27846 - numpy/__init__.py: @@ -151,10 +151,10 @@|;|         left_shift, less, less_equal, lexsort, linspace, little_endian, log,|;|         log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not,|;|         logical_or, logical_xor, logspace, long, longdouble, longlong, matmul,|;|-        matrix_transpose, max, maximum, may_share_memory, mean, memmap, min,|;|-        min_scalar_type, minimum, mod, modf, moveaxis, multiply, nan, ndarray,|;|-        ndim, nditer, negative, nested_iters, newaxis, nextafter, nonzero,|;|-        not_equal, number, object_, ones, ones_like, outer, partition,|;|+        matvec, matrix_transpose, max, maximum, may_share_memory, mean, memmap,|;|+        min, min_scalar_type, minimum, mod, modf, moveaxis, multiply, nan,|;|+        ndarray, ndim, nditer, negative, nested_iters, newaxis, nextafter,|;|+        nonzero, not_equal, number, object_, ones, ones_like, outer, partition,|;|         permute_dims, pi, positive, pow, power, printoptions, prod,|;|         promote_types, ptp, put, putmask, rad2deg, radians, ravel, recarray,|;|         reciprocal, record, remainder, repeat, require, reshape, resize,|;|@@ -165,8 +165,8 @@|;|         str_, subtract, sum, swapaxes, take, tan, tanh, tensordot,|;|         timedelta64, trace, transpose, true_divide, trunc, typecodes, ubyte,|;|         ufunc, uint, uint16, uint32, uint64, uint8, uintc, uintp, ulong,|;|-        ulonglong, unsignedinteger, unstack, ushort, var, vdot, vecdot, void,|;|-        vstack, where, zeros, zeros_like|;|+        ulonglong, unsignedinteger, unstack, ushort, var, vdot, vecdot,|;|+        vecmat, void, vstack, where, zeros, zeros_like|;|     )|;| |;|     # NOTE: It's still under discussion whether these aliases || PR#27846 - numpy/__init__.pyi: @@ -4490,6 +4490,7 @@ logical_not: _UFunc_Nin1_Nout1[L['logical_not'], L[20], None]|;| logical_or: _UFunc_Nin2_Nout1[L['logical_or'], L[20], L[False]]|;| logical_xor: _UFunc_Nin2_Nout1[L['logical_xor'], L[19], L[False]]|;| matmul: _GUFunc_Nin2_Nout1[L['matmul'], L[19], None, L[""(n?,k),(k,m?)->(n?,m?)""]]|;|+matvec: _GUFunc_Nin2_Nout1[L['matvec'], L[19], None, L[""(m,n),(n)->(m)""]]|;| maximum: _UFunc_Nin2_Nout1[L['maximum'], L[21], None]|;| minimum: _UFunc_Nin2_Nout1[L['minimum'], L[21], None]|;| mod: _UFunc_Nin2_Nout1[L['remainder'], L[16], None]|;|@@ -4519,6 +4520,7 @@ tanh: _UFunc_Nin1_Nout1[L['tanh'], L[8], None]|;| true_divide: _UFunc_Nin2_Nout1[L['true_divide'], L[11], None]|;| trunc: _UFunc_Nin1_Nout1[L['trunc'], L[7], None]|;| vecdot: _GUFunc_Nin2_Nout1[L['vecdot'], L[19], None, L[""(n),(n)->()""]]|;|+vecmat: _GUFunc_Nin2_Nout1[L['vecmat'], L[19], None, L[""(n),(n,m)->(m)""]]|;| |;| abs = absolute|;| acos = arccos || PR#27846 - numpy/_core/code_generators/generate_umath.py: @@ -1152,6 +1152,22 @@ def english_upper(s):|;|           TD(O),|;|           signature='(n),(n)->()',|;|           ),|;|+'matvec':|;|+    Ufunc(2, 1, None,|;|+          docstrings.get('numpy._core.umath.matvec'),|;|+          ""PyUFunc_SimpleUniformOperationTypeResolver"",|;|+          TD(notimes_or_obj),|;|+          TD(O),|;|+          signature='(m,n),(n)->(m)',|;|+          ),|;|+'vecmat':|;|+    Ufunc(2, 1, None,|;|+          docstrings.get('numpy._core.umath.vecmat'),|;|+          ""PyUFunc_SimpleUniformOperationTypeResolver"",|;|+          TD(notimes_or_obj),|;|+          TD(O),|;|+          signature='(n),(n,m)->(m)',|;|+          ),|;| 'str_len':|;|     Ufunc(1, 1, Zero,|;|           docstrings.get('numpy._core.umath.str_len'), || PR#27846 - numpy/_core/code_generators/ufunc_docstrings.py: @@ -44,7 +44,7 @@ def add_newdoc(place, name, doc):|;| |;|     skip = (|;|         # gufuncs do not use the OUT_SCALAR replacement strings|;|-        'matmul', 'vecdot',|;|+        'matmul', 'vecdot', 'matvec', 'vecmat',|;|         # clip has 3 inputs, which is not handled by this|;|         'clip',|;|     )|;|@@ -2793,7 +2793,9 @@ def add_newdoc(place, name, doc):|;| |;|     See Also|;|     --------|;|-    vdot : Complex-conjugating dot product.|;|+    vecdot : Complex-conjugating dot product for stacks of vectors.|;|+    matvec : Matrix-vector product for stacks of matrices and vectors.|;|+    vecmat : Vector-matrix product for stacks of vectors and matrices.|;|     tensordot : Sum products over arbitrary axes.|;|     einsum : Einstein summation convention.|;|     dot : alternative matrix product with different broadcasting rules.|;|@@ -2808,10 +2810,10 @@ def add_newdoc(place, name, doc):|;|       matrices residing in the last two indexes and broadcast accordingly.|;|     - If the first argument is 1-D, it is promoted to a matrix by|;|       prepending a 1 to its dimensions. After matrix multiplication|;|-      the prepended 1 is removed.|;|+      the prepended 1 is removed. (For stacks of vectors, use ``vecmat``.)|;|     - If the second argument is 1-D, it is promoted to a matrix by|;|       appending a 1 to its dimensions. After matrix multiplication|;|-      the appended 1 is removed.|;|+      the appended 1 is removed. (For stacks of vectors, use ``matvec``.)|;| |;|     ``matmul`` differs from ``dot`` in two important ways:|;| |;|@@ -2910,8 +2912,8 @@ def add_newdoc(place, name, doc):|;|         Input arrays, scalars not allowed.|;|     out : ndarray, optional|;|         A location into which the result is stored. If provided, it must have|;|-        a shape that the broadcasted shape of `x1` and `x2` with the last axis|;|-        removed. If not provided or None, a freshly-allocated array is used.|;|+        the broadcasted shape of `x1` and `x2` with the last axis removed.|;|+        If not provided or None, a freshly-allocated array is used.|;|     **kwargs|;|         For other keyword-only arguments, see the|;|         :ref:`ufunc docs <ufuncs.kwargs>`.|;|@@ -2933,6 +2935,9 @@ def add_newdoc(place, name, doc):|;|     See Also|;|     --------|;|     vdot : same but flattens arguments first|;|+    matmul : Matrix-matrix product.|;|+    vecmat : Vector-matrix product.|;|+    matvec : Matrix-vector product.|;|     einsum : Einstein summation convention.|;| |;|     Examples|;|@@ -2949,6 +2954,135 @@ def add_newdoc(place, name, doc):|;|     .. versionadded:: 2.0.0|;|     """""")|;| |;|+add_newdoc('numpy._core.umath', 'matvec',|;|+    """"""|;|+    Matrix-vector dot product of two arrays.|;|+|;|+    Given a matrix (or stack of matrices) :math:`\\mathbf{A}` in ``x1`` and|;|+    a vector (or stack of vectors) :math:`\\mathbf{v}` in ``x2``, the|;|+    matrix-vector product is defined as:|;|+|;|+    .. math::|;|+       \\mathbf{A} \\cdot \\mathbf{b} = \\sum_{j=0}^{n-1} A_{ij} v_j|;|+|;|+    where the sum is over the last dimensions in ``x1`` and ``x2``|;|+    (unless ``axes`` is specified).  (For a matrix-vector product with the|;|+    vector conjugated, use ``np.vecmat(x2, x1.mT)``.)|;|+|;|+    Parameters|;|+    ----------|;|+    x1, x2 : array_like|;|+        Input arrays, scalars not allowed.|;|+    out : ndarray, optional|;|+        A location into which the result is stored. If provided, it must have|;|+        the broadcasted shape of ``x1`` and ``x2`` with the summation axis|;|+        removed. If not provided or None, a freshly-allocated array is used.|;|+    **kwargs|;|+        For other keyword-only arguments, see the|;|+        :ref:`ufunc docs <ufuncs.kwargs>`.|;|+|;|+    Returns|;|+    -------|;|+    y : ndarray|;|+        The matrix-vector product of the inputs.|;|+|;|+    Raises|;|+    ------|;|+    ValueError|;|+        If the last dimensions of ``x1`` and ``x2`` are not the same size.|;|+|;|+        If a scalar value is passed in.|;|+|;|+    See Also|;|+    --------|;|+    vecdot : Vector-vector product.|;|+    vecmat : Vector-matrix product.|;|+    matmul : Matrix-matrix product.|;|+    einsum : Einstein summation convention.|;|+|;|+    Examples|;|+    --------|;|+    Rotate a set of vectors from Y to X along Z.|;|+|;|+    >>> a = np.array([[0., 1., 0.],|;|+    ...               [-1., 0., 0.],|;|+    ...               [0., 0., 1.]])|;|+    >>> v = np.array([[1., 0., 0.],|;|+    ...               [0., 1., 0.],|;|+    ...               [0., 0., 1.],|;|+    ...               [0., 6., 8.]])|;|+    >>> np.matvec(a, v)|;|+    array([[ 0., -1.,  0.],|;|+           [ 1.,  0.,  0.],|;|+           [ 0.,  0.,  1.],|;|+           [ 6.,  0.,  8.]])|;|+|;|+    .. versionadded:: 2.1.0|;|+    """""")|;|+|;|+add_newdoc('numpy._core.umath', 'vecmat',|;|+    """"""|;|+    Vector-matrix dot product of two arrays.|;|+|;|+    Given a vector (or stack of vector) :math:`\\mathbf{v}` in ``x1`` and|;|+    a matrix (or stack of matrices) :math:`\\mathbf{A}` in ``x2``, the|;|+    vector-matrix product is defined as:|;|+|;|+    .. math::|;|+       \\mathbf{b} \\cdot \\mathbf{A} = \\sum_{i=0}^{n-1} \\overline{v_i}A_{ij}|;|+|;|+    where the sum is over the last dimension of ``x1`` and the one-but-last|;|+    dimensions in ``x2`` (unless `axes` is specified) and where|;|+    :math:`\\overline{v_i}` denotes the complex conjugate if :math:`v`|;|+    is complex and the identity otherwise. (For a non-conjugated vector-matrix|;|+    product, use ``np.matvec(x2.mT, x1)``.)|;|+|;|+    Parameters|;|+    ----------|;|+    x1, x2 : array_like|;|+        Input arrays, scalars not allowed.|;|+    out : ndarray, optional|;|+        A location into which the result is stored. If provided, it must have|;|+        the broadcasted shape of ``x1`` and ``x2`` with the summation axis|;|+        removed. If not provided or None, a freshly-allocated array is used.|;|+    **kwargs|;|+        For other keyword-only arguments, see the|;|+        :ref:`ufunc docs <ufuncs.kwargs>`.|;|+|;|+    Returns|;|+    -------|;|+    y : ndarray|;|+        The vector-matrix product of the inputs.|;|+|;|+    Raises|;|+    ------|;|+    ValueError|;|+        If the last dimensions of ``x1`` and the one-but-last dimension of|;|+        ``x2`` are not the same size.|;|+|;|+        If a scalar value is passed in.|;|+|;|+    See Also|;|+    --------|;|+    vecdot : Vector-vector product.|;|+    matvec : Matrix-vector product.|;|+    matmul : Matrix-matrix product.|;|+    einsum : Einstein summation convention.|;|+|;|+    Examples|;|+    --------|;|+    Project a vector along X and Y.|;|+|;|+    >>> v = np.array([0., 4., 2.])|;|+    >>> a = np.array([[1., 0., 0.],|;|+    ...               [0., 1., 0.],|;|+    ...               [0., 0., 0.]])|;|+    >>> np.vecmat(v, a)|;|+    array([ 0.,  4., 0.])|;|+|;|+    .. versionadded:: 2.1.0|;|+    """""")|;|+|;| add_newdoc('numpy._core.umath', 'modf',|;|     """"""|;|     Return the fractional and integral parts of an array, element-wise. || PR#27846 - numpy/_core/multiarray.py: @@ -83,11 +83,11 @@ def _override___module__():|;|         'isfinite', 'isinf', 'isnan', 'isnat', 'lcm', 'ldexp', 'less',|;|         'less_equal', 'log', 'log10', 'log1p', 'log2', 'logaddexp',|;|         'logaddexp2', 'logical_and', 'logical_not', 'logical_or',|;|-        'logical_xor', 'matmul', 'maximum', 'minimum', 'remainder', 'modf',|;|-        'multiply', 'negative', 'nextafter', 'not_equal', 'positive', 'power',|;|-        'rad2deg', 'radians', 'reciprocal', 'rint', 'sign', 'signbit', 'sin',|;|-        'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|-        'trunc', 'vecdot',|;|+        'logical_xor', 'matmul', 'matvec', 'maximum', 'minimum', 'remainder',|;|+        'modf', 'multiply', 'negative', 'nextafter', 'not_equal', 'positive',|;|+        'power', 'rad2deg', 'radians', 'reciprocal', 'rint', 'sign', 'signbit',|;|+        'sin', 'sinh', 'spacing', 'sqrt', 'square', 'subtract', 'tan', 'tanh',|;|+        'trunc', 'vecdot', 'vecmat',|;|     ]:|;|         ufunc = namespace_names[ufunc_name]|;|         ufunc.__module__ = ""numpy"" || PR#27846 - numpy/_core/src/umath/matmul.c.src: @@ -81,9 +81,9 @@ static const npy_cfloat oneF = 1.0f, zeroF = 0.0f|;|;  */|;| NPY_NO_EXPORT void|;| @name@_gemv(void *ip1, npy_intp is1_m, npy_intp is1_n,|;|-            void *ip2, npy_intp is2_n, npy_intp NPY_UNUSED(is2_p),|;|-            void *op, npy_intp op_m, npy_intp NPY_UNUSED(op_p),|;|-            npy_intp m, npy_intp n, npy_intp NPY_UNUSED(p))|;|+            void *ip2, npy_intp is2_n,|;|+            void *op, npy_intp op_m,|;|+            npy_intp m, npy_intp n)|;| {|;|     /*|;|      * Vector matrix multiplication -- Level 2 BLAS|;|@@ -465,13 +465,12 @@ NPY_NO_EXPORT void|;|                                            op, os_m, os_p, dm, dn, dp)|;|;             } else if (vector_matrix) {|;|                 /* vector @ matrix, switch ip1, ip2, p and m */|;|-                @TYPE@_gemv(ip2, is2_p, is2_n, ip1, is1_n, is1_m,|;|-                            op, os_p, os_m, dp, dn, dm)|;|;+                @TYPE@_gemv(ip2, is2_p, is2_n, ip1, is1_n,|;|+                            op, os_p, dp, dn)|;|;             } else if  (matrix_vector) {|;|                 /* matrix @ vector */|;|-                @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n, is2_p,|;|-|;|-                            op, os_m, os_p, dm, dn, dp)|;|;+                @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n,|;|+                            op, os_m, dm, dn)|;|;             } else {|;|                 /* column @ row, 2d output, no blas needed or non-blas-able input */|;|                 @TYPE@_matmul_inner_noblas(ip1, is1_m, is1_n,|;|@@ -655,3 +654,174 @@ NPY_NO_EXPORT void|;|     }|;| }|;| /**end repeat**/|;|+|;|+#if defined(HAVE_CBLAS)|;|+/*|;|+ * Blas complex vector-matrix product via gemm (gemv cannot conjugate the vector).|;|+ */|;|+/**begin repeat|;|+ *|;|+ * #name = CFLOAT, CDOUBLE#|;|+ * #typ = npy_cfloat, npy_cdouble#|;|+ * #prefix = c, z#|;|+ * #step1 = &oneF, &oneD#|;|+ * #step0 = &zeroF, &zeroD#|;|+ */|;|+NPY_NO_EXPORT void|;|+@name@_vecmat_via_gemm(void *ip1, npy_intp is1_n,|;|+                       void *ip2, npy_intp is2_n, npy_intp is2_m,|;|+                       void *op, npy_intp os_m,|;|+                       npy_intp n, npy_intp m)|;|+{|;|+    enum CBLAS_ORDER order = CblasRowMajor|;|;+    enum CBLAS_TRANSPOSE trans1, trans2|;|;+    CBLAS_INT N, M, lda, ldb, ldc|;|;+    assert(n <= BLAS_MAXSIZE && m <= BLAS_MAXSIZE)|;|;+    N = (CBLAS_INT)n|;|;+    M = (CBLAS_INT)m|;|;+|;|+    assert(os_m == sizeof(@typ@))|;|;+    ldc = (CBLAS_INT)m|;|;+|;|+    assert(is_blasable2d(is1_n, sizeof(@typ@), n, 1, sizeof(@typ@)))|;|;+    trans1 = CblasConjTrans|;|;+    lda = (CBLAS_INT)(is1_n / sizeof(@typ@))|;|;+|;|+    if (is_blasable2d(is2_n, is2_m, n, m, sizeof(@typ@))) {|;|+        trans2 = CblasNoTrans|;|;+        ldb = (CBLAS_INT)(is2_n / sizeof(@typ@))|;|;+    }|;|+    else {|;|+        assert(is_blasable2d(is2_m, is2_n, m, n, sizeof(@typ@)))|;|;+        trans2 = CblasTrans|;|;+        ldb = (CBLAS_INT)(is2_m / sizeof(@typ@))|;|;+    }|;|+    CBLAS_FUNC(cblas_@prefix@gemm)(|;|+        order, trans1, trans2, 1, M, N, @step1@, ip1, lda,|;|+        ip2, ldb, @step0@, op, ldc)|;|;+}|;|+/**end repeat**/|;|+#endif|;|+|;|+/*|;|+ * matvec loops, using blas gemv if possible, and TYPE_dot implementations otherwise.|;|+ * signature is (m,n),(n)->(m)|;|+ */|;|+/**begin repeat|;|+ *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|+ *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|+ *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|+ *          BYTE, SHORT, INT, LONG, LONGLONG,|;|+ *          BOOL, OBJECT#|;|+ *  #typ = npy_float,npy_double,npy_longdouble, npy_half,|;|+ *         npy_cfloat, npy_cdouble, npy_clongdouble,|;|+ *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,|;|+ *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,|;|+ *         npy_bool, npy_object#|;|+ * #USEBLAS = 1, 1, 0, 0, 1, 1, 0*13#|;|+ * #CHECK_PYERR = 0*18, 1#|;|+ */|;|+NPY_NO_EXPORT void|;|+@TYPE@_matvec(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|+{|;|+    npy_intp n_outer = dimensions[0]|;|;+    npy_intp s0=steps[0], s1=steps[1], s2=steps[2]|;|;+    npy_intp dm = dimensions[1], dn = dimensions[2]|;|;+    npy_intp is1_m=steps[3], is1_n=steps[4], is2_n=steps[5], os_m=steps[6]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+    npy_bool too_big_for_blas = (dm > BLAS_MAXSIZE || dn > BLAS_MAXSIZE)|;|;+    npy_bool i1_c_blasable = is_blasable2d(is1_m, is1_n, dm, dn, sizeof(@typ@))|;|;+    npy_bool i1_f_blasable = is_blasable2d(is1_n, is1_m, dn, dm, sizeof(@typ@))|;|;+    npy_bool i2_blasable = is_blasable2d(is2_n, sizeof(@typ@), dn, 1, sizeof(@typ@))|;|;+    npy_bool blasable = ((i1_c_blasable || i1_f_blasable) && i2_blasable|;|+                         && !too_big_for_blas && dn > 1 && dm > 1)|;|;+#endif|;|+    for (npy_intp i = 0; i < n_outer; i++,|;|+             args[0] += s0, args[1] += s1, args[2] += s2) {|;|+        char *ip1=args[0], *ip2=args[1], *op=args[2]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+        if (blasable) {|;|+            @TYPE@_gemv(ip1, is1_m, is1_n, ip2, is2_n, op, os_m, dm, dn)|;|;+            continue|;|;+        }|;|+#endif|;|+        /*|;|+         * Dot the different matrix rows with the vector to get output elements.|;|+         * (no conjugation for complex, unlike vecdot and vecmat)|;|+         */|;|+        for (npy_intp j = 0; j < dm; j++, ip1 += is1_m, op += os_m) {|;|+            @TYPE@_dot(ip1, is1_n, ip2, is2_n, op, dn, NULL)|;|;+#if @CHECK_PYERR@|;|+            if (PyErr_Occurred()) {|;|+                return|;|;+            }|;|+#endif|;|+        }|;|+    }|;|+}|;|+/**end repeat**/|;|+|;|+/*|;|+ * vecmat loops, using blas gemv for float and gemm for complex if possible,|;|+ * and TYPE_dot[c] implementations otherwise.|;|+ * Note that we cannot use gemv for complex, since we need to conjugate the vector.|;|+ * signature is (n),(n,m)->(m)|;|+ */|;|+/**begin repeat|;|+ *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|+ *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|+ *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|+ *          BYTE, SHORT, INT, LONG, LONGLONG,|;|+ *          BOOL, OBJECT#|;|+ *  #typ = npy_float,npy_double,npy_longdouble, npy_half,|;|+ *         npy_cfloat, npy_cdouble, npy_clongdouble,|;|+ *         npy_ubyte, npy_ushort, npy_uint, npy_ulong, npy_ulonglong,|;|+ *         npy_byte, npy_short, npy_int, npy_long, npy_longlong,|;|+ *         npy_bool, npy_object#|;|+ * #USEBLAS = 1, 1, 0, 0, 1, 1, 0*13#|;|+ * #COMPLEX = 0*4, 1*3, 0*11, 1#|;|+ * #DOT = dot*4, dotc*3, dot*11, dotc#|;|+ * #CHECK_PYERR = 0*18, 1#|;|+ */|;|+NPY_NO_EXPORT void|;|+@TYPE@_vecmat(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|+{|;|+    npy_intp n_outer = dimensions[0]|;|;+    npy_intp s0=steps[0], s1=steps[1], s2=steps[2]|;|;+    npy_intp dn = dimensions[1], dm = dimensions[2]|;|;+    npy_intp is1_n=steps[3], is2_n=steps[4], is2_m=steps[5], os_m=steps[6]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+    npy_bool too_big_for_blas = (dm > BLAS_MAXSIZE || dn > BLAS_MAXSIZE)|;|;+    npy_bool i1_blasable = is_blasable2d(is1_n, sizeof(@typ@), dn, 1, sizeof(@typ@))|;|;+    npy_bool i2_c_blasable = is_blasable2d(is2_n, is2_m, dn, dm, sizeof(@typ@))|;|;+    npy_bool i2_f_blasable = is_blasable2d(is2_m, is2_n, dm, dn, sizeof(@typ@))|;|;+    npy_bool blasable = (i1_blasable && (i2_c_blasable || i2_f_blasable)|;|+                         && !too_big_for_blas && dn > 1 && dm > 1)|;|;+#endif|;|+    for (npy_intp i = 0; i < n_outer; i++,|;|+             args[0] += s0, args[1] += s1, args[2] += s2) {|;|+        char *ip1=args[0], *ip2=args[1], *op=args[2]|;|;+#if @USEBLAS@ && defined(HAVE_CBLAS)|;|+        if (blasable) {|;|+#if @COMPLEX@|;|+            /* For complex, use gemm so we can conjugate the vector */|;|+            @TYPE@_vecmat_via_gemm(ip1, is1_n, ip2, is2_n, is2_m, op, os_m, dn, dm)|;|;+#else|;|+            /* For float, use gemv (hence flipped order) */|;|+            @TYPE@_gemv(ip2, is2_m, is2_n, ip1, is1_n, op, os_m, dm, dn)|;|;+#endif|;|+            continue|;|;+        }|;|+#endif|;|+        /* Dot the vector with different matrix columns to get output elements. */|;|+        for (npy_intp j = 0; j < dm; j++, ip2 += is2_m, op += os_m) {|;|+            @TYPE@_@DOT@(ip1, is1_n, ip2, is2_n, op, dn, NULL)|;|;+#if @CHECK_PYERR@|;|+            if (PyErr_Occurred()) {|;|+                return|;|;+            }|;|+#endif|;|+        }|;|+    }|;|+}|;|+/**end repeat**/ || PR#27846 - numpy/_core/src/umath/matmul.h.src: @@ -7,15 +7,10 @@|;|  **/|;| NPY_NO_EXPORT void|;| @TYPE@_matmul(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;-/**end repeat**/|;|-|;|-/**begin repeat|;|- *  #TYPE = FLOAT, DOUBLE, LONGDOUBLE, HALF,|;|- *          CFLOAT, CDOUBLE, CLONGDOUBLE,|;|- *          UBYTE, USHORT, UINT, ULONG, ULONGLONG,|;|- *          BYTE, SHORT, INT, LONG, LONGLONG,|;|- *          BOOL, OBJECT#|;|- */|;| NPY_NO_EXPORT void|;| @TYPE@_vecdot(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;+NPY_NO_EXPORT void|;|+@TYPE@_matvec(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|;+NPY_NO_EXPORT void|;|+@TYPE@_vecmat(char **args, npy_intp const *dimensions, npy_intp const *steps, void *NPY_UNUSED(func))|;|; /**end repeat**/ || PR#27846 - numpy/_core/tests/test_ufunc.py: @@ -824,20 +824,77 @@ def test_vecdot(self):|;|         actual3 = np.vecdot(arr1.astype(""object""), arr2)|;|         assert_array_equal(actual3, expected.astype(""object""))|;| |;|-    def test_vecdot_complex(self):|;|-        arr1 = np.array([1, 2j, 3])|;|-        arr2 = np.array([1, 2, 3])|;|+    def test_matvec(self):|;|+        arr1 = np.arange(6).reshape((2, 3))|;|+        arr2 = np.arange(3).reshape((1, 3))|;|+|;|+        actual = np.matvec(arr1, arr2)|;|+        expected = np.array([[5, 14]])|;| |;|-        actual = np.vecdot(arr1, arr2)|;|-        expected = np.array([10-4j])|;|         assert_array_equal(actual, expected)|;| |;|-        actual2 = np.vecdot(arr2, arr1)|;|-        assert_array_equal(actual2, expected.conj())|;|+        actual2 = np.matvec(arr1.T, arr2.T, axes=[(-1, -2), -2, -1])|;|+        assert_array_equal(actual2, expected)|;| |;|-        actual3 = np.vecdot(arr1.astype(""object""), arr2.astype(""object""))|;|+        actual3 = np.matvec(arr1.astype(""object""), arr2)|;|         assert_array_equal(actual3, expected.astype(""object""))|;| |;|+    @pytest.mark.parametrize(""vec"", [|;|+        np.array([[1., 2., 3.], [4., 5., 6.]]),|;|+        np.array([[1., 2j, 3.], [4., 5., 6j]]),|;|+        np.array([[1., 2., 3.], [4., 5., 6.]], dtype=object),|;|+        np.array([[1., 2j, 3.], [4., 5., 6j]], dtype=object)])|;|+    @pytest.mark.parametrize(""matrix"", [|;|+        None,|;|+        np.array([[1.+1j, 0.5, -0.5j],|;|+                  [0.25, 2j, 0.],|;|+                  [4., 0., -1j]])])|;|+    def test_vecmatvec_identity(self, matrix, vec):|;|+        """"""Check that (x†A)x equals x†(Ax).""""""|;|+        mat = matrix if matrix is not None else np.eye(3)|;|+        matvec = np.matvec(mat, vec)  # Ax|;|+        vecmat = np.vecmat(vec, mat)  # x†A|;|+        if matrix is None:|;|+            assert_array_equal(matvec, vec)|;|+            assert_array_equal(vecmat.conj(), vec)|;|+        assert_array_equal(matvec, (mat @ vec[..., np.newaxis]).squeeze(-1))|;|+        assert_array_equal(vecmat, (vec[..., np.newaxis].mT.conj()|;|+                                    @ mat).squeeze(-2))|;|+        expected = np.einsum('...i,ij,...j', vec.conj(), mat, vec)|;|+        vec_matvec = (vec.conj() * matvec).sum(-1)|;|+        vecmat_vec = (vecmat * vec).sum(-1)|;|+        assert_array_equal(vec_matvec, expected)|;|+        assert_array_equal(vecmat_vec, expected)|;|+|;|+    @pytest.mark.parametrize(""ufunc, shape1, shape2, conj"", [|;|+        (np.vecdot, (3,), (3,), True),|;|+        (np.vecmat, (3,), (3, 1), True),|;|+        (np.matvec, (1, 3), (3,), False),|;|+        (np.matmul, (1, 3), (3, 1), False),|;|+    ])|;|+    def test_vecdot_matvec_vecmat_complex(self, ufunc, shape1, shape2, conj):|;|+        arr1 = np.array([1, 2j, 3])|;|+        arr2 = np.array([1, 2, 3])|;|+|;|+        actual1 = ufunc(arr1.reshape(shape1), arr2.reshape(shape2))|;|+        expected1 = np.array(((arr1.conj() if conj else arr1) * arr2).sum(),|;|+                             ndmin=min(len(shape1), len(shape2)))|;|+        assert_array_equal(actual1, expected1)|;|+        # This would fail for conj=True, since matmul omits the conjugate.|;|+        if not conj:|;|+            assert_array_equal(arr1.reshape(shape1) @ arr2.reshape(shape2),|;|+                               expected1)|;|+|;|+        actual2 = ufunc(arr2.reshape(shape1), arr1.reshape(shape2))|;|+        expected2 = np.array(((arr2.conj() if conj else arr2) * arr1).sum(),|;|+                             ndmin=min(len(shape1), len(shape2)))|;|+        assert_array_equal(actual2, expected2)|;|+|;|+        actual3 = ufunc(arr1.reshape(shape1).astype(""object""),|;|+                        arr2.reshape(shape2).astype(""object""))|;|+        expected3 = expected1.astype(object)|;|+        assert_array_equal(actual3, expected3)|;|+|;|     def test_vecdot_subclass(self):|;|         class MySubclass(np.ndarray):|;|             pass|;|@@ -2757,20 +2814,19 @@ def test_ufunc_noncontiguous(ufunc):|;|             # bool, object, datetime are too irregular for this simple test|;|             continue|;|         inp, out = typ.split('->')|;|-        args_c = [np.empty(6, t) for t in inp]|;|-        # non contiguous (3 step)|;|-        args_n = [np.empty(18, t)[::3] for t in inp]|;|+        args_c = [np.empty((6, 6), t) for t in inp]|;|+        # non contiguous (2, 3 step on the two dimensions)|;|+        args_n = [np.empty((12, 18), t)[::2, ::3] for t in inp]|;|         # alignment != itemsize is possible.  So create an array with such|;|         # an odd step manually.|;|         args_o = []|;|         for t in inp:|;|             orig_dt = np.dtype(t)|;|             off_dt = f""S{orig_dt.alignment}""  # offset by alignment|;|             dtype = np.dtype([(""_"", off_dt), (""t"", orig_dt)], align=False)|;|-            args_o.append(np.empty(6, dtype=dtype)[""t""])|;|-|;|+            args_o.append(np.empty((6, 6), dtype=dtype)[""t""])|;|         for a in args_c + args_n + args_o:|;|-            a.flat = range(1,7)|;|+            a.flat = range(1, 37)|;| |;|         with warnings.catch_warnings(record=True):|;|             warnings.filterwarnings(""always"")|;|@@ -2788,7 +2844,7 @@ def test_ufunc_noncontiguous(ufunc):|;|                 # since different algorithms (libm vs. intrinsics) can be used|;|                 # for different input strides|;|                 res_eps = np.finfo(dt).eps|;|-                tol = 2*res_eps|;|+                tol = 3*res_eps|;|                 assert_allclose(res_c, res_n, atol=tol, rtol=tol)|;|                 assert_allclose(res_c, res_o, atol=tol, rtol=tol)|;|             else: || PR#27846 - numpy/_core/umath.py: @@ -33,8 +33,8 @@|;|     'heaviside', 'hypot', 'invert', 'isfinite', 'isinf', 'isnan', 'isnat',|;|     'lcm', 'ldexp', 'left_shift', 'less', 'less_equal', 'log', 'log10',|;|     'log1p', 'log2', 'logaddexp', 'logaddexp2', 'logical_and', 'logical_not',|;|-    'logical_or', 'logical_xor', 'maximum', 'minimum', 'mod', 'modf',|;|+    'logical_or', 'logical_xor', 'matvec', 'maximum', 'minimum', 'mod', 'modf',|;|     'multiply', 'negative', 'nextafter', 'not_equal', 'pi', 'positive',|;|     'power', 'rad2deg', 'radians', 'reciprocal', 'remainder', 'right_shift',|;|     'rint', 'sign', 'signbit', 'sin', 'sinh', 'spacing', 'sqrt', 'square',|;|-    'subtract', 'tan', 'tanh', 'true_divide', 'trunc']|;|+    'subtract', 'tan', 'tanh', 'true_divide', 'trunc', 'vecdot', 'vecmat']","ENH: define matvec and vecmat gufuncs

Internally, they mostly just call the relevant blas, or vecdot
routines. || ENH: define matvec and vecmat gufuncs

Internally, they mostly just call the relevant blas, or vecdot
routines."
numpy/numpy,mattip,27825,CI: circleCI build of NumPy is failing,"The cirecleCI build, using their [python3.11.8 image](https://github.com/numpy/numpy/blob/5f70dc85d16454c81b19c02a012ce08cca9fc28e/.circleci/config.yml#L12), is failing to compile NumPy. Here are the relevant bits from the [build log](https://app.circleci.com/pipelines/github/numpy/numpy/29772/workflows/fb91454e-ee15-4217-96c5-ce2d5fc5a09d/jobs/43788). The gcc 11.3.0 compiler is crashing when compiling `loops_unary_fp_le.dispatch.c.src: In function ‘FLOAT_isfinite_SSE41’`:
```
The Meson build system
Version: 1.5.2
Source dir: /home/circleci/repo
Build dir: /home/circleci/repo/build
Build type: native build
Project name: NumPy
Project version: 2.3.0.dev0+git20241124.8c021fc
C compiler for the host machine: cc (gcc 11.3.0 ""cc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0"")
C linker for the host machine: cc ld.bfd 2.38
C++ compiler for the host machine: c++ (gcc 11.3.0 ""c++ (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0"")
C++ linker for the host machine: c++ ld.bfd 2.38
Cython compiler for the host machine: cython (cython 3.0.11)
Host machine cpu family: x86_64
Host machine cpu: x86_64
...
Configuring npy_cpu_dispatch_config.h using configuration
Message: 
CPU Optimization Options
  baseline:
    Requested : min
    Enabled   : SSE SSE2 SSE3
  dispatch:
    Requested : max -xop -fma4
    Enabled   : SSSE3 SSE41 POPCNT SSE42 AVX F16C FMA3 AVX2 AVX512F AVX512CD AVX512_KNL AVX512_KNM AVX512_SKX AVX512_CLX AVX512_CNL AVX512_ICL
...
NOTICE: Future-deprecated features used:
 * 1.3.0: {'Source file src/umath/svml/linux/avx512/svml_z0_acos_d_la.s in the 'objects' kwarg is not an object.'}

NumPy 2.3.0.dev0+git20241124.8c021fc

  User defined options
    prefix: /usr

Found ninja-1.11.1.git.kitware.jobserver-1 at /home/circleci/repo/venv/bin/ninja
...
[256/527] Generating 'numpy/_core/_multiarray_umath.cpython-311-x86_64-linux-gnu.so.p/einsum_sumprod.c'
[257/527] Compiling C object numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/meson-generated_loops_unary_complex.dispatch.c.o
FAILED: numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/meson-generated_loops_unary_complex.dispatch.c.o 
cc -Inumpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p -Inumpy/_core -I../numpy/_core -Inumpy/_core/include -I../numpy/_core/include -I../numpy/_core/src/common -I../numpy/_core/src/multiarray -I../numpy/_core/src/npymath -I../numpy/_core/src/umath -I../numpy/_core/src/highway -I/home/circleci/.pyenv/versions/3.11.8/include/python3.11 -I/home/circleci/repo/build/meson_cpu -fdiagnostics-color=always -Wall -Winvalid-pch -std=c11 -O2 -g -fno-strict-aliasing -msse -msse2 -msse3 -fPIC -DNPY_INTERNAL_BUILD -DHAVE_NPY_CONFIG_H -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -O3 -DNPY_HAVE_SSE2 -DNPY_HAVE_SSE -DNPY_HAVE_SSE3 -DNPY_HAVE_SSSE3 -DNPY_HAVE_SSE41 -DNPY_HAVE_POPCNT -DNPY_HAVE_SSE42 -DNPY_HAVE_AVX -DNPY_HAVE_F16C -DNPY_HAVE_FMA3 -DNPY_HAVE_AVX2 -msse -msse2 -msse3 -mssse3 -msse4.1 -mpopcnt -msse4.2 -mavx -mf16c -mfma -mavx2 -maes -mpclmul -mbmi -mbmi2 -DNPY_MTARGETS_CURRENT=AVX2 -MD -MQ numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/meson-generated_loops_unary_complex.dispatch.c.o -MF numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/meson-generated_loops_unary_complex.dispatch.c.o.d -o numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/meson-generated_loops_unary_complex.dispatch.c.o -c numpy/_core/libloops_unary_complex.dispatch.h_AVX2.a.p/loops_unary_complex.dispatch.c
during RTL pass: cse2
../numpy/_core/src/umath/loops_unary_complex.dispatch.c.src: In function ‘CFLOAT_absolute_AVX2’:
../numpy/_core/src/umath/loops_unary_complex.dispatch.c.src:138:1: internal compiler error: Segmentation fault
  138 | }
      | ^
0xd7403d internal_error(char const*, ...)
        ???:0
Please submit a full bug report,
with preprocessed source if appropriate.
Please include the complete backtrace with any bug report.
See <file:///usr/share/doc/gcc-11/README.Bugs> for instructions.
[258/527] Compiling C object numpy/_core/libloops_arithm_fp.dispatch.h_baseline.a.p/meson-generated_loops_arithm_fp.dispatch.c.o
[259/527] Compiling C object numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/meson-generated_loops_unary_fp_le.dispatch.c.o
FAILED: numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/meson-generated_loops_unary_fp_le.dispatch.c.o 
cc -Inumpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p -Inumpy/_core -I../numpy/_core -Inumpy/_core/include -I../numpy/_core/include -I../numpy/_core/src/common -I../numpy/_core/src/multiarray -I../numpy/_core/src/npymath -I../numpy/_core/src/umath -I../numpy/_core/src/highway -I/home/circleci/.pyenv/versions/3.11.8/include/python3.11 -I/home/circleci/repo/build/meson_cpu -fdiagnostics-color=always -Wall -Winvalid-pch -std=c11 -O2 -g -fno-strict-aliasing -msse -msse2 -msse3 -fPIC -DNPY_INTERNAL_BUILD -DHAVE_NPY_CONFIG_H -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -O3 -DNPY_HAVE_SSE2 -DNPY_HAVE_SSE -DNPY_HAVE_SSE3 -DNPY_HAVE_SSSE3 -DNPY_HAVE_SSE41 -msse -msse2 -msse3 -mssse3 -msse4.1 -DNPY_MTARGETS_CURRENT=SSE41 -MD -MQ numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/meson-generated_loops_unary_fp_le.dispatch.c.o -MF numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/meson-generated_loops_unary_fp_le.dispatch.c.o.d -o numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/meson-generated_loops_unary_fp_le.dispatch.c.o -c numpy/_core/libloops_unary_fp_le.dispatch.h_SSE41.a.p/loops_unary_fp_le.dispatch.c
during RTL pass: sched2
../numpy/_core/src/umath/loops_unary_fp_le.dispatch.c.src: In function ‘FLOAT_isfinite_SSE41’:
../numpy/_core/src/umath/loops_unary_fp_le.dispatch.c.src:560:1: internal compiler error: Segmentation fault
  560 | }
      | ^
```

Is this a known problem with that compiler?","The newer image in #27826 updates to gcc 11.4.0, but still crashes @seiko2plus is this a known issue with gcc 11? || >  is this a known issue with gcc 11?

No, but I checked the build log. The errors seems random ambiguous to me, so it is probably related to resource limitations, such as nproc or memory. Have you tried building with parallel compiling disabled, e.g., using `-j1`? || Thanks, `-j2` seems to have solved it. Now there are doc build problems with distutils... || @mattip Hello, could you please send me the files you compiled numpy in a package? Including the .c file obtained after cython with the .c.src suffix. Thank you very much.",closed,2024-11-24T07:16:03+00:00,2024-11-24T18:03:46+00:00,mattip,component: CI,1,"PR#27826 - .circleci/config.yml: @@ -9,7 +9,7 @@ _defaults: &defaults|;|   docker:|;|     # CircleCI maintains a library of pre-built images|;|     # documented at https://circleci.com/developer/images/image/cimg/python|;|-    - image: cimg/python:3.11.8|;|+    - image: cimg/python:3.11.10|;|   working_directory: ~/repo|;| |;| |;|@@ -60,7 +60,7 @@ jobs:|;|             # get newer, pre-release versions of critical packages|;|             pip install --progress-bar=off --pre -r requirements/doc_requirements.txt|;|             # then install numpy HEAD, which will override the version installed above|;|-            spin build --with-scipy-openblas=64|;|+            spin build --with-scipy-openblas=64 -j 2|;| |;|       - run:|;|           name: build devdocs w/ref warnings|;|@@ -97,8 +97,8 @@ jobs:|;|             #  - validates ReST blocks (via validate_rst_syntax)|;|             #  - checks that all of a module's `__all__` is reflected in the|;|             #    module-level docstring autosummary|;|-            echo calling python tools/refguide_check.py -v|;|-            python tools/refguide_check.py -v|;|+            echo calling python3 tools/refguide_check.py -v|;|+            python3 tools/refguide_check.py -v|;| |;|       - persist_to_workspace:|;|           root: ~/repo","CI: update circleci to python3.12.7, ubuntu 20.04.3 [skip actions][skip azp] || limit to 2 parallel build jobs || using python3.12 fails to build numpy.distutils, use 3.11 instead || typo"
numpy/numpy,mhvk,27500,BUG: np.ndarray.__array_function__ cannot be handle NEP 35 creation functions,"### Describe the issue:

NEP 35 introduced the ability to pass in an instance via `like=` for array creation functions such as `zeros` and `arange`, which are passed through `__array_function__`. But `ndarray` subclasses cannot use `super().__array_function__`: one gets
```
a = np.array([])
a.__array_function__(np.asarray, (np.ndarray,), [1., 2., 3.], {})

AttributeError: 'builtin_function_or_method' object has no attribute '_implementation'
```

### Reproduce the code example:

```python
import numpy as np
a = np.arange(3)
# Passing through reshape works fine
a.__array_function__(np.reshape, (np.ndarray,), (a, (3,1)), {})
# array([[0],
#        [1],
#        [2]])
# But not asarray
a.__array_function__(np.asarray, (np.ndarray,), [1., 2., 3.], {})
# AttributeError: 'builtin_function_or_method' object has no attribute '_implementation'
```


### Error message:

_No response_

### Python and NumPy Versions:

2.1.1
3.11.2 (main, Aug 26 2024, 07:20:54) [GCC 12.2.0]


### Runtime Environment:

_No response_

### Context for the issue:

Found while trying to add support for NEP 35 functions for astropy's Quantity.

Related: #27451, about these creation functions not being present in the output of `np.testing.overrides.get_overridable_numpy_array_functions`","Hmmm, yeah.  Not that I am sure `super()` is very useful...  Should we have an `_implementation` that just ignores the `like=`!?  Or uses it for `.view()` on the result?
(Just thinking that might be easier for symmetry then some dropping of `like=` itself.) || It is definitely not super useful, but I liked how for a subclass one does not have to know about `_implementation` generally, but can just call `super()`. Currently, the implementation of `ndarray.__array_function__` explicitly looks for `_implementation`: https://github.com/numpy/numpy/blob/5c8f540f3ed82138d7075fceb5e9738e918abf9d/numpy/_core/src/multiarray/arrayfunction_override.c#L159-L161

Ideally, it would just call functions that do not have this directly. Note that `__array_function__` is not passed the `like` argument, though it does have its `type`, so I guess in principle one could do a view. I don't know that that is really necessary, just not failing would be good enough!

Note that I'm happy to make the change, just not quite sure what it should be: just call the function directly if there is no `_implementation`? That should be OK in principle... || p.s. Looking more at the code, I see that if a subclass does not define `__array_function__` one is just passed on to the regular implementation, so it seems reasonable to do the same for a `super()` call. || @seberg - see #27504 for a possible fix (built on #27503, since I found I could cause segfaults with bad calls to `ndarray.__array_function__`...) || Thanks, I have to think about it abit and look at all of the open PRs on this in the next day or two!",closed,2024-10-04T14:31:07+00:00,2024-11-21T16:01:56+00:00,mhvk,"00 - Bug, component: numpy._core",1,"PR#27504 - numpy/_core/src/multiarray/arrayfunction_override.c: @@ -155,11 +155,22 @@ array_function_method_impl(PyObject *func, PyObject *types, PyObject *args,|;|             return Py_NotImplemented|;|;         }|;|     }|;|-|;|-    PyObject *implementation = PyObject_GetAttr(func, npy_interned_str.implementation)|;|;-    if (implementation == NULL) {|;|+    /*|;|+     * Python functions are wrapped, and we should now call their|;|+     * implementation, so that we do not dispatch a second time|;|+     * on possible subclasses.|;|+     * C functions that can be overridden with ""like"" are not wrapped and|;|+     * thus do not have an _implementation attribute, but since the like|;|+     * keyword has been removed, we can safely call those directly.|;|+     */|;|+    PyObject *implementation|;|;+    if (PyObject_GetOptionalAttr(|;|+            func, npy_interned_str.implementation, &implementation) < 0) {|;|         return NULL|;|;     }|;|+    else if (implementation == NULL) {|;|+        return PyObject_Call(func, args, kwargs)|;|;+    }|;|     PyObject *result = PyObject_Call(implementation, args, kwargs)|;|;     Py_DECREF(implementation)|;|;     return result; || PR#27504 - numpy/_core/tests/test_overrides.py: @@ -194,14 +194,22 @@ class OverrideSub(np.ndarray):|;|         assert_equal(result, expected.view(OverrideSub))|;| |;|     def test_no_wrapper(self):|;|-        # This shouldn't happen unless a user intentionally calls|;|-        # __array_function__ with invalid arguments, but check that we raise|;|-        # an appropriate error all the same.|;|+        # Regular numpy functions have wrappers, but do not presume|;|+        # all functions do (array creation ones do not): check that|;|+        # we just call the function in that case.|;|         array = np.array(1)|;|-        func = lambda x: x|;|-        with assert_raises_regex(AttributeError, '_implementation'):|;|-            array.__array_function__(func=func, types=(np.ndarray,),|;|-                                     args=(array,), kwargs={})|;|+        func = lambda x: x * 2|;|+        result = array.__array_function__(func=func, types=(np.ndarray,),|;|+                                          args=(array,), kwargs={})|;|+        assert_equal(result, array * 2)|;|+|;|+    def test_wrong_arguments(self):|;|+        # Check our implementation guards against wrong arguments.|;|+        a = np.array([1, 2])|;|+        with pytest.raises(TypeError, match=""args must be a tuple""):|;|+            a.__array_function__(np.reshape, (np.ndarray,), a, (2, 1))|;|+        with pytest.raises(TypeError, match=""kwargs must be a dict""):|;|+            a.__array_function__(np.reshape, (np.ndarray,), (a,), (2, 1))|;| |;|     def test_wrong_arguments(self):|;|         # Check our implementation guards against wrong arguments.|;|@@ -568,6 +576,13 @@ def __init__(self, function=None):|;| |;|         self.MyNoArrayFunctionArray = MyNoArrayFunctionArray|;| |;|+        class MySubclass(np.ndarray):|;|+            def __array_function__(self, func, types, args, kwargs):|;|+                result = super().__array_function__(func, types, args, kwargs)|;|+                return result.view(self.__class__)|;|+|;|+        self.MySubclass = MySubclass|;|+|;|     def add_method(self, name, arr_class, enable_value_error=False):|;|         def _definition(*args, **kwargs):|;|             # Check that `like=` isn't propagated downstream|;|@@ -661,6 +676,19 @@ def test_no_array_function_like(self, function, args, kwargs, ref):|;|                 'The `like` argument must be an array-like that implements'):|;|             np_func(*like_args, **kwargs, like=ref)|;| |;|+    @pytest.mark.parametrize('function, args, kwargs', _array_tests)|;|+    def test_subclass(self, function, args, kwargs):|;|+        ref = np.array(1).view(self.MySubclass)|;|+        np_func = getattr(np, function)|;|+        like_args = tuple(a() if callable(a) else a for a in args)|;|+        array_like = np_func(*like_args, **kwargs, like=ref)|;|+        assert type(array_like) is self.MySubclass|;|+        if np_func is np.empty:|;|+            return|;|+        np_args = tuple(a() if callable(a) else a for a in args)|;|+        np_arr = np_func(*np_args, **kwargs)|;|+        assert_equal(array_like.view(np.ndarray), np_arr)|;|+|;|     @pytest.mark.parametrize('numpy_ref', [True, False])|;|     def test_array_like_fromfile(self, numpy_ref):|;|         self.add_method('array', self.MyArray)",ENH: support like= functions in ndarray.__array_function__
numpy/numpy,laarohi,27722,BUG: numpy._core.memmap Error when offset is a multiple of allocation granularity,"### Describe the issue:

`numpy.memmap` fails when attempting to create an empty `memmap` that has an `offset` which is a multiple of `mmap.ALLOCATIONGRANULARITY`. 

The issue occurs due to the fact that under these conditions, `numpy.memmap` calls `mmap.mmap` which `length=0` which numpy assumes means a length of zero however as described in the [mmap python docs](https://docs.python.org/3/library/mmap.html#mmap.mmap): 
> If length is 0, the maximum length of the map will be the current size of the file when [mmap](https://docs.python.org/3/library/mmap.html#mmap.mmap) is called.

### Reproduce the code example:

```python
import numpy as np

def empty_memmap(offset):
    fname = ""test.dat""
    a = np.array([])  # empty array 
    with open(fname, 'wb+') as f:
        f.write(b'c'*offset)
        mm = np.memmap(f, shape=a.shape, dtype=a.dtype, offset=offset, mode='r+')
        print(mm)

# This works
empty_memmap(4321)

# This fails
empty_memmap(4096)

# This also fails
empty_memmap(2*4096)
```


### Error message:

```shell
Traceback (most recent call last):
  File ""/home/luke/m.py"", line 15, in <module>
    empty_memmap(4096)
  File ""/home/luke/m.py"", line 8, in empty_memmap
    mm = np.memmap(f, shape=a.shape, dtype=a.dtype, offset=offset, mode='r+')
  File ""/home/luke/user310/lib/python3.10/site-packages/numpy/_core/memmap.py"", line 280, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
ValueError: mmap offset is greater than file size
```


### Python and NumPy Versions:

2.1.3
3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]


### Runtime Environment:

[{'numpy_version': '2.1.3',
  'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]',
  'uname': uname_result(system='Linux', node='titan', release='5.15.0-122-generic', version='#132-Ubuntu SMP Thu Aug 29 13:45:52 UTC 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2'],
                      'not_found': ['AVX512F',
                                    'AVX512CD',
                                    'AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_SKX',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}}]


### Context for the issue:

While this is an extreme edge case it is also important to resolve. In my case I had a program which had been running reliably in a production setting for number of years and which crashed due to this issue when the offset of my memmap coincidentally happened to be a multiple of the allocation ganularity. 

The fix to this issue is fairly straightforward and I will be submitting a pull request shortly.",,closed,2024-11-08T16:44:32+00:00,2024-11-18T16:57:23+00:00,laarohi,00 - Bug,1,"PR#27723 - doc/release/upcoming_changes/27723.improvement.rst: @@ -0,0 +1,4 @@|;|+* Improved support for empty `memmap`. Previously an empty `memmap` would fail|;|+  unless a non-zero ``offset`` was set. Now a zero-size `memmap` is supported|;|+  even if ``offset=0``. To achieve this, if a `memmap` is mapped to an empty|;|+  file that file is padded with a single byte. || PR#27723 - numpy/_core/memmap.py: @@ -262,10 +262,14 @@ def __new__(subtype, filename, dtype=uint8, mode='r+', offset=0,|;| |;|             bytes = int(offset + size*_dbytes)|;| |;|-            if mode in ('w+', 'r+') and flen < bytes:|;|-                fid.seek(bytes - 1, 0)|;|-                fid.write(b'\0')|;|-                fid.flush()|;|+            if mode in ('w+', 'r+'):|;|+                # gh-27723|;|+                # if bytes == 0, we write out 1 byte to allow empty memmap.|;|+                bytes = max(bytes, 1)|;|+                if flen < bytes:|;|+                    fid.seek(bytes - 1, 0)|;|+                    fid.write(b'\0')|;|+                    fid.flush()|;| |;|             if mode == 'c':|;|                 acc = mmap.ACCESS_COPY|;|@@ -276,6 +280,11 @@ def __new__(subtype, filename, dtype=uint8, mode='r+', offset=0,|;| |;|             start = offset - offset % mmap.ALLOCATIONGRANULARITY|;|             bytes -= start|;|+            # bytes == 0 is problematic as in mmap length=0 maps the full file.|;|+            # See PR gh-27723 for a more detailed explanation.|;|+            if bytes == 0 and start > 0:|;|+                bytes += mmap.ALLOCATIONGRANULARITY|;|+                start -= mmap.ALLOCATIONGRANULARITY|;|             array_offset = offset - start|;|             mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)|;|  || PR#27723 - numpy/_core/tests/test_memmap.py: @@ -199,6 +199,13 @@ def test_mmap_offset_greater_than_allocation_granularity(self):|;|         fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)|;|         assert_(fp.offset == offset)|;| |;|+    def test_empty_array_with_offset_multiple_of_allocation_granularity(self):|;|+        self.tmpfp.write(b'a'*mmap.ALLOCATIONGRANULARITY)|;|+        size = 0|;|+        offset = mmap.ALLOCATIONGRANULARITY|;|+        fp = memmap(self.tmpfp, shape=size, mode='w+', offset=offset)|;|+        assert_equal(fp.offset, offset)|;|+|;|     def test_no_shape(self):|;|         self.tmpfp.write(b'a'*16)|;|         mm = memmap(self.tmpfp, dtype='float64')|;|@@ -207,12 +214,14 @@ def test_no_shape(self):|;|     def test_empty_array(self):|;|         # gh-12653|;|         with pytest.raises(ValueError, match='empty file'):|;|-            memmap(self.tmpfp, shape=(0,4), mode='w+')|;|+            memmap(self.tmpfp, shape=(0, 4), mode='r')|;| |;|-        self.tmpfp.write(b'\0')|;|+        # gh-27723|;|+        # empty memmap works with mode in ('w+','r+')|;|+        memmap(self.tmpfp, shape=(0, 4), mode='w+')|;| |;|         # ok now the file is not empty|;|-        memmap(self.tmpfp, shape=(0,4), mode='w+')|;|+        memmap(self.tmpfp, shape=(0, 4), mode='w+')|;| |;|     def test_shape_type(self):|;|         memmap(self.tmpfp, shape=3, mode='w+')","BUG: error empty memmap offset is a multiple of allocation granularity || DOC: added a code comment explaining issue with `bytes==0` in memmap || TST: test for arr.offset being correct || ENH: allow empty memmap || TST: adjust test for empty memmap || STY: numpy/_core/tests/test_memmap.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || STY: Update numpy/_core/tests/test_memmap.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || STY: Update numpy/_core/tests/test_memmap.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || TST: Update numpy/_core/tests/test_memmap.py

Co-authored-by: Sebastian Berg <sebastian@sipsolutions.net> || DOC: added enhancement release note for gh-27723"
numpy/numpy,HaoZeke,27622,BUG: Modules from Fortran interface not accessible in Numpy 2.x (current 2.1.2),"### Describe the issue:

Using Numpy 2.x (tried 2.02, 2.1.2) I can no longer access module data.  

After `f2py` I get the `pyf` file
```fortran
!    -*- f90 -*-
! Note: the context of this file is case sensitive.

python module _solver ! in 
    interface  ! in :_solver
        module types ! in :_solver:solver.f90
            integer, parameter,optional :: int32=selected_int_kind(8)
            integer, parameter,optional :: int64=selected_int_kind(16)
            integer, parameter,optional :: real64=selected_real_kind(15)
        end module types
        module lanedata ! in :_solver:solver.f90
            use types, only: real64,int32
            integer(kind=4), parameter,optional :: maxdata=1048575
            real(kind=8), allocatable,dimension(:,:) :: theta
            integer(kind=4) :: ndata
        end module lanedata
        subroutine freelanedata ! in :_solver:solver.f90
            use lanedata, only: ndata,theta
        end subroutine freelanedata
        subroutine lane(dx,n,w) ! in :_solver:solver.f90
            use types, only: int32,real64
            use lanedata, only: maxdata,theta,ndata
            real(kind=8) intent(in) :: dx
            real(kind=8) intent(in) :: n
            real(kind=8) intent(in) :: w
        end subroutine lane
        subroutine rk4(x0,y0,y1,dx,n,w,z0,z1) ! in :_solver:solver.f90
            use types, only: real64
            real(kind=8) intent(in) :: x0
            real(kind=8) intent(in) :: y0
            real(kind=8) intent(in) :: y1
            real(kind=8) intent(in) :: dx
            real(kind=8) intent(in) :: n
            real(kind=8) intent(in) :: w
            real(kind=8) intent(out) :: z0
            real(kind=8) intent(out) :: z1
        end subroutine rk4
    end interface 
end python module _solver

! This file was auto-generated with f2py (version:2.1.2).
! See:
! https://web.archive.org/web/20140822061353/http://cens.ioc.ee/projects/f2py2e
```
but when I try to access the data, as suggested in the online doc (just checking that this is still as it used to be, https://numpy.org/doc/2.1/f2py/python-usage.html#fortran-90-module-data), I get
```
 In [2]: print(laneemden._solver.__doc__)
This module '_solver' is auto-generated with f2py (version:2.1.2).
Functions:
    freelanedata()
    lane(dx,n,w)
    z0,z1 = rk4(x0,y0,y1,dx,n,w)
.
```
or 
```
In [3]: dir(laneemden._solver)
Out[3]: 
['__doc__',
 '__f2py_numpy_version__',
 '__file__',
 '__loader__',
 '__name__',
 '__package__',
 '__solver_error',
 '__spec__',
 '__version__',
 'freelanedata',
 'lane',
 'rk4']
```
so, not trace of `module lanedata`.  This used to work (and still does) in Numpy 1.x.

### Reproduce the code example:

```python
from laneemden._solver import lanedata
```

Here my code, `solver.f90`

```
! 20111212 Alexander Heger

! 1/z**2 d/dz (z**2 d/dz theta(z)) + theta(z)**n = 0
! for small z one can approximate
! theta(z) = 1. + (-1/6.)*z**2 + (n/120.)*z**4 + O(z**6)
! Therefore lim(z)-->0 d**2 theta(z)/d z**2 = -1/3

! 20120423 Alexander Heger

! if we include a constant rotation rate Omega the equation becomes
! 1/z**2 d/dz (z**2 d/dz theta(z)) + theta(z)**n - w = 0
! where
! w = W/rho_c
! W = 2 Omega**2 / 4 pi G
! for small z one can approximate
! theta(z) = 1. + (w - 1)/6. *z**2 + (1.-w)*(n/120.)*z**4 + O(z**6)
! Therefore lim(z)-->0 d**2 theta(z)/d z**2 = (w-1.)/3

module types

  implicit none

  INTEGER, PARAMETER :: int32 = SELECTED_INT_KIND(8)
  INTEGER, PARAMETER :: int64 = SELECTED_INT_KIND(16)
  INTEGER, PARAMETER :: real64 = SELECTED_REAL_KIND(15)

end module types


module lanedata

  use types, only: &
       real64, int32

  implicit none

  save

  integer(kind=int32), parameter :: &
       maxdata = 2**20-1

  real(kind=real64), dimension(:,:), allocatable :: &
       theta

  integer(kind=int32) :: &
       ndata

end module lanedata


subroutine freelanedata()

  use lanedata, only: &
       ndata, theta

  implicit none

  if (allocated(theta)) deallocate(theta)
  ndata = -1

end subroutine freelanedata


subroutine lane(dx, n, w)

  ! lane emden integration, return data,
  ! including first invalid (rho < 0) point for interpolation.

  use types, only: &
       int32, real64

  use lanedata, only: &
       maxdata, theta, ndata

  implicit none

!f2py real(kind=real64), intent(in) :: dx, n, w

  real(kind=real64), intent(in) :: &
       dx, n, w

  real(kind=real64) :: &
       x
  integer(kind=int32) :: &
       i, j

  real(kind=real64), dimension(0:1) :: &
       y, z

  real(kind=real64), dimension(:,:), allocatable :: &
       theta_

  if (allocated(theta)) deallocate(theta)
  j = maxdata
  allocate(theta_(0:j, 0:1))

  x = 0.d0
  y(0:1) = (/1.d0, 0.d0/)

  i = 0
  theta_(i,:) = y(:)
  do while (.True.)
     call rk4(x,y(0),y(1),dx,n,w,z(0),z(1))
     if (i == j) then
        j = j + maxdata
        allocate(theta(0:j,0:1))
        theta(0:i,:) = theta_(0:i,:)
        deallocate(theta_)
        call move_alloc(theta, theta_)
     endif

     i = i+1
     theta_(i, :) = z(:)
     x = x + dx
     y(:) = z(:)

     if (y(0) < 0.d0) exit
  enddo
  ndata = i

  allocate(theta(0:ndata, 0:1))
  theta(0:ndata,0:1) = theta_(0:ndata,0:1)
  deallocate(theta_)

end subroutine lane


subroutine rk4(x0, y0, y1, dx, n, w, z0, z1)

  use types, only: &
       real64

  implicit none

  real(kind=real64), parameter :: &
       p13 = 1.d0 / 3.d0, &
       p16 = 1.d0 / 6.d0

  real(kind=real64), intent(in)  :: &
       x0, y0, y1
  real(kind=real64), intent(in)  :: &
       dx, n, w
  real(kind=real64), intent(out) :: &
       z0, z1

  real(kind=real64) :: &
       xh, dh
  real(kind=real64) :: &
       k10, k11, k20, k21, k30, k31, k40, k41

!f2py real(8), intent(in) :: x0, dx, n, w
!f2py real(8), intent(in) :: y0, y1
!f2py real(8), intent(out) :: z0, z1

  xh = x0 + 0.5d0 * dx
  dh = 0.5d0 * dx

  k10 = y1
  if (x0 == 0) then
     k11 = (w - 1.d0) * p13
  else
     k11 = -2.d0 / x0 * y1 - (max(y0, 0.d0))**n + w
  endif

  k20 = y1 + dh*k11
  k21 = -2.d0 / xh * k20 - (max(y0 + dh*k10, 0.d0))**n

  k30 = y1 + dh*k21
  k31 = -2.d0 / xh * k30 - (max(y0 + dh*k20, 0.d0))**n

  k40 = y1 + dx*k31
  k41 = -2.d0 / (x0+dx) * k40 - (max(y0 + dx*k30,0.d0))**n

  z0 = y0 + dx*(k10 + 2.d0 * (k20 + k30) + k40) * p16
  z1 = y1 + dx*(k11 + 2.d0 * (k21 + k31) + k41) * p16

end subroutine rk4
```
I use a custom build package that does not work with meson (and sadly, the usually very helpful Numpy developers out of principle refused to include fixes to obvious bugs in the build script to this day and a small patch to make my script continue to work, for both of which I had posted patches) and that are lengthy, so I won't include.

The issue seems to be that there is on interface in module lanedata.  If I include an interface into the definition of `module lanedata` so it becomes, e.g., 
```fortran
module lanedata

  use types, only: &
       real64, int32

  implicit none

  save

  integer(kind=int32), parameter :: &
       maxdata = 2**20-1

  real(kind=real64), dimension(:,:), allocatable :: &
       theta

  integer(kind=int32) :: &
       ndata

contains

  subroutine phoney
  end subroutine phoney
  
end module lanedata
```
then the module is included and an interface generated.  This behaviour to skip modules w/o interface contents (just adding the `contains` line but an empty section does not suffice).  

Maybe the Python 1.x behaviour can be restored, as it is common to have plain data modules w/o definition of functions or subroutines.

It is also possible that I missed a flag / behaviour change, my apologies in this case and please advise.


### Error message:

```shell
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
Cell In[4], line 1
----> 1 from laneemden._solver import lanedata

ImportError: cannot import name 'lanedata' from 'laneemden._solver' (/home/alex/python/source/laneemden/_solver.cpython-311-x86_64-linux-gnu.so)
```


### Python and NumPy Versions:

2.1.2
3.11.10 (main, Sep  8 2024, 14:25:06) [GCC 14.2.1 20240801 (Red Hat 14.2.1-1)]


### Runtime Environment:

[{'numpy_version': '2.1.2',
  'python': '3.11.10 (main, Sep  8 2024, 14:25:06) [GCC 14.2.1 20240801 (Red '
            'Hat 14.2.1-1)]',
  'uname': uname_result(system='Linux', node='w.2sn.net', release='6.11.3-200.fc40.x86_64', version='#1 SMP PREEMPT_DYNAMIC Thu Oct 10 22:31:19 UTC 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX'],
                      'not_found': ['AVX512_KNL',
                                    'AVX512_KNM',
                                    'AVX512_CLX',
                                    'AVX512_CNL',
                                    'AVX512_ICL']}},
 {'architecture': 'SkylakeX',
  'filepath': '/home/alex/Python_3.11.10/lib/python3.11/site-packages/numpy.libs/libscipy_openblas64_-ff651d7f.so',
  'internal_api': 'openblas',
  'num_threads': 16,
  'prefix': 'libscipy_openblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.27'}]


### Context for the issue:

breaks code, can no longer access module data that worked in Numpy < 2.0.  ","ping @HaoZeke  || Ran into a similar issue recently, a workaround is to add
```fortran
contains
subroutine has_module_lanedata()
end subroutine has_module_lanedata
```
before the `end module lanedata` (and similarly before `end module types`).  NumPy assumes that data-only modules `use`d by other Fortran code are for Fortran reference purposes only, and are not to be exported to Python. || @DWesl Thank you.  Yes, that this is a workaround for the current behaviour, as I wrote.   

However, 
- this is not what f2py did in the past, so breaks backward compatibility w/o need. 
- this assumption would be very unreasonable as I have a lot more moldes with subroutines that are used internally only then the other way round.

If it was desired to exclude modules, a f2py directive to hide modules are parts thereof should be introduced.

Things I do not want in the interface I compile in external libraries.  There used to be f2py commands to include/exclude specific subroutines/symbols on interface creation.  Things I put in the interface and for which I use f2py to make the pyf file are there because I explicitly want them in the interface on the first place. || FWIW I don't think this was an intended change. f2py is complicated, has poor test coverage, and few people understand the internals. We would have left it alone, but the removal of distutils by Python forced us to make some changes and you're seeing the fallout.

It's not a perfect situation at all. If you want to help to fix this issue that would be very appreciated. || Thanks everyone for the discussion here, I've been thinking of how best to resolve this and will have a PR up this weekend most likely. As far as I can remember this (poorly documented) breaking change had to do with the way F2PY was extended to handle derived types.

The solution is better docs + an explicit hiding directive to handle declaration only derived type modules. || @HaoZeke is one of the people who have a lot of knowledge of f2py internals, so I'll defer to them :) || @HaoZeke You have been always very helpful fixing things swiftly.  Thank you so much for that!

My recent small patch suggestions to allow the setup for my f2py build framework to continue work with Python 3.12 after the discontinuation of distutils (at least one of them seems a real bug, the other was adding a simple option for backward compatibility that would not have broken anything else or had side effects other than having to ""maintain"" three extra lines of code), however, were rejected, so I found it futile to suggest further patches myself.  

What do people do in this case, maybe need to make a branch and rebase every time there is a numpy update?  (For `matplotlib` I also just have a `mplfixes` module where obviously useful natural extensions were not accepted.) || > @HaoZeke You have been always very helpful fixing things swiftly. Thank you so much for that!
> 

Thanks, sorry this one took a while to get to.

> My recent small patch suggestions to allow the setup for my f2py build framework to continue work with Python 3.12 after the discontinuation of distutils (at least one of them seems a real bug, the other was adding a simple option for backward compatibility that would not have broken anything else or had side effects other than having to ""maintain"" three extra lines of code), however, were rejected, so I found it futile to suggest further patches myself.
>

Sorry could you refresh my memory on this? Generally I'd love to try to get either existing working patchsets in or equivalent changes (i.e. those which pass the original test failure)
 
> What do people do in this case, maybe need to make a branch and rebase every time there is a numpy update? (For `matplotlib` I also just have a `mplfixes` module where obviously useful natural extensions were not accepted.)

There's (IMO terrible) precedent set in the form of `f90wrap` which has a hard dependency on `f2py` but is technically a different project; and eventually diverges and winds down..

For build systems, it is probable that a separate extension module will be used (since NumPy will not vendor any `distutils` code anymore), but making a branch and rebasing is not ergonomic (and confusing to everyone using it too). || @HaoZeke OK, I may try to cast these into real pull requests.

It is related to the thread https://github.com/numpy/numpy/issues/24874 with items
https://github.com/numpy/numpy/issues/24874#issuecomment-1751584993
and after
https://github.com/numpy/numpy/issues/24874#issuecomment-1833045199
as well as
https://github.com/numpy/numpy/issues/24874#issuecomment-1751666778
It does not seem obvious to me why not just allow users pass their own flags if they really want to, even if it is not in the spirit of usual package distribution; some --- possibly many --- people just want to develop and compile locally for their own use, no distribution intended. || I dug into this a bit, and it certainly is an interesting one, thanks for reporting! For starters, it seems to only show up in certain cases, for instance, this works:

```f90
module types

  implicit none

  INTEGER, PARAMETER :: int32 = SELECTED_INT_KIND(8)
  INTEGER, PARAMETER :: int64 = SELECTED_INT_KIND(16)
  INTEGER, PARAMETER :: real64 = SELECTED_REAL_KIND(15)
end module types

module lanedata

  use types, only: &
       real64, int32

  implicit none

  save

  integer(kind=int32), parameter :: &
       maxdata = 2**20-1

  real(kind=real64), dimension(:,:), allocatable :: &
       theta

  integer(kind=int32) :: &
       ndata

end module lanedata
```

in `blah.f90` with `f2py -m ltest blah.f90 -c` works fine:

```python
In [1]: import ltest

In [2]: dir(ltest)
Out[2]: 
['__doc__',
 '__f2py_numpy_version__',
 '__file__',
 '__loader__',
 '__name__',
 '__package__',
 '__spec__',
 '__version__',
 '_ltest_error',
 'lanedata']

In [3]: dir(ltest.lanedata)
Out[3]: 
['__call__',
 '__class__',
 '__delattr__',
 '__dir__',
 '__doc__',
 '__eq__',
 '__format__',
 '__ge__',
 '__getattribute__',
 '__getstate__',
 '__gt__',
 '__hash__',
 '__init__',
 '__init_subclass__',
 '__le__',
 '__lt__',
 '__ne__',
 '__new__',
 '__reduce__',
 '__reduce_ex__',
 '__repr__',
 '__setattr__',
 '__sizeof__',
 '__str__',
 '__subclasshook__',
 'maxdata',
 'ndata']

In [4]: ltest.lanedata.ndata
Out[4]: array(0, dtype=int32)

In [5]: ltest.lanedata.maxdata
Out[5]: array(1048575, dtype=int32)
```

However, the bug is reproducible, ~~**if a `subroutine` outside a module is present** (which a situation we don't currently have tests for)~~, if there is more than one module present in a single file.

```f90
module types

  implicit none

  INTEGER, PARAMETER :: int32 = SELECTED_INT_KIND(8)
  INTEGER, PARAMETER :: int64 = SELECTED_INT_KIND(16)
  INTEGER, PARAMETER :: real64 = SELECTED_REAL_KIND(15)

end module types

module lanedata

  use types, only: &
       real64, int32

  implicit none

  save

  integer(kind=int32), parameter :: &
       maxdata = 2**20-1

  real(kind=real64), dimension(:,:), allocatable :: &
       theta

  integer(kind=int32) :: &
       ndata

end module lanedata

subroutine freelanedata()

  use lanedata, only: &
       ndata, theta

  implicit none

  if (allocated(theta)) deallocate(theta)
  ndata = -1

end subroutine freelanedata
```

Where now, with `f2py -m ltest blah.f90 -c`:

```python

In [1]: import ltest

In [2]: dir(ltest)
Out[2]: 
['__doc__',
 '__f2py_numpy_version__',
 '__file__',
 '__loader__',
 '__name__',
 '__package__',
 '__spec__',
 '__version__',
 '_ltest_error',
 'freelanedata']

In [3]: 
```

There are a few things I need to understand conceptually about what the intended behavior is though. The reason this happens is because when there are subroutines they get exported into a module of the same name as requested on the command line (`ltest` in this case), and there is likely a bug in the way the modules are (not) being exported. Should have a fix soon.

Bizarrely, I think there's something more specific to the modules reported here by @2sn; since this also works:

```f90
module datonly

  implicit none

  integer, parameter :: max_value = 100

  real, dimension(:), allocatable :: data_array

end module datonly


module dat

  implicit none

  integer, parameter :: max_= 1009

end module dat

subroutine simple_subroutine(arg)
  integer, intent(inout) :: arg
  arg = arg * 5
end subroutine simple_subroutine
``` 

This also works..

```python

In [1]: import datonly

In [2]: datonly.datonly.max_value
Out[2]: array(100, dtype=int32)

In [3]: datonly.datonly.max_value
Out[3]: array(100, dtype=int32)

In [4]: datonly.dat.max_
Out[4]: array(1009, dtype=int32)

In [5]: dir(datonly)
Out[5]: 
['__doc__',
 '__f2py_numpy_version__',
 '__file__',
 '__loader__',
 '__name__',
 '__package__',
 '__spec__',
 '__version__',
 '_datonly_error',
 'dat',
 'datonly',
 'simple_subroutine']
``` || @HaoZeke Thank you very much for looking into this.

I am not sure whether your question about the intent/use case is directed at me.  What my Python code dies is trying to access the date in module  `lanedata` directly.  Obviously, one could add a function to return the data, but such calls also tend to be rather expensive.  

I do not know how access to module data is done internally by `f2py`, maybe there is a similar implicit function call in the first place, but it is certainly easier in terms of syntax (unless one creates a fancy Python class wrapping such function calls).

Do you plan to have a `f2py` directive to hide or explicitly include modules (there used to be some `f2py` command line flags to include or exclude symbols from wapping), or just include all?  Except for a small bit of overhead at compile time (and maybe small increase in module size), what would be reasons to not include all module and their public members by default?  Hiding private implementation details?  Looking at hour case study, it seems what is included and what not is based upon some guesses what the user may likely have intended and desired, but it seems hard to anticipate actual use cases in general. || > @HaoZeke Thank you very much for looking into this.
> 
> I am not sure whether your question about the intent/use case is directed at me. What my Python code dies is trying to access the date in module `lanedata` directly. Obviously, one could add a function to return the data, but such calls also tend to be rather expensive.
> 
> I do not know how access to module data is done internally by `f2py`, maybe there is a similar implicit function call in the first place, but it is certainly easier in terms of syntax (unless one creates a fancy Python class wrapping such function calls).
> 
> Do you plan to have a `f2py` directive to hide or explicitly include modules (there used to be some `f2py` command line flags to include or exclude symbols from wapping), or just include all? Except for a small bit of overhead at compile time (and maybe small increase in module size), what would be reasons to not include all module and their public members by default? Hiding private implementation details? Looking at hour case study, it seems what is included and what not is based upon some guesses what the user may likely have intended and desired, but it seems hard to anticipate actual use cases in general.

Include all should definitely be the default (and is again after #27695). There are tests for the `hide` directives, so that should be OK.

I'm thinking of adding some examples on using derived types soon, but otherwise, mostly just thinking of bugfixes / docs in the short term.",closed,2024-10-23T01:36:03+00:00,2024-11-04T12:26:21+00:00,2sn,"00 - Bug, component: numpy.f2py",2,"PR#27780 - doc/release/upcoming_changes/27695.improvement.rst: @@ -0,0 +1,5 @@|;|+``f2py`` handles multiple modules and exposes variables again|;|+-------------------------------------------------------------|;|+A regression has been fixed which allows F2PY users to expose variables to|;|+Python in modules with only assignments, and also fixes situations where|;|+multiple modules are present within a single source file. || PR#27780 - numpy/f2py/auxfuncs.py: @@ -44,7 +44,7 @@|;|     'isunsigned_long_long', 'isunsigned_long_longarray', 'isunsigned_short',|;|     'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess', 'replace',|;|     'show', 'stripcomma', 'throw_error', 'isattr_value', 'getuseblocks',|;|-    'process_f2cmap_dict'|;|+    'process_f2cmap_dict', 'containscommon'|;| ]|;| |;|  || PR#27780 - numpy/f2py/f90mod_rules.py: @@ -97,9 +97,6 @@ def dadd(line, s=doc):|;| |;|     usenames = getuseblocks(pymod)|;|     for m in findf90modules(pymod):|;|-        contains_functions_or_subroutines = any(|;|-            item for item in m[""body""] if item[""block""] in [""function"", ""subroutine""]|;|-        )|;|         sargs, fargs, efargs, modobjs, notvars, onlyvars = [], [], [], [], [|;|             m['name']], []|;|         sargsp = []|;|@@ -120,8 +117,9 @@ def dadd(line, s=doc):|;|             outmess(f""\t\t\tSkipping {m['name']} since there are no public vars/func in this module...\n"")|;|             continue|;| |;|-        if m['name'] in usenames and not contains_functions_or_subroutines:|;|-            outmess(f""\t\t\tSkipping {m['name']} since it is in 'use'...\n"")|;|+        # gh-25186|;|+        if m['name'] in usenames and containscommon(m):|;|+            outmess(f""\t\t\tSkipping {m['name']} since it is in 'use' and contains a common block...\n"")|;|             continue|;|         if onlyvars:|;|             outmess('\t\t  Variables: %s\n' % (' '.join(onlyvars))) || PR#27780 - numpy/f2py/tests/src/regression/datonly.f90: @@ -0,0 +1,17 @@|;|+module datonly|;|+  implicit none|;|+  integer, parameter :: max_value = 100|;|+  real, dimension(:), allocatable :: data_array|;|+end module datonly|;|+|;|+module dat|;|+  implicit none|;|+  integer, parameter :: max_= 1009|;|+end module dat|;|+|;|+subroutine simple_subroutine(ain, aout)|;|+  use dat, only: max_|;|+  integer, intent(in) :: ain|;|+  integer, intent(out) :: aout|;|+  aout = ain + max_|;|+end subroutine simple_subroutine || PR#27780 - numpy/f2py/tests/test_regression.py: @@ -24,6 +24,18 @@ def test_inout(self):|;|         assert np.allclose(x, [3, 1, 2])|;| |;| |;|+class TestDataOnlyMultiModule(util.F2PyTest):|;|+    # Check that modules without subroutines work|;|+    sources = [util.getpath(""tests"", ""src"", ""regression"", ""datonly.f90"")]|;|+|;|+    @pytest.mark.slow|;|+    def test_mdat(self):|;|+        assert self.module.datonly.max_value == 100|;|+        assert self.module.dat.max_ == 1009|;|+        int_in = 5|;|+        assert self.module.simple_subroutine(5) == 1014|;|+|;|+|;| class TestNegativeBounds(util.F2PyTest):|;|     # Check that negative bounds work correctly|;|     sources = [util.getpath(""tests"", ""src"", ""negative_bounds"", ""issue_20853.f90"")] || PR#27695 - numpy/f2py/auxfuncs.py: @@ -43,7 +43,7 @@|;|     'isunsigned_long_long', 'isunsigned_long_longarray', 'isunsigned_short',|;|     'isunsigned_shortarray', 'l_and', 'l_not', 'l_or', 'outmess', 'replace',|;|     'show', 'stripcomma', 'throw_error', 'isattr_value', 'getuseblocks',|;|-    'process_f2cmap_dict'|;|+    'process_f2cmap_dict', 'containscommon'|;| ]|;| |;|  || PR#27695 - numpy/f2py/f90mod_rules.py: @@ -97,9 +97,6 @@ def dadd(line, s=doc):|;| |;|     usenames = getuseblocks(pymod)|;|     for m in findf90modules(pymod):|;|-        contains_functions_or_subroutines = any(|;|-            item for item in m[""body""] if item[""block""] in [""function"", ""subroutine""]|;|-        )|;|         sargs, fargs, efargs, modobjs, notvars, onlyvars = [], [], [], [], [|;|             m['name']], []|;|         sargsp = []|;|@@ -120,8 +117,9 @@ def dadd(line, s=doc):|;|             outmess(f""\t\t\tSkipping {m['name']} since there are no public vars/func in this module...\n"")|;|             continue|;| |;|-        if m['name'] in usenames and not contains_functions_or_subroutines:|;|-            outmess(f""\t\t\tSkipping {m['name']} since it is in 'use'...\n"")|;|+        # gh-25186|;|+        if m['name'] in usenames and containscommon(m):|;|+            outmess(f""\t\t\tSkipping {m['name']} since it is in 'use' and contains a common block...\n"")|;|             continue|;|         if onlyvars:|;|             outmess('\t\t  Variables: %s\n' % (' '.join(onlyvars))) || PR#27695 - numpy/f2py/tests/src/regression/datonly.f90: @@ -0,0 +1,17 @@|;|+module datonly|;|+  implicit none|;|+  integer, parameter :: max_value = 100|;|+  real, dimension(:), allocatable :: data_array|;|+end module datonly|;|+|;|+module dat|;|+  implicit none|;|+  integer, parameter :: max_= 1009|;|+end module dat|;|+|;|+subroutine simple_subroutine(ain, aout)|;|+  use dat, only: max_|;|+  integer, intent(in) :: ain|;|+  integer, intent(out) :: aout|;|+  aout = ain + max_|;|+end subroutine simple_subroutine || PR#27695 - numpy/f2py/tests/test_regression.py: @@ -24,6 +24,18 @@ def test_inout(self):|;|         assert np.allclose(x, [3, 1, 2])|;| |;| |;|+class TestDataOnlyMultiModule(util.F2PyTest):|;|+    # Check that modules without subroutines work|;|+    sources = [util.getpath(""tests"", ""src"", ""regression"", ""datonly.f90"")]|;|+|;|+    @pytest.mark.slow|;|+    def test_mdat(self):|;|+        assert self.module.datonly.max_value == 100|;|+        assert self.module.dat.max_ == 1009|;|+        int_in = 5|;|+        assert self.module.simple_subroutine(5) == 1014|;|+|;|+|;| class TestNegativeBounds(util.F2PyTest):|;|     # Check that negative bounds work correctly|;|     sources = [util.getpath(""tests"", ""src"", ""negative_bounds"", ""issue_20853.f90"")]","TST: Multiple modules in single pyf for gh-27622 || BUG: Handle multi-module files and common better

Fixes gh-25186 gh-25337 gh-27622 || TST: Multiple modules in single pyf for gh-27622 || BUG: Handle multi-module files and common better

Fixes gh-25186 gh-25337 gh-27622"
numpy/numpy,HaoZeke,27167,BUG: f2py in numpy 2.0.1 does not expose variables to Python in modules containing only assignments.,"### Describe the issue:

Take this F90 module:

```
MODULE F_GLOBALS
     IMPLICIT NONE
     INTEGER, PARAMETER :: N_MAX = 16
     INTEGER, PARAMETER :: I_MAX = 18
     INTEGER, PARAMETER :: J_MAX = 72
     ...
END MODULE F_GLOBALS
```

When compiled with f2py 2.0.1 and included as ""f_test"" in a Python script, this:

```
import f_test as f
maxN = f.f_globals.n_max
maxI = f.f_globals.i_max
maxJ = f.f_globals.j_max
```

will cause this error message:

```
AttributeError: module 'f_test' has no attribute 'f_globals'
```

### Reproduce the code example:

```python
> f2py -c -m f_test F_GLOBALS.f90

import f_test as f
maxN = f.f_globals.n_max
maxI = f.f_globals.i_max
maxJ = f.f_globals.j_max
```


### Error message:

```shell
AttributeError: module 'f_test' has no attribute 'f_globals'
```


### Python and NumPy Versions:

Python 3.12.4
numpy 2.0.1
Fortran compiler for the host machine: gfortran (gcc 14.1.0 ""GNU Fortran (Homebrew GCC 14.1.0_2) 14.1.0"")
Fortran linker for the host machine: gfortran ld64 1053.12
C compiler for the host machine: cc (clang 15.0.0 ""Apple clang version 15.0.0 (clang-1500.3.9.4)"")
C linker for the host machine: cc ld64 1053.12
Host machine cpu family: aarch64
Host machine cpu: aarch64

>>> import sys
>>> print(numpy.__version__)
2.0.1
>>> print(sys.version)
3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 (clang-1500.3.9.4)]

### Runtime Environment:

Python 3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 (clang-1500.3.9.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy
>>> numpy.show_runtime()
[{'numpy_version': '2.0.1',
  'python': '3.12.4 (main, Jun  6 2024, 18:26:44) [Clang 15.0.0 '
            '(clang-1500.3.9.4)]',
  'uname': uname_result(system='Darwin', node='MBP2023.fritz.box', release='23.5.0', version='Darwin Kernel Version 23.5.0: Wed May  1 20:12:58 PDT 2024; root:xnu-10063.121.3~5/RELEASE_ARM64_T6000', machine='arm64')},
 {'simd_extensions': {'baseline': ['NEON', 'NEON_FP16', 'NEON_VFPV4', 'ASIMD'],
                      'found': ['ASIMDHP'],
                      'not_found': ['ASIMDFHM']}},
 {'architecture': 'neoversen1',
  'filepath': '/opt/homebrew/Cellar/openblas/0.3.27/lib/libopenblasp-r0.3.27.dylib',
  'internal_api': 'openblas',
  'num_threads': 10,
  'prefix': 'libopenblas',
  'threading_layer': 'openmp',
  'user_api': 'blas',
  'version': '0.3.27'},
 {'filepath': '/opt/homebrew/Cellar/gcc/14.1.0_2/lib/gcc/current/libgomp.1.dylib',
  'internal_api': 'openmp',
  'num_threads': 10,
  'prefix': 'libgomp',
  'user_api': 'openmp',
  'version': None}]

### Context for the issue:

Code which ran fine in numpy 1.26 fails to run in numpy 2.0.1.
A simple if ugly workaround is to add some executable code within the module. Only then will it become visible in Python, including all the assigned variables..","Running into the same issue here. Our CI (which tests against a Fortran reference code) has been broken since NumPy 2.0. || @HaoZeke Ping. || Until a fix comes around, you can always add some bogus executable statements to the assignment module. They do not even need to be reachable. Worked fine for me. || I can't reproduce this on NumPy main, I think this might be fixed:

```
goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
± cat test.py
import f_test as f
maxN = f.f_globals.n_max
maxI = f.f_globals.i_max
maxJ = f.f_globals.j_max

goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
± f2py -c -m f_test F_GLOBALS.f90
Cannot use distutils backend with Python>=3.12, using meson backend instead.
Using meson backend
Will pass --lower to f2py
See https://numpy.org/doc/stable/f2py/buildtools/meson.html
Reading fortran codes...
	Reading file 'F_GLOBALS.f90' (format:free)
Post-processing...
	Block: f_test
			Block: f_globals
Applying post-processing hooks...
  character_backward_compatibility_hook
Post-processing (stage 2)...
	Block: f_test
		Block: unknown_interface
			Block: f_globals
Building modules...
    Building module ""f_test""...
		Constructing F90 module support for ""f_globals""...
		  Variables: n_max i_max j_max
    Wrote C/API module ""f_test"" to file ""./f_testmodule.c""
    Fortran 90 wrappers are saved to ""./f_test-f2pywrappers2.f90""
The Meson build system
Version: 1.4.0
Source dir: /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4
Build dir: /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir
Build type: native build
Project name: f_test
Project version: 0.1
Fortran compiler for the host machine: gfortran (gcc 14.2.0 ""GNU Fortran (Homebrew GCC 14.2.0) 14.2.0"")
Fortran linker for the host machine: gfortran ld64 1053.12
C compiler for the host machine: ccache cc (clang 15.0.0 ""Apple clang version 15.0.0 (clang-1500.3.9.4)"")
C linker for the host machine: cc ld64 1053.12
Host machine cpu family: aarch64
Host machine cpu: aarch64
Program /Users/goldbaum/.pyenv/versions/3.12.3/bin/python found: YES (/Users/goldbaum/.pyenv/versions/3.12.3/bin/python)
Found pkg-config: YES (/opt/homebrew/bin/pkg-config) 0.29.2
Run-time dependency python found: YES 3.12
Library quadmath found: YES
Build targets in project: 1

Found ninja-1.11.1.git.kitware.jobserver-1 at /Users/goldbaum/.pyenv/versions/3.12.3/bin/ninja
INFO: autodetecting backend as ninja
INFO: calculating backend command to run: /Users/goldbaum/.pyenv/versions/3.12.3/bin/ninja -C /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir
ninja: Entering directory `/private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir'
[6/6] Linking target f_test.cpython-312-darwin.so

goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
± python test.py
```

@P-Kaempf is there any chance you can try again using Numpy 2.1.1? It looks like it's fixed there as well.
 || Here is what I did:

==> Upgrading numpy
  2.0.1 -> 2.1.1 
==> Pouring numpy--2.1.1.arm64_sonoma.bottle.tar.gz
==> Caveats
To run `f2py`, you may need to `brew install ***@***.***`
and
==> Upgrading gcc
  14.1.0_2 -> 14.2.0 
==> Pouring gcc--14.2.0.arm64_sonoma.bottle.tar.gz
🍺  /opt/homebrew/Cellar/gcc/14.2.0: 1,913 files, 473.4MB
==> Running `brew cleanup gcc`...
then
***@***.*** geo % python
Python 3.12.6 (main, Sep  6 2024, 19:03:47) [Clang 15.0.0 (clang-1500.3.9.4)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy
>>> numpy.__version__
'2.1.1'
>>> 
but still, when running the compiled code, I get:
AttributeError: module 'geo.geoplot' has no attribute 'geoplot_globals'

only when I add this to the geoplot_globals module (which only contains variable declarations otherwise) can this error be avoided:

         CONTAINS
           SUBROUTINE DUMMY (UNSINN)
             INTEGER :: UNSINN
             OPEN(UNIT=29, FILE=""/Users/peter/Applications/Python/PyVFE/geo/FOR29.txt"", STATUS = 'UNKNOWN')
             WRITE(29,""(I8)"") UNSINN
             CLOSE (29)
           END SUBROUTINE DUMMY

This is an acceptable workaround. What is a bigger nuisance is that since numpy 2.0 all ASCII characters > 127 are not allowed in comments!

Best Regards,

Peter

> Am 20.09.2024 um 21:20 schrieb Nathan Goldbaum ***@***.***>:
> 
> 
> I can't reproduce this on NumPy main, I think this might be fixed:
> 
> goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
> ± cat test.py
> import f_test as f
> maxN = f.f_globals.n_max
> maxI = f.f_globals.i_max
> maxJ = f.f_globals.j_max
> 
> goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
> ± f2py -c -m f_test F_GLOBALS.f90
> Cannot use distutils backend with Python>=3.12, using meson backend instead.
> Using meson backend
> Will pass --lower to f2py
> See https://numpy.org/doc/stable/f2py/buildtools/meson.html
> Reading fortran codes...
> 	Reading file 'F_GLOBALS.f90' (format:free)
> Post-processing...
> 	Block: f_test
> 			Block: f_globals
> Applying post-processing hooks...
>   character_backward_compatibility_hook
> Post-processing (stage 2)...
> 	Block: f_test
> 		Block: unknown_interface
> 			Block: f_globals
> Building modules...
>     Building module ""f_test""...
> 		Constructing F90 module support for ""f_globals""...
> 		  Variables: n_max i_max j_max
>     Wrote C/API module ""f_test"" to file ""./f_testmodule.c""
>     Fortran 90 wrappers are saved to ""./f_test-f2pywrappers2.f90""
> The Meson build system
> Version: 1.4.0
> Source dir: /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4
> Build dir: /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir
> Build type: native build
> Project name: f_test
> Project version: 0.1
> Fortran compiler for the host machine: gfortran (gcc 14.2.0 ""GNU Fortran (Homebrew GCC 14.2.0) 14.2.0"")
> Fortran linker for the host machine: gfortran ld64 1053.12
> C compiler for the host machine: ccache cc (clang 15.0.0 ""Apple clang version 15.0.0 (clang-1500.3.9.4)"")
> C linker for the host machine: cc ld64 1053.12
> Host machine cpu family: aarch64
> Host machine cpu: aarch64
> Program /Users/goldbaum/.pyenv/versions/3.12.3/bin/python found: YES (/Users/goldbaum/.pyenv/versions/3.12.3/bin/python)
> Found pkg-config: YES (/opt/homebrew/bin/pkg-config) 0.29.2
> Run-time dependency python found: YES 3.12
> Library quadmath found: YES
> Build targets in project: 1
> 
> Found ninja-1.11.1.git.kitware.jobserver-1 at /Users/goldbaum/.pyenv/versions/3.12.3/bin/ninja
> INFO: autodetecting backend as ninja
> INFO: calculating backend command to run: /Users/goldbaum/.pyenv/versions/3.12.3/bin/ninja -C /private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir
> ninja: Entering directory `/private/var/folders/nk/yds4mlh97kg9qdq745g715rw0000gn/T/tmpkizrdx_4/bbdir'
> [6/6] Linking target f_test.cpython-312-darwin.so
> 
> goldbaum at Nathans-MBP in ~/Documents/f2py-test on main!
> ± python test.py
> @P-Kaempf <https://github.com/P-Kaempf> is there any chance you can try again using Numpy 2.1.1?
> 
> —
> Reply to this email directly, view it on GitHub <https://github.com/numpy/numpy/issues/27167#issuecomment-2364416200>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AAQ5YLJLBVLJDNWZZDZSWFDZXRYODAVCNFSM6AAAAABMJLFJR6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUGQYTMMRQGA>.
> You are receiving this because you were mentioned.
> 

 || Does the example in the issue trigger the bug for you? The output you shared looks like it's about different code. If it doesn't can you share an example I can trigger the issue with?

If you are still able to reproduce the issue as described, then either I made a mistake trying to reproduce it, or there's some difference in our environments.

For the non-ASCII character thing, please file a separate issue about that so it doesn't get lost, assuming there isn't an open issue already. || The example is an excerpt from a much longer code file. Indeed, if I run this short example, it works now as advertised.

I need to isolate the issue better. I cannot post an example with more than 6300 lines! || The sample needs some executable added. Here is the minimum viable code for reproducing the issue:

Fortran:

```
      MODULE MOD_TYPES
        INTEGER, PARAMETER :: SP = SELECTED_REAL_KIND(6, 37)
        INTEGER, PARAMETER :: DP = SELECTED_REAL_KIND(15, 307)
      END MODULE
!
      MODULE F_GLOBALS
         USE MOD_TYPES
         IMPLICIT NONE
         INTEGER, PARAMETER :: N_MAX = 16
         INTEGER, PARAMETER :: I_MAX = 18
         INTEGER, PARAMETER :: J_MAX = 72
         REAL(SP) :: XREF
      END MODULE F_GLOBALS
!
       SUBROUTINE DUMMY ()
!
       USE F_GLOBALS
       USE MOD_TYPES
       IMPLICIT NONE
!
       REAL(SP) :: MINIMAL
       MINIMAL = 0.01*XREF
       RETURN
!
       END SUBROUTINE DUMMY

```

Python:

```
import f_globals as f

def test():
        maxN = f.f_globals.n_max
        maxI = f.f_globals.i_max
        maxJ = f.f_globals.j_max
        print(""maxN = "", maxN, maxI, maxJ)

test()

```
peter@MBP2023 geo % python test.py
Traceback (most recent call last):
  File ""/Users/peter/Applications/Python/PyVFE/geo/test.py"", line 9, in <module>
    test()
  File ""/Users/peter/Applications/Python/PyVFE/geo/test.py"", line 4, in test
    maxN = f.f_globals.n_max
           ^^^^^^^^^^^
AttributeError: module 'f_globals' has no attribute 'f_globals'
 || This is fixed by https://github.com/numpy/numpy/pull/27695

From the fortran code in https://github.com/numpy/numpy/issues/27167#issuecomment-2369707816

saved to a file `fbug.f90` and compiled with:

```bash
python -m numpy.f2py -c -m fbug fbug.f90
```

The function works as expected.

```ipython
In [1]: import fbug as f

In [2]: def test():
   ...:         maxN = f.f_globals.n_max
   ...:         maxI = f.f_globals.i_max
   ...:         maxJ = f.f_globals.j_max
   ...:         print(""maxN = "", maxN, maxI, maxJ)
   ...: 
   ...: test()
maxN =  16 18 72
```

I'll leave this open since I want to add a test and a release note for https://github.com/numpy/numpy/pull/27695 anyway.

*EDIT*: @P-Kaempf did you open an issue for the ASCII thing suggested by @ngoldbaum?",closed,2024-08-10T01:00:18+00:00,2024-11-16T22:15:43+00:00,P-Kaempf,"00 - Bug, component: numpy.f2py",1,"PR#27730 - doc/release/upcoming_changes/27695.improvement.rst: @@ -0,0 +1,5 @@|;|+``f2py`` handles multiple modules and exposes variables again|;|+-------------------------------------------------------------|;|+A regression has been fixed which allows F2PY users to expose variables to|;|+Python in modules with only assignments, and also fixes situations where|;|+multiple modules are present within a single source file. || PR#27730 - numpy/f2py/tests/src/regression/assignOnlyModule.f90: @@ -0,0 +1,25 @@|;|+      MODULE MOD_TYPES|;|+        INTEGER, PARAMETER :: SP = SELECTED_REAL_KIND(6, 37)|;|+        INTEGER, PARAMETER :: DP = SELECTED_REAL_KIND(15, 307)|;|+      END MODULE|;|+!|;|+      MODULE F_GLOBALS|;|+         USE MOD_TYPES|;|+         IMPLICIT NONE|;|+         INTEGER, PARAMETER :: N_MAX = 16|;|+         INTEGER, PARAMETER :: I_MAX = 18|;|+         INTEGER, PARAMETER :: J_MAX = 72|;|+         REAL(SP) :: XREF|;|+      END MODULE F_GLOBALS|;|+!|;|+       SUBROUTINE DUMMY ()|;|+!|;|+       USE F_GLOBALS|;|+       USE MOD_TYPES|;|+       IMPLICIT NONE|;|+!|;|+       REAL(SP) :: MINIMAL|;|+       MINIMAL = 0.01*XREF|;|+       RETURN|;|+!|;|+       END SUBROUTINE DUMMY || PR#27730 - numpy/f2py/tests/test_regression.py: @@ -151,3 +151,15 @@ def test_gh25784():|;|         )|;|     except ImportError as rerr:|;|         assert ""unknown_subroutine_"" in str(rerr)|;|+|;|+|;|+@pytest.mark.slow|;|+class TestAssignmentOnlyModules(util.F2PyTest):|;|+    # Ensure that variables are exposed without functions or subroutines in a module|;|+    sources = [util.getpath(""tests"", ""src"", ""regression"", ""assignOnlyModule.f90"")]|;|+|;|+    @pytest.mark.slow|;|+    def test_gh27167(self):|;|+        assert (self.module.f_globals.n_max == 16)|;|+        assert (self.module.f_globals.i_max == 18)|;|+        assert (self.module.f_globals.j_max == 72)","TST: F2PY test regression on variables

Co-authored-by: P-Kaempf <P-Kaempf@users.noreply.github.com> || REL: Add a note for gh-27695"
numpy/numpy,HaoZeke,25799,BUG: The F2PY statement `fortranname` does not work for functions. ,"### Describe the issue:

# F2PY - Fortranname


As I understand it, the statement `fortranname` should work for both
subroutines and functions. However, The F2PY statement `fortranname`
seems only to work for subroutines and not for functions.

### Reproduce the code example:

## Subroutine

The F2PY statement `fortranname` works in subroutines.

`subfortranname.f`

```fortran
      SUBROUTINE SUBFORTRANNAME(A,B,C)
      REAL*8 A, B, C
      C = A + B
      END SUBROUTINE
```

`subfortranname.pyf`

``` python
python module subfortranname ! in 
    interface  ! in :subfortranname
        subroutine subfortranname_default(a,b,c) ! in :subfortranname:subfortranname.f
            fortranname subfortranname
            real*8 :: a
            real*8 :: b
            real*8, intent(out) :: c
        end subroutine subfortranname_default
    end interface 
end python module subfortranname
```

`test_subfortranname.py`

``` python
import subfortranname

print(subfortranname.__doc__)
```

``` bash
This module 'subfortranname' is auto-generated with f2py (version:1.26.4).
Functions:
    c = subfortranname_default(a,b)
.
```

## Function

The F2PY statement `fortranname` does not work in functions.

`funcfortranname.f`

``` fortran
      REAL*8 FUNCTION FUNCFORTRANNAME(A,B)
      REAL*8 A, B
      FUNCFORTRANNAME = A + B
      RETURN
      END FUNCTION
```

`funcfortranname.pyf`

``` python
python module funcfortranname ! in 
    interface  ! in :funcfortranname
        function funcfortranname_default(a,b) ! in :funcfortranname:funcfortranname.f
            fortranname funcfortranname
            real*8 :: a
            real*8 :: b
            real*8, intent(out) :: funcfortranname
        end function funcfortranname_default
    end interface 
end python module funcfortranname
```

`test_funcfortranname.py`

``` python
import funcfortranname

print(funcfortranname.__doc__)
```

``` bash
Traceback (most recent call last):
  File ""/home/johannes/Sandbox/f2py/fortranname/test_f.py"", line 1, in <module>
    import funcfortranname
ImportError: /home/johannes/Sandbox/f2py/fortranname/funcfortranname.cpython-310-x86_64-linux-gnu.so: undefined symbol: funcfortranname_default_
```


### Error message:

_No response_

### Python and NumPy Versions:

Python 3.10.12 and 3.12.1
Numpy 1.26.4

```bash
1.26.4
3.12.1 (main, Dec 10 2023, 15:07:36) [GCC 11.4.0]
```

### Runtime Environment:

_No response_

### Context for the issue:

_No response_","Thanks for the report. This should be fixed in #27731. Note that there is a mistake in the `.pyf` for the function. Without specifying the `kind` for `funcfortranname_default` it defaults to `real` so will give `0` even with the fix in #27731.

However, if the `pyf` is changed to:

```fortran
python module funcfortranname ! in
    interface  ! in :funcfortranname
        function funcfortranname_default(a,b) ! in :funcfortranname:funcfortranname.f
            fortranname funcfortranname
            real*8 :: a
            real*8 :: b
            real*8 :: funcfortranname_default
            real*8, intent(out) :: funcfortranname
        end function funcfortranname_default
    end interface
end python module funcfortranname
```

i.e. the correct kind is specified, then with #27731 it will work:

```python
# python -m numpy.f2py -c funcfortranname.f funcfortranname.pyf

In [1]: import funcfortranname

In [2]: funcfortranname.funcfortranname_default(1,2000)
Out[2]: 2001.0
```",closed,2024-02-09T21:09:05+00:00,2024-11-16T22:03:33+00:00,KybernetikJo,"00 - Bug, component: numpy.f2py",1,"PR#27731 - numpy/f2py/rules.py: @@ -459,7 +459,7 @@|;|     {|;|       extern #ctype# #F_FUNC#(#name_lower#,#NAME#)(void)|;|;       PyObject* o = PyDict_GetItemString(d,""#name#"")|;|;-      tmp = F2PyCapsule_FromVoidPtr((void*)#F_FUNC#(#name_lower#,#NAME#),NULL)|;|;+      tmp = F2PyCapsule_FromVoidPtr((void*)#F_WRAPPEDFUNC#(#name_lower#,#NAME#),NULL)|;|;       PyObject_SetAttrString(o,""_cpointer"", tmp)|;|;       Py_DECREF(tmp)|;|;       s = PyUnicode_FromString(""#name#""); || PR#27731 - numpy/f2py/tests/src/routines/funcfortranname.f: @@ -0,0 +1,5 @@|;|+      REAL*8 FUNCTION FUNCFORTRANNAME(A,B)|;|+      REAL*8 A, B|;|+      FUNCFORTRANNAME = A + B|;|+      RETURN|;|+      END FUNCTION || PR#27731 - numpy/f2py/tests/src/routines/funcfortranname.pyf: @@ -0,0 +1,11 @@|;|+python module funcfortranname ! in|;|+    interface  ! in :funcfortranname|;|+        function funcfortranname_default(a,b) ! in :funcfortranname:funcfortranname.f|;|+            fortranname funcfortranname|;|+            real*8 :: a|;|+            real*8 :: b|;|+            real*8 :: funcfortranname_default|;|+            real*8, intent(out) :: funcfortranname|;|+        end function funcfortranname_default|;|+    end interface|;|+end python module funcfortranname || PR#27731 - numpy/f2py/tests/src/routines/subrout.f: @@ -0,0 +1,4 @@|;|+      SUBROUTINE SUBROUT(A,B,C)|;|+      REAL*8 A, B, C|;|+      C = A + B|;|+      END SUBROUTINE || PR#27731 - numpy/f2py/tests/src/routines/subrout.pyf: @@ -0,0 +1,10 @@|;|+python module subrout ! in|;|+    interface  ! in :subrout|;|+        subroutine subrout_default(a,b,c) ! in :subrout:subrout.f|;|+            fortranname subrout|;|+            real*8 :: a|;|+            real*8 :: b|;|+            real*8, intent(out) :: c|;|+        end subroutine subrout_default|;|+    end interface|;|+end python module subrout || PR#27731 - numpy/f2py/tests/test_routines.py: @@ -0,0 +1,28 @@|;|+import pytest|;|+from . import util|;|+|;|+|;|+@pytest.mark.slow|;|+class TestRenamedFunc(util.F2PyTest):|;|+    sources = [|;|+        util.getpath(""tests"", ""src"", ""routines"", ""funcfortranname.f""),|;|+        util.getpath(""tests"", ""src"", ""routines"", ""funcfortranname.pyf""),|;|+    ]|;|+    module_name = ""funcfortranname""|;|+|;|+    def test_gh25799(self):|;|+        assert dir(self.module)|;|+        assert self.module.funcfortranname_default(200, 12) == 212|;|+|;|+|;|+@pytest.mark.slow|;|+class TestRenamedSubroutine(util.F2PyTest):|;|+    sources = [|;|+        util.getpath(""tests"", ""src"", ""routines"", ""subrout.f""),|;|+        util.getpath(""tests"", ""src"", ""routines"", ""subrout.pyf""),|;|+    ]|;|+    module_name = ""subrout""|;|+|;|+    def test_renamed_subroutine(self):|;|+        assert dir(self.module)|;|+        assert self.module.subrout_default(200, 12) == 212","TST: Add some for fortranname

Co-authored-by: KybernetikJo <KybernetikJo@users.noreply.github.com> || BUG: Fix wrappers for fortranname

Closes gh-25700"
numpy/numpy,HaoZeke,2547,f2py: --no-lower does not work in one-step compilation (Trac #1954),"_Original ticket http://projects.scipy.org/numpy/ticket/1954 on 2011-09-26 by trac user azrael, assigned to @pearu._

In order to impliment exception handling for Fortran errors into a f2py wrapped function, I followed this advice:

[http://mail.scipy.org/pipermail/numpy-discussion/2009-January/039672.html]

I wanted this to work without editing the .pyf file, and got that by adding the following to the Fortran code:

```
!f2py callstatement (*f2py_func)( ... ); if (ierr == 1) PyErr_SetString(PyExc_ValueError, ""msg"")
!f2py callprotoargument ...
```

(The ... is just a replacement for actual code)

When I tried to compile this with

```
f2py -c -m m src.f
```

I got several warnings/errors like this

```
warning: implicit declaration of function ‘pyerr_setstring’
```

Obviously the case-lowering acted on this line. As far as I understand the User Guide this should not happen, since I didn't call f2py with '-h' or '--lower'. Nevertheless I added the '--no-lower', but still got the same warnings/errors.

Then I tried whether the added line will show up in the .pyf correctly, which it did, when I used '--no-lower' like this:

```
f2py --no-lower -m m -h m.pyf src.f
```

After generating the .pyf I can compile the module - **without** further editing in the .pyf!

```
f2py -c m.pyf src.f
```

---
1. Is this intended behaviour? Should it make a difference whether I generate the .pyf first and then compile or use the one-step way?
2. Is there a way to circumvent using ""callprotoargument""? I'd much rather have f2py do it's magic to guess the first line in callstatement and the callprotoargument, and then just add my piece of extra code. Can this be done? Something like a 'addtocallstatement' directive comes to mind ...
","_trac user azrael wrote on 2011-09-26_

Somehow some questions got lost from preview to submit:
1. As I understand the User Guide one cannot add multi-line blocks to the Fortran code, I have to add them to the .pyf. Is this correct? Thus, there is no nicer looking way to add the C code line than the one I used...?
2. Is there any way to mark single lines as not-to-be-lowered? In my current approach I don't get the lowering where I actually would need it, e.g. the function's name ... I have to make sure it's lower case everywhere it's used by hand, or will have to call it uppercase from Python ...
 || Don't know what to say to this. f2py is currently in minimal maintenance mode.
 || I'm unsure where the original files to reproduce this bug are (the archive 404s for me) and it seems that this is a feature request. || https://mail.python.org/pipermail/numpy-discussion/2009-January/039672.html but I think this reference is just wrong.

Notice that this issue reports a number of bugs/missing features and most of these are valid. It might make sense to create a reproducer of each of these and report these in separate numpy issues. || This is one of a couple of these mainly due to differences in the way `-c` and without `-c` is handled, e.g. #13553 and #25179.",closed,2012-10-19T22:31:21+00:00,2024-11-16T22:44:47+00:00,numpy-gitbot,"00 - Bug, component: numpy.f2py",1,"PR#27728 - doc/source/f2py/python-usage.rst: @@ -243,6 +243,13 @@ In Python:|;| .. literalinclude:: ./code/results/extcallback_session.dat|;|   :language: python|;| |;|+.. note::|;|+|;|+   When using modified Fortran code via ``callstatement`` or other directives,|;|+   the wrapped Python function must be called as a callback, otherwise only the|;|+   bare Fortran routine will be used. For more details, see|;|+   https://github.com/numpy/numpy/issues/26681#issuecomment-2466460943|;|+|;| Resolving arguments to call-back functions|;| ------------------------------------------|;|  || PR#27728 - numpy/f2py/crackfortran.py: @@ -425,11 +425,14 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[-1] not in ""\n\r\f"":|;|                 break|;|             l = l[:-1]|;|+        # Do not lower for directives, gh-2547, gh-27697, gh-26681|;|+        is_f2py_directive = False|;|         # Unconditionally remove comments|;|         (l, rl) = split_by_unquoted(l, '!')|;|         l += ' '|;|         if rl[:5].lower() == '!f2py':  # f2py directive|;|             l, _ = split_by_unquoted(l + 4 * ' ' + rl[5:], '!')|;|+            is_f2py_directive = True|;|         if l.strip() == '':  # Skip empty line|;|             if sourcecodeform == 'free':|;|                 # In free form, a statement continues in the next line|;|@@ -449,8 +452,10 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[0] in ['*', 'c', '!', 'C', '#']:|;|                 if l[1:5].lower() == 'f2py':  # f2py directive|;|                     l = '     ' + l[5:]|;|+                    is_f2py_directive = True|;|                 else:  # Skip comment line|;|                     cont = False|;|+                    is_f2py_directive = False|;|                     continue|;|             elif strictf77:|;|                 if len(l) > 72:|;|@@ -476,6 +481,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 else:|;|                     # clean up line beginning from possible digits.|;|                     l = '     ' + l[5:]|;|+                    # f2py directives are already stripped by this point|;|                     if localdolowercase:|;|                         finalline = ll.lower()|;|                     else:|;|@@ -505,7 +511,11 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 origfinalline = ''|;|             else:|;|                 if localdolowercase:|;|-                    finalline = ll.lower()|;|+                    # lines with intent() should be lowered otherwise|;|+                    # TestString::test_char fails due to mixed case|;|+                    # f2py directives without intent() should be left untouched|;|+                    # gh-2547, gh-27697, gh-26681|;|+                    finalline = ll.lower() if ""intent"" in ll.lower() or not is_f2py_directive else ll|;|                 else:|;|                     finalline = ll|;|                 origfinalline = ll|;|@@ -537,6 +547,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|         else:|;|             dowithline(finalline)|;|         l1 = ll|;|+    # Last line should never have an f2py directive anyway|;|     if localdolowercase:|;|         finalline = ll.lower()|;|     else: || PR#27728 - numpy/f2py/tests/src/callback/gh26681.f90: @@ -0,0 +1,18 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+|;|+    subroutine do_something(message)|;|+        !f2py    intent(callback, hide) mypy_abort|;|+        character(len=*), intent(in) :: message|;|+        call mypy_abort(message)|;|+    end subroutine do_something|;|+end module utils || PR#27728 - numpy/f2py/tests/src/crackfortran/gh27697.f90: @@ -0,0 +1,12 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+end module utils || PR#27728 - numpy/f2py/tests/test_callback.py: @@ -5,6 +5,7 @@|;| import threading|;| import traceback|;| import time|;|+import platform|;| |;| import numpy as np|;| from numpy.testing import IS_PYPY|;|@@ -244,3 +245,17 @@ def bar(x):|;| |;|         res = self.module.foo(bar)|;|         assert res == 110|;|+|;|+|;|+@pytest.mark.slow|;|+@pytest.mark.xfail(condition=(platform.system().lower() == 'darwin'),|;|+                   run=False,|;|+                   reason=""Callback aborts cause CI failures on macOS"")|;|+class TestCBFortranCallstatement(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""callback"", ""gh26681.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_callstatement_fortran(self):|;|+        with pytest.raises(ValueError, match='helpme') as exc:|;|+            self.module.mypy_abort = self.module.utils.my_abort|;|+            self.module.utils.do_something('helpme') || PR#27728 - numpy/f2py/tests/test_crackfortran.py: @@ -403,3 +403,12 @@ def test_param_eval_too_many_dims(self):|;|         dimspec = '(0:4, 3:12, 5)'|;|         pytest.raises(ValueError, crackfortran.param_eval, v, g_params, params,|;|                       dimspec=dimspec)|;|+|;|+@pytest.mark.slow|;|+class TestLowerF2PYDirective(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""crackfortran"", ""gh27697.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_no_lower_fail(self):|;|+        with pytest.raises(ValueError, match='aborting directly') as exc:|;|+            self.module.utils.my_abort('aborting directly')","BUG: Fix handling of f2py directives with --lower

Closes gh-2547, gh-27697, gh-26681 || TST: For --lower with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || TST: Callbacks with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || DOC: Note regarding modified fortran wrappers || BUG: Cleanup and use directives correctly || BUG: Handle more edge cases with --lower || TST: Skip runs on macOS for cb aborts"
numpy/numpy,HaoZeke,27697,BUG: `--lower` breaks `callstatement`,"Consider the issue reported in #26681.

```f90
module utils
    implicit none
  contains
    subroutine my_abort(message)
      implicit none
      character(len=*), intent(in) :: message
      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0;
      !f2py callprotoargument char*
      write(0,*) ""THIS SHOULD NOT APPEAR""
      stop 1
    end subroutine my_abort

    subroutine do_something()
        call my_abort(""aborting inside"")
    end subroutine do_something
end module utils
```

Since the `meson` build automatically passes `--lower` some more issues have cropped up, namely:

```
  640 |                 pyerr_setstring(pyexc_valueerror, message);f2py_success = 0;;
      |                 ^~~~~~~~~~~~~~~
      |                 PyErr_SetString
../cstmtmodule.c:640:33: error: 'pyexc_valueerror' undeclared (first use in this function); did you mean 'PyExc_ValueError'?
  640 |                 pyerr_setstring(pyexc_valueerror, message);f2py_success = 0;;
      |                                 ^~~~~~~~~~~~~~~~
      |                                 PyExc_ValueError
```
",Actually this (`lower` issue) is likely also a problem with any `f2py` directive in C or Fortran files. || Also reported in #2547.,closed,2024-11-04T02:49:51+00:00,2024-11-16T22:44:47+00:00,HaoZeke,"00 - Bug, component: numpy.f2py",1,"PR#27728 - doc/source/f2py/python-usage.rst: @@ -243,6 +243,13 @@ In Python:|;| .. literalinclude:: ./code/results/extcallback_session.dat|;|   :language: python|;| |;|+.. note::|;|+|;|+   When using modified Fortran code via ``callstatement`` or other directives,|;|+   the wrapped Python function must be called as a callback, otherwise only the|;|+   bare Fortran routine will be used. For more details, see|;|+   https://github.com/numpy/numpy/issues/26681#issuecomment-2466460943|;|+|;| Resolving arguments to call-back functions|;| ------------------------------------------|;|  || PR#27728 - numpy/f2py/crackfortran.py: @@ -425,11 +425,14 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[-1] not in ""\n\r\f"":|;|                 break|;|             l = l[:-1]|;|+        # Do not lower for directives, gh-2547, gh-27697, gh-26681|;|+        is_f2py_directive = False|;|         # Unconditionally remove comments|;|         (l, rl) = split_by_unquoted(l, '!')|;|         l += ' '|;|         if rl[:5].lower() == '!f2py':  # f2py directive|;|             l, _ = split_by_unquoted(l + 4 * ' ' + rl[5:], '!')|;|+            is_f2py_directive = True|;|         if l.strip() == '':  # Skip empty line|;|             if sourcecodeform == 'free':|;|                 # In free form, a statement continues in the next line|;|@@ -449,8 +452,10 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[0] in ['*', 'c', '!', 'C', '#']:|;|                 if l[1:5].lower() == 'f2py':  # f2py directive|;|                     l = '     ' + l[5:]|;|+                    is_f2py_directive = True|;|                 else:  # Skip comment line|;|                     cont = False|;|+                    is_f2py_directive = False|;|                     continue|;|             elif strictf77:|;|                 if len(l) > 72:|;|@@ -476,6 +481,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 else:|;|                     # clean up line beginning from possible digits.|;|                     l = '     ' + l[5:]|;|+                    # f2py directives are already stripped by this point|;|                     if localdolowercase:|;|                         finalline = ll.lower()|;|                     else:|;|@@ -505,7 +511,11 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 origfinalline = ''|;|             else:|;|                 if localdolowercase:|;|-                    finalline = ll.lower()|;|+                    # lines with intent() should be lowered otherwise|;|+                    # TestString::test_char fails due to mixed case|;|+                    # f2py directives without intent() should be left untouched|;|+                    # gh-2547, gh-27697, gh-26681|;|+                    finalline = ll.lower() if ""intent"" in ll.lower() or not is_f2py_directive else ll|;|                 else:|;|                     finalline = ll|;|                 origfinalline = ll|;|@@ -537,6 +547,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|         else:|;|             dowithline(finalline)|;|         l1 = ll|;|+    # Last line should never have an f2py directive anyway|;|     if localdolowercase:|;|         finalline = ll.lower()|;|     else: || PR#27728 - numpy/f2py/tests/src/callback/gh26681.f90: @@ -0,0 +1,18 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+|;|+    subroutine do_something(message)|;|+        !f2py    intent(callback, hide) mypy_abort|;|+        character(len=*), intent(in) :: message|;|+        call mypy_abort(message)|;|+    end subroutine do_something|;|+end module utils || PR#27728 - numpy/f2py/tests/src/crackfortran/gh27697.f90: @@ -0,0 +1,12 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+end module utils || PR#27728 - numpy/f2py/tests/test_callback.py: @@ -5,6 +5,7 @@|;| import threading|;| import traceback|;| import time|;|+import platform|;| |;| import numpy as np|;| from numpy.testing import IS_PYPY|;|@@ -244,3 +245,17 @@ def bar(x):|;| |;|         res = self.module.foo(bar)|;|         assert res == 110|;|+|;|+|;|+@pytest.mark.slow|;|+@pytest.mark.xfail(condition=(platform.system().lower() == 'darwin'),|;|+                   run=False,|;|+                   reason=""Callback aborts cause CI failures on macOS"")|;|+class TestCBFortranCallstatement(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""callback"", ""gh26681.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_callstatement_fortran(self):|;|+        with pytest.raises(ValueError, match='helpme') as exc:|;|+            self.module.mypy_abort = self.module.utils.my_abort|;|+            self.module.utils.do_something('helpme') || PR#27728 - numpy/f2py/tests/test_crackfortran.py: @@ -403,3 +403,12 @@ def test_param_eval_too_many_dims(self):|;|         dimspec = '(0:4, 3:12, 5)'|;|         pytest.raises(ValueError, crackfortran.param_eval, v, g_params, params,|;|                       dimspec=dimspec)|;|+|;|+@pytest.mark.slow|;|+class TestLowerF2PYDirective(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""crackfortran"", ""gh27697.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_no_lower_fail(self):|;|+        with pytest.raises(ValueError, match='aborting directly') as exc:|;|+            self.module.utils.my_abort('aborting directly')","BUG: Fix handling of f2py directives with --lower

Closes gh-2547, gh-27697, gh-26681 || TST: For --lower with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || TST: Callbacks with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || DOC: Note regarding modified fortran wrappers || BUG: Cleanup and use directives correctly || BUG: Handle more edge cases with --lower || TST: Skip runs on macOS for cb aborts"
numpy/numpy,HaoZeke,26681,f2py callstatement is ineffective in subroutines called from other subroutines,"### Describe the issue:

When using `callstatement` to overrride a subroutine with different code as per [the docs ](https://numpy.org/doc/stable/f2py/signature-file.html#f2py-statements), this works when said subroutine is directly invoked by Python. However, when invoking another subroutine that calls the first subroutine, this override is not in effect.

MWE:
test.f90
```fortran
module utils
    implicit none
  contains
    subroutine my_abort(message)
      implicit none
      character(len=*), intent(in) :: message
      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0;
      !f2py callprotoargument char*
      write(0,*) ""THIS SHOULD NOT APPEAR""
      stop 1
    end subroutine my_abort

    subroutine do_something()
        call my_abort(""aborting inside"")
    end subroutine do_something
end module utils
```

To avoid #2547, you have to do the compilation in 2 steps:
```
python3 -m numpy.f2py -h test.pyf --no-lower -m test test.f90
python3 -m numpy.f2py -c --f90exec=gfortran --fcompiler=gnu95 test.pyf test.f90
```

Invoking `my_abort` directly works as expected, raising the ValueError I have defined:
```
$ python3 -c ""import test; test.utils.my_abort('aborting directly')""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ValueError: aborting directly
```

However, when calling `do_something`, which in turn calls `my_abort`, the override seems to do nothing, and we run into the `stop`:
```
$ python3 -c ""import test; test.utils.do_something()""
 THIS SHOULD NOT APPEAR
STOP 1
```
Expected result: Python raises `ValueError: aborting inside`


### Reproduce the code example:

```python
python3 -c ""import test; test.utils.do_something()""
 THIS SHOULD NOT APPEAR
STOP 1

# Expected result: Python raises `ValueError: aborting inside`
```


### Error message:

_No response_

### Python and NumPy Versions:

Numpy: 2.0.0rc2 via conda-forge
python: 3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]
gfortran: GNU Fortran (conda-forge gcc 11.2.0-16) 11.2.0

Using 2.0.0rc2 to avoid issue #26156

### Runtime Environment:

[{'numpy_version': '2.0.0rc2',
  'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) '
            '[GCC 12.3.0]',
  'uname': uname_result(system='Linux', node='b5dc6932b437', release='5.15.146.1-microsoft-standard-WSL2', version='#1 SMP Thu Jan 11 04:09:03 UTC 2024', machine='x86_64')},
 {'simd_extensions': {'baseline': ['SSE', 'SSE2', 'SSE3'],
                      'found': ['SSSE3',
                                'SSE41',
                                'POPCNT',
                                'SSE42',
                                'AVX',
                                'F16C',
                                'FMA3',
                                'AVX2',
                                'AVX512F',
                                'AVX512CD',
                                'AVX512_SKX',
                                'AVX512_CLX',
                                'AVX512_CNL',
                                'AVX512_ICL'],
                      'not_found': ['AVX512_KNL', 'AVX512_KNM', 'AVX512_SPR']}},
 {'architecture': 'SkylakeX',
  'filepath': '/opt/conda/envs/xplengine/lib/libopenblasp-r0.3.27.so',
  'internal_api': 'openblas',
  'num_threads': 4,
  'prefix': 'libopenblas',
  'threading_layer': 'pthreads',
  'user_api': 'blas',
  'version': '0.3.27'}]

### Context for the issue:

What I'm intending here is to avoid executing the Fortran `stop` statement when running wrapped code in Python, because that also kills the Python *interpreter* and thus, in my case, the `pytest` run of a whole test suite that this code is part of.

This `my_abort` cleanup subroutine is potentially called from many places throughout the actual codebase.

A similar-feeling issue involving callbacks: #7855
Feels related: #26156
ping @HaoZeke","I found an even smaller MWE, turns out that this also happens when both subroutines are in one module. Edited the OP. || I was thinking about this a bit. I don't really think this is something which F2PY can handle. Basically, when you call `my_abort` in `do_something()` it calls the Fortran subroutine, but the `callstatement` is only valid for calls from Python into `my_abort` (basically because the `my_abort` Python wrapper includes the `callstatement`).

This behavior is integral to the way F2PY works efficiently, since always calling Python wrapped variants of Fortran routines would be pretty inefficient.

The way to call the Python wrapped variant would be using callbacks. I'm open to more design ideas about this but as it stands this isn't actionable.

There however a bug with `callstatement` and `--lower` wherein code like this:

```
      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0;
```

ends up with issues like so:

```
  640 |                 pyerr_setstring(pyexc_valueerror, message);f2py_success = 0;;
      |                 ^~~~~~~~~~~~~~~
      |                 PyErr_SetString
../cstmtmodule.c:640:33: error: 'pyexc_valueerror' undeclared (first use in this function); did you mean 'PyExc_ValueError'?
  640 |                 pyerr_setstring(pyexc_valueerror, message);f2py_success = 0;;
      |                                 ^~~~~~~~~~~~~~~~
      |                                 PyExc_ValueError
```

I'll work on that in another issue. || > There however a bug with `callstatement` and `--lower` wherein code like this:

Yeah, that's basically the #2547 that I mentioned working around in the OP. 👍  || > I was thinking about this a bit. I don't really think this is something which F2PY can handle. Basically, when you call `my_abort` in `do_something()` it calls the Fortran subroutine, but the `callstatement` is only valid for calls from Python into `my_abort` (basically because the `my_abort` Python wrapper includes the `callstatement`).
> 
> This behavior is integral to the way F2PY works efficiently, since always calling Python wrapped variants of Fortran routines would be pretty inefficient.
> 
> The way to call the Python wrapped variant would be using callbacks. I'm open to more design ideas about this but as it stands this isn't actionable.

Sad to hear that. Can't offer design ideas because the whole space is way too confusing/intricate for me -- if you say it can't be handled, then that's how it is.

I'm not sure what you mean exactly with this idea about callbacks? Could you maybe find the time to demonstrate this by adapting the MWE in here to that callback approach? 
I.e. so that `python3 -c ""import test; test.utils.do_something()""` raises the `ValueError` instead of STOPping? Then I could translate that back into my real solution. 
Thanks!
 || Sure, here is a rough sketch:

```fortran
module utils
    implicit none
  contains
    subroutine my_abort(message)
      implicit none
      character(len=*), intent(in) :: message
      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0;
      !f2py callprotoargument char*
      write(0,*) ""THIS SHOULD NOT APPEAR""
      stop 1
    end subroutine my_abort


    subroutine do_something(message)
        !f2py intent(callback, hide) mypy_abort
        character(len=*), intent(in) :: message
        call mypy_abort(message)
    end subroutine do_something
end module utils
```

Note that the key change is that `mypy_abort` is called, which can be set to the wrapped Fortran function, i.e. the one with the `callstatement` changes. This is then called as:

```ipython
In [1]: import test

In [2]: test.utils.my_abort('aborting directly')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[2], line 1
----> 1 test.utils.my_abort('aborting directly')

ValueError: aborting directly

In [3]: test.mypy_abort = test.utils.my_abort

In [4]: test.utils.do_something('helpme')
capi_return is NULL
Call-back cb_mypy_abort_in_do_something__user__routines failed.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In[4], line 1
----> 1 test.utils.do_something('helpme')

ValueError: helpme
```

There's a fix for the `--lower` issue in https://github.com/numpy/numpy/pull/27728 as well as a documentation note about this. || Thanks a lot for that demo! One thing that's not clear to me is how to achieve this interaction correctly when only using Fortran, i.e. when _not_ involving Python/pytest. 
As explained above, ...

> What I'm intending here is to avoid executing the Fortran `stop` statement when running wrapped code in Python, because that also kills the Python _interpreter_ and thus, in my case, the `pytest` run of a whole test suite that this code is part of.

...Python/pytest just implements the test suite for a Fortran code. How can I modify the above to make sure when the main/proper simulation code runs, `do_something(message)` calls `my_abort(message)`, not `mypy_abort(message)`, as f2py is not involved then? That's what the `callstatement` nicely deals with automatically.
AFAICT, `call mypy_abort(message)` would just fail/not compile because the compiler is not aware of the `!f2py` meta-comment. 😕  || > Thanks a lot for that demo! One thing that's not clear to me is how to achieve this interaction correctly when only using Fortran, i.e. when _not_ involving Python/pytest. As explained above, ...
> 
> > What I'm intending here is to avoid executing the Fortran `stop` statement when running wrapped code in Python, because that also kills the Python _interpreter_ and thus, in my case, the `pytest` run of a whole test suite that this code is part of.
> 
> ...Python/pytest just implements the test suite for a Fortran code. How can I modify the above to make sure when the main/proper simulation code runs, `do_something(message)` calls `my_abort(message)`, not `mypy_abort(message)`, as f2py is not involved then? That's what the `callstatement` nicely deals with automatically. AFAICT, `call mypy_abort(message)` would just fail/not compile because the compiler is not aware of the `!f2py` meta-comment. 😕

Good question, it can be done, but makes it a bit more verbose. My personal preference would be to use `fypp` or some other preprocessor to make calls to either `my_abort(message)` or `mypy_abort(message)` depending on a compile time check (e.g. are Python libraries being linked).

Another approach would be to pass a free function into the `do_something` routine itself, and marking it as `external` but this is pretty tedious (and can lead to very long calls). || Thank you for the pointers :-) , I'll see if i can use either approach. ",closed,2024-06-13T11:09:35+00:00,2024-11-16T22:44:47+00:00,bilderbuchi,"00 - Bug, component: numpy.f2py",1,"PR#27728 - doc/source/f2py/python-usage.rst: @@ -243,6 +243,13 @@ In Python:|;| .. literalinclude:: ./code/results/extcallback_session.dat|;|   :language: python|;| |;|+.. note::|;|+|;|+   When using modified Fortran code via ``callstatement`` or other directives,|;|+   the wrapped Python function must be called as a callback, otherwise only the|;|+   bare Fortran routine will be used. For more details, see|;|+   https://github.com/numpy/numpy/issues/26681#issuecomment-2466460943|;|+|;| Resolving arguments to call-back functions|;| ------------------------------------------|;|  || PR#27728 - numpy/f2py/crackfortran.py: @@ -425,11 +425,14 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[-1] not in ""\n\r\f"":|;|                 break|;|             l = l[:-1]|;|+        # Do not lower for directives, gh-2547, gh-27697, gh-26681|;|+        is_f2py_directive = False|;|         # Unconditionally remove comments|;|         (l, rl) = split_by_unquoted(l, '!')|;|         l += ' '|;|         if rl[:5].lower() == '!f2py':  # f2py directive|;|             l, _ = split_by_unquoted(l + 4 * ' ' + rl[5:], '!')|;|+            is_f2py_directive = True|;|         if l.strip() == '':  # Skip empty line|;|             if sourcecodeform == 'free':|;|                 # In free form, a statement continues in the next line|;|@@ -449,8 +452,10 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|             if l[0] in ['*', 'c', '!', 'C', '#']:|;|                 if l[1:5].lower() == 'f2py':  # f2py directive|;|                     l = '     ' + l[5:]|;|+                    is_f2py_directive = True|;|                 else:  # Skip comment line|;|                     cont = False|;|+                    is_f2py_directive = False|;|                     continue|;|             elif strictf77:|;|                 if len(l) > 72:|;|@@ -476,6 +481,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 else:|;|                     # clean up line beginning from possible digits.|;|                     l = '     ' + l[5:]|;|+                    # f2py directives are already stripped by this point|;|                     if localdolowercase:|;|                         finalline = ll.lower()|;|                     else:|;|@@ -505,7 +511,11 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|                 origfinalline = ''|;|             else:|;|                 if localdolowercase:|;|-                    finalline = ll.lower()|;|+                    # lines with intent() should be lowered otherwise|;|+                    # TestString::test_char fails due to mixed case|;|+                    # f2py directives without intent() should be left untouched|;|+                    # gh-2547, gh-27697, gh-26681|;|+                    finalline = ll.lower() if ""intent"" in ll.lower() or not is_f2py_directive else ll|;|                 else:|;|                     finalline = ll|;|                 origfinalline = ll|;|@@ -537,6 +547,7 @@ def readfortrancode(ffile, dowithline=show, istop=1):|;|         else:|;|             dowithline(finalline)|;|         l1 = ll|;|+    # Last line should never have an f2py directive anyway|;|     if localdolowercase:|;|         finalline = ll.lower()|;|     else: || PR#27728 - numpy/f2py/tests/src/callback/gh26681.f90: @@ -0,0 +1,18 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+|;|+    subroutine do_something(message)|;|+        !f2py    intent(callback, hide) mypy_abort|;|+        character(len=*), intent(in) :: message|;|+        call mypy_abort(message)|;|+    end subroutine do_something|;|+end module utils || PR#27728 - numpy/f2py/tests/src/crackfortran/gh27697.f90: @@ -0,0 +1,12 @@|;|+module utils|;|+    implicit none|;|+  contains|;|+    subroutine my_abort(message)|;|+      implicit none|;|+      character(len=*), intent(in) :: message|;|+      !f2py callstatement PyErr_SetString(PyExc_ValueError, message);f2py_success = 0|;|;+      !f2py callprotoargument char*|;|+      write(0,*) ""THIS SHOULD NOT APPEAR""|;|+      stop 1|;|+    end subroutine my_abort|;|+end module utils || PR#27728 - numpy/f2py/tests/test_callback.py: @@ -5,6 +5,7 @@|;| import threading|;| import traceback|;| import time|;|+import platform|;| |;| import numpy as np|;| from numpy.testing import IS_PYPY|;|@@ -244,3 +245,17 @@ def bar(x):|;| |;|         res = self.module.foo(bar)|;|         assert res == 110|;|+|;|+|;|+@pytest.mark.slow|;|+@pytest.mark.xfail(condition=(platform.system().lower() == 'darwin'),|;|+                   run=False,|;|+                   reason=""Callback aborts cause CI failures on macOS"")|;|+class TestCBFortranCallstatement(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""callback"", ""gh26681.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_callstatement_fortran(self):|;|+        with pytest.raises(ValueError, match='helpme') as exc:|;|+            self.module.mypy_abort = self.module.utils.my_abort|;|+            self.module.utils.do_something('helpme') || PR#27728 - numpy/f2py/tests/test_crackfortran.py: @@ -403,3 +403,12 @@ def test_param_eval_too_many_dims(self):|;|         dimspec = '(0:4, 3:12, 5)'|;|         pytest.raises(ValueError, crackfortran.param_eval, v, g_params, params,|;|                       dimspec=dimspec)|;|+|;|+@pytest.mark.slow|;|+class TestLowerF2PYDirective(util.F2PyTest):|;|+    sources = [util.getpath(""tests"", ""src"", ""crackfortran"", ""gh27697.f90"")]|;|+    options = ['--lower']|;|+|;|+    def test_no_lower_fail(self):|;|+        with pytest.raises(ValueError, match='aborting directly') as exc:|;|+            self.module.utils.my_abort('aborting directly')","BUG: Fix handling of f2py directives with --lower

Closes gh-2547, gh-27697, gh-26681 || TST: For --lower with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || TST: Callbacks with callstatement

Co-authored-by: bilderbuchi <bilderbuchi@users.noreply.github.com> || DOC: Note regarding modified fortran wrappers || BUG: Cleanup and use directives correctly || BUG: Handle more edge cases with --lower || TST: Skip runs on macOS for cb aborts"
numpy/numpy,nullSoup,27747,DOC: Windows build documentation missing important details,"### Issue with current documentation:

Users attempting to build numpy in Windows will likely face roadblocks without additional details. Build process description in:

doc/source/building/index.rst

would benefit from 1) recommending a UCRT version for Windows (not all will work), 2) clarifying that MSVC variables will be set by conda activation of the numpy-dev environment so long as the the right build tools are installed, and 3) giving information on working around a meson bug that selects the wrong build tools on Windows.

### Idea or request for content:

I have created [gh-27746](https://github.com/numpy/numpy/pull/27746) to add guidance to the documentation for all these concerns. Any feedback is appreciated, especially regarding the best way to handle the meson problem.",,closed,2024-11-13T06:59:44+00:00,2024-11-15T20:42:29+00:00,nullSoup,04 - Documentation,1,"PR#27746 - doc/source/building/index.rst: @@ -161,7 +161,8 @@ your system.|;|     This is needed even if you use the MinGW-w64 or Intel compilers, in order|;|     to ensure you have the Windows Universal C Runtime (the other components of|;|     Visual Studio are not needed when using Mingw-w64, and can be deselected if|;|-    desired, to save disk space).|;|+    desired, to save disk space). The recommended version of the UCRT is|;|+    >= 10.0.22621.0.|;| |;|     .. tab-set::|;| |;|@@ -174,6 +175,12 @@ your system.|;|         run a ``.bat`` file for the correct bitness and architecture (e.g., for|;|         64-bit Intel CPUs, use ``vcvars64.bat``).|;| |;|+        If using a Conda environment while a version of Visual Studio 2019+ is|;|+        installed that includes the MSVC v142 package (VS 2019 C++ x86/x64|;|+        build tools), activating the conda environment should cause Visual|;|+        Studio to be found and the appropriate .bat file executed to set|;|+        these variables.|;|+|;|         For detailed guidance, see `Use the Microsoft C++ toolset from the command line|;|         <https://learn.microsoft.com/en-us/cpp/build/building-on-the-command-line?view=msvc-170>`__.|;| |;|@@ -256,6 +263,12 @@ Building from source to use NumPy|;|       git submodule update --init|;|       pip install . --no-build-isolation|;| |;|+    .. warning::|;|+|;|+        On Windows, the AR, LD, and LDFLAGS environment variables may be set,|;|+        which will cause the pip install command to fail. These variables are only|;|+        needed for flang and can be safely unset prior to running pip install.|;|+|;|   .. tab-item:: Virtual env or system Python|;|     :sync: pip|;| |;|@@ -363,6 +376,13 @@ like build the html documentation or running benchmarks. The ``spin``|;| interface is self-documenting, so please see ``spin --help`` and|;| ``spin <subcommand> --help`` for detailed guidance.|;| |;|+.. warning::|;|+|;|+    In an activated conda enviroment on Windows, the AR, LD, and LDFLAGS|;|+    environment variables may be set, which will cause the build to fail.|;|+    These variables are only needed for flang and can be safely unset|;|+    for build.|;|+|;| .. _meson-editable-installs:|;| |;| .. admonition:: IDE support & editable installs",DOC: Added additional guidance for compiling in Windows || DOC: Updated Windows build guidance based on Pull Request review recommendations
